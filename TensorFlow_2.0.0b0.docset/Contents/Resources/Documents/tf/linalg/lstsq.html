<div itemscope="" itemtype="http://developers.google.com/ReferenceObject">
<p><meta itemprop="name" content="tf.linalg.lstsq" /> <meta itemprop="path" content="Stable" /></p>
</div>
<a name="//apple_ref/cpp/Function/tf.linalg.lstsq" class="dashAnchor"></a><h1 id="tf.linalg.lstsq">tf.linalg.lstsq</h1>
<p>Solves one or more linear least-squares problems.</p>
<h3 id="aliases">Aliases:</h3>
<ul>
<li><code>tf.compat.v1.linalg.lstsq</code></li>
<li><code>tf.compat.v1.matrix_solve_ls</code></li>
<li><code>tf.compat.v2.linalg.lstsq</code></li>
<li><code>tf.linalg.lstsq</code></li>
</ul>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">tf.linalg.lstsq(
    matrix,
    rhs,
    l2_regularizer<span class="op">=</span><span class="fl">0.0</span>,
    fast<span class="op">=</span><span class="va">True</span>,
    name<span class="op">=</span><span class="va">None</span>
)</code></pre></div>
<p>Defined in <a href="/code/stable/tensorflow/python/ops/linalg_ops.py"><code>python/ops/linalg_ops.py</code></a>.</p>
<!-- Placeholder for "Used in" -->
<p><code>matrix</code> is a tensor of shape <code>[..., M, N]</code> whose inner-most 2 dimensions form <code>M</code>-by-<code>N</code> matrices. Rhs is a tensor of shape <code>[..., M, K]</code> whose inner-most 2 dimensions form <code>M</code>-by-<code>K</code> matrices. The computed output is a <code>Tensor</code> of shape <code>[..., N, K]</code> whose inner-most 2 dimensions form <code>M</code>-by-<code>K</code> matrices that solve the equations <code>matrix[..., :, :] * output[..., :, :] = rhs[..., :, :]</code> in the least squares sense.</p>
<p>Below we will use the following notation for each pair of matrix and right-hand sides in the batch:</p>
<p><code>matrix</code>=\(A ^{m n}\), <code>rhs</code>=\(B ^{m k}\), <code>output</code>=\(X ^{n k}\), <code>l2_regularizer</code>=\(\).</p>
<p>If <code>fast</code> is <code>True</code>, then the solution is computed by solving the normal equations using Cholesky decomposition. Specifically, if \(m n\) then \(X = (A^T A + I)^{-1} A^T B\), which solves the least-squares problem \(X = _{Z ^{n k}} ||A Z - B||_F^2 + ||Z||<em>F^2\). If \(m n\) then <code>output</code> is computed as \(X = A^T (A A^T + I)^{-1} B\), which (for \(= 0\)) is the minimum-norm solution to the under-determined linear system, i.e. \(X = </em>{Z ^{n k}} ||Z||_F^2 \), subject to \(A Z = B\). Notice that the fast path is only numerically stable when \(A\) is numerically full rank and has a condition number \((A) \) or\(\) is sufficiently large.</p>
<p>If <code>fast</code> is <code>False</code> an algorithm based on the numerically robust complete orthogonal decomposition is used. This computes the minimum-norm least-squares solution, even when \(A\) is rank deficient. This path is typically 6-7 times slower than the fast path. If <code>fast</code> is <code>False</code> then <code>l2_regularizer</code> is ignored.</p>
<h4 id="args">Args:</h4>
<ul>
<li><b><code>matrix</code></b>: <code>Tensor</code> of shape <code>[..., M, N]</code>.</li>
<li><b><code>rhs</code></b>: <code>Tensor</code> of shape <code>[..., M, K]</code>.</li>
<li><b><code>l2_regularizer</code></b>: 0-D <code>double</code> <code>Tensor</code>. Ignored if <code>fast=False</code>.</li>
<li><b><code>fast</code></b>: bool. Defaults to <code>True</code>.</li>
<li><b><code>name</code></b>: string, optional name of the operation.</li>
</ul>
<h4 id="returns">Returns:</h4>
<ul>
<li><b><code>output</code></b>: <code>Tensor</code> of shape <code>[..., N, K]</code> whose inner-most 2 dimensions form <code>M</code>-by-<code>K</code> matrices that solve the equations <code>matrix[..., :, :] * output[..., :, :] = rhs[..., :, :]</code> in the least squares sense.</li>
</ul>
<h4 id="raises">Raises:</h4>
<ul>
<li><b><code>NotImplementedError</code></b>: linalg.lstsq is currently disabled for complex128 and l2_regularizer != 0 due to poor accuracy.</li>
</ul>

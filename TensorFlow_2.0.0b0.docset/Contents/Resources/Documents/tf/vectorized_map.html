<div itemscope="" itemtype="http://developers.google.com/ReferenceObject">
<p><meta itemprop="name" content="tf.vectorized_map" /> <meta itemprop="path" content="Stable" /></p>
</div>
<a name="//apple_ref/cpp/Function/tf.vectorized_map" class="dashAnchor"></a><h1 id="tf.vectorized_map">tf.vectorized_map</h1>
<p>Parallel map on the list of tensors unpacked from <code>elems</code> on dimension 0.</p>
<h3 id="aliases">Aliases:</h3>
<ul>
<li><code>tf.compat.v1.vectorized_map</code></li>
<li><code>tf.compat.v2.vectorized_map</code></li>
<li><code>tf.vectorized_map</code></li>
</ul>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">tf.vectorized_map(
    fn,
    elems
)</code></pre></div>
<p>Defined in <a href="/code/stable/tensorflow/python/ops/parallel_for/control_flow_ops.py"><code>python/ops/parallel_for/control_flow_ops.py</code></a>.</p>
<!-- Placeholder for "Used in" -->
<p>This method works similar to tf.map_fn but is optimized to run much faster, but possibly with a much larger memory footprint. The speedups are obtained by vectorization (see https://arxiv.org/pdf/1903.04243.pdf). The idea behind vectorization is to semantically launch all the invocations of <code>fn</code> in parallel and fuse corresponding operations across all these invocations. This fusion is done statically at graph generation time and the generated code is often similar in performance to a manually fused version.</p>
<p>For example, let's look at a method that calculates the outer product of a matrix.</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="kw">def</span> outer_product(a):
  <span class="cf">return</span> tf.tensordot(a, a, <span class="dv">0</span>)

<span class="co"># outer_product was designed to not support batching.</span>
c <span class="op">=</span> outer_product(tf.ones((<span class="dv">2</span>, <span class="dv">3</span>)))
<span class="co"># The shape is consistent</span>
<span class="cf">assert</span> c.shape <span class="op">==</span> (<span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">2</span>, <span class="dv">3</span>)</code></pre></div>
<p>Now suppose we want an efficient batched version of outer_product. We can simply write:</p>
<p><code>python batch_size = 100 a = tf.ones((batch_size, 32, 32)) c = tf.vectorized_map(outer_product, a) assert c.shape == (batch_size, 32, 32, 32, 32)</code></p>
<p>Because <a href="../tf/vectorized_map.html"><code>tf.vectorized_map</code></a> fully parallelizes the batch, this method will generally be significantly faster than using <a href="../tf/map_fn.html"><code>tf.map_fn</code></a>, especially in eager mode.</p>
<p>This is an experimental feature and currently has a lot of limitations: - There should be no data dependency between the different semantic invocations of <code>fn</code>, i.e. it should be safe to map the elements of the inputs in any order. - Stateful kernels may mostly not be supported since these often imply a data dependency. We do support a limited set of such stateful kernels though (like RandomFoo, Variable operations like reads, etc). - <code>fn</code> has limited support for control flow operations. <a href="../tf/cond.html"><code>tf.cond</code></a> in particular is not supported. - <code>fn</code> should return nested structure of Tensors or Operations. However if an Operation is returned, it should have zero outputs. - The shape and dtype of <code>fn</code> outputs should not depend on the input to <code>fn</code>.</p>
<h4 id="args">Args:</h4>
<ul>
<li><b><code>fn</code></b>: The callable to be performed. It accepts one argument, which will have the same (possibly nested) structure as <code>elems</code>, and returns a possibly nested structure of Tensors and Operations, which may be different than the structure of <code>elems</code>.</li>
<li><b><code>elems</code></b>: A tensor or (possibly nested) sequence of tensors, each of which will be unpacked along their first dimension. The nested sequence of the resulting slices will be mapped over by <code>fn</code>.</li>
</ul>
<h4 id="returns">Returns:</h4>
<p>A tensor or (possibly nested) sequence of tensors. Each tensor packs the results of applying fn to tensors unpacked from elems along the first dimension, from first to last.</p>

<div itemscope="" itemtype="http://developers.google.com/ReferenceObject">
<p><meta itemprop="name" content="tf.feature_column.shared_embeddings" /> <meta itemprop="path" content="Stable" /></p>
</div>
<a name="//apple_ref/cpp/Function/tf.feature_column.shared_embeddings" class="dashAnchor"></a><h1 id="tf.feature_column.shared_embeddings">tf.feature_column.shared_embeddings</h1>
<p>List of dense columns that convert from sparse, categorical input.</p>
<h3 id="aliases">Aliases:</h3>
<ul>
<li><code>tf.compat.v2.feature_column.shared_embeddings</code></li>
<li><code>tf.feature_column.shared_embeddings</code></li>
</ul>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">tf.feature_column.shared_embeddings(
    categorical_columns,
    dimension,
    combiner<span class="op">=</span><span class="st">&#39;mean&#39;</span>,
    initializer<span class="op">=</span><span class="va">None</span>,
    shared_embedding_collection_name<span class="op">=</span><span class="va">None</span>,
    ckpt_to_load_from<span class="op">=</span><span class="va">None</span>,
    tensor_name_in_ckpt<span class="op">=</span><span class="va">None</span>,
    max_norm<span class="op">=</span><span class="va">None</span>,
    trainable<span class="op">=</span><span class="va">True</span>
)</code></pre></div>
<p>Defined in <a href="/code/stable/tensorflow/python/feature_column/feature_column_v2.py"><code>python/feature_column/feature_column_v2.py</code></a>.</p>
<!-- Placeholder for "Used in" -->
<p>This is similar to <code>embedding_column</code>, except that it produces a list of embedding columns that share the same embedding weights.</p>
<p>Use this when your inputs are sparse and of the same type (e.g. watched and impression video IDs that share the same vocabulary), and you want to convert them to a dense representation (e.g., to feed to a DNN).</p>
<p>Inputs must be a list of categorical columns created by any of the <code>categorical_column_*</code> function. They must all be of the same type and have the same arguments except <code>key</code>. E.g. they can be categorical_column_with_vocabulary_file with the same vocabulary_file. Some or all columns could also be weighted_categorical_column.</p>
<p>Here is an example embedding of two features for a DNNClassifier model:</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">watched_video_id <span class="op">=</span> categorical_column_with_vocabulary_file(
    <span class="st">&#39;watched_video_id&#39;</span>, video_vocabulary_file, video_vocabulary_size)
impression_video_id <span class="op">=</span> categorical_column_with_vocabulary_file(
    <span class="st">&#39;impression_video_id&#39;</span>, video_vocabulary_file, video_vocabulary_size)
columns <span class="op">=</span> shared_embedding_columns(
    [watched_video_id, impression_video_id], dimension<span class="op">=</span><span class="dv">10</span>)

estimator <span class="op">=</span> tf.estimator.DNNClassifier(feature_columns<span class="op">=</span>columns, ...)

label_column <span class="op">=</span> ...
<span class="kw">def</span> input_fn():
  features <span class="op">=</span> tf.io.parse_example(
      ..., features<span class="op">=</span>make_parse_example_spec(columns <span class="op">+</span> [label_column]))
  labels <span class="op">=</span> features.pop(label_column.name)
  <span class="cf">return</span> features, labels

estimator.train(input_fn<span class="op">=</span>input_fn, steps<span class="op">=</span><span class="dv">100</span>)</code></pre></div>
<p>Here is an example using <code>shared_embedding_columns</code> with model_fn:</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="kw">def</span> model_fn(features, ...):
  watched_video_id <span class="op">=</span> categorical_column_with_vocabulary_file(
      <span class="st">&#39;watched_video_id&#39;</span>, video_vocabulary_file, video_vocabulary_size)
  impression_video_id <span class="op">=</span> categorical_column_with_vocabulary_file(
      <span class="st">&#39;impression_video_id&#39;</span>, video_vocabulary_file, video_vocabulary_size)
  columns <span class="op">=</span> shared_embedding_columns(
      [watched_video_id, impression_video_id], dimension<span class="op">=</span><span class="dv">10</span>)
  dense_tensor <span class="op">=</span> input_layer(features, columns)
  <span class="co"># Form DNN layers, calculate loss, and return EstimatorSpec.</span>
  ...</code></pre></div>
<h4 id="args">Args:</h4>
<ul>
<li><b><code>categorical_columns</code></b>: List of categorical columns created by a <code>categorical_column_with_*</code> function. These columns produce the sparse IDs that are inputs to the embedding lookup. All columns must be of the same type and have the same arguments except <code>key</code>. E.g. they can be categorical_column_with_vocabulary_file with the same vocabulary_file. Some or all columns could also be weighted_categorical_column.</li>
<li><b><code>dimension</code></b>: An integer specifying dimension of the embedding, must be &gt; 0.</li>
<li><b><code>combiner</code></b>: A string specifying how to reduce if there are multiple entries in a single row. Currently 'mean', 'sqrtn' and 'sum' are supported, with 'mean' the default. 'sqrtn' often achieves good accuracy, in particular with bag-of-words columns. Each of this can be thought as example level normalizations on the column. For more information, see <code>tf.embedding_lookup_sparse</code>.</li>
<li><b><code>initializer</code></b>: A variable initializer function to be used in embedding variable initialization. If not specified, defaults to <a href="../../tf/compat/v1/truncated_normal_initializer.html"><code>tf.compat.v1.truncated_normal_initializer</code></a> with mean <code>0.0</code> and standard deviation <code>1/sqrt(dimension)</code>.</li>
<li><b><code>shared_embedding_collection_name</code></b>: Optional collective name of these columns. If not given, a reasonable name will be chosen based on the names of <code>categorical_columns</code>.</li>
<li><b><code>ckpt_to_load_from</code></b>: String representing checkpoint name/pattern from which to restore column weights. Required if <code>tensor_name_in_ckpt</code> is not <code>None</code>.</li>
<li><b><code>tensor_name_in_ckpt</code></b>: Name of the <code>Tensor</code> in <code>ckpt_to_load_from</code> from which to restore the column weights. Required if <code>ckpt_to_load_from</code> is not <code>None</code>.</li>
<li><b><code>max_norm</code></b>: If not <code>None</code>, each embedding is clipped if its l2-norm is larger than this value, before combining.</li>
<li><b><code>trainable</code></b>: Whether or not the embedding is trainable. Default is True.</li>
</ul>
<h4 id="returns">Returns:</h4>
<p>A list of dense columns that converts from sparse input. The order of results follows the ordering of <code>categorical_columns</code>.</p>
<h4 id="raises">Raises:</h4>
<ul>
<li><b><code>ValueError</code></b>: if <code>dimension</code> not &gt; 0.</li>
<li><b><code>ValueError</code></b>: if any of the given <code>categorical_columns</code> is of different type or has different arguments than the others.</li>
<li><b><code>ValueError</code></b>: if exactly one of <code>ckpt_to_load_from</code> and <code>tensor_name_in_ckpt</code> is specified.</li>
<li><b><code>ValueError</code></b>: if <code>initializer</code> is specified and is not callable.</li>
<li><b><code>RuntimeError</code></b>: if eager execution is enabled.</li>
</ul>

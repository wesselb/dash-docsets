<div itemscope="" itemtype="http://developers.google.com/ReferenceObject">
<p><meta itemprop="name" content="tf.tensor_scatter_nd_update" /> <meta itemprop="path" content="Stable" /></p>
</div>
<a name="//apple_ref/cpp/Function/tf.tensor_scatter_nd_update" class="dashAnchor"></a><h1 id="tf.tensor_scatter_nd_update">tf.tensor_scatter_nd_update</h1>
<p>Scatter <code>updates</code> into an existing tensor according to <code>indices</code>.</p>
<h3 id="aliases">Aliases:</h3>
<ul>
<li><code>tf.compat.v1.tensor_scatter_nd_update</code></li>
<li><code>tf.compat.v1.tensor_scatter_update</code></li>
<li><code>tf.compat.v2.tensor_scatter_nd_update</code></li>
<li><code>tf.tensor_scatter_nd_update</code></li>
</ul>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">tf.tensor_scatter_nd_update(
    tensor,
    indices,
    updates,
    name<span class="op">=</span><span class="va">None</span>
)</code></pre></div>
<p>Defined in generated file: <code>python/ops/gen_array_ops.py</code>.</p>
<!-- Placeholder for "Used in" -->
<p>This operation creates a new tensor by applying sparse <code>updates</code> to the passed in <code>tensor</code>. This operation is very similar to <a href="../tf/scatter_nd.html"><code>tf.scatter_nd</code></a>, except that the updates are scattered onto an existing tensor (as opposed to a zero-tensor). If the memory for the existing tensor cannot be re-used, a copy is made and updated.</p>
<p>If <code>indices</code> contains duplicates, then their updates are accumulated (summed).</p>
<p><strong>WARNING</strong>: The order in which updates are applied is nondeterministic, so the output will be nondeterministic if <code>indices</code> contains duplicates -- because of some numerical approximation issues, numbers summed in different order may yield different results.</p>
<p><code>indices</code> is an integer tensor containing indices into a new tensor of shape <code>shape</code>. The last dimension of <code>indices</code> can be at most the rank of <code>shape</code>:</p>
<pre><code>indices.shape[-1] &lt;= shape.rank</code></pre>
<p>The last dimension of <code>indices</code> corresponds to indices into elements (if <code>indices.shape[-1] = shape.rank</code>) or slices (if <code>indices.shape[-1] &lt; shape.rank</code>) along dimension <code>indices.shape[-1]</code> of <code>shape</code>. <code>updates</code> is a tensor with shape</p>
<pre><code>indices.shape[:-1] + shape[indices.shape[-1]:]</code></pre>
<p>The simplest form of scatter is to insert individual elements in a tensor by index. For example, say we want to insert 4 scattered elements in a rank-1 tensor with 8 elements.</p>
<div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;">
<p><img style="width:100%" src="https://www.tensorflow.org/images/ScatterNd1.png" alt></p>
</div>
<p>In Python, this scatter operation would look like this:</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">    indices <span class="op">=</span> tf.constant([[<span class="dv">4</span>], [<span class="dv">3</span>], [<span class="dv">1</span>], [<span class="dv">7</span>]])
    updates <span class="op">=</span> tf.constant([<span class="dv">9</span>, <span class="dv">10</span>, <span class="dv">11</span>, <span class="dv">12</span>])
    tensor <span class="op">=</span> tf.ones([<span class="dv">8</span>], dtype<span class="op">=</span>tf.int32)
    updated <span class="op">=</span> tf.tensor_scatter_update(tensor, indices, updates)
    <span class="cf">with</span> tf.Session() <span class="im">as</span> sess:
      <span class="bu">print</span>(sess.run(scatter))</code></pre></div>
<p>The resulting tensor would look like this:</p>
<pre><code>[1, 11, 1, 10, 9, 1, 1, 12]</code></pre>
<p>We can also, insert entire slices of a higher rank tensor all at once. For example, if we wanted to insert two slices in the first dimension of a rank-3 tensor with two matrices of new values.</p>
<p>In Python, this scatter operation would look like this:</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">    indices <span class="op">=</span> tf.constant([[<span class="dv">0</span>], [<span class="dv">2</span>]])
    updates <span class="op">=</span> tf.constant([[[<span class="dv">5</span>, <span class="dv">5</span>, <span class="dv">5</span>, <span class="dv">5</span>], [<span class="dv">6</span>, <span class="dv">6</span>, <span class="dv">6</span>, <span class="dv">6</span>],
                            [<span class="dv">7</span>, <span class="dv">7</span>, <span class="dv">7</span>, <span class="dv">7</span>], [<span class="dv">8</span>, <span class="dv">8</span>, <span class="dv">8</span>, <span class="dv">8</span>]],
                           [[<span class="dv">5</span>, <span class="dv">5</span>, <span class="dv">5</span>, <span class="dv">5</span>], [<span class="dv">6</span>, <span class="dv">6</span>, <span class="dv">6</span>, <span class="dv">6</span>],
                            [<span class="dv">7</span>, <span class="dv">7</span>, <span class="dv">7</span>, <span class="dv">7</span>], [<span class="dv">8</span>, <span class="dv">8</span>, <span class="dv">8</span>, <span class="dv">8</span>]]])
    tensor <span class="op">=</span> tf.ones([<span class="dv">4</span>, <span class="dv">4</span>, <span class="dv">4</span>])
    updated <span class="op">=</span> tf.tensor_scatter_update(tensor, indices, updates)
    <span class="cf">with</span> tf.Session() <span class="im">as</span> sess:
      <span class="bu">print</span>(sess.run(scatter))</code></pre></div>
<p>The resulting tensor would look like this:</p>
<pre><code>[[[5, 5, 5, 5], [6, 6, 6, 6], [7, 7, 7, 7], [8, 8, 8, 8]],
 [[1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1]],
 [[5, 5, 5, 5], [6, 6, 6, 6], [7, 7, 7, 7], [8, 8, 8, 8]],
 [[1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1]]]</code></pre>
<p>Note that on CPU, if an out of bound index is found, an error is returned. On GPU, if an out of bound index is found, the index is ignored.</p>
<h4 id="args">Args:</h4>
<ul>
<li><b><code>tensor</code></b>: A <code>Tensor</code>. Tensor to copy/update.</li>
<li><b><code>indices</code></b>: A <code>Tensor</code>. Must be one of the following types: <code>int32</code>, <code>int64</code>. Index tensor.</li>
<li><b><code>updates</code></b>: A <code>Tensor</code>. Must have the same type as <code>tensor</code>. Updates to scatter into output.</li>
<li><b><code>name</code></b>: A name for the operation (optional).</li>
</ul>
<h4 id="returns">Returns:</h4>
<p>A <code>Tensor</code>. Has the same type as <code>tensor</code>.</p>

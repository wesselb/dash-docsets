<div itemscope="" itemtype="http://developers.google.com/ReferenceObject">
<p><meta itemprop="name" content="tf.compat.v1.estimator.experimental.dnn_logit_fn_builder" /> <meta itemprop="path" content="Stable" /></p>
</div>
<a name="//apple_ref/cpp/Function/tf.compat.v1.estimator.experimental.dnn_logit_fn_builder" class="dashAnchor"></a><h1 id="tf.compat.v1.estimator.experimental.dnn_logit_fn_builder">tf.compat.v1.estimator.experimental.dnn_logit_fn_builder</h1>
<p>Function builder for a dnn logit_fn.</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">tf.compat.v1.estimator.experimental.dnn_logit_fn_builder(
    units,
    hidden_units,
    feature_columns,
    activation_fn,
    dropout,
    input_layer_partitioner,
    batch_norm
)</code></pre></div>
<p>Defined in <a href="https://github.com/tensorflow/estimator/tree/master/tensorflow_estimator/python/estimator/canned/dnn.py"><code>python/estimator/canned/dnn.py</code></a>.</p>
<!-- Placeholder for "Used in" -->
<h4 id="args">Args:</h4>
<ul>
<li><b><code>units</code></b>: An int indicating the dimension of the logit layer. In the MultiHead case, this should be the sum of all component Heads' logit dimensions.</li>
<li><b><code>hidden_units</code></b>: Iterable of integer number of hidden units per layer.</li>
<li><b><code>feature_columns</code></b>: Iterable of <code>feature_column._FeatureColumn</code> model inputs.</li>
<li><b><code>activation_fn</code></b>: Activation function applied to each layer.</li>
<li><b><code>dropout</code></b>: When not <code>None</code>, the probability we will drop out a given coordinate.</li>
<li><b><code>input_layer_partitioner</code></b>: Partitioner for input layer.</li>
<li><b><code>batch_norm</code></b>: Whether to use batch normalization after each hidden layer.</li>
</ul>
<h4 id="returns">Returns:</h4>
<p>A logit_fn (see below).</p>
<h4 id="raises">Raises:</h4>
<ul>
<li><b><code>ValueError</code></b>: If units is not an int.</li>
</ul>

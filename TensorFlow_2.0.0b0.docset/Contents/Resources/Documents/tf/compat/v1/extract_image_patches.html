<div itemscope="" itemtype="http://developers.google.com/ReferenceObject">
<p><meta itemprop="name" content="tf.compat.v1.extract_image_patches" /> <meta itemprop="path" content="Stable" /></p>
</div>
<a name="//apple_ref/cpp/Function/tf.compat.v1.extract_image_patches" class="dashAnchor"></a><h1 id="tf.compat.v1.extract_image_patches">tf.compat.v1.extract_image_patches</h1>
<p>Extract <code>patches</code> from <code>images</code> and put them in the &quot;depth&quot; output dimension.</p>
<h3 id="aliases">Aliases:</h3>
<ul>
<li><code>tf.compat.v1.extract_image_patches</code></li>
<li><code>tf.compat.v1.image.extract_image_patches</code></li>
</ul>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">tf.compat.v1.extract_image_patches(
    images,
    ksizes<span class="op">=</span><span class="va">None</span>,
    strides<span class="op">=</span><span class="va">None</span>,
    rates<span class="op">=</span><span class="va">None</span>,
    padding<span class="op">=</span><span class="va">None</span>,
    name<span class="op">=</span><span class="va">None</span>,
    sizes<span class="op">=</span><span class="va">None</span>
)</code></pre></div>
<p>Defined in <a href="/code/stable/tensorflow/python/ops/array_ops.py"><code>python/ops/array_ops.py</code></a>.</p>
<!-- Placeholder for "Used in" -->
<h4 id="args">Args:</h4>
<ul>
<li><b><code>images</code></b>: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>, <code>int32</code>, <code>uint8</code>, <code>int16</code>, <code>int8</code>, <code>int64</code>, <code>bfloat16</code>, <code>uint16</code>, <code>half</code>, <code>uint32</code>, <code>uint64</code>. 4-D Tensor with shape <code>[batch, in_rows, in_cols, depth]</code>.</li>
<li><b><code>ksizes</code></b>: A list of <code>ints</code> that has length <code>&gt;= 4</code>. The size of the sliding window for each dimension of <code>images</code>.</li>
<li><b><code>strides</code></b>: A list of <code>ints</code> that has length <code>&gt;= 4</code>. 1-D of length 4. How far the centers of two consecutive patches are in the images. Must be: <code>[1, stride_rows, stride_cols, 1]</code>.</li>
<li><b><code>rates</code></b>: A list of <code>ints</code> that has length <code>&gt;= 4</code>. 1-D of length 4. Must be: <code>[1, rate_rows, rate_cols, 1]</code>. This is the input stride, specifying how far two consecutive patch samples are in the input. Equivalent to extracting patches with <code>patch_sizes_eff = patch_sizes + (patch_sizes - 1) * (rates - 1)</code>, followed by subsampling them spatially by a factor of <code>rates</code>. This is equivalent to <code>rate</code> in dilated (a.k.a. Atrous) convolutions.</li>
<li><b><code>padding</code></b>: A <code>string</code> from: <code>&quot;SAME&quot;, &quot;VALID&quot;</code>. The type of padding algorithm to use.</li>
</ul>
<p>We specify the size-related attributes as:</p>
<p><code>python         ksizes = [1, ksize_rows, ksize_cols, 1]         strides = [1, strides_rows, strides_cols, 1]         rates = [1, rates_rows, rates_cols, 1]</code> * <b><code>name</code></b>: A name for the operation (optional).</p>
<h4 id="returns">Returns:</h4>
<p>A <code>Tensor</code>. Has the same type as <code>images</code>.</p>

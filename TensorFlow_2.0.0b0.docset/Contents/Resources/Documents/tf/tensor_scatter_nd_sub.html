<div itemscope="" itemtype="http://developers.google.com/ReferenceObject">
<p><meta itemprop="name" content="tf.tensor_scatter_nd_sub" /> <meta itemprop="path" content="Stable" /></p>
</div>
<a name="//apple_ref/cpp/Function/tf.tensor_scatter_nd_sub" class="dashAnchor"></a><h1 id="tf.tensor_scatter_nd_sub">tf.tensor_scatter_nd_sub</h1>
<p>Subtracts sparse <code>updates</code> from an existing tensor according to <code>indices</code>.</p>
<h3 id="aliases">Aliases:</h3>
<ul>
<li><code>tf.compat.v1.tensor_scatter_nd_sub</code></li>
<li><code>tf.compat.v1.tensor_scatter_sub</code></li>
<li><code>tf.compat.v2.tensor_scatter_nd_sub</code></li>
<li><code>tf.tensor_scatter_nd_sub</code></li>
</ul>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">tf.tensor_scatter_nd_sub(
    tensor,
    indices,
    updates,
    name<span class="op">=</span><span class="va">None</span>
)</code></pre></div>
<p>Defined in generated file: <code>python/ops/gen_array_ops.py</code>.</p>
<!-- Placeholder for "Used in" -->
<p>This operation creates a new tensor by subtracting sparse <code>updates</code> from the passed in <code>tensor</code>. This operation is very similar to <code>tf.scatter_nd_sub</code>, except that the updates are subtracted from an existing tensor (as opposed to a variable). If the memory for the existing tensor cannot be re-used, a copy is made and updated.</p>
<p><code>indices</code> is an integer tensor containing indices into a new tensor of shape <code>shape</code>. The last dimension of <code>indices</code> can be at most the rank of <code>shape</code>:</p>
<pre><code>indices.shape[-1] &lt;= shape.rank</code></pre>
<p>The last dimension of <code>indices</code> corresponds to indices into elements (if <code>indices.shape[-1] = shape.rank</code>) or slices (if <code>indices.shape[-1] &lt; shape.rank</code>) along dimension <code>indices.shape[-1]</code> of <code>shape</code>. <code>updates</code> is a tensor with shape</p>
<pre><code>indices.shape[:-1] + shape[indices.shape[-1]:]</code></pre>
<p>The simplest form of tensor_scatter_sub is to subtract individual elements from a tensor by index. For example, say we want to insert 4 scattered elements in a rank-1 tensor with 8 elements.</p>
<p>In Python, this scatter subtract operation would look like this:</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">    indices <span class="op">=</span> tf.constant([[<span class="dv">4</span>], [<span class="dv">3</span>], [<span class="dv">1</span>], [<span class="dv">7</span>]])
    updates <span class="op">=</span> tf.constant([<span class="dv">9</span>, <span class="dv">10</span>, <span class="dv">11</span>, <span class="dv">12</span>])
    tensor <span class="op">=</span> tf.ones([<span class="dv">8</span>], dtype<span class="op">=</span>tf.int32)
    updated <span class="op">=</span> tf.tensor_scatter_sub(tensor, indices, updates)
    <span class="cf">with</span> tf.Session() <span class="im">as</span> sess:
      <span class="bu">print</span>(sess.run(scatter))</code></pre></div>
<p>The resulting tensor would look like this:</p>
<pre><code>[1, -10, 1, -9, -8, 1, 1, -11]</code></pre>
<p>We can also, insert entire slices of a higher rank tensor all at once. For example, if we wanted to insert two slices in the first dimension of a rank-3 tensor with two matrices of new values.</p>
<p>In Python, this scatter add operation would look like this:</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">    indices <span class="op">=</span> tf.constant([[<span class="dv">0</span>], [<span class="dv">2</span>]])
    updates <span class="op">=</span> tf.constant([[[<span class="dv">5</span>, <span class="dv">5</span>, <span class="dv">5</span>, <span class="dv">5</span>], [<span class="dv">6</span>, <span class="dv">6</span>, <span class="dv">6</span>, <span class="dv">6</span>],
                            [<span class="dv">7</span>, <span class="dv">7</span>, <span class="dv">7</span>, <span class="dv">7</span>], [<span class="dv">8</span>, <span class="dv">8</span>, <span class="dv">8</span>, <span class="dv">8</span>]],
                           [[<span class="dv">5</span>, <span class="dv">5</span>, <span class="dv">5</span>, <span class="dv">5</span>], [<span class="dv">6</span>, <span class="dv">6</span>, <span class="dv">6</span>, <span class="dv">6</span>],
                            [<span class="dv">7</span>, <span class="dv">7</span>, <span class="dv">7</span>, <span class="dv">7</span>], [<span class="dv">8</span>, <span class="dv">8</span>, <span class="dv">8</span>, <span class="dv">8</span>]]])
    tensor <span class="op">=</span> tf.ones([<span class="dv">4</span>, <span class="dv">4</span>, <span class="dv">4</span>])
    updated <span class="op">=</span> tf.tensor_scatter_sub(tensor, indices, updates)
    <span class="cf">with</span> tf.Session() <span class="im">as</span> sess:
      <span class="bu">print</span>(sess.run(scatter))</code></pre></div>
<p>The resulting tensor would look like this:</p>
<pre><code>[[[-4, -4, -4, -4], [-5, -5, -5, -5], [-6, -6, -6, -6], [-7, -7, -7, -7]],
 [[1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1]],
 [[-4, -4, -4, -4], [-5, -5, -5, -5], [-6, -6, -6, -6], [-7, -7, -7, -7]],
 [[1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1]]]</code></pre>
<p>Note that on CPU, if an out of bound index is found, an error is returned. On GPU, if an out of bound index is found, the index is ignored.</p>
<h4 id="args">Args:</h4>
<ul>
<li><b><code>tensor</code></b>: A <code>Tensor</code>. Tensor to copy/update.</li>
<li><b><code>indices</code></b>: A <code>Tensor</code>. Must be one of the following types: <code>int32</code>, <code>int64</code>. Index tensor.</li>
<li><b><code>updates</code></b>: A <code>Tensor</code>. Must have the same type as <code>tensor</code>. Updates to scatter into output.</li>
<li><b><code>name</code></b>: A name for the operation (optional).</li>
</ul>
<h4 id="returns">Returns:</h4>
<p>A <code>Tensor</code>. Has the same type as <code>tensor</code>.</p>

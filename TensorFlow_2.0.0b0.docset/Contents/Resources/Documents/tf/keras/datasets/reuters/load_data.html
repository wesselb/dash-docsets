<div itemscope="" itemtype="http://developers.google.com/ReferenceObject">
<p><meta itemprop="name" content="tf.keras.datasets.reuters.load_data" /> <meta itemprop="path" content="Stable" /></p>
</div>
<a name="//apple_ref/cpp/Function/tf.keras.datasets.reuters.load_data" class="dashAnchor"></a><h1 id="tf.keras.datasets.reuters.load_data">tf.keras.datasets.reuters.load_data</h1>
<p>Loads the Reuters newswire classification dataset.</p>
<h3 id="aliases">Aliases:</h3>
<ul>
<li><code>tf.compat.v1.keras.datasets.reuters.load_data</code></li>
<li><code>tf.compat.v2.keras.datasets.reuters.load_data</code></li>
<li><code>tf.keras.datasets.reuters.load_data</code></li>
</ul>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">tf.keras.datasets.reuters.load_data(
    path<span class="op">=</span><span class="st">&#39;reuters.npz&#39;</span>,
    num_words<span class="op">=</span><span class="va">None</span>,
    skip_top<span class="op">=</span><span class="dv">0</span>,
    maxlen<span class="op">=</span><span class="va">None</span>,
    test_split<span class="op">=</span><span class="fl">0.2</span>,
    seed<span class="op">=</span><span class="dv">113</span>,
    start_char<span class="op">=</span><span class="dv">1</span>,
    oov_char<span class="op">=</span><span class="dv">2</span>,
    index_from<span class="op">=</span><span class="dv">3</span>,
    <span class="op">**</span>kwargs
)</code></pre></div>
<p>Defined in <a href="/code/stable/tensorflow/python/keras/datasets/reuters.py"><code>python/keras/datasets/reuters.py</code></a>.</p>
<!-- Placeholder for "Used in" -->
<h4 id="arguments">Arguments:</h4>
<ul>
<li><b><code>path</code></b>: where to cache the data (relative to <code>~/.keras/dataset</code>).</li>
<li><b><code>num_words</code></b>: max number of words to include. Words are ranked by how often they occur (in the training set) and only the most frequent words are kept</li>
<li><b><code>skip_top</code></b>: skip the top N most frequently occurring words (which may not be informative).</li>
<li><b><code>maxlen</code></b>: truncate sequences after this length.</li>
<li><b><code>test_split</code></b>: Fraction of the dataset to be used as test data.</li>
<li><b><code>seed</code></b>: random seed for sample shuffling.</li>
<li><b><code>start_char</code></b>: The start of a sequence will be marked with this character. Set to 1 because 0 is usually the padding character.</li>
<li><b><code>oov_char</code></b>: words that were cut out because of the <code>num_words</code> or <code>skip_top</code> limit will be replaced with this character.</li>
<li><b><code>index_from</code></b>: index actual words with this index and higher.</li>
<li><b><code>**kwargs</code></b>: Used for backwards compatibility.</li>
</ul>
<h4 id="returns">Returns:</h4>
<p>Tuple of Numpy arrays: <code>(x_train, y_train), (x_test, y_test)</code>.</p>
<p>Note that the 'out of vocabulary' character is only used for words that were present in the training set but are not included because they're not making the <code>num_words</code> cut here. Words that were not seen in the training set but are in the test set have simply been skipped.</p>

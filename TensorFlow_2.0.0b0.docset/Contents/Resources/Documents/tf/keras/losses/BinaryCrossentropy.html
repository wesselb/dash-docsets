<div itemscope="" itemtype="http://developers.google.com/ReferenceObject">
<p><meta itemprop="name" content="tf.keras.losses.BinaryCrossentropy" /> <meta itemprop="path" content="Stable" /> <meta itemprop="property" content="__call__"/> <meta itemprop="property" content="__init__"/> <meta itemprop="property" content="from_config"/> <meta itemprop="property" content="get_config"/></p>
</div>
<a name="//apple_ref/cpp/Class/tf.keras.losses.BinaryCrossentropy" class="dashAnchor"></a><h1 id="tf.keras.losses.binarycrossentropy">tf.keras.losses.BinaryCrossentropy</h1>
<h2 id="class-binarycrossentropy">Class <code>BinaryCrossentropy</code></h2>
<p>Computes the cross-entropy loss between true labels and predicted labels.</p>
<h3 id="aliases">Aliases:</h3>
<ul>
<li>Class <code>tf.compat.v1.keras.losses.BinaryCrossentropy</code></li>
<li>Class <code>tf.compat.v2.keras.losses.BinaryCrossentropy</code></li>
<li>Class <code>tf.compat.v2.losses.BinaryCrossentropy</code></li>
<li>Class <code>tf.keras.losses.BinaryCrossentropy</code></li>
<li>Class <code>tf.losses.BinaryCrossentropy</code></li>
</ul>
<p>Defined in <a href="/code/stable/tensorflow/python/keras/losses.py"><code>python/keras/losses.py</code></a>.</p>
<!-- Placeholder for "Used in" -->
<p>Use this cross-entropy loss when there are only two label classes (assumed to be 0 and 1). For each example, there should be a single floating-point value per prediction.</p>
<p>In the snippet below, each of the four examples has only a single floating-pointing value, and both <code>y_pred</code> and <code>y_true</code> have the shape <code>[batch_size]</code>.</p>
<h4 id="usage">Usage:</h4>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">bce <span class="op">=</span> tf.keras.losses.BinaryCrossentropy()
loss <span class="op">=</span> bce([<span class="dv">0</span>., <span class="dv">0</span>., <span class="dv">1</span>., <span class="dv">1</span>.], [<span class="dv">1</span>., <span class="dv">1</span>., <span class="dv">1</span>., <span class="dv">0</span>.])
<span class="bu">print</span>(<span class="st">&#39;Loss: &#39;</span>, loss.numpy())  <span class="co"># Loss: 11.522857</span></code></pre></div>
<p>Usage with the <a href="../../../tf/keras.html"><code>tf.keras</code></a> API:</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">model <span class="op">=</span> tf.keras.Model(inputs, outputs)
model.<span class="bu">compile</span>(<span class="st">&#39;sgd&#39;</span>, loss<span class="op">=</span>tf.keras.losses.BinaryCrossentropy())</code></pre></div>
<h4 id="args">Args:</h4>
<ul>
<li><b><code>from_logits</code></b>: Whether to interpret <code>y_pred</code> as a tensor of <a href="https://en.wikipedia.org/wiki/Logit">logit</a> values. By default, we assume that <code>y_pred</code> contains probabilities (i.e., values in [0, 1]).</li>
<li><b><code>label_smoothing</code></b>: Float in [0, 1]. When 0, no smoothing occurs. When &gt; 0, we compute the loss between the predicted labels and a smoothed version of the true labels, where the smoothing squeezes the labels towards 0.5. Larger values of <code>label_smoothing</code> correspond to heavier smoothing.</li>
<li><b><code>reduction</code></b>: (Optional) Type of <a href="../../../tf/keras/losses/Reduction.html"><code>tf.keras.losses.Reduction</code></a> to apply to loss. Default value is <code>AUTO</code>. <code>AUTO</code> indicates that the reduction option will be determined by the usage context. For almost all cases this defaults to <code>SUM_OVER_BATCH_SIZE</code>. When used with <a href="../../../tf/distribute/Strategy.html"><code>tf.distribute.Strategy</code></a>, outside of built-in training loops such as <a href="../../../tf/keras.html"><code>tf.keras</code></a> <code>compile</code> and <code>fit</code>, using <code>AUTO</code> or <code>SUM_OVER_BATCH_SIZE</code> will raise an error. Please see https://www.tensorflow.org/alpha/tutorials/distribute/training_loops for more details on this.</li>
<li><b><code>name</code></b>: (Optional) Name for the op.</li>
</ul>
<h2 id="__init__">
<code><strong>init</strong></code>
</h2>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="fu">__init__</span>(
    from_logits<span class="op">=</span><span class="va">False</span>,
    label_smoothing<span class="op">=</span><span class="dv">0</span>,
    reduction<span class="op">=</span>losses_utils.ReductionV2.AUTO,
    name<span class="op">=</span><span class="st">&#39;binary_crossentropy&#39;</span>
)</code></pre></div>
<p>Initialize self. See help(type(self)) for accurate signature.</p>
<h2 id="methods">Methods</h2>
<h3 id="__call__">
<code><strong>call</strong></code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="fu">__call__</span>(
    y_true,
    y_pred,
    sample_weight<span class="op">=</span><span class="va">None</span>
)</code></pre></div>
<p>Invokes the <code>Loss</code> instance.</p>
<h4 id="args-1">Args:</h4>
<ul>
<li><b><code>y_true</code></b>: Ground truth values.</li>
<li><b><code>y_pred</code></b>: The predicted values.</li>
<li><b><code>sample_weight</code></b>: Optional <code>Tensor</code> whose rank is either 0, or the same rank as <code>y_true</code>, or is broadcastable to <code>y_true</code>. <code>sample_weight</code> acts as a coefficient for the loss. If a scalar is provided, then the loss is simply scaled by the given value. If <code>sample_weight</code> is a tensor of size <code>[batch_size]</code>, then the total loss for each sample of the batch is rescaled by the corresponding element in the <code>sample_weight</code> vector. If the shape of <code>sample_weight</code> matches the shape of <code>y_pred</code>, then the loss of each measurable element of <code>y_pred</code> is scaled by the corresponding value of <code>sample_weight</code>.</li>
</ul>
<h4 id="returns">Returns:</h4>
<p>Weighted loss float <code>Tensor</code>. If <code>reduction</code> is <code>NONE</code>, this has the same shape as <code>y_true</code>; otherwise, it is scalar.</p>
<h4 id="raises">Raises:</h4>
<ul>
<li><b><code>ValueError</code></b>: If the shape of <code>sample_weight</code> is invalid.</li>
</ul>
<h3 id="from_config">
<code>from_config</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">from_config(
    cls,
    config
)</code></pre></div>
<p>Instantiates a <code>Loss</code> from its config (output of <code>get_config()</code>).</p>
<h4 id="args-2">Args:</h4>
<ul>
<li><b><code>config</code></b>: Output of <code>get_config()</code>.</li>
</ul>
<h4 id="returns-1">Returns:</h4>
<p>A <code>Loss</code> instance.</p>
<h3 id="get_config">
<code>get_config</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">get_config()</code></pre></div>

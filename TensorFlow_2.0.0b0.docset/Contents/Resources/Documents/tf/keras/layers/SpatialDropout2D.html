<div itemscope="" itemtype="http://developers.google.com/ReferenceObject">
<p><meta itemprop="name" content="tf.keras.layers.SpatialDropout2D" /> <meta itemprop="path" content="Stable" /> <meta itemprop="property" content="__init__"/></p>
</div>
<a name="//apple_ref/cpp/Class/tf.keras.layers.SpatialDropout2D" class="dashAnchor"></a><h1 id="tf.keras.layers.spatialdropout2d">tf.keras.layers.SpatialDropout2D</h1>
<h2 id="class-spatialdropout2d">Class <code>SpatialDropout2D</code></h2>
<p>Spatial 2D version of Dropout.</p>
<p>Inherits From: <a href="../../../tf/keras/layers/Dropout.html"><code>Dropout</code></a></p>
<h3 id="aliases">Aliases:</h3>
<ul>
<li>Class <code>tf.compat.v1.keras.layers.SpatialDropout2D</code></li>
<li>Class <code>tf.compat.v2.keras.layers.SpatialDropout2D</code></li>
<li>Class <code>tf.keras.layers.SpatialDropout2D</code></li>
</ul>
<p>Defined in <a href="/code/stable/tensorflow/python/keras/layers/core.py"><code>python/keras/layers/core.py</code></a>.</p>
<!-- Placeholder for "Used in" -->
<p>This version performs the same function as Dropout, however it drops entire 2D feature maps instead of individual elements. If adjacent pixels within feature maps are strongly correlated (as is normally the case in early convolution layers) then regular dropout will not regularize the activations and will otherwise just result in an effective learning rate decrease. In this case, SpatialDropout2D will help promote independence between feature maps and should be used instead.</p>
<h4 id="arguments">Arguments:</h4>
<ul>
<li><b><code>rate</code></b>: Float between 0 and 1. Fraction of the input units to drop.</li>
<li><b><code>data_format</code></b>: 'channels_first' or 'channels_last'. In 'channels_first' mode, the channels dimension (the depth) is at index 1, in 'channels_last' mode is it at index 3. It defaults to the <code>image_data_format</code> value found in your Keras config file at <code>~/.keras/keras.json</code>. If you never set it, then it will be &quot;channels_last&quot;.</li>
</ul>
<h4 id="call-arguments">Call arguments:</h4>
<ul>
<li><b><code>inputs</code></b>: A 4D tensor.</li>
<li><b><code>training</code></b>: Python boolean indicating whether the layer should behave in training mode (adding dropout) or in inference mode (doing nothing).</li>
</ul>
<h4 id="input-shape">Input shape:</h4>
<p>4D tensor with shape: <code>(samples, channels, rows, cols)</code> if data_format='channels_first' or 4D tensor with shape: <code>(samples, rows, cols, channels)</code> if data_format='channels_last'.</p>
<h4 id="output-shape">Output shape:</h4>
<p>Same as input.</p>
<h4 id="references">References:</h4>
<ul>
<li><a href="https://arxiv.org/abs/1411.4280">Efficient Object Localization Using Convolutional Networks</a></li>
</ul>
<h2 id="__init__">
<code><strong>init</strong></code>
</h2>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="fu">__init__</span>(
    rate,
    data_format<span class="op">=</span><span class="va">None</span>,
    <span class="op">**</span>kwargs
)</code></pre></div>

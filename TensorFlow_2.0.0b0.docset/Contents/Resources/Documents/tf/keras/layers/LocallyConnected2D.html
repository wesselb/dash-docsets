<div itemscope="" itemtype="http://developers.google.com/ReferenceObject">
<p><meta itemprop="name" content="tf.keras.layers.LocallyConnected2D" /> <meta itemprop="path" content="Stable" /> <meta itemprop="property" content="__init__"/></p>
</div>
<a name="//apple_ref/cpp/Class/tf.keras.layers.LocallyConnected2D" class="dashAnchor"></a><h1 id="tf.keras.layers.locallyconnected2d">tf.keras.layers.LocallyConnected2D</h1>
<h2 id="class-locallyconnected2d">Class <code>LocallyConnected2D</code></h2>
<p>Locally-connected layer for 2D inputs.</p>
<p>Inherits From: <a href="../../../tf/keras/layers/Layer.html"><code>Layer</code></a></p>
<h3 id="aliases">Aliases:</h3>
<ul>
<li>Class <code>tf.compat.v1.keras.layers.LocallyConnected2D</code></li>
<li>Class <code>tf.compat.v2.keras.layers.LocallyConnected2D</code></li>
<li>Class <code>tf.keras.layers.LocallyConnected2D</code></li>
</ul>
<p>Defined in <a href="/code/stable/tensorflow/python/keras/layers/local.py"><code>python/keras/layers/local.py</code></a>.</p>
<!-- Placeholder for "Used in" -->
<p>The <code>LocallyConnected2D</code> layer works similarly to the <code>Conv2D</code> layer, except that weights are unshared, that is, a different set of filters is applied at each different patch of the input.</p>
<h4 id="examples">Examples:</h4>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">    <span class="co"># apply a 3x3 unshared weights convolution with 64 output filters on a</span>
    32x32 image
    <span class="co"># with `data_format=&quot;channels_last&quot;`:</span>
    model <span class="op">=</span> Sequential()
    model.add(LocallyConnected2D(<span class="dv">64</span>, (<span class="dv">3</span>, <span class="dv">3</span>), input_shape<span class="op">=</span>(<span class="dv">32</span>, <span class="dv">32</span>, <span class="dv">3</span>)))
    <span class="co"># now model.output_shape == (None, 30, 30, 64)</span>
    <span class="co"># notice that this layer will consume (30*30)*(3*3*3*64) + (30*30)*64</span>
    parameters

    <span class="co"># add a 3x3 unshared weights convolution on top, with 32 output filters:</span>
    model.add(LocallyConnected2D(<span class="dv">32</span>, (<span class="dv">3</span>, <span class="dv">3</span>)))
    <span class="co"># now model.output_shape == (None, 28, 28, 32)</span></code></pre></div>
<h4 id="arguments">Arguments:</h4>
<ul>
<li><b><code>filters</code></b>: Integer, the dimensionality of the output space (i.e. the number of output filters in the convolution).</li>
<li><b><code>kernel_size</code></b>: An integer or tuple/list of 2 integers, specifying the width and height of the 2D convolution window. Can be a single integer to specify the same value for all spatial dimensions.</li>
<li><b><code>strides</code></b>: An integer or tuple/list of 2 integers, specifying the strides of the convolution along the width and height. Can be a single integer to specify the same value for all spatial dimensions.</li>
<li><b><code>padding</code></b>: Currently only support <code>&quot;valid&quot;</code> (case-insensitive). <code>&quot;same&quot;</code> will be supported in future.</li>
<li><b><code>data_format</code></b>: A string, one of <code>channels_last</code> (default) or <code>channels_first</code>. The ordering of the dimensions in the inputs. <code>channels_last</code> corresponds to inputs with shape <code>(batch, height, width, channels)</code> while <code>channels_first</code> corresponds to inputs with shape <code>(batch, channels, height, width)</code>. It defaults to the <code>image_data_format</code> value found in your Keras config file at <code>~/.keras/keras.json</code>. If you never set it, then it will be &quot;channels_last&quot;.</li>
<li><b><code>activation</code></b>: Activation function to use. If you don't specify anything, no activation is applied (ie. &quot;linear&quot; activation: <code>a(x) = x</code>).</li>
<li><b><code>use_bias</code></b>: Boolean, whether the layer uses a bias vector.</li>
<li><b><code>kernel_initializer</code></b>: Initializer for the <code>kernel</code> weights matrix.</li>
<li><b><code>bias_initializer</code></b>: Initializer for the bias vector.</li>
<li><b><code>kernel_regularizer</code></b>: Regularizer function applied to the <code>kernel</code> weights matrix.</li>
<li><b><code>bias_regularizer</code></b>: Regularizer function applied to the bias vector.</li>
<li><b><code>activity_regularizer</code></b>: Regularizer function applied to the output of the layer (its &quot;activation&quot;).</li>
<li><b><code>kernel_constraint</code></b>: Constraint function applied to the kernel matrix.</li>
<li><b><code>bias_constraint</code></b>: Constraint function applied to the bias vector.</li>
<li><p><b><code>implementation</code></b>: implementation mode, either <code>1</code> or <code>2</code>. <code>1</code> loops over input spatial locations to perform the forward pass. It is memory-efficient but performs a lot of (small) ops.</p>
<p><code>2</code> stores layer weights in a dense but sparsely-populated 2D matrix and implements the forward pass as a single matrix-multiply. It uses a lot of RAM but performs few (large) ops.</p>
<p>Depending on the inputs, layer parameters, hardware, and <code>tf.executing_eagerly()</code> one implementation can be dramatically faster (e.g. 50X) than another.</p>
<p>It is recommended to benchmark both in the setting of interest to pick the most efficient one (in terms of speed and memory usage).</p>
<p>Following scenarios could benefit from setting <code>implementation=2</code>: - eager execution; - inference; - running on CPU; - large amount of RAM available; - small models (few filters, small kernel); - using <code>padding=same</code> (only possible with <code>implementation=2</code>).</p></li>
</ul>
<h4 id="input-shape">Input shape:</h4>
<p>4D tensor with shape: <code>(samples, channels, rows, cols)</code> if data_format='channels_first' or 4D tensor with shape: <code>(samples, rows, cols, channels)</code> if data_format='channels_last'.</p>
<h4 id="output-shape">Output shape:</h4>
<p>4D tensor with shape: <code>(samples, filters, new_rows, new_cols)</code> if data_format='channels_first' or 4D tensor with shape: <code>(samples, new_rows, new_cols, filters)</code> if data_format='channels_last'. <code>rows</code> and <code>cols</code> values might have changed due to padding.</p>
<h2 id="__init__">
<code><strong>init</strong></code>
</h2>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="fu">__init__</span>(
    filters,
    kernel_size,
    strides<span class="op">=</span>(<span class="dv">1</span>, <span class="dv">1</span>),
    padding<span class="op">=</span><span class="st">&#39;valid&#39;</span>,
    data_format<span class="op">=</span><span class="va">None</span>,
    activation<span class="op">=</span><span class="va">None</span>,
    use_bias<span class="op">=</span><span class="va">True</span>,
    kernel_initializer<span class="op">=</span><span class="st">&#39;glorot_uniform&#39;</span>,
    bias_initializer<span class="op">=</span><span class="st">&#39;zeros&#39;</span>,
    kernel_regularizer<span class="op">=</span><span class="va">None</span>,
    bias_regularizer<span class="op">=</span><span class="va">None</span>,
    activity_regularizer<span class="op">=</span><span class="va">None</span>,
    kernel_constraint<span class="op">=</span><span class="va">None</span>,
    bias_constraint<span class="op">=</span><span class="va">None</span>,
    implementation<span class="op">=</span><span class="dv">1</span>,
    <span class="op">**</span>kwargs
)</code></pre></div>

<div itemscope="" itemtype="http://developers.google.com/ReferenceObject">
<p><meta itemprop="name" content="tf.linalg.LinearOperatorScaledIdentity" /> <meta itemprop="path" content="Stable" /> <meta itemprop="property" content="H"/> <meta itemprop="property" content="batch_shape"/> <meta itemprop="property" content="domain_dimension"/> <meta itemprop="property" content="dtype"/> <meta itemprop="property" content="graph_parents"/> <meta itemprop="property" content="is_non_singular"/> <meta itemprop="property" content="is_positive_definite"/> <meta itemprop="property" content="is_self_adjoint"/> <meta itemprop="property" content="is_square"/> <meta itemprop="property" content="multiplier"/> <meta itemprop="property" content="name"/> <meta itemprop="property" content="range_dimension"/> <meta itemprop="property" content="shape"/> <meta itemprop="property" content="tensor_rank"/> <meta itemprop="property" content="__init__"/> <meta itemprop="property" content="add_to_tensor"/> <meta itemprop="property" content="adjoint"/> <meta itemprop="property" content="assert_non_singular"/> <meta itemprop="property" content="assert_positive_definite"/> <meta itemprop="property" content="assert_self_adjoint"/> <meta itemprop="property" content="batch_shape_tensor"/> <meta itemprop="property" content="cholesky"/> <meta itemprop="property" content="determinant"/> <meta itemprop="property" content="diag_part"/> <meta itemprop="property" content="domain_dimension_tensor"/> <meta itemprop="property" content="inverse"/> <meta itemprop="property" content="log_abs_determinant"/> <meta itemprop="property" content="matmul"/> <meta itemprop="property" content="matvec"/> <meta itemprop="property" content="range_dimension_tensor"/> <meta itemprop="property" content="shape_tensor"/> <meta itemprop="property" content="solve"/> <meta itemprop="property" content="solvevec"/> <meta itemprop="property" content="tensor_rank_tensor"/> <meta itemprop="property" content="to_dense"/> <meta itemprop="property" content="trace"/></p>
</div>
<a name="//apple_ref/cpp/Class/tf.linalg.LinearOperatorScaledIdentity" class="dashAnchor"></a><h1 id="tf.linalg.linearoperatorscaledidentity">tf.linalg.LinearOperatorScaledIdentity</h1>
<h2 id="class-linearoperatorscaledidentity">Class <code>LinearOperatorScaledIdentity</code></h2>
<p><code>LinearOperator</code> acting like a scaled [batch] identity matrix <code>A = c I</code>.</p>
<h3 id="aliases">Aliases:</h3>
<ul>
<li>Class <code>tf.compat.v1.linalg.LinearOperatorScaledIdentity</code></li>
<li>Class <code>tf.compat.v2.linalg.LinearOperatorScaledIdentity</code></li>
<li>Class <code>tf.linalg.LinearOperatorScaledIdentity</code></li>
</ul>
<p>Defined in <a href="/code/stable/tensorflow/python/ops/linalg/linear_operator_identity.py"><code>python/ops/linalg/linear_operator_identity.py</code></a>.</p>
<!-- Placeholder for "Used in" -->
<p>This operator acts like a scaled [batch] identity matrix <code>A</code> with shape <code>[B1,...,Bb, N, N]</code> for some <code>b &gt;= 0</code>. The first <code>b</code> indices index a batch member. For every batch index <code>(i1,...,ib)</code>, <code>A[i1,...,ib, : :]</code> is a scaled version of the <code>N x N</code> identity matrix.</p>
<p><code>LinearOperatorIdentity</code> is initialized with <code>num_rows</code>, and a <code>multiplier</code> (a <code>Tensor</code>) of shape <code>[B1,...,Bb]</code>. <code>N</code> is set to <code>num_rows</code>, and the <code>multiplier</code> determines the scale for each batch member.</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="co"># Create a 2 x 2 scaled identity matrix.</span>
operator <span class="op">=</span> LinearOperatorIdentity(num_rows<span class="op">=</span><span class="dv">2</span>, multiplier<span class="op">=</span><span class="dv">3</span>.)

operator.to_dense()
<span class="op">==&gt;</span> [[<span class="dv">3</span>., <span class="dv">0</span>.]
     [<span class="dv">0</span>., <span class="dv">3</span>.]]

operator.shape
<span class="op">==&gt;</span> [<span class="dv">2</span>, <span class="dv">2</span>]

operator.log_abs_determinant()
<span class="op">==&gt;</span> <span class="dv">2</span> <span class="op">*</span> Log[<span class="dv">3</span>]

x <span class="op">=</span> ... Shape [<span class="dv">2</span>, <span class="dv">4</span>] Tensor
operator.matmul(x)
<span class="op">==&gt;</span> <span class="dv">3</span> <span class="op">*</span> x

y <span class="op">=</span> tf.random.normal(shape<span class="op">=</span>[<span class="dv">3</span>, <span class="dv">2</span>, <span class="dv">4</span>])
<span class="co"># Note that y.shape is compatible with operator.shape because operator.shape</span>
<span class="co"># is broadcast to [3, 2, 2].</span>
x <span class="op">=</span> operator.solve(y)
<span class="op">==&gt;</span> <span class="dv">3</span> <span class="op">*</span> x

<span class="co"># Create a 2-batch of 2x2 identity matrices</span>
operator <span class="op">=</span> LinearOperatorIdentity(num_rows<span class="op">=</span><span class="dv">2</span>, multiplier<span class="op">=</span><span class="dv">5</span>.)
operator.to_dense()
<span class="op">==&gt;</span> [[[<span class="dv">5</span>., <span class="dv">0</span>.]
      [<span class="dv">0</span>., <span class="dv">5</span>.]],
     [[<span class="dv">5</span>., <span class="dv">0</span>.]
      [<span class="dv">0</span>., <span class="dv">5</span>.]]]

x <span class="op">=</span> ... Shape [<span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">3</span>]
operator.matmul(x)
<span class="op">==&gt;</span> <span class="dv">5</span> <span class="op">*</span> x

<span class="co"># Here the operator and x have different batch_shape, and are broadcast.</span>
x <span class="op">=</span> ... Shape [<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>]
operator.matmul(x)
<span class="op">==&gt;</span> <span class="dv">5</span> <span class="op">*</span> x</code></pre></div>
<h3 id="shape-compatibility">Shape compatibility</h3>
<p>This operator acts on [batch] matrix with compatible shape. <code>x</code> is a batch matrix with compatible shape for <code>matmul</code> and <code>solve</code> if</p>
<pre><code>operator.shape = [B1,...,Bb] + [N, N],  with b &gt;= 0
x.shape =   [C1,...,Cc] + [N, R],
and [C1,...,Cc] broadcasts with [B1,...,Bb] to [D1,...,Dd]</code></pre>
<h3 id="performance">Performance</h3>
<ul>
<li><code>operator.matmul(x)</code> is <code>O(D1*...*Dd*N*R)</code></li>
<li><code>operator.solve(x)</code> is <code>O(D1*...*Dd*N*R)</code></li>
<li><code>operator.determinant()</code> is <code>O(D1*...*Dd)</code></li>
</ul>
<h4 id="matrix-property-hints">Matrix property hints</h4>
<p>This <code>LinearOperator</code> is initialized with boolean flags of the form <code>is_X</code>, for <code>X = non_singular, self_adjoint, positive_definite, square</code>. These have the following meaning * If <code>is_X == True</code>, callers should expect the operator to have the property <code>X</code>. This is a promise that should be fulfilled, but is <em>not</em> a runtime assert. For example, finite floating point precision may result in these promises being violated. * If <code>is_X == False</code>, callers should expect the operator to not have <code>X</code>. * If <code>is_X == None</code> (the default), callers should have no expectation either way.</p>
<h2 id="__init__">
<code><strong>init</strong></code>
</h2>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="fu">__init__</span>(
    num_rows,
    multiplier,
    is_non_singular<span class="op">=</span><span class="va">None</span>,
    is_self_adjoint<span class="op">=</span><span class="va">None</span>,
    is_positive_definite<span class="op">=</span><span class="va">None</span>,
    is_square<span class="op">=</span><span class="va">True</span>,
    assert_proper_shapes<span class="op">=</span><span class="va">False</span>,
    name<span class="op">=</span><span class="st">&#39;LinearOperatorScaledIdentity&#39;</span>
)</code></pre></div>
<p>Initialize a <code>LinearOperatorScaledIdentity</code>.</p>
<p>The <code>LinearOperatorScaledIdentity</code> is initialized with <code>num_rows</code>, which determines the size of each identity matrix, and a <code>multiplier</code>, which defines <code>dtype</code>, batch shape, and scale of each matrix.</p>
<p>This operator is able to broadcast the leading (batch) dimensions.</p>
<h4 id="args">Args:</h4>
<ul>
<li><b><code>num_rows</code></b>: Scalar non-negative integer <code>Tensor</code>. Number of rows in the corresponding identity matrix.</li>
<li><b><code>multiplier</code></b>: <code>Tensor</code> of shape <code>[B1,...,Bb]</code>, or <code>[]</code> (a scalar).</li>
<li><b><code>is_non_singular</code></b>: Expect that this operator is non-singular.</li>
<li><b><code>is_self_adjoint</code></b>: Expect that this operator is equal to its hermitian transpose.</li>
<li><b><code>is_positive_definite</code></b>: Expect that this operator is positive definite, meaning the quadratic form <code>x^H A x</code> has positive real part for all nonzero <code>x</code>. Note that we do not require the operator to be self-adjoint to be positive-definite. See: https://en.wikipedia.org/wiki/Positive-definite_matrix#Extension_for_non-symmetric_matrices</li>
<li><b><code>is_square</code></b>: Expect that this operator acts like square [batch] matrices.</li>
<li><b><code>assert_proper_shapes</code></b>: Python <code>bool</code>. If <code>False</code>, only perform static checks that initialization and method arguments have proper shape. If <code>True</code>, and static checks are inconclusive, add asserts to the graph.</li>
<li><b><code>name</code></b>: A name for this <code>LinearOperator</code></li>
</ul>
<h4 id="raises">Raises:</h4>
<ul>
<li><b><code>ValueError</code></b>: If <code>num_rows</code> is determined statically to be non-scalar, or negative.</li>
</ul>
<h2 id="properties">Properties</h2>
<h3 id="H">
<code>H</code>
</h3>
<p>Returns the adjoint of the current <code>LinearOperator</code>.</p>
<p>Given <code>A</code> representing this <code>LinearOperator</code>, return <code>A*</code>. Note that calling <code>self.adjoint()</code> and <code>self.H</code> are equivalent.</p>
<h4 id="args-1">Args:</h4>
<ul>
<li><b><code>name</code></b>: A name for this <code>Op</code>.</li>
</ul>
<h4 id="returns">Returns:</h4>
<p><code>LinearOperator</code> which represents the adjoint of this <code>LinearOperator</code>.</p>
<h3 id="batch_shape">
<code>batch_shape</code>
</h3>
<p><code>TensorShape</code> of batch dimensions of this <code>LinearOperator</code>.</p>
<p>If this operator acts like the batch matrix <code>A</code> with <code>A.shape = [B1,...,Bb, M, N]</code>, then this returns <code>TensorShape([B1,...,Bb])</code>, equivalent to <code>A.get_shape()[:-2]</code></p>
<h4 id="returns-1">Returns:</h4>
<p><code>TensorShape</code>, statically determined, may be undefined.</p>
<h3 id="domain_dimension">
<code>domain_dimension</code>
</h3>
<p>Dimension (in the sense of vector spaces) of the domain of this operator.</p>
<p>If this operator acts like the batch matrix <code>A</code> with <code>A.shape = [B1,...,Bb, M, N]</code>, then this returns <code>N</code>.</p>
<h4 id="returns-2">Returns:</h4>
<p><code>Dimension</code> object.</p>
<h3 id="dtype">
<code>dtype</code>
</h3>
<p>The <code>DType</code> of <code>Tensor</code>s handled by this <code>LinearOperator</code>.</p>
<h3 id="graph_parents">
<code>graph_parents</code>
</h3>
<p>List of graph dependencies of this <code>LinearOperator</code>.</p>
<h3 id="is_non_singular">
<code>is_non_singular</code>
</h3>
<h3 id="is_positive_definite">
<code>is_positive_definite</code>
</h3>
<h3 id="is_self_adjoint">
<code>is_self_adjoint</code>
</h3>
<h3 id="is_square">
<code>is_square</code>
</h3>
<p>Return <code>True/False</code> depending on if this operator is square.</p>
<h3 id="multiplier">
<code>multiplier</code>
</h3>
<p>The [batch] scalar <code>Tensor</code>, <code>c</code> in <code>cI</code>.</p>
<h3 id="name">
<code>name</code>
</h3>
<p>Name prepended to all ops created by this <code>LinearOperator</code>.</p>
<h3 id="range_dimension">
<code>range_dimension</code>
</h3>
<p>Dimension (in the sense of vector spaces) of the range of this operator.</p>
<p>If this operator acts like the batch matrix <code>A</code> with <code>A.shape = [B1,...,Bb, M, N]</code>, then this returns <code>M</code>.</p>
<h4 id="returns-3">Returns:</h4>
<p><code>Dimension</code> object.</p>
<h3 id="shape">
<code>shape</code>
</h3>
<p><code>TensorShape</code> of this <code>LinearOperator</code>.</p>
<p>If this operator acts like the batch matrix <code>A</code> with <code>A.shape = [B1,...,Bb, M, N]</code>, then this returns <code>TensorShape([B1,...,Bb, M, N])</code>, equivalent to <code>A.get_shape()</code>.</p>
<h4 id="returns-4">Returns:</h4>
<p><code>TensorShape</code>, statically determined, may be undefined.</p>
<h3 id="tensor_rank">
<code>tensor_rank</code>
</h3>
<p>Rank (in the sense of tensors) of matrix corresponding to this operator.</p>
<p>If this operator acts like the batch matrix <code>A</code> with <code>A.shape = [B1,...,Bb, M, N]</code>, then this returns <code>b + 2</code>.</p>
<h4 id="args-2">Args:</h4>
<ul>
<li><b><code>name</code></b>: A name for this <code>Op</code>.</li>
</ul>
<h4 id="returns-5">Returns:</h4>
<p>Python integer, or None if the tensor rank is undefined.</p>
<h2 id="methods">Methods</h2>
<h3 id="add_to_tensor">
<code>add_to_tensor</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">add_to_tensor(
    mat,
    name<span class="op">=</span><span class="st">&#39;add_to_tensor&#39;</span>
)</code></pre></div>
<p>Add matrix represented by this operator to <code>mat</code>. Equiv to <code>I + mat</code>.</p>
<h4 id="args-3">Args:</h4>
<ul>
<li><b><code>mat</code></b>: <code>Tensor</code> with same <code>dtype</code> and shape broadcastable to <code>self</code>.</li>
<li><b><code>name</code></b>: A name to give this <code>Op</code>.</li>
</ul>
<h4 id="returns-6">Returns:</h4>
<p>A <code>Tensor</code> with broadcast shape and same <code>dtype</code> as <code>self</code>.</p>
<h3 id="adjoint">
<code>adjoint</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">adjoint(name<span class="op">=</span><span class="st">&#39;adjoint&#39;</span>)</code></pre></div>
<p>Returns the adjoint of the current <code>LinearOperator</code>.</p>
<p>Given <code>A</code> representing this <code>LinearOperator</code>, return <code>A*</code>. Note that calling <code>self.adjoint()</code> and <code>self.H</code> are equivalent.</p>
<h4 id="args-4">Args:</h4>
<ul>
<li><b><code>name</code></b>: A name for this <code>Op</code>.</li>
</ul>
<h4 id="returns-7">Returns:</h4>
<p><code>LinearOperator</code> which represents the adjoint of this <code>LinearOperator</code>.</p>
<h3 id="assert_non_singular">
<code>assert_non_singular</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">assert_non_singular(name<span class="op">=</span><span class="st">&#39;assert_non_singular&#39;</span>)</code></pre></div>
<p>Returns an <code>Op</code> that asserts this operator is non singular.</p>
<p>This operator is considered non-singular if</p>
<pre><code>ConditionNumber &lt; max{100, range_dimension, domain_dimension} * eps,
eps := np.finfo(self.dtype.as_numpy_dtype).eps</code></pre>
<h4 id="args-5">Args:</h4>
<ul>
<li><b><code>name</code></b>: A string name to prepend to created ops.</li>
</ul>
<h4 id="returns-8">Returns:</h4>
<p>An <code>Assert</code> <code>Op</code>, that, when run, will raise an <code>InvalidArgumentError</code> if the operator is singular.</p>
<h3 id="assert_positive_definite">
<code>assert_positive_definite</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">assert_positive_definite(name<span class="op">=</span><span class="st">&#39;assert_positive_definite&#39;</span>)</code></pre></div>
<p>Returns an <code>Op</code> that asserts this operator is positive definite.</p>
<p>Here, positive definite means that the quadratic form <code>x^H A x</code> has positive real part for all nonzero <code>x</code>. Note that we do not require the operator to be self-adjoint to be positive definite.</p>
<h4 id="args-6">Args:</h4>
<ul>
<li><b><code>name</code></b>: A name to give this <code>Op</code>.</li>
</ul>
<h4 id="returns-9">Returns:</h4>
<p>An <code>Assert</code> <code>Op</code>, that, when run, will raise an <code>InvalidArgumentError</code> if the operator is not positive definite.</p>
<h3 id="assert_self_adjoint">
<code>assert_self_adjoint</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">assert_self_adjoint(name<span class="op">=</span><span class="st">&#39;assert_self_adjoint&#39;</span>)</code></pre></div>
<p>Returns an <code>Op</code> that asserts this operator is self-adjoint.</p>
<p>Here we check that this operator is <em>exactly</em> equal to its hermitian transpose.</p>
<h4 id="args-7">Args:</h4>
<ul>
<li><b><code>name</code></b>: A string name to prepend to created ops.</li>
</ul>
<h4 id="returns-10">Returns:</h4>
<p>An <code>Assert</code> <code>Op</code>, that, when run, will raise an <code>InvalidArgumentError</code> if the operator is not self-adjoint.</p>
<h3 id="batch_shape_tensor">
<code>batch_shape_tensor</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">batch_shape_tensor(name<span class="op">=</span><span class="st">&#39;batch_shape_tensor&#39;</span>)</code></pre></div>
<p>Shape of batch dimensions of this operator, determined at runtime.</p>
<p>If this operator acts like the batch matrix <code>A</code> with <code>A.shape = [B1,...,Bb, M, N]</code>, then this returns a <code>Tensor</code> holding <code>[B1,...,Bb]</code>.</p>
<h4 id="args-8">Args:</h4>
<ul>
<li><b><code>name</code></b>: A name for this <code>Op</code>.</li>
</ul>
<h4 id="returns-11">Returns:</h4>
<p><code>int32</code> <code>Tensor</code></p>
<h3 id="cholesky">
<code>cholesky</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">cholesky(name<span class="op">=</span><span class="st">&#39;cholesky&#39;</span>)</code></pre></div>
<p>Returns a Cholesky factor as a <code>LinearOperator</code>.</p>
<p>Given <code>A</code> representing this <code>LinearOperator</code>, if <code>A</code> is positive definite self-adjoint, return <code>L</code>, where <code>A = L L^T</code>, i.e. the cholesky decomposition.</p>
<h4 id="args-9">Args:</h4>
<ul>
<li><b><code>name</code></b>: A name for this <code>Op</code>.</li>
</ul>
<h4 id="returns-12">Returns:</h4>
<p><code>LinearOperator</code> which represents the lower triangular matrix in the Cholesky decomposition.</p>
<h4 id="raises-1">Raises:</h4>
<ul>
<li><b><code>ValueError</code></b>: When the <code>LinearOperator</code> is not hinted to be positive definite and self adjoint.</li>
</ul>
<h3 id="determinant">
<code>determinant</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">determinant(name<span class="op">=</span><span class="st">&#39;det&#39;</span>)</code></pre></div>
<p>Determinant for every batch member.</p>
<h4 id="args-10">Args:</h4>
<ul>
<li><b><code>name</code></b>: A name for this <code>Op</code>.</li>
</ul>
<h4 id="returns-13">Returns:</h4>
<p><code>Tensor</code> with shape <code>self.batch_shape</code> and same <code>dtype</code> as <code>self</code>.</p>
<h4 id="raises-2">Raises:</h4>
<ul>
<li><b><code>NotImplementedError</code></b>: If <code>self.is_square</code> is <code>False</code>.</li>
</ul>
<h3 id="diag_part">
<code>diag_part</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">diag_part(name<span class="op">=</span><span class="st">&#39;diag_part&#39;</span>)</code></pre></div>
<p>Efficiently get the [batch] diagonal part of this operator.</p>
<p>If this operator has shape <code>[B1,...,Bb, M, N]</code>, this returns a <code>Tensor</code> <code>diagonal</code>, of shape <code>[B1,...,Bb, min(M, N)]</code>, where <code>diagonal[b1,...,bb, i] = self.to_dense()[b1,...,bb, i, i]</code>.</p>
<pre><code>my_operator = LinearOperatorDiag([1., 2.])

# Efficiently get the diagonal
my_operator.diag_part()
==&gt; [1., 2.]

# Equivalent, but inefficient method
tf.linalg.diag_part(my_operator.to_dense())
==&gt; [1., 2.]</code></pre>
<h4 id="args-11">Args:</h4>
<ul>
<li><b><code>name</code></b>: A name for this <code>Op</code>.</li>
</ul>
<h4 id="returns-14">Returns:</h4>
<ul>
<li><b><code>diag_part</code></b>: A <code>Tensor</code> of same <code>dtype</code> as self.</li>
</ul>
<h3 id="domain_dimension_tensor">
<code>domain_dimension_tensor</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">domain_dimension_tensor(name<span class="op">=</span><span class="st">&#39;domain_dimension_tensor&#39;</span>)</code></pre></div>
<p>Dimension (in the sense of vector spaces) of the domain of this operator.</p>
<p>Determined at runtime.</p>
<p>If this operator acts like the batch matrix <code>A</code> with <code>A.shape = [B1,...,Bb, M, N]</code>, then this returns <code>N</code>.</p>
<h4 id="args-12">Args:</h4>
<ul>
<li><b><code>name</code></b>: A name for this <code>Op</code>.</li>
</ul>
<h4 id="returns-15">Returns:</h4>
<p><code>int32</code> <code>Tensor</code></p>
<h3 id="inverse">
<code>inverse</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">inverse(name<span class="op">=</span><span class="st">&#39;inverse&#39;</span>)</code></pre></div>
<p>Returns the Inverse of this <code>LinearOperator</code>.</p>
<p>Given <code>A</code> representing this <code>LinearOperator</code>, return a <code>LinearOperator</code> representing <code>A^-1</code>.</p>
<h4 id="args-13">Args:</h4>
<ul>
<li><b><code>name</code></b>: A name scope to use for ops added by this method.</li>
</ul>
<h4 id="returns-16">Returns:</h4>
<p><code>LinearOperator</code> representing inverse of this matrix.</p>
<h4 id="raises-3">Raises:</h4>
<ul>
<li><b><code>ValueError</code></b>: When the <code>LinearOperator</code> is not hinted to be <code>non_singular</code>.</li>
</ul>
<h3 id="log_abs_determinant">
<code>log_abs_determinant</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">log_abs_determinant(name<span class="op">=</span><span class="st">&#39;log_abs_det&#39;</span>)</code></pre></div>
<p>Log absolute value of determinant for every batch member.</p>
<h4 id="args-14">Args:</h4>
<ul>
<li><b><code>name</code></b>: A name for this <code>Op</code>.</li>
</ul>
<h4 id="returns-17">Returns:</h4>
<p><code>Tensor</code> with shape <code>self.batch_shape</code> and same <code>dtype</code> as <code>self</code>.</p>
<h4 id="raises-4">Raises:</h4>
<ul>
<li><b><code>NotImplementedError</code></b>: If <code>self.is_square</code> is <code>False</code>.</li>
</ul>
<h3 id="matmul">
<code>matmul</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">matmul(
    x,
    adjoint<span class="op">=</span><span class="va">False</span>,
    adjoint_arg<span class="op">=</span><span class="va">False</span>,
    name<span class="op">=</span><span class="st">&#39;matmul&#39;</span>
)</code></pre></div>
<p>Transform [batch] matrix <code>x</code> with left multiplication: <code>x --&gt; Ax</code>.</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="co"># Make an operator acting like batch matrix A.  Assume A.shape = [..., M, N]</span>
operator <span class="op">=</span> LinearOperator(...)
operator.shape <span class="op">=</span> [..., M, N]

X <span class="op">=</span> ... <span class="co"># shape [..., N, R], batch matrix, R &gt; 0.</span>

Y <span class="op">=</span> operator.matmul(X)
Y.shape
<span class="op">==&gt;</span> [..., M, R]

Y[..., :, r] <span class="op">=</span> sum_j A[..., :, j] X[j, r]</code></pre></div>
<h4 id="args-15">Args:</h4>
<ul>
<li><b><code>x</code></b>: <code>LinearOperator</code> or <code>Tensor</code> with compatible shape and same <code>dtype</code> as <code>self</code>. See class docstring for definition of compatibility.</li>
<li><b><code>adjoint</code></b>: Python <code>bool</code>. If <code>True</code>, left multiply by the adjoint: <code>A^H x</code>.</li>
<li><b><code>adjoint_arg</code></b>: Python <code>bool</code>. If <code>True</code>, compute <code>A x^H</code> where <code>x^H</code> is the hermitian transpose (transposition and complex conjugation).</li>
<li><b><code>name</code></b>: A name for this <code>Op</code>.</li>
</ul>
<h4 id="returns-18">Returns:</h4>
<p>A <code>LinearOperator</code> or <code>Tensor</code> with shape <code>[..., M, R]</code> and same <code>dtype</code> as <code>self</code>.</p>
<h3 id="matvec">
<code>matvec</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">matvec(
    x,
    adjoint<span class="op">=</span><span class="va">False</span>,
    name<span class="op">=</span><span class="st">&#39;matvec&#39;</span>
)</code></pre></div>
<p>Transform [batch] vector <code>x</code> with left multiplication: <code>x --&gt; Ax</code>.</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="co"># Make an operator acting like batch matric A.  Assume A.shape = [..., M, N]</span>
operator <span class="op">=</span> LinearOperator(...)

X <span class="op">=</span> ... <span class="co"># shape [..., N], batch vector</span>

Y <span class="op">=</span> operator.matvec(X)
Y.shape
<span class="op">==&gt;</span> [..., M]

Y[..., :] <span class="op">=</span> sum_j A[..., :, j] X[..., j]</code></pre></div>
<h4 id="args-16">Args:</h4>
<ul>
<li><b><code>x</code></b>: <code>Tensor</code> with compatible shape and same <code>dtype</code> as <code>self</code>. <code>x</code> is treated as a [batch] vector meaning for every set of leading dimensions, the last dimension defines a vector. See class docstring for definition of compatibility.</li>
<li><b><code>adjoint</code></b>: Python <code>bool</code>. If <code>True</code>, left multiply by the adjoint: <code>A^H x</code>.</li>
<li><b><code>name</code></b>: A name for this <code>Op</code>.</li>
</ul>
<h4 id="returns-19">Returns:</h4>
<p>A <code>Tensor</code> with shape <code>[..., M]</code> and same <code>dtype</code> as <code>self</code>.</p>
<h3 id="range_dimension_tensor">
<code>range_dimension_tensor</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">range_dimension_tensor(name<span class="op">=</span><span class="st">&#39;range_dimension_tensor&#39;</span>)</code></pre></div>
<p>Dimension (in the sense of vector spaces) of the range of this operator.</p>
<p>Determined at runtime.</p>
<p>If this operator acts like the batch matrix <code>A</code> with <code>A.shape = [B1,...,Bb, M, N]</code>, then this returns <code>M</code>.</p>
<h4 id="args-17">Args:</h4>
<ul>
<li><b><code>name</code></b>: A name for this <code>Op</code>.</li>
</ul>
<h4 id="returns-20">Returns:</h4>
<p><code>int32</code> <code>Tensor</code></p>
<h3 id="shape_tensor">
<code>shape_tensor</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">shape_tensor(name<span class="op">=</span><span class="st">&#39;shape_tensor&#39;</span>)</code></pre></div>
<p>Shape of this <code>LinearOperator</code>, determined at runtime.</p>
<p>If this operator acts like the batch matrix <code>A</code> with <code>A.shape = [B1,...,Bb, M, N]</code>, then this returns a <code>Tensor</code> holding <code>[B1,...,Bb, M, N]</code>, equivalent to <code>tf.shape(A)</code>.</p>
<h4 id="args-18">Args:</h4>
<ul>
<li><b><code>name</code></b>: A name for this <code>Op</code>.</li>
</ul>
<h4 id="returns-21">Returns:</h4>
<p><code>int32</code> <code>Tensor</code></p>
<h3 id="solve">
<code>solve</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">solve(
    rhs,
    adjoint<span class="op">=</span><span class="va">False</span>,
    adjoint_arg<span class="op">=</span><span class="va">False</span>,
    name<span class="op">=</span><span class="st">&#39;solve&#39;</span>
)</code></pre></div>
<p>Solve (exact or approx) <code>R</code> (batch) systems of equations: <code>A X = rhs</code>.</p>
<p>The returned <code>Tensor</code> will be close to an exact solution if <code>A</code> is well conditioned. Otherwise closeness will vary. See class docstring for details.</p>
<h4 id="examples">Examples:</h4>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="co"># Make an operator acting like batch matrix A.  Assume A.shape = [..., M, N]</span>
operator <span class="op">=</span> LinearOperator(...)
operator.shape <span class="op">=</span> [..., M, N]

<span class="co"># Solve R &gt; 0 linear systems for every member of the batch.</span>
RHS <span class="op">=</span> ... <span class="co"># shape [..., M, R]</span>

X <span class="op">=</span> operator.solve(RHS)
<span class="co"># X[..., :, r] is the solution to the r&#39;th linear system</span>
<span class="co"># sum_j A[..., :, j] X[..., j, r] = RHS[..., :, r]</span>

operator.matmul(X)
<span class="op">==&gt;</span> RHS</code></pre></div>
<h4 id="args-19">Args:</h4>
<ul>
<li><b><code>rhs</code></b>: <code>Tensor</code> with same <code>dtype</code> as this operator and compatible shape. <code>rhs</code> is treated like a [batch] matrix meaning for every set of leading dimensions, the last two dimensions defines a matrix. See class docstring for definition of compatibility.</li>
<li><b><code>adjoint</code></b>: Python <code>bool</code>. If <code>True</code>, solve the system involving the adjoint of this <code>LinearOperator</code>: <code>A^H X = rhs</code>.</li>
<li><b><code>adjoint_arg</code></b>: Python <code>bool</code>. If <code>True</code>, solve <code>A X = rhs^H</code> where <code>rhs^H</code> is the hermitian transpose (transposition and complex conjugation).</li>
<li><b><code>name</code></b>: A name scope to use for ops added by this method.</li>
</ul>
<h4 id="returns-22">Returns:</h4>
<p><code>Tensor</code> with shape <code>[...,N, R]</code> and same <code>dtype</code> as <code>rhs</code>.</p>
<h4 id="raises-5">Raises:</h4>
<ul>
<li><b><code>NotImplementedError</code></b>: If <code>self.is_non_singular</code> or <code>is_square</code> is False.</li>
</ul>
<h3 id="solvevec">
<code>solvevec</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">solvevec(
    rhs,
    adjoint<span class="op">=</span><span class="va">False</span>,
    name<span class="op">=</span><span class="st">&#39;solve&#39;</span>
)</code></pre></div>
<p>Solve single equation with best effort: <code>A X = rhs</code>.</p>
<p>The returned <code>Tensor</code> will be close to an exact solution if <code>A</code> is well conditioned. Otherwise closeness will vary. See class docstring for details.</p>
<h4 id="examples-1">Examples:</h4>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="co"># Make an operator acting like batch matrix A.  Assume A.shape = [..., M, N]</span>
operator <span class="op">=</span> LinearOperator(...)
operator.shape <span class="op">=</span> [..., M, N]

<span class="co"># Solve one linear system for every member of the batch.</span>
RHS <span class="op">=</span> ... <span class="co"># shape [..., M]</span>

X <span class="op">=</span> operator.solvevec(RHS)
<span class="co"># X is the solution to the linear system</span>
<span class="co"># sum_j A[..., :, j] X[..., j] = RHS[..., :]</span>

operator.matvec(X)
<span class="op">==&gt;</span> RHS</code></pre></div>
<h4 id="args-20">Args:</h4>
<ul>
<li><b><code>rhs</code></b>: <code>Tensor</code> with same <code>dtype</code> as this operator. <code>rhs</code> is treated like a [batch] vector meaning for every set of leading dimensions, the last dimension defines a vector. See class docstring for definition of compatibility regarding batch dimensions.</li>
<li><b><code>adjoint</code></b>: Python <code>bool</code>. If <code>True</code>, solve the system involving the adjoint of this <code>LinearOperator</code>: <code>A^H X = rhs</code>.</li>
<li><b><code>name</code></b>: A name scope to use for ops added by this method.</li>
</ul>
<h4 id="returns-23">Returns:</h4>
<p><code>Tensor</code> with shape <code>[...,N]</code> and same <code>dtype</code> as <code>rhs</code>.</p>
<h4 id="raises-6">Raises:</h4>
<ul>
<li><b><code>NotImplementedError</code></b>: If <code>self.is_non_singular</code> or <code>is_square</code> is False.</li>
</ul>
<h3 id="tensor_rank_tensor">
<code>tensor_rank_tensor</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">tensor_rank_tensor(name<span class="op">=</span><span class="st">&#39;tensor_rank_tensor&#39;</span>)</code></pre></div>
<p>Rank (in the sense of tensors) of matrix corresponding to this operator.</p>
<p>If this operator acts like the batch matrix <code>A</code> with <code>A.shape = [B1,...,Bb, M, N]</code>, then this returns <code>b + 2</code>.</p>
<h4 id="args-21">Args:</h4>
<ul>
<li><b><code>name</code></b>: A name for this <code>Op</code>.</li>
</ul>
<h4 id="returns-24">Returns:</h4>
<p><code>int32</code> <code>Tensor</code>, determined at runtime.</p>
<h3 id="to_dense">
<code>to_dense</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">to_dense(name<span class="op">=</span><span class="st">&#39;to_dense&#39;</span>)</code></pre></div>
<p>Return a dense (batch) matrix representing this operator.</p>
<h3 id="trace">
<code>trace</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">trace(name<span class="op">=</span><span class="st">&#39;trace&#39;</span>)</code></pre></div>
<p>Trace of the linear operator, equal to sum of <code>self.diag_part()</code>.</p>
<p>If the operator is square, this is also the sum of the eigenvalues.</p>
<h4 id="args-22">Args:</h4>
<ul>
<li><b><code>name</code></b>: A name for this <code>Op</code>.</li>
</ul>
<h4 id="returns-25">Returns:</h4>
<p>Shape <code>[B1,...,Bb]</code> <code>Tensor</code> of same <code>dtype</code> as <code>self</code>.</p>

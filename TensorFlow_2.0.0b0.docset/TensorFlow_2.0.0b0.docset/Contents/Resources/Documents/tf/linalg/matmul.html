<div itemscope="" itemtype="http://developers.google.com/ReferenceObject">
<p><meta itemprop="name" content="tf.linalg.matmul" /> <meta itemprop="path" content="Stable" /></p>
</div>
<a name="//apple_ref/cpp/Function/tf.linalg.matmul" class="dashAnchor"></a><h1 id="tf.linalg.matmul">tf.linalg.matmul</h1>
<p>Multiplies matrix <code>a</code> by matrix <code>b</code>, producing <code>a</code> * <code>b</code>.</p>
<h3 id="aliases">Aliases:</h3>
<ul>
<li><code>tf.compat.v1.linalg.matmul</code></li>
<li><code>tf.compat.v1.matmul</code></li>
<li><code>tf.compat.v2.linalg.matmul</code></li>
<li><code>tf.compat.v2.matmul</code></li>
<li><code>tf.linalg.matmul</code></li>
<li><code>tf.matmul</code></li>
</ul>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">tf.linalg.matmul(
    a,
    b,
    transpose_a<span class="op">=</span><span class="va">False</span>,
    transpose_b<span class="op">=</span><span class="va">False</span>,
    adjoint_a<span class="op">=</span><span class="va">False</span>,
    adjoint_b<span class="op">=</span><span class="va">False</span>,
    a_is_sparse<span class="op">=</span><span class="va">False</span>,
    b_is_sparse<span class="op">=</span><span class="va">False</span>,
    name<span class="op">=</span><span class="va">None</span>
)</code></pre></div>
<p>Defined in <a href="/code/stable/tensorflow/python/ops/math_ops.py"><code>python/ops/math_ops.py</code></a>.</p>
<!-- Placeholder for "Used in" -->
<p>The inputs must, following any transpositions, be tensors of rank &gt;= 2 where the inner 2 dimensions specify valid matrix multiplication arguments, and any further outer dimensions match.</p>
<p>Both matrices must be of the same type. The supported types are: <code>float16</code>, <code>float32</code>, <code>float64</code>, <code>int32</code>, <code>complex64</code>, <code>complex128</code>.</p>
<p>Either matrix can be transposed or adjointed (conjugated and transposed) on the fly by setting one of the corresponding flag to <code>True</code>. These are <code>False</code> by default.</p>
<p>If one or both of the matrices contain a lot of zeros, a more efficient multiplication algorithm can be used by setting the corresponding <code>a_is_sparse</code> or <code>b_is_sparse</code> flag to <code>True</code>. These are <code>False</code> by default. This optimization is only available for plain matrices (rank-2 tensors) with datatypes <code>bfloat16</code> or <code>float32</code>.</p>
<h4 id="for-example">For example:</h4>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="co"># 2-D tensor `a`</span>
<span class="co"># [[1, 2, 3],</span>
<span class="co">#  [4, 5, 6]]</span>
a <span class="op">=</span> tf.constant([<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">6</span>], shape<span class="op">=</span>[<span class="dv">2</span>, <span class="dv">3</span>])

<span class="co"># 2-D tensor `b`</span>
<span class="co"># [[ 7,  8],</span>
<span class="co">#  [ 9, 10],</span>
<span class="co">#  [11, 12]]</span>
b <span class="op">=</span> tf.constant([<span class="dv">7</span>, <span class="dv">8</span>, <span class="dv">9</span>, <span class="dv">10</span>, <span class="dv">11</span>, <span class="dv">12</span>], shape<span class="op">=</span>[<span class="dv">3</span>, <span class="dv">2</span>])

<span class="co"># `a` * `b`</span>
<span class="co"># [[ 58,  64],</span>
<span class="co">#  [139, 154]]</span>
c <span class="op">=</span> tf.matmul(a, b)


<span class="co"># 3-D tensor `a`</span>
<span class="co"># [[[ 1,  2,  3],</span>
<span class="co">#   [ 4,  5,  6]],</span>
<span class="co">#  [[ 7,  8,  9],</span>
<span class="co">#   [10, 11, 12]]]</span>
a <span class="op">=</span> tf.constant(np.arange(<span class="dv">1</span>, <span class="dv">13</span>, dtype<span class="op">=</span>np.int32),
                shape<span class="op">=</span>[<span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">3</span>])

<span class="co"># 3-D tensor `b`</span>
<span class="co"># [[[13, 14],</span>
<span class="co">#   [15, 16],</span>
<span class="co">#   [17, 18]],</span>
<span class="co">#  [[19, 20],</span>
<span class="co">#   [21, 22],</span>
<span class="co">#   [23, 24]]]</span>
b <span class="op">=</span> tf.constant(np.arange(<span class="dv">13</span>, <span class="dv">25</span>, dtype<span class="op">=</span>np.int32),
                shape<span class="op">=</span>[<span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">2</span>])

<span class="co"># `a` * `b`</span>
<span class="co"># [[[ 94, 100],</span>
<span class="co">#   [229, 244]],</span>
<span class="co">#  [[508, 532],</span>
<span class="co">#   [697, 730]]]</span>
c <span class="op">=</span> tf.matmul(a, b)

<span class="co"># Since python &gt;= 3.5 the @ operator is supported (see PEP 465).</span>
<span class="co"># In TensorFlow, it simply calls the `tf.matmul()` function, so the</span>
<span class="co"># following lines are equivalent:</span>
d <span class="op">=</span> a <span class="op">@</span> b <span class="op">@</span> [[<span class="dv">10</span>.], [<span class="dv">11</span>.]]
d <span class="op">=</span> tf.matmul(tf.matmul(a, b), [[<span class="dv">10</span>.], [<span class="dv">11</span>.]])</code></pre></div>
<h4 id="args">Args:</h4>
<ul>
<li><b><code>a</code></b>: <code>Tensor</code> of type <code>float16</code>, <code>float32</code>, <code>float64</code>, <code>int32</code>, <code>complex64</code>, <code>complex128</code> and rank &gt; 1.</li>
<li><b><code>b</code></b>: <code>Tensor</code> with same type and rank as <code>a</code>.</li>
<li><b><code>transpose_a</code></b>: If <code>True</code>, <code>a</code> is transposed before multiplication.</li>
<li><b><code>transpose_b</code></b>: If <code>True</code>, <code>b</code> is transposed before multiplication.</li>
<li><b><code>adjoint_a</code></b>: If <code>True</code>, <code>a</code> is conjugated and transposed before multiplication.</li>
<li><b><code>adjoint_b</code></b>: If <code>True</code>, <code>b</code> is conjugated and transposed before multiplication.</li>
<li><b><code>a_is_sparse</code></b>: If <code>True</code>, <code>a</code> is treated as a sparse matrix.</li>
<li><b><code>b_is_sparse</code></b>: If <code>True</code>, <code>b</code> is treated as a sparse matrix.</li>
<li><b><code>name</code></b>: Name for the operation (optional).</li>
</ul>
<h4 id="returns">Returns:</h4>
<p>A <code>Tensor</code> of the same type as <code>a</code> and <code>b</code> where each inner-most matrix is the product of the corresponding matrices in <code>a</code> and <code>b</code>, e.g. if all transpose or adjoint attributes are <code>False</code>:</p>
<p><code>output</code>[..., i, j] = sum_k (<code>a</code>[..., i, k] * <code>b</code>[..., k, j]), for all indices i, j.</p>
<ul>
<li><b><code>Note</code></b>: This is matrix product, not element-wise product.</li>
</ul>
<h4 id="raises">Raises:</h4>
<ul>
<li><b><code>ValueError</code></b>: If transpose_a and adjoint_a, or transpose_b and adjoint_b are both set to True.</li>
</ul>

<div itemscope="" itemtype="http://developers.google.com/ReferenceObject">
<p><meta itemprop="name" content="tf.compat.v1.nn.embedding_lookup_sparse" /> <meta itemprop="path" content="Stable" /></p>
</div>
<a name="//apple_ref/cpp/Function/tf.compat.v1.nn.embedding_lookup_sparse" class="dashAnchor"></a><h1 id="tf.compat.v1.nn.embedding_lookup_sparse">tf.compat.v1.nn.embedding_lookup_sparse</h1>
<p>Computes embeddings for the given ids and weights.</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">tf.compat.v1.nn.embedding_lookup_sparse(
    params,
    sp_ids,
    sp_weights,
    partition_strategy<span class="op">=</span><span class="st">&#39;mod&#39;</span>,
    name<span class="op">=</span><span class="va">None</span>,
    combiner<span class="op">=</span><span class="va">None</span>,
    max_norm<span class="op">=</span><span class="va">None</span>
)</code></pre></div>
<p>Defined in <a href="/code/stable/tensorflow/python/ops/embedding_ops.py"><code>python/ops/embedding_ops.py</code></a>.</p>
<!-- Placeholder for "Used in" -->
<p>This op assumes that there is at least one id for each row in the dense tensor represented by sp_ids (i.e. there are no rows with empty features), and that all the indices of sp_ids are in canonical row-major order.</p>
<p>It also assumes that all id values lie in the range [0, p0), where p0 is the sum of the size of params along dimension 0.</p>
<h4 id="args">Args:</h4>
<ul>
<li><b><code>params</code></b>: A single tensor representing the complete embedding tensor, or a list of P tensors all of same shape except for the first dimension, representing sharded embedding tensors. Alternatively, a <code>PartitionedVariable</code>, created by partitioning along dimension 0. Each element must be appropriately sized for the given <code>partition_strategy</code>.</li>
<li><b><code>sp_ids</code></b>: N x M <code>SparseTensor</code> of int64 ids where N is typically batch size and M is arbitrary.</li>
<li><b><code>sp_weights</code></b>: either a <code>SparseTensor</code> of float / double weights, or <code>None</code> to indicate all weights should be taken to be 1. If specified, <code>sp_weights</code> must have exactly the same shape and indices as <code>sp_ids</code>.</li>
<li><b><code>partition_strategy</code></b>: A string specifying the partitioning strategy, relevant if <code>len(params) &gt; 1</code>. Currently <code>&quot;div&quot;</code> and <code>&quot;mod&quot;</code> are supported. Default is <code>&quot;mod&quot;</code>. See <a href="../../../../tf/nn/embedding_lookup.html"><code>tf.nn.embedding_lookup</code></a> for more details.</li>
<li><b><code>name</code></b>: Optional name for the op.</li>
<li><b><code>combiner</code></b>: A string specifying the reduction op. Currently &quot;mean&quot;, &quot;sqrtn&quot; and &quot;sum&quot; are supported. &quot;sum&quot; computes the weighted sum of the embedding results for each row. &quot;mean&quot; is the weighted sum divided by the total weight. &quot;sqrtn&quot; is the weighted sum divided by the square root of the sum of the squares of the weights.</li>
<li><b><code>max_norm</code></b>: If not <code>None</code>, each embedding is clipped if its l2-norm is larger than this value, before combining.</li>
</ul>
<h4 id="returns">Returns:</h4>
<p>A dense tensor representing the combined embeddings for the sparse ids. For each row in the dense tensor represented by <code>sp_ids</code>, the op looks up the embeddings for all ids in that row, multiplies them by the corresponding weight, and combines these embeddings as specified.</p>
<p>In other words, if</p>
<p><code>shape(combined params) = [p0, p1, ..., pm]</code></p>
<p>and</p>
<p><code>shape(sp_ids) = shape(sp_weights) = [d0, d1, ..., dn]</code></p>
<p>then</p>
<p><code>shape(output) = [d0, d1, ..., dn-1, p1, ..., pm]</code>.</p>
<p>For instance, if params is a 10x20 matrix, and sp_ids / sp_weights are</p>
<p><code>python   [0, 0]: id 1, weight 2.0   [0, 1]: id 3, weight 0.5   [1, 0]: id 0, weight 1.0   [2, 3]: id 1, weight 3.0</code></p>
<p>with <code>combiner</code>=&quot;mean&quot;, then the output will be a 3x20 matrix where</p>
<p><code>python   output[0, :] = (params[1, :] * 2.0 + params[3, :] * 0.5) / (2.0 + 0.5)   output[1, :] = (params[0, :] * 1.0) / 1.0   output[2, :] = (params[1, :] * 3.0) / 3.0</code></p>
<h4 id="raises">Raises:</h4>
<ul>
<li><b><code>TypeError</code></b>: If <code>sp_ids</code> is not a <code>SparseTensor</code>, or if <code>sp_weights</code> is neither <code>None</code> nor <code>SparseTensor</code>.</li>
<li><b><code>ValueError</code></b>: If <code>combiner</code> is not one of {&quot;mean&quot;, &quot;sqrtn&quot;, &quot;sum&quot;}.</li>
</ul>

<div itemscope="" itemtype="http://developers.google.com/ReferenceObject">
<p><meta itemprop="name" content="tf.compat.v1.train.import_meta_graph" /> <meta itemprop="path" content="Stable" /></p>
</div>
<a name="//apple_ref/cpp/Function/tf.compat.v1.train.import_meta_graph" class="dashAnchor"></a><h1 id="tf.compat.v1.train.import_meta_graph">tf.compat.v1.train.import_meta_graph</h1>
<p>Recreates a Graph saved in a <code>MetaGraphDef</code> proto.</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">tf.compat.v1.train.import_meta_graph(
    meta_graph_or_file,
    clear_devices<span class="op">=</span><span class="va">False</span>,
    import_scope<span class="op">=</span><span class="va">None</span>,
    <span class="op">**</span>kwargs
)</code></pre></div>
<p>Defined in <a href="/code/stable/tensorflow/python/training/saver.py"><code>python/training/saver.py</code></a>.</p>
<!-- Placeholder for "Used in" -->
<p>This function takes a <code>MetaGraphDef</code> protocol buffer as input. If the argument is a file containing a <code>MetaGraphDef</code> protocol buffer , it constructs a protocol buffer from the file content. The function then adds all the nodes from the <code>graph_def</code> field to the current graph, recreates all the collections, and returns a saver constructed from the <code>saver_def</code> field.</p>
<p>In combination with <code>export_meta_graph()</code>, this function can be used to</p>
<ul>
<li><p>Serialize a graph along with other Python objects such as <code>QueueRunner</code>, <code>Variable</code> into a <code>MetaGraphDef</code>.</p></li>
<li><p>Restart training from a saved graph and checkpoints.</p></li>
<li><p>Run inference from a saved graph and checkpoints.</p></li>
</ul>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">...
<span class="co"># Create a saver.</span>
saver <span class="op">=</span> tf.compat.v1.train.Saver(...variables...)
<span class="co"># Remember the training_op we want to run by adding it to a collection.</span>
tf.compat.v1.add_to_collection(<span class="st">&#39;train_op&#39;</span>, train_op)
sess <span class="op">=</span> tf.compat.v1.Session()
<span class="cf">for</span> step <span class="kw">in</span> <span class="bu">xrange</span>(<span class="dv">1000000</span>):
    sess.run(train_op)
    <span class="cf">if</span> step <span class="op">%</span> <span class="dv">1000</span> <span class="op">==</span> <span class="dv">0</span>:
        <span class="co"># Saves checkpoint, which by default also exports a meta_graph</span>
        <span class="co"># named &#39;my-model-global_step.meta&#39;.</span>
        saver.save(sess, <span class="st">&#39;my-model&#39;</span>, global_step<span class="op">=</span>step)</code></pre></div>
<p>Later we can continue training from this saved <code>meta_graph</code> without building the model from scratch.</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="cf">with</span> tf.compat.v1.Session() <span class="im">as</span> sess:
  new_saver <span class="op">=</span>
  tf.compat.v1.train.import_meta_graph(<span class="st">&#39;my-save-dir/my-model-10000.meta&#39;</span>)
  new_saver.restore(sess, <span class="st">&#39;my-save-dir/my-model-10000&#39;</span>)
  <span class="co"># tf.compat.v1.get_collection() returns a list. In this example we only want</span>
  <span class="co"># the first one.</span>
  train_op <span class="op">=</span> tf.compat.v1.get_collection(<span class="st">&#39;train_op&#39;</span>)[<span class="dv">0</span>]
  <span class="cf">for</span> step <span class="kw">in</span> <span class="bu">xrange</span>(<span class="dv">1000000</span>):
    sess.run(train_op)</code></pre></div>
<p>NOTE: Restarting training from saved <code>meta_graph</code> only works if the device assignments have not changed.</p>
<h4 id="example-2">Example 2:</h4>
<p>Variables, placeholders, and independent operations can also be stored, as shown in the following example.</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="co"># Saving contents and operations.</span>
v1 <span class="op">=</span> tf.compat.v1.placeholder(tf.float32, name<span class="op">=</span><span class="st">&quot;v1&quot;</span>)
v2 <span class="op">=</span> tf.compat.v1.placeholder(tf.float32, name<span class="op">=</span><span class="st">&quot;v2&quot;</span>)
v3 <span class="op">=</span> tf.mul(v1, v2)
vx <span class="op">=</span> tf.Variable(<span class="fl">10.0</span>, name<span class="op">=</span><span class="st">&quot;vx&quot;</span>)
v4 <span class="op">=</span> tf.add(v3, vx, name<span class="op">=</span><span class="st">&quot;v4&quot;</span>)
saver <span class="op">=</span> tf.compat.v1.train.Saver([vx])
sess <span class="op">=</span> tf.compat.v1.Session()
sess.run(tf.compat.v1.initialize_all_variables())
sess.run(vx.assign(tf.add(vx, vx)))
result <span class="op">=</span> sess.run(v4, feed_dict<span class="op">=</span>{v1:<span class="fl">12.0</span>, v2:<span class="fl">3.3</span>})
<span class="bu">print</span>(result)
saver.save(sess, <span class="st">&quot;./model_ex1&quot;</span>)</code></pre></div>
<p>Later this model can be restored and contents loaded.</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="co"># Restoring variables and running operations.</span>
saver <span class="op">=</span> tf.compat.v1.train.import_meta_graph(<span class="st">&quot;./model_ex1.meta&quot;</span>)
sess <span class="op">=</span> tf.compat.v1.Session()
saver.restore(sess, <span class="st">&quot;./model_ex1&quot;</span>)
result <span class="op">=</span> sess.run(<span class="st">&quot;v4:0&quot;</span>, feed_dict<span class="op">=</span>{<span class="st">&quot;v1:0&quot;</span>: <span class="fl">12.0</span>, <span class="st">&quot;v2:0&quot;</span>: <span class="fl">3.3</span>})
<span class="bu">print</span>(result)</code></pre></div>
<h4 id="args">Args:</h4>
<ul>
<li><b><code>meta_graph_or_file</code></b>: <code>MetaGraphDef</code> protocol buffer or filename (including the path) containing a <code>MetaGraphDef</code>.</li>
<li><b><code>clear_devices</code></b>: Whether or not to clear the device field for an <code>Operation</code> or <code>Tensor</code> during import.</li>
<li><b><code>import_scope</code></b>: Optional <code>string</code>. Name scope to add. Only used when initializing from protocol buffer.</li>
<li><b><code>**kwargs</code></b>: Optional keyed arguments.</li>
</ul>
<h4 id="returns">Returns:</h4>
<p>A saver constructed from <code>saver_def</code> in <code>MetaGraphDef</code> or None.</p>
<p>A None value is returned if no variables exist in the <code>MetaGraphDef</code> (i.e., there are no variables to restore).</p>
<h4 id="raises">Raises:</h4>
<ul>
<li><b><code>RuntimeError</code></b>: If called with eager execution enabled.</li>
</ul>
<h4 id="eager-compatibility">Eager Compatibility</h4>
<p>Exporting/importing meta graphs is not supported. No graph exists when eager execution is enabled.</p>

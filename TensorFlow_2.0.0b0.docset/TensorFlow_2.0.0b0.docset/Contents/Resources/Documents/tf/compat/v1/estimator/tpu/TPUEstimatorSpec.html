<div itemscope="" itemtype="http://developers.google.com/ReferenceObject">
<p><meta itemprop="name" content="tf.compat.v1.estimator.tpu.TPUEstimatorSpec" /> <meta itemprop="path" content="Stable" /> <meta itemprop="property" content="mode"/> <meta itemprop="property" content="predictions"/> <meta itemprop="property" content="loss"/> <meta itemprop="property" content="train_op"/> <meta itemprop="property" content="eval_metrics"/> <meta itemprop="property" content="export_outputs"/> <meta itemprop="property" content="scaffold_fn"/> <meta itemprop="property" content="host_call"/> <meta itemprop="property" content="training_hooks"/> <meta itemprop="property" content="evaluation_hooks"/> <meta itemprop="property" content="prediction_hooks"/> <meta itemprop="property" content="as_estimator_spec"/></p>
</div>
<a name="//apple_ref/cpp/Class/tf.compat.v1.estimator.tpu.TPUEstimatorSpec" class="dashAnchor"></a><h1 id="tf.compat.v1.estimator.tpu.tpuestimatorspec">tf.compat.v1.estimator.tpu.TPUEstimatorSpec</h1>
<h2 id="class-tpuestimatorspec">Class <code>TPUEstimatorSpec</code></h2>
<p>Ops and objects returned from a <code>model_fn</code> and passed to <code>TPUEstimator</code>.</p>
<p>Defined in <a href="https://github.com/tensorflow/estimator/tree/master/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"><code>python/estimator/tpu/tpu_estimator.py</code></a>.</p>
<!-- Placeholder for "Used in" -->
<p>See <code>EstimatorSpec</code> for <code>mode</code>, <code>predictions</code>, <code>loss</code>, <code>train_op</code>, and <code>export_outputs</code>.</p>
<p>For evaluation, <code>eval_metrics</code>is a tuple of <code>metric_fn</code> and <code>tensors</code>, where <code>metric_fn</code> runs on CPU to generate metrics and <code>tensors</code> represents the <code>Tensor</code>s transferred from TPU system to CPU host and passed to <code>metric_fn</code>. To be precise, TPU evaluation expects a slightly different signature from the <a href="../../../../../tf/estimator/Estimator.html"><code>tf.estimator.Estimator</code></a>. While <code>EstimatorSpec.eval_metric_ops</code> expects a dict, <code>TPUEstimatorSpec.eval_metrics</code> is a tuple of <code>metric_fn</code> and <code>tensors</code>. The <code>tensors</code> could be a list of <code>Tensor</code>s or dict of names to <code>Tensor</code>s. The <code>tensors</code> usually specify the model logits, which are transferred back from TPU system to CPU host. All tensors must have be batch-major, i.e., the batch size is the first dimension. Once all tensors are available at CPU host from all shards, they are concatenated (on CPU) and passed as positional arguments to the <code>metric_fn</code> if <code>tensors</code> is list or keyword arguments if <code>tensors</code> is a dict. <code>metric_fn</code> takes the <code>tensors</code> and returns a dict from metric string name to the result of calling a metric function, namely a <code>(metric_tensor, update_op)</code> tuple. See <code>TPUEstimator</code> for MNIST example how to specify the <code>eval_metrics</code>.</p>
<p><code>scaffold_fn</code> is a function running on CPU to generate the <code>Scaffold</code>. This function should not capture any Tensors in <code>model_fn</code>.</p>
<p><code>host_call</code> is a tuple of a <code>function</code> and a list or dictionary of <code>tensors</code> to pass to that function and returns a list of Tensors. <code>host_call</code> currently works for train() and evaluate(). The Tensors returned by the function is executed on the CPU on every step, so there is communication overhead when sending tensors from TPU to CPU. To reduce the overhead, try reducing the size of the tensors. The <code>tensors</code> are concatenated along their major (batch) dimension, and so must be &gt;= rank 1. The <code>host_call</code> is useful for writing summaries with <code>tf.contrib.summary.create_file_writer</code>.</p>
<h2 id="properties">Properties</h2>
<h3 id="mode">
<code>mode</code>
</h3>
<h3 id="predictions">
<code>predictions</code>
</h3>
<h3 id="loss">
<code>loss</code>
</h3>
<h3 id="train_op">
<code>train_op</code>
</h3>
<h3 id="eval_metrics">
<code>eval_metrics</code>
</h3>
<h3 id="export_outputs">
<code>export_outputs</code>
</h3>
<h3 id="scaffold_fn">
<code>scaffold_fn</code>
</h3>
<h3 id="host_call">
<code>host_call</code>
</h3>
<h3 id="training_hooks">
<code>training_hooks</code>
</h3>
<h3 id="evaluation_hooks">
<code>evaluation_hooks</code>
</h3>
<h3 id="prediction_hooks">
<code>prediction_hooks</code>
</h3>
<h2 id="methods">Methods</h2>
<h3 id="as_estimator_spec">
<code>as_estimator_spec</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">as_estimator_spec()</code></pre></div>
<p>Creates an equivalent <code>EstimatorSpec</code> used by CPU train/eval.</p>

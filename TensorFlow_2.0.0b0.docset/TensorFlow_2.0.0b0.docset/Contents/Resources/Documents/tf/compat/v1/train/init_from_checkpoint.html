<div itemscope="" itemtype="http://developers.google.com/ReferenceObject">
<p><meta itemprop="name" content="tf.compat.v1.train.init_from_checkpoint" /> <meta itemprop="path" content="Stable" /></p>
</div>
<a name="//apple_ref/cpp/Function/tf.compat.v1.train.init_from_checkpoint" class="dashAnchor"></a><h1 id="tf.compat.v1.train.init_from_checkpoint">tf.compat.v1.train.init_from_checkpoint</h1>
<p>Replaces <a href="../../../../tf/Variable.html"><code>tf.Variable</code></a> initializers so they load from a checkpoint file.</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">tf.compat.v1.train.init_from_checkpoint(
    ckpt_dir_or_file,
    assignment_map
)</code></pre></div>
<p>Defined in <a href="/code/stable/tensorflow/python/training/checkpoint_utils.py"><code>python/training/checkpoint_utils.py</code></a>.</p>
<!-- Placeholder for "Used in" -->
<p>Values are not loaded immediately, but when the initializer is run (typically by running a <a href="../../../../tf/compat/v1/global_variables_initializer.html"><code>tf.compat.v1.global_variables_initializer</code></a> op).</p>
<p>Note: This overrides default initialization ops of specified variables and redefines dtype.</p>
<p>Assignment map supports following syntax:</p>
<ul>
<li><code>'checkpoint_scope_name/': 'scope_name/'</code> - will load all variables in current <code>scope_name</code> from <code>checkpoint_scope_name</code> with matching tensor names.</li>
<li><code>'checkpoint_scope_name/some_other_variable': 'scope_name/variable_name'</code> - will initialize <code>scope_name/variable_name</code> variable from <code>checkpoint_scope_name/some_other_variable</code>.</li>
<li><code>'scope_variable_name': variable</code> - will initialize given <a href="../../../../tf/Variable.html"><code>tf.Variable</code></a> object with tensor 'scope_variable_name' from the checkpoint.</li>
<li><code>'scope_variable_name': list(variable)</code> - will initialize list of partitioned variables with tensor 'scope_variable_name' from the checkpoint.</li>
<li><code>'/': 'scope_name/'</code> - will load all variables in current <code>scope_name</code> from checkpoint's root (e.g. no scope).</li>
</ul>
<p>Supports loading into partitioned variables, which are represented as <code>'&lt;variable&gt;/part_&lt;part #&gt;'</code>.</p>
<h4 id="example">Example:</h4>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">
<span class="co"># Say, &#39;/tmp/model.ckpt&#39; has the following tensors:</span>
<span class="co">#  -- name=&#39;old_scope_1/var1&#39;, shape=[20, 2]</span>
<span class="co">#  -- name=&#39;old_scope_1/var2&#39;, shape=[50, 4]</span>
<span class="co">#  -- name=&#39;old_scope_2/var3&#39;, shape=[100, 100]</span>

<span class="co"># Create new model&#39;s variables</span>
<span class="cf">with</span> tf.compat.v1.variable_scope(<span class="st">&#39;new_scope_1&#39;</span>):
  var1 <span class="op">=</span> tf.compat.v1.get_variable(<span class="st">&#39;var1&#39;</span>, shape<span class="op">=</span>[<span class="dv">20</span>, <span class="dv">2</span>],
                         initializer<span class="op">=</span>tf.compat.v1.zeros_initializer())
<span class="cf">with</span> tf.compat.v1.variable_scope(<span class="st">&#39;new_scope_2&#39;</span>):
  var2 <span class="op">=</span> tf.compat.v1.get_variable(<span class="st">&#39;var2&#39;</span>, shape<span class="op">=</span>[<span class="dv">50</span>, <span class="dv">4</span>],
                         initializer<span class="op">=</span>tf.compat.v1.zeros_initializer())
  <span class="co"># Partition into 5 variables along the first axis.</span>
  var3 <span class="op">=</span> tf.compat.v1.get_variable(name<span class="op">=</span><span class="st">&#39;var3&#39;</span>, shape<span class="op">=</span>[<span class="dv">100</span>, <span class="dv">100</span>],
                         initializer<span class="op">=</span>tf.compat.v1.zeros_initializer(),
                         partitioner<span class="op">=</span><span class="kw">lambda</span> shape, dtype: [<span class="dv">5</span>, <span class="dv">1</span>])

<span class="co"># Initialize all variables in `new_scope_1` from `old_scope_1`.</span>
init_from_checkpoint(<span class="st">&#39;/tmp/model.ckpt&#39;</span>, {<span class="st">&#39;old_scope_1/&#39;</span>: <span class="st">&#39;new_scope_1&#39;</span>})

<span class="co"># Use names to specify which variables to initialize from checkpoint.</span>
init_from_checkpoint(<span class="st">&#39;/tmp/model.ckpt&#39;</span>,
                     {<span class="st">&#39;old_scope_1/var1&#39;</span>: <span class="st">&#39;new_scope_1/var1&#39;</span>,
                      <span class="st">&#39;old_scope_1/var2&#39;</span>: <span class="st">&#39;new_scope_2/var2&#39;</span>})

<span class="co"># Or use tf.Variable objects to identify what to initialize.</span>
init_from_checkpoint(<span class="st">&#39;/tmp/model.ckpt&#39;</span>,
                     {<span class="st">&#39;old_scope_1/var1&#39;</span>: var1,
                      <span class="st">&#39;old_scope_1/var2&#39;</span>: var2})

<span class="co"># Initialize partitioned variables using variable&#39;s name</span>
init_from_checkpoint(<span class="st">&#39;/tmp/model.ckpt&#39;</span>,
                     {<span class="st">&#39;old_scope_2/var3&#39;</span>: <span class="st">&#39;new_scope_2/var3&#39;</span>})

<span class="co"># Or specify the list of tf.Variable objects.</span>
init_from_checkpoint(<span class="st">&#39;/tmp/model.ckpt&#39;</span>,
                     {<span class="st">&#39;old_scope_2/var3&#39;</span>: var3._get_variable_list()})</code></pre></div>
<h4 id="args">Args:</h4>
<ul>
<li><b><code>ckpt_dir_or_file</code></b>: Directory with checkpoints file or path to checkpoint.</li>
<li><b><code>assignment_map</code></b>: Dict, where keys are names of the variables in the checkpoint and values are current variables or names of current variables (in default graph).</li>
</ul>
<h4 id="raises">Raises:</h4>
<ul>
<li><b><code>ValueError</code></b>: If missing variables in current graph, or if missing checkpoints or tensors in checkpoints.</li>
</ul>

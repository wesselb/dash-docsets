<div itemscope="" itemtype="http://developers.google.com/ReferenceObject">
<p><meta itemprop="name" content="tf.math.accumulate_n" /> <meta itemprop="path" content="Stable" /></p>
</div>
<a name="//apple_ref/cpp/Function/tf.math.accumulate_n" class="dashAnchor"></a><h1 id="tf.math.accumulate_n">tf.math.accumulate_n</h1>
<p>Returns the element-wise sum of a list of tensors.</p>
<h3 id="aliases">Aliases:</h3>
<ul>
<li><code>tf.compat.v1.accumulate_n</code></li>
<li><code>tf.compat.v1.math.accumulate_n</code></li>
<li><code>tf.compat.v2.math.accumulate_n</code></li>
<li><code>tf.math.accumulate_n</code></li>
</ul>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">tf.math.accumulate_n(
    inputs,
    shape<span class="op">=</span><span class="va">None</span>,
    tensor_dtype<span class="op">=</span><span class="va">None</span>,
    name<span class="op">=</span><span class="va">None</span>
)</code></pre></div>
<p>Defined in <a href="/code/stable/tensorflow/python/ops/math_ops.py"><code>python/ops/math_ops.py</code></a>.</p>
<!-- Placeholder for "Used in" -->
<p>Optionally, pass <code>shape</code> and <code>tensor_dtype</code> for shape and type checking, otherwise, these are inferred.</p>
<p><code>accumulate_n</code> performs the same operation as <a href="../../tf/math/add_n.html"><code>tf.math.add_n</code></a>, but does not wait for all of its inputs to be ready before beginning to sum. This approach can save memory if inputs are ready at different times, since minimum temporary storage is proportional to the output size rather than the inputs' size.</p>
<p><code>accumulate_n</code> is differentiable (but wasn't previous to TensorFlow 1.7).</p>
<h4 id="for-example">For example:</h4>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">a <span class="op">=</span> tf.constant([[<span class="dv">1</span>, <span class="dv">2</span>], [<span class="dv">3</span>, <span class="dv">4</span>]])
b <span class="op">=</span> tf.constant([[<span class="dv">5</span>, <span class="dv">0</span>], [<span class="dv">0</span>, <span class="dv">6</span>]])
tf.math.accumulate_n([a, b, a])  <span class="co"># [[7, 4], [6, 14]]</span>

<span class="co"># Explicitly pass shape and type</span>
tf.math.accumulate_n([a, b, a], shape<span class="op">=</span>[<span class="dv">2</span>, <span class="dv">2</span>], tensor_dtype<span class="op">=</span>tf.int32)
                                                               <span class="co"># [[7,  4],</span>
                                                               <span class="co">#  [6, 14]]</span></code></pre></div>
<h4 id="args">Args:</h4>
<ul>
<li><b><code>inputs</code></b>: A list of <code>Tensor</code> objects, each with same shape and type.</li>
<li><b><code>shape</code></b>: Expected shape of elements of <code>inputs</code> (optional). Also controls the output shape of this op, which may affect type inference in other ops. A value of <code>None</code> means &quot;infer the input shape from the shapes in <code>inputs</code>&quot;.</li>
<li><b><code>tensor_dtype</code></b>: Expected data type of <code>inputs</code> (optional). A value of <code>None</code> means &quot;infer the input dtype from <code>inputs[0]</code>&quot;.</li>
<li><b><code>name</code></b>: A name for the operation (optional).</li>
</ul>
<h4 id="returns">Returns:</h4>
<p>A <code>Tensor</code> of same shape and type as the elements of <code>inputs</code>.</p>
<h4 id="raises">Raises:</h4>
<ul>
<li><b><code>ValueError</code></b>: If <code>inputs</code> don't all have same shape and dtype or the shape cannot be inferred.</li>
</ul>

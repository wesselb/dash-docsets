<div itemscope="" itemtype="http://developers.google.com/ReferenceObject">
<p><meta itemprop="name" content="tf.tpu.experimental.DeviceAssignment" /> <meta itemprop="path" content="Stable" /> <meta itemprop="property" content="core_assignment"/> <meta itemprop="property" content="num_cores_per_replica"/> <meta itemprop="property" content="num_replicas"/> <meta itemprop="property" content="topology"/> <meta itemprop="property" content="__init__"/> <meta itemprop="property" content="build"/> <meta itemprop="property" content="coordinates"/> <meta itemprop="property" content="host_device"/> <meta itemprop="property" content="lookup_replicas"/> <meta itemprop="property" content="tpu_device"/> <meta itemprop="property" content="tpu_ordinal"/></p>
</div>
<a name="//apple_ref/cpp/Class/tf.tpu.experimental.DeviceAssignment" class="dashAnchor"></a><h1 id="tf.tpu.experimental.deviceassignment">tf.tpu.experimental.DeviceAssignment</h1>
<h2 id="class-deviceassignment">Class <code>DeviceAssignment</code></h2>
<p>Mapping from logical cores in a computation to the physical TPU topology.</p>
<h3 id="aliases">Aliases:</h3>
<ul>
<li>Class <code>tf.compat.v1.tpu.experimental.DeviceAssignment</code></li>
<li>Class <code>tf.compat.v2.tpu.experimental.DeviceAssignment</code></li>
<li>Class <code>tf.tpu.experimental.DeviceAssignment</code></li>
</ul>
<p>Defined in <a href="/code/stable/tensorflow/python/tpu/device_assignment.py"><code>python/tpu/device_assignment.py</code></a>.</p>
<!-- Placeholder for "Used in" -->
<p>Prefer to use the <code>DeviceAssignment.build()</code> helper to construct a <code>DeviceAssignment</code>; it is easier if less flexible than constructing a <code>DeviceAssignment</code> directly.</p>
<h2 id="__init__">
<code><strong>init</strong></code>
</h2>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="fu">__init__</span>(
    topology,
    core_assignment
)</code></pre></div>
<p>Constructs a <code>DeviceAssignment</code> object.</p>
<h4 id="args">Args:</h4>
<ul>
<li><b><code>topology</code></b>: A <code>Topology</code> object that describes the physical TPU topology.</li>
<li><b><code>core_assignment</code></b>: A logical to physical core mapping, represented as a rank 3 numpy array. See the description of the <code>core_assignment</code> property for more details.</li>
</ul>
<h4 id="raises">Raises:</h4>
<ul>
<li><b><code>ValueError</code></b>: If <code>topology</code> is not <code>Topology</code> object.</li>
<li><b><code>ValueError</code></b>: If <code>core_assignment</code> is not a rank 3 numpy array.</li>
</ul>
<h2 id="properties">Properties</h2>
<h3 id="core_assignment">
<code>core_assignment</code>
</h3>
<p>The logical to physical core mapping.</p>
<h4 id="returns">Returns:</h4>
<p>An integer numpy array of rank 3, with shape <code>[num_replicas, num_cores_per_replica, topology_rank]</code>. Maps (replica, logical core) pairs to physical topology coordinates.</p>
<h3 id="num_cores_per_replica">
<code>num_cores_per_replica</code>
</h3>
<p>The number of cores per replica.</p>
<h3 id="num_replicas">
<code>num_replicas</code>
</h3>
<p>The number of replicas of the computation.</p>
<h3 id="topology">
<code>topology</code>
</h3>
<p>A <code>Topology</code> that describes the TPU topology.</p>
<h2 id="methods">Methods</h2>
<h3 id="build">
<code>build</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="at">@staticmethod</span>
build(
    topology,
    computation_shape<span class="op">=</span><span class="va">None</span>,
    computation_stride<span class="op">=</span><span class="va">None</span>,
    num_replicas<span class="op">=</span><span class="dv">1</span>
)</code></pre></div>
<h3 id="coordinates">
<code>coordinates</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">coordinates(
    replica,
    logical_core
)</code></pre></div>
<p>Returns the physical topology coordinates of a logical core.</p>
<h3 id="host_device">
<code>host_device</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">host_device(
    replica<span class="op">=</span><span class="dv">0</span>,
    logical_core<span class="op">=</span><span class="dv">0</span>,
    job<span class="op">=</span><span class="va">None</span>
)</code></pre></div>
<p>Returns the CPU device attached to a logical core.</p>
<h3 id="lookup_replicas">
<code>lookup_replicas</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">lookup_replicas(
    task_id,
    logical_core
)</code></pre></div>
<p>Lookup replica ids by task number and logical core.</p>
<h4 id="args-1">Args:</h4>
<ul>
<li><b><code>task_id</code></b>: TensorFlow task number.</li>
<li><b><code>logical_core</code></b>: An integer, identifying a logical core.</li>
</ul>
<h4 id="returns-1">Returns:</h4>
<p>A sorted list of the replicas that are attached to that task and logical_core.</p>
<h4 id="raises-1">Raises:</h4>
<ul>
<li><b><code>ValueError</code></b>: If no replica exists in the task which contains the logical core.</li>
</ul>
<h3 id="tpu_device">
<code>tpu_device</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">tpu_device(
    replica<span class="op">=</span><span class="dv">0</span>,
    logical_core<span class="op">=</span><span class="dv">0</span>,
    job<span class="op">=</span><span class="va">None</span>
)</code></pre></div>
<p>Returns the name of the TPU device assigned to a logical core.</p>
<h3 id="tpu_ordinal">
<code>tpu_ordinal</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">tpu_ordinal(
    replica<span class="op">=</span><span class="dv">0</span>,
    logical_core<span class="op">=</span><span class="dv">0</span>
)</code></pre></div>
<p>Returns the ordinal of the TPU device assigned to a logical core.</p>

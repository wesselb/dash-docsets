<div itemscope="" itemtype="http://developers.google.com/ReferenceObject">
<p><meta itemprop="name" content="tf.keras.layers.SimpleRNN" /> <meta itemprop="path" content="Stable" /> <meta itemprop="property" content="activation"/> <meta itemprop="property" content="bias_constraint"/> <meta itemprop="property" content="bias_initializer"/> <meta itemprop="property" content="bias_regularizer"/> <meta itemprop="property" content="dropout"/> <meta itemprop="property" content="kernel_constraint"/> <meta itemprop="property" content="kernel_initializer"/> <meta itemprop="property" content="kernel_regularizer"/> <meta itemprop="property" content="recurrent_constraint"/> <meta itemprop="property" content="recurrent_dropout"/> <meta itemprop="property" content="recurrent_initializer"/> <meta itemprop="property" content="recurrent_regularizer"/> <meta itemprop="property" content="states"/> <meta itemprop="property" content="units"/> <meta itemprop="property" content="use_bias"/> <meta itemprop="property" content="__init__"/> <meta itemprop="property" content="get_initial_state"/> <meta itemprop="property" content="reset_states"/></p>
</div>
<a name="//apple_ref/cpp/Class/tf.keras.layers.SimpleRNN" class="dashAnchor"></a><h1 id="tf.keras.layers.simplernn">tf.keras.layers.SimpleRNN</h1>
<h2 id="class-simplernn">Class <code>SimpleRNN</code></h2>
<p>Fully-connected RNN where the output is to be fed back to input.</p>
<p>Inherits From: <a href="../../../tf/keras/layers/RNN.html"><code>RNN</code></a></p>
<h3 id="aliases">Aliases:</h3>
<ul>
<li>Class <code>tf.compat.v1.keras.layers.SimpleRNN</code></li>
<li>Class <code>tf.compat.v2.keras.layers.SimpleRNN</code></li>
<li>Class <code>tf.keras.layers.SimpleRNN</code></li>
</ul>
<p>Defined in <a href="/code/stable/tensorflow/python/keras/layers/recurrent.py"><code>python/keras/layers/recurrent.py</code></a>.</p>
<!-- Placeholder for "Used in" -->
<h4 id="arguments">Arguments:</h4>
<ul>
<li><b><code>units</code></b>: Positive integer, dimensionality of the output space.</li>
<li><b><code>activation</code></b>: Activation function to use. Default: hyperbolic tangent (<code>tanh</code>). If you pass None, no activation is applied (ie. &quot;linear&quot; activation: <code>a(x) = x</code>).</li>
<li><b><code>use_bias</code></b>: Boolean, whether the layer uses a bias vector.</li>
<li><b><code>kernel_initializer</code></b>: Initializer for the <code>kernel</code> weights matrix, used for the linear transformation of the inputs.</li>
<li><b><code>recurrent_initializer</code></b>: Initializer for the <code>recurrent_kernel</code> weights matrix, used for the linear transformation of the recurrent state.</li>
<li><b><code>bias_initializer</code></b>: Initializer for the bias vector.</li>
<li><b><code>kernel_regularizer</code></b>: Regularizer function applied to the <code>kernel</code> weights matrix.</li>
<li><b><code>recurrent_regularizer</code></b>: Regularizer function applied to the <code>recurrent_kernel</code> weights matrix.</li>
<li><b><code>bias_regularizer</code></b>: Regularizer function applied to the bias vector.</li>
<li><b><code>activity_regularizer</code></b>: Regularizer function applied to the output of the layer (its &quot;activation&quot;)..</li>
<li><b><code>kernel_constraint</code></b>: Constraint function applied to the <code>kernel</code> weights matrix.</li>
<li><b><code>recurrent_constraint</code></b>: Constraint function applied to the <code>recurrent_kernel</code> weights matrix.</li>
<li><b><code>bias_constraint</code></b>: Constraint function applied to the bias vector.</li>
<li><b><code>dropout</code></b>: Float between 0 and 1. Fraction of the units to drop for the linear transformation of the inputs.</li>
<li><b><code>recurrent_dropout</code></b>: Float between 0 and 1. Fraction of the units to drop for the linear transformation of the recurrent state.</li>
<li><b><code>return_sequences</code></b>: Boolean. Whether to return the last output in the output sequence, or the full sequence.</li>
<li><b><code>return_state</code></b>: Boolean. Whether to return the last state in addition to the output.</li>
<li><b><code>go_backwards</code></b>: Boolean (default False). If True, process the input sequence backwards and return the reversed sequence.</li>
<li><b><code>stateful</code></b>: Boolean (default False). If True, the last state for each sample at index i in a batch will be used as initial state for the sample of index i in the following batch.</li>
<li><b><code>unroll</code></b>: Boolean (default False). If True, the network will be unrolled, else a symbolic loop will be used. Unrolling can speed-up a RNN, although it tends to be more memory-intensive. Unrolling is only suitable for short sequences.</li>
</ul>
<h4 id="call-arguments">Call arguments:</h4>
<ul>
<li><b><code>inputs</code></b>: A 3D tensor.</li>
<li><b><code>mask</code></b>: Binary tensor of shape <code>(samples, timesteps)</code> indicating whether a given timestep should be masked.</li>
<li><b><code>training</code></b>: Python boolean indicating whether the layer should behave in training mode or in inference mode. This argument is passed to the cell when calling it. This is only relevant if <code>dropout</code> or <code>recurrent_dropout</code> is used.</li>
<li><b><code>initial_state</code></b>: List of initial state tensors to be passed to the first call of the cell.</li>
</ul>
<h2 id="__init__">
<code><strong>init</strong></code>
</h2>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="fu">__init__</span>(
    units,
    activation<span class="op">=</span><span class="st">&#39;tanh&#39;</span>,
    use_bias<span class="op">=</span><span class="va">True</span>,
    kernel_initializer<span class="op">=</span><span class="st">&#39;glorot_uniform&#39;</span>,
    recurrent_initializer<span class="op">=</span><span class="st">&#39;orthogonal&#39;</span>,
    bias_initializer<span class="op">=</span><span class="st">&#39;zeros&#39;</span>,
    kernel_regularizer<span class="op">=</span><span class="va">None</span>,
    recurrent_regularizer<span class="op">=</span><span class="va">None</span>,
    bias_regularizer<span class="op">=</span><span class="va">None</span>,
    activity_regularizer<span class="op">=</span><span class="va">None</span>,
    kernel_constraint<span class="op">=</span><span class="va">None</span>,
    recurrent_constraint<span class="op">=</span><span class="va">None</span>,
    bias_constraint<span class="op">=</span><span class="va">None</span>,
    dropout<span class="op">=</span><span class="fl">0.0</span>,
    recurrent_dropout<span class="op">=</span><span class="fl">0.0</span>,
    return_sequences<span class="op">=</span><span class="va">False</span>,
    return_state<span class="op">=</span><span class="va">False</span>,
    go_backwards<span class="op">=</span><span class="va">False</span>,
    stateful<span class="op">=</span><span class="va">False</span>,
    unroll<span class="op">=</span><span class="va">False</span>,
    <span class="op">**</span>kwargs
)</code></pre></div>
<h2 id="properties">Properties</h2>
<h3 id="activation">
<code>activation</code>
</h3>
<h3 id="bias_constraint">
<code>bias_constraint</code>
</h3>
<h3 id="bias_initializer">
<code>bias_initializer</code>
</h3>
<h3 id="bias_regularizer">
<code>bias_regularizer</code>
</h3>
<h3 id="dropout">
<code>dropout</code>
</h3>
<h3 id="kernel_constraint">
<code>kernel_constraint</code>
</h3>
<h3 id="kernel_initializer">
<code>kernel_initializer</code>
</h3>
<h3 id="kernel_regularizer">
<code>kernel_regularizer</code>
</h3>
<h3 id="recurrent_constraint">
<code>recurrent_constraint</code>
</h3>
<h3 id="recurrent_dropout">
<code>recurrent_dropout</code>
</h3>
<h3 id="recurrent_initializer">
<code>recurrent_initializer</code>
</h3>
<h3 id="recurrent_regularizer">
<code>recurrent_regularizer</code>
</h3>
<h3 id="states">
<code>states</code>
</h3>
<h3 id="units">
<code>units</code>
</h3>
<h3 id="use_bias">
<code>use_bias</code>
</h3>
<h2 id="methods">Methods</h2>
<h3 id="get_initial_state">
<code>get_initial_state</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">get_initial_state(inputs)</code></pre></div>
<h3 id="reset_states">
<code>reset_states</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">reset_states(states<span class="op">=</span><span class="va">None</span>)</code></pre></div>

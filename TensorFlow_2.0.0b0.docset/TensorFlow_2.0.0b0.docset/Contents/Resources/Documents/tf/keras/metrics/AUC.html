<div itemscope="" itemtype="http://developers.google.com/ReferenceObject">
<p><meta itemprop="name" content="tf.keras.metrics.AUC" /> <meta itemprop="path" content="Stable" /> <meta itemprop="property" content="__init__"/> <meta itemprop="property" content="interpolate_pr_auc"/> <meta itemprop="property" content="reset_states"/> <meta itemprop="property" content="result"/> <meta itemprop="property" content="update_state"/></p>
</div>
<a name="//apple_ref/cpp/Class/tf.keras.metrics.AUC" class="dashAnchor"></a><h1 id="tf.keras.metrics.auc">tf.keras.metrics.AUC</h1>
<h2 id="class-auc">Class <code>AUC</code></h2>
<p>Computes the approximate AUC (Area under the curve) via a Riemann sum.</p>
<p>Inherits From: <a href="../../../tf/keras/metrics/Metric.html"><code>Metric</code></a></p>
<h3 id="aliases">Aliases:</h3>
<ul>
<li>Class <code>tf.compat.v1.keras.metrics.AUC</code></li>
<li>Class <code>tf.compat.v2.keras.metrics.AUC</code></li>
<li>Class <code>tf.compat.v2.metrics.AUC</code></li>
<li>Class <code>tf.keras.metrics.AUC</code></li>
<li>Class <code>tf.metrics.AUC</code></li>
</ul>
<p>Defined in <a href="/code/stable/tensorflow/python/keras/metrics.py"><code>python/keras/metrics.py</code></a>.</p>
<!-- Placeholder for "Used in" -->
<p>This metric creates four local variables, <code>true_positives</code>, <code>true_negatives</code>, <code>false_positives</code> and <code>false_negatives</code> that are used to compute the AUC. To discretize the AUC curve, a linearly spaced set of thresholds is used to compute pairs of recall and precision values. The area under the ROC-curve is therefore computed using the height of the recall values by the false positive rate, while the area under the PR-curve is the computed using the height of the precision values by the recall.</p>
<p>This value is ultimately returned as <code>auc</code>, an idempotent operation that computes the area under a discretized curve of precision versus recall values (computed using the aforementioned variables). The <code>num_thresholds</code> variable controls the degree of discretization with larger numbers of thresholds more closely approximating the true AUC. The quality of the approximation may vary dramatically depending on <code>num_thresholds</code>. The <code>thresholds</code> parameter can be used to manually specify thresholds which split the predictions more evenly.</p>
<p>For best results, <code>predictions</code> should be distributed approximately uniformly in the range [0, 1] and not peaked around 0 or 1. The quality of the AUC approximation may be poor if this is not the case. Setting <code>summation_method</code> to 'minoring' or 'majoring' can help quantify the error in the approximation by providing lower or upper bound estimate of the AUC.</p>
<p>If <code>sample_weight</code> is <code>None</code>, weights default to 1. Use <code>sample_weight</code> of 0 to mask values.</p>
<h4 id="usage">Usage:</h4>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">m <span class="op">=</span> tf.keras.metrics.AUC(num_thresholds<span class="op">=</span><span class="dv">3</span>)
m.update_state([<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1</span>], [<span class="dv">0</span>, <span class="fl">0.5</span>, <span class="fl">0.3</span>, <span class="fl">0.9</span>])

<span class="co"># threshold values are [0 - 1e-7, 0.5, 1 + 1e-7]</span>
<span class="co"># tp = [2, 1, 0], fp = [2, 0, 0], fn = [0, 1, 2], tn = [0, 2, 2]</span>
<span class="co"># recall = [1, 0.5, 0], fp_rate = [1, 0, 0]</span>
<span class="co"># auc = ((((1+0.5)/2)*(1-0))+ (((0.5+0)/2)*(0-0))) = 0.75</span>

<span class="bu">print</span>(<span class="st">&#39;Final result: &#39;</span>, m.result().numpy())  <span class="co"># Final result: 0.75</span></code></pre></div>
<p>Usage with tf.keras API:</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">model <span class="op">=</span> tf.keras.Model(inputs, outputs)
model.<span class="bu">compile</span>(<span class="st">&#39;sgd&#39;</span>, loss<span class="op">=</span><span class="st">&#39;mse&#39;</span>, metrics<span class="op">=</span>[tf.keras.metrics.AUC()])</code></pre></div>
<h2 id="__init__">
<code><strong>init</strong></code>
</h2>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="fu">__init__</span>(
    num_thresholds<span class="op">=</span><span class="dv">200</span>,
    curve<span class="op">=</span><span class="st">&#39;ROC&#39;</span>,
    summation_method<span class="op">=</span><span class="st">&#39;interpolation&#39;</span>,
    name<span class="op">=</span><span class="va">None</span>,
    dtype<span class="op">=</span><span class="va">None</span>,
    thresholds<span class="op">=</span><span class="va">None</span>
)</code></pre></div>
<p>Creates an <code>AUC</code> instance.</p>
<h4 id="args">Args:</h4>
<ul>
<li><b><code>num_thresholds</code></b>: (Optional) Defaults to 200. The number of thresholds to use when discretizing the roc curve. Values must be &gt; 1.</li>
<li><b><code>curve</code></b>: (Optional) Specifies the name of the curve to be computed, 'ROC' [default] or 'PR' for the Precision-Recall-curve.</li>
<li><b><code>summation_method</code></b>: (Optional) Specifies the Riemann summation method used (https://en.wikipedia.org/wiki/Riemann_sum): 'interpolation' [default], applies mid-point summation scheme for <code>ROC</code>. For PR-AUC, interpolates (true/false) positives but not the ratio that is precision (see Davis &amp; Goadrich 2006 for details); 'minoring' that applies left summation for increasing intervals and right summation for decreasing intervals; 'majoring' that does the opposite.</li>
<li><b><code>name</code></b>: (Optional) string name of the metric instance.</li>
<li><b><code>dtype</code></b>: (Optional) data type of the metric result.</li>
<li><b><code>thresholds</code></b>: (Optional) A list of floating point values to use as the thresholds for discretizing the curve. If set, the <code>num_thresholds</code> parameter is ignored. Values should be in [0, 1]. Endpoint thresholds equal to {-epsilon, 1+epsilon} for a small positive epsilon value will be automatically included with these to correctly handle predictions equal to exactly 0 or 1.</li>
</ul>
<h2 id="methods">Methods</h2>
<h3 id="interpolate_pr_auc">
<code>interpolate_pr_auc</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">interpolate_pr_auc()</code></pre></div>
<p>Interpolation formula inspired by section 4 of Davis &amp; Goadrich 2006.</p>
<p>https://www.biostat.wisc.edu/~page/rocpr.pdf</p>
<p>Note here we derive &amp; use a closed formula not present in the paper as follows:</p>
<p>Precision = TP / (TP + FP) = TP / P</p>
<p>Modeling all of TP (true positive), FP (false positive) and their sum P = TP + FP (predicted positive) as varying linearly within each interval [A, B] between successive thresholds, we get</p>
<p>Precision slope = dTP / dP = (TP_B - TP_A) / (P_B - P_A) = (TP - TP_A) / (P - P_A) Precision = (TP_A + slope * (P - P_A)) / P</p>
<p>The area within the interval is (slope / total_pos_weight) times</p>
<p>int_A^B{Precision.dP} = int_A^B{(TP_A + slope * (P - P_A)) * dP / P} int_A^B{Precision.dP} = int_A^B{slope * dP + intercept * dP / P}</p>
<p>where intercept = TP_A - slope * P_A = TP_B - slope * P_B, resulting in</p>
<p>int_A^B{Precision.dP} = TP_B - TP_A + intercept * log(P_B / P_A)</p>
<p>Bringing back the factor (slope / total_pos_weight) we'd put aside, we get</p>
<p>slope * [dTP + intercept * log(P_B / P_A)] / total_pos_weight</p>
<p>where dTP == TP_B - TP_A.</p>
<p>Note that when P_A == 0 the above calculation simplifies into</p>
<p>int_A^B{Precision.dTP} = int_A^B{slope * dTP} = slope * (TP_B - TP_A)</p>
<p>which is really equivalent to imputing constant precision throughout the first bucket having &gt;0 true positives.</p>
<h4 id="returns">Returns:</h4>
<ul>
<li><b><code>pr_auc</code></b>: an approximation of the area under the P-R curve.</li>
</ul>
<h3 id="reset_states">
<code>reset_states</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">reset_states()</code></pre></div>
<p>Resets all of the metric state variables.</p>
<p>This function is called between epochs/steps, when a metric is evaluated during training.</p>
<h3 id="result">
<code>result</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">result()</code></pre></div>
<p>Computes and returns the metric value tensor.</p>
<p>Result computation is an idempotent operation that simply calculates the metric value using the state variables.</p>
<h3 id="update_state">
<code>update_state</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">update_state(
    y_true,
    y_pred,
    sample_weight<span class="op">=</span><span class="va">None</span>
)</code></pre></div>
<p>Accumulates confusion matrix statistics.</p>
<h4 id="args-1">Args:</h4>
<ul>
<li><b><code>y_true</code></b>: The ground truth values.</li>
<li><b><code>y_pred</code></b>: The predicted values.</li>
<li><b><code>sample_weight</code></b>: Optional weighting of each example. Defaults to 1. Can be a <code>Tensor</code> whose rank is either 0, or the same rank as <code>y_true</code>, and must be broadcastable to <code>y_true</code>.</li>
</ul>
<h4 id="returns-1">Returns:</h4>
<p>Update op.</p>

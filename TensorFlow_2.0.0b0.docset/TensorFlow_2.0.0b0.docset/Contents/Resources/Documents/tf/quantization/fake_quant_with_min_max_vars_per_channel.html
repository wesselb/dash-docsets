<div itemscope="" itemtype="http://developers.google.com/ReferenceObject">
<p><meta itemprop="name" content="tf.quantization.fake_quant_with_min_max_vars_per_channel" /> <meta itemprop="path" content="Stable" /></p>
</div>
<a name="//apple_ref/cpp/Function/tf.quantization.fake_quant_with_min_max_vars_per_channel" class="dashAnchor"></a><h1 id="tf.quantization.fake_quant_with_min_max_vars_per_channel">tf.quantization.fake_quant_with_min_max_vars_per_channel</h1>
<p>Fake-quantize the 'inputs' tensor of type float and one of the shapes: <code>[d]</code>,</p>
<h3 id="aliases">Aliases:</h3>
<ul>
<li><code>tf.compat.v1.fake_quant_with_min_max_vars_per_channel</code></li>
<li><code>tf.compat.v1.quantization.fake_quant_with_min_max_vars_per_channel</code></li>
<li><code>tf.compat.v2.quantization.fake_quant_with_min_max_vars_per_channel</code></li>
<li><code>tf.quantization.fake_quant_with_min_max_vars_per_channel</code></li>
</ul>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">tf.quantization.fake_quant_with_min_max_vars_per_channel(
    inputs,
    <span class="bu">min</span>,
    <span class="bu">max</span>,
    num_bits<span class="op">=</span><span class="dv">8</span>,
    narrow_range<span class="op">=</span><span class="va">False</span>,
    name<span class="op">=</span><span class="va">None</span>
)</code></pre></div>
<p>Defined in generated file: <code>python/ops/gen_array_ops.py</code>.</p>
<!-- Placeholder for "Used in" -->
<p><code>[b, d]</code> <code>[b, h, w, d]</code> via per-channel floats <code>min</code> and <code>max</code> of shape <code>[d]</code> to 'outputs' tensor of same shape as <code>inputs</code>.</p>
<p><code>[min; max]</code> define the clamping range for the <code>inputs</code> data. <code>inputs</code> values are quantized into the quantization range (<code>[0; 2^num_bits - 1]</code> when <code>narrow_range</code> is false and <code>[1; 2^num_bits - 1]</code> when it is true) and then de-quantized and output as floats in <code>[min; max]</code> interval. <code>num_bits</code> is the bitwidth of the quantization; between 2 and 16, inclusive.</p>
<p>Before quantization, <code>min</code> and <code>max</code> values are adjusted with the following logic. It is suggested to have <code>min &lt;= 0 &lt;= max</code>. If <code>0</code> is not in the range of values, the behavior can be unexpected: If <code>0 &lt; min &lt; max</code>: <code>min_adj = 0</code> and <code>max_adj = max - min</code>. If <code>min &lt; max &lt; 0</code>: <code>min_adj = min - max</code> and <code>max_adj = 0</code>. If <code>min &lt;= 0 &lt;= max</code>: <code>scale = (max - min) / (2^num_bits - 1)</code>, <code>min_adj = scale * round(min / scale)</code> and <code>max_adj = max + min_adj - min</code>.</p>
<p>This operation has a gradient and thus allows for training <code>min</code> and <code>max</code> values.</p>
<h4 id="args">Args:</h4>
<ul>
<li><b><code>inputs</code></b>: A <code>Tensor</code> of type <code>float32</code>.</li>
<li><b><code>min</code></b>: A <code>Tensor</code> of type <code>float32</code>.</li>
<li><b><code>max</code></b>: A <code>Tensor</code> of type <code>float32</code>.</li>
<li><b><code>num_bits</code></b>: An optional <code>int</code>. Defaults to <code>8</code>.</li>
<li><b><code>narrow_range</code></b>: An optional <code>bool</code>. Defaults to <code>False</code>.</li>
<li><b><code>name</code></b>: A name for the operation (optional).</li>
</ul>
<h4 id="returns">Returns:</h4>
<p>A <code>Tensor</code> of type <code>float32</code>.</p>

<!-- This file is machine generated: DO NOT EDIT! -->
<h1 id="higher-order-functions">Higher Order Functions</h1>
<p>Note: Functions taking <code>Tensor</code> arguments can also take anything accepted by <a href="framework.md#convert_to_tensor"><code>tf.convert_to_tensor</code></a>.</p>
<p>[TOC]</p>
<p>Functional operations.</p>
<h2 id="higher-order-operators">Higher Order Operators</h2>
<p>TensorFlow provides several higher order operators to simplify the common map-reduce programming patterns.</p>
<hr />
<h3 id="tf.map_fnfn-elems-dtypenone-parallel_iterations10-back_proptrue-swap_memoryfalse-infer_shapetrue-namenone"><a name="//apple_ref/cpp/Function/map_fn" class="dashAnchor"></a><code id="map_fn">tf.map_fn(fn, elems, dtype=None, parallel_iterations=10, back_prop=True, swap_memory=False, infer_shape=True, name=None)</code></h3>
<p>map on the list of tensors unpacked from <code>elems</code> on dimension 0.</p>
<p>The simplest version of <code>map</code> repeatedly applies the callable <code>fn</code> to a sequence of elements from first to last. The elements are made of the tensors unpacked from <code>elems</code>. <code>dtype</code> is the data type of the return value of <code>fn</code>. Users must provide <code>dtype</code> if it is different from the data type of <code>elems</code>.</p>
<p>Suppose that <code>elems</code> is unpacked into <code>values</code>, a list of tensors. The shape of the result tensor is <code>[values.shape[0]] + fn(values[0]).shape</code>.</p>
<p>This method also allows multi-arity <code>elems</code> and output of <code>fn</code>. If <code>elems</code> is a (possibly nested) list or tuple of tensors, then each of these tensors must have a matching first (unpack) dimension. The signature of <code>fn</code> may match the structure of <code>elems</code>. That is, if <code>elems</code> is <code>(t1, [t2, t3, [t4, t5]])</code>, then an appropriate signature for <code>fn</code> is: <code>fn = lambda (t1, [t2, t3, [t4, t5]]):</code>.</p>
<p>Furthermore, <code>fn</code> may emit a different structure than its input. For example, <code>fn</code> may look like: <code>fn = lambda t1: return (t1 + 1, t1 - 1)</code>. In this case, the <code>dtype</code> parameter is not optional: <code>dtype</code> must be a type or (possibly nested) tuple of types matching the output of <code>fn</code>.</p>
<p>To apply a functional operation to the nonzero elements of a SparseTensor one of the following methods is recommended. First, if the function is expressible as TensorFlow ops, use</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">  result <span class="op">=</span> SparseTensor(<span class="bu">input</span>.indices, fn(<span class="bu">input</span>.values), <span class="bu">input</span>.shape)</code></pre></div>
<p>If, however, the function is not expressible as a TensorFlow op, then use</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">result <span class="op">=</span> SparseTensor(<span class="bu">input</span>.indices, map_fn(fn, <span class="bu">input</span>.values), <span class="bu">input</span>.shape)</code></pre></div>
<p>instead.</p>
<h5 id="args">Args:</h5>
<ul>
<li><b><code>fn</code></b>: The callable to be performed. It accepts one argument, which will have the same (possibly nested) structure as <code>elems</code>. Its output must have the same structure as <code>dtype</code> if one is provided, otherwise it must have the same structure as <code>elems</code>.</li>
<li><b><code>elems</code></b>: A tensor or (possibly nested) sequence of tensors, each of which will be unpacked along their first dimension. The nested sequence of the resulting slices will be applied to <code>fn</code>.</li>
<li><b><code>dtype</code></b>: (optional) The output type(s) of <code>fn</code>. If <code>fn</code> returns a structure of Tensors differing from the structure of <code>elems</code>, then <code>dtype</code> is not optional and must have the same structure as the output of <code>fn</code>.</li>
<li><b><code>parallel_iterations</code></b>: (optional) The number of iterations allowed to run in parallel.</li>
<li><b><code>back_prop</code></b>: (optional) True enables support for back propagation.</li>
<li><b><code>swap_memory</code></b>: (optional) True enables GPU-CPU memory swapping.</li>
<li><b><code>infer_shape</code></b>: (optional) False disables tests for consistent output shapes.</li>
<li><b><code>name</code></b>: (optional) Name prefix for the returned tensors.</li>
</ul>
<h5 id="returns">Returns:</h5>
<p>A tensor or (possibly nested) sequence of tensors. Each tensor packs the results of applying <code>fn</code> to tensors unpacked from <code>elems</code> along the first dimension, from first to last.</p>
<h5 id="raises">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>fn</code> is not callable or the structure of the output of <code>fn</code> and <code>dtype</code> do not match, or if elems is a SparseTensor.</li>
<li><b><code>ValueError</code></b>: if the lengths of the output of <code>fn</code> and <code>dtype</code> do not match.</li>
</ul>
<h5 id="examples">Examples:</h5>
<p><code>python   elems = np.array([1, 2, 3, 4, 5, 6])   squares = map_fn(lambda x: x * x, elems)   # squares == [1, 4, 9, 16, 25, 36]</code></p>
<p><code>python   elems = (np.array([1, 2, 3]), np.array([-1, 1, -1]))   alternate = map_fn(lambda x: x[0] * x[1], elems, dtype=tf.int64)   # alternate == [-1, 2, -3]</code></p>
<p><code>python   elems = np.array([1, 2, 3])   alternates = map_fn(lambda x: (x, -x), elems, dtype=(tf.int64, tf.int64))   # alternates[0] == [1, 2, 3]   # alternates[1] == [-1, -2, -3]</code></p>
<hr />
<h3 id="tf.foldlfn-elems-initializernone-parallel_iterations10-back_proptrue-swap_memoryfalse-namenone"><a name="//apple_ref/cpp/Function/foldl" class="dashAnchor"></a><code id="foldl">tf.foldl(fn, elems, initializer=None, parallel_iterations=10, back_prop=True, swap_memory=False, name=None)</code></h3>
<p>foldl on the list of tensors unpacked from <code>elems</code> on dimension 0.</p>
<p>This foldl operator repeatedly applies the callable <code>fn</code> to a sequence of elements from first to last. The elements are made of the tensors unpacked from <code>elems</code> on dimension 0. The callable fn takes two tensors as arguments. The first argument is the accumulated value computed from the preceding invocation of fn. If <code>initializer</code> is None, <code>elems</code> must contain at least one element, and its first element is used as the initializer.</p>
<p>Suppose that <code>elems</code> is unpacked into <code>values</code>, a list of tensors. The shape of the result tensor is fn(initializer, values[0]).shape`.</p>
<h5 id="args-1">Args:</h5>
<ul>
<li><b><code>fn</code></b>: The callable to be performed.</li>
<li><b><code>elems</code></b>: A tensor to be unpacked on dimension 0.</li>
<li><b><code>initializer</code></b>: (optional) The initial value for the accumulator.</li>
<li><b><code>parallel_iterations</code></b>: (optional) The number of iterations allowed to run in parallel.</li>
<li><b><code>back_prop</code></b>: (optional) True enables support for back propagation.</li>
<li><b><code>swap_memory</code></b>: (optional) True enables GPU-CPU memory swapping.</li>
<li><b><code>name</code></b>: (optional) Name prefix for the returned tensors.</li>
</ul>
<h5 id="returns-1">Returns:</h5>
<p>A tensor resulting from applying <code>fn</code> consecutively to the list of tensors unpacked from <code>elems</code>, from first to last.</p>
<h5 id="raises-1">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>fn</code> is not callable.</li>
</ul>
<h5 id="example">Example:</h5>
<p><code>python   elems = [1, 2, 3, 4, 5, 6]   sum = foldl(lambda a, x: a + x, elems)   # sum == 21</code></p>
<hr />
<h3 id="tf.foldrfn-elems-initializernone-parallel_iterations10-back_proptrue-swap_memoryfalse-namenone"><a name="//apple_ref/cpp/Function/foldr" class="dashAnchor"></a><code id="foldr">tf.foldr(fn, elems, initializer=None, parallel_iterations=10, back_prop=True, swap_memory=False, name=None)</code></h3>
<p>foldr on the list of tensors unpacked from <code>elems</code> on dimension 0.</p>
<p>This foldr operator repeatedly applies the callable <code>fn</code> to a sequence of elements from last to first. The elements are made of the tensors unpacked from <code>elems</code>. The callable fn takes two tensors as arguments. The first argument is the accumulated value computed from the preceding invocation of fn. If <code>initializer</code> is None, <code>elems</code> must contain at least one element, and its first element is used as the initializer.</p>
<p>Suppose that <code>elems</code> is unpacked into <code>values</code>, a list of tensors. The shape of the result tensor is <code>fn(initializer, values[0]).shape</code>.</p>
<h5 id="args-2">Args:</h5>
<ul>
<li><b><code>fn</code></b>: The callable to be performed.</li>
<li><b><code>elems</code></b>: A tensor that is unpacked into a sequence of tensors to apply <code>fn</code>.</li>
<li><b><code>initializer</code></b>: (optional) The initial value for the accumulator.</li>
<li><b><code>parallel_iterations</code></b>: (optional) The number of iterations allowed to run in parallel.</li>
<li><b><code>back_prop</code></b>: (optional) True enables support for back propagation.</li>
<li><b><code>swap_memory</code></b>: (optional) True enables GPU-CPU memory swapping.</li>
<li><b><code>name</code></b>: (optional) Name prefix for the returned tensors.</li>
</ul>
<h5 id="returns-2">Returns:</h5>
<p>A tensor resulting from applying <code>fn</code> consecutively to the list of tensors unpacked from <code>elems</code>, from last to first.</p>
<h5 id="raises-2">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>fn</code> is not callable.</li>
</ul>
<h5 id="example-1">Example:</h5>
<p><code>python   elems = [1, 2, 3, 4, 5, 6]   sum = foldr(lambda a, x: a + x, elems)   # sum == 21</code></p>
<hr />
<h3 id="tf.scanfn-elems-initializernone-parallel_iterations10-back_proptrue-swap_memoryfalse-infer_shapetrue-namenone"><a name="//apple_ref/cpp/Function/scan" class="dashAnchor"></a><code id="scan">tf.scan(fn, elems, initializer=None, parallel_iterations=10, back_prop=True, swap_memory=False, infer_shape=True, name=None)</code></h3>
<p>scan on the list of tensors unpacked from <code>elems</code> on dimension 0.</p>
<p>The simplest version of <code>scan</code> repeatedly applies the callable <code>fn</code> to a sequence of elements from first to last. The elements are made of the tensors unpacked from <code>elems</code> on dimension 0. The callable fn takes two tensors as arguments. The first argument is the accumulated value computed from the preceding invocation of fn. If <code>initializer</code> is None, <code>elems</code> must contain at least one element, and its first element is used as the initializer.</p>
<p>Suppose that <code>elems</code> is unpacked into <code>values</code>, a list of tensors. The shape of the result tensor is <code>[len(values)] + fn(initializer, values[0]).shape</code>.</p>
<p>This method also allows multi-arity <code>elems</code> and accumulator. If <code>elems</code> is a (possibly nested) list or tuple of tensors, then each of these tensors must have a matching first (unpack) dimension. The second argument of <code>fn</code> must match the structure of <code>elems</code>.</p>
<p>If no <code>initializer</code> is provided, the output structure and dtypes of <code>fn</code> are assumed to be the same as its input; and in this case, the first argument of <code>fn</code> must match the structure of <code>elems</code>.</p>
<p>If an <code>initializer</code> is provided, then the output of <code>fn</code> must have the same structure as <code>initializer</code>; and the first argument of <code>fn</code> must match this structure.</p>
<p>For example, if <code>elems</code> is <code>(t1, [t2, t3])</code> and <code>initializer</code> is <code>[i1, i2]</code> then an appropriate signature for <code>fn</code> in <code>python2</code> is: <code>fn = lambda (acc_p1, acc_p2), (t1 [t2, t3]):</code> and <code>fn</code> must return a list, <code>[acc_n1, acc_n2]</code>. An alternative correct signature for <code>fn</code>, and the one that works in <code>python3</code>, is: <code>fn = lambda a, t:</code>, where <code>a</code> and <code>t</code> correspond to the input tuples.</p>
<h5 id="args-3">Args:</h5>
<ul>
<li><b><code>fn</code></b>: The callable to be performed. It accepts two arguments. The first will have the same structure as <code>initializer</code> if one is provided, otherwise it will have the same structure as <code>elems</code>. The second will have the same (possibly nested) structure as <code>elems</code>. Its output must have the same structure as <code>initializer</code> if one is provided, otherwise it must have the same structure as <code>elems</code>.</li>
<li><b><code>elems</code></b>: A tensor or (possibly nested) sequence of tensors, each of which will be unpacked along their first dimension. The nested sequence of the resulting slices will be the first argument to <code>fn</code>.</li>
<li><b><code>initializer</code></b>: (optional) A tensor or (possibly nested) sequence of tensors, initial value for the accumulator, and the expected output type of <code>fn</code>.</li>
<li><b><code>parallel_iterations</code></b>: (optional) The number of iterations allowed to run in parallel.</li>
<li><b><code>back_prop</code></b>: (optional) True enables support for back propagation.</li>
<li><b><code>swap_memory</code></b>: (optional) True enables GPU-CPU memory swapping.</li>
<li><b><code>infer_shape</code></b>: (optional) False disables tests for consistent output shapes.</li>
<li><b><code>name</code></b>: (optional) Name prefix for the returned tensors.</li>
</ul>
<h5 id="returns-3">Returns:</h5>
<p>A tensor or (possibly nested) sequence of tensors. Each tensor packs the results of applying <code>fn</code> to tensors unpacked from <code>elems</code> along the first dimension, and the previous accumulator value(s), from first to last.</p>
<h5 id="raises-3">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>fn</code> is not callable or the structure of the output of <code>fn</code> and <code>initializer</code> do not match.</li>
<li><b><code>ValueError</code></b>: if the lengths of the output of <code>fn</code> and <code>initializer</code> do not match.</li>
</ul>
<h5 id="examples-1">Examples:</h5>
<p><code>python   elems = np.array([1, 2, 3, 4, 5, 6])   sum = scan(lambda a, x: a + x, elems)   # sum == [1, 3, 6, 10, 15, 21]</code></p>
<p><code>python   elems = np.array([1, 2, 3, 4, 5, 6])   initializer = np.array(0)   sum_one = scan(       lambda a, x: x[0] - x[1] + a, (elems + 1, elems), initializer)   # sum_one == [1, 2, 3, 4, 5, 6]</code></p>
<p><code>python   elems = np.array([1, 0, 0, 0, 0, 0])   initializer = (np.array(0), np.array(1))   fibonaccis = scan(lambda a, _: (a[1], a[0] + a[1]), elems, initializer)   # fibonaccis == ([1, 1, 2, 3, 5, 8], [1, 2, 3, 5, 8, 13])</code></p>

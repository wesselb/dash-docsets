<!-- This file is machine generated: DO NOT EDIT! -->
<h1 id="statistical-distributions-contrib">Statistical distributions (contrib)</h1>
<p>[TOC]</p>
<p>Classes representing statistical distributions and ops for working with them.</p>
<h2 id="classes-for-statistical-distributions.">Classes for statistical distributions.</h2>
<p>Classes that represent batches of statistical distributions. Each class is initialized with parameters that define the distributions.</p>
<h2 id="base-classes">Base classes</h2>
<hr />
<h3 id="class-tf.contrib.distributions.distribution"><a name="//apple_ref/cpp/Class/Distribution" class="dashAnchor"></a><code id="Distribution">class tf.contrib.distributions.Distribution</code></h3>
<p>A generic probability distribution base class.</p>
<p><code>Distribution</code> is a base class for constructing and organizing properties (e.g., mean, variance) of random variables (e.g, Bernoulli, Gaussian).</p>
<h3 id="subclassing">Subclassing</h3>
<p>Subclasses are expected to implement a leading-underscore version of the same-named function. The argument signature should be identical except for the omission of <code>name=&quot;...&quot;</code>. For example, to enable <code>log_prob(value, name=&quot;log_prob&quot;)</code> a subclass should implement <code>_log_prob(value)</code>.</p>
<p>Subclasses can append to public-level docstrings by providing docstrings for their method specializations. For example:</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="at">@distribution_util.AppendDocstring</span>(<span class="st">&quot;Some other details.&quot;</span>)
<span class="kw">def</span> _log_prob(<span class="va">self</span>, value):
  ...</code></pre></div>
<p>would add the string &quot;Some other details.&quot; to the <code>log_prob</code> function docstring. This is implemented as a simple decorator to avoid python linter complaining about missing Args/Returns/Raises sections in the partial docstrings.</p>
<h3 id="broadcasting-batching-and-shapes">Broadcasting, batching, and shapes</h3>
<p>All distributions support batches of independent distributions of that type. The batch shape is determined by broadcasting together the parameters.</p>
<p>The shape of arguments to <code>__init__</code>, <code>cdf</code>, <code>log_cdf</code>, <code>prob</code>, and <code>log_prob</code> reflect this broadcasting, as does the return value of <code>sample</code> and <code>sample_n</code>.</p>
<p><code>sample_n_shape = (n,) + batch_shape + event_shape</code>, where <code>sample_n_shape</code> is the shape of the <code>Tensor</code> returned from <code>sample_n</code>, <code>n</code> is the number of samples, <code>batch_shape</code> defines how many independent distributions there are, and <code>event_shape</code> defines the shape of samples from each of those independent distributions. Samples are independent along the <code>batch_shape</code> dimensions, but not necessarily so along the <code>event_shape</code> dimensions (depending on the particulars of the underlying distribution).</p>
<p>Using the <code>Uniform</code> distribution as an example:</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">minval <span class="op">=</span> <span class="fl">3.0</span>
maxval <span class="op">=</span> [[<span class="fl">4.0</span>, <span class="fl">6.0</span>],
          [<span class="fl">10.0</span>, <span class="fl">12.0</span>]]

<span class="co"># Broadcasting:</span>
<span class="co"># This instance represents 4 Uniform distributions. Each has a lower bound at</span>
<span class="co"># 3.0 as the `minval` parameter was broadcasted to match `maxval`&#39;s shape.</span>
u <span class="op">=</span> Uniform(minval, maxval)

<span class="co"># `event_shape` is `TensorShape([])`.</span>
event_shape <span class="op">=</span> u.get_event_shape()
<span class="co"># `event_shape_t` is a `Tensor` which will evaluate to [].</span>
event_shape_t <span class="op">=</span> u.event_shape

<span class="co"># Sampling returns a sample per distribution.  `samples` has shape</span>
<span class="co"># (5, 2, 2), which is (n,) + batch_shape + event_shape, where n=5,</span>
<span class="co"># batch_shape=(2, 2), and event_shape=().</span>
samples <span class="op">=</span> u.sample_n(<span class="dv">5</span>)

<span class="co"># The broadcasting holds across methods. Here we use `cdf` as an example. The</span>
<span class="co"># same holds for `log_cdf` and the likelihood functions.</span>

<span class="co"># `cum_prob` has shape (2, 2) as the `value` argument was broadcasted to the</span>
<span class="co"># shape of the `Uniform` instance.</span>
cum_prob_broadcast <span class="op">=</span> u.cdf(<span class="fl">4.0</span>)

<span class="co"># `cum_prob`&#39;s shape is (2, 2), one per distribution. No broadcasting</span>
<span class="co"># occurred.</span>
cum_prob_per_dist <span class="op">=</span> u.cdf([[<span class="fl">4.0</span>, <span class="fl">5.0</span>],
                           [<span class="fl">6.0</span>, <span class="fl">7.0</span>]])

<span class="co"># INVALID as the `value` argument is not broadcastable to the distribution&#39;s</span>
<span class="co"># shape.</span>
cum_prob_invalid <span class="op">=</span> u.cdf([<span class="fl">4.0</span>, <span class="fl">5.0</span>, <span class="fl">6.0</span>])</code></pre></div>
<h3 id="parameter-values-leading-to-undefined-statistics-or-distributions.">Parameter values leading to undefined statistics or distributions.</h3>
<p>Some distributions do not have well-defined statistics for all initialization parameter values. For example, the beta distribution is parameterized by positive real numbers <code>a</code> and <code>b</code>, and does not have well-defined mode if <code>a &lt; 1</code> or <code>b &lt; 1</code>.</p>
<p>The user is given the option of raising an exception or returning <code>NaN</code>.</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">a <span class="op">=</span> tf.exp(tf.matmul(logits, weights_a))
b <span class="op">=</span> tf.exp(tf.matmul(logits, weights_b))

<span class="co"># Will raise exception if ANY batch member has a &lt; 1 or b &lt; 1.</span>
dist <span class="op">=</span> distributions.beta(a, b, allow_nan_stats<span class="op">=</span><span class="va">False</span>)
mode <span class="op">=</span> dist.mode().<span class="bu">eval</span>()

<span class="co"># Will return NaN for batch members with either a &lt; 1 or b &lt; 1.</span>
dist <span class="op">=</span> distributions.beta(a, b, allow_nan_stats<span class="op">=</span><span class="va">True</span>)  <span class="co"># Default behavior</span>
mode <span class="op">=</span> dist.mode().<span class="bu">eval</span>()</code></pre></div>
<p>In all cases, an exception is raised if <em>invalid</em> parameters are passed, e.g.</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="co"># Will raise an exception if any Op is run.</span>
negative_a <span class="op">=</span> <span class="op">-</span><span class="fl">1.0</span> <span class="op">*</span> a  <span class="co"># beta distribution by definition has a &gt; 0.</span>
dist <span class="op">=</span> distributions.beta(negative_a, b, allow_nan_stats<span class="op">=</span><span class="va">True</span>)
dist.mean().<span class="bu">eval</span>()</code></pre></div>
<hr />
<h4 id="tf.contrib.distributions.distribution.__init__dtype-is_continuous-is_reparameterized-validate_args-allow_nan_stats-parametersnone-graph_parentsnone-namenone"><code id="Distribution.__init__">tf.contrib.distributions.Distribution.__init__(dtype, is_continuous, is_reparameterized, validate_args, allow_nan_stats, parameters=None, graph_parents=None, name=None)</code></h4>
<p>Constructs the <code>Distribution</code>.</p>
<p><strong>This is a private method for subclass use.</strong></p>
<h5 id="args">Args:</h5>
<ul>
<li><b><code>dtype</code></b>: The type of the event samples. <code>None</code> implies no type-enforcement.</li>
<li><b><code>is_continuous</code></b>: Python boolean. If <code>True</code> this <code>Distribution</code> is continuous over its supported domain.</li>
<li><b><code>is_reparameterized</code></b>: Python boolean. If <code>True</code> this <code>Distribution</code> can be reparameterized in terms of some standard distribution with a function whose Jacobian is constant for the support of the standard distribution.</li>
<li><b><code>validate_args</code></b>: Python boolean. Whether to validate input with asserts. If <code>validate_args</code> is <code>False</code>, and the inputs are invalid, correct behavior is not guaranteed.</li>
<li><b><code>allow_nan_stats</code></b>: Python boolean. If <code>False</code>, raise an exception if a statistic (e.g., mean, mode) is undefined for any batch member. If True, batch members with valid parameters leading to undefined statistics will return <code>NaN</code> for this statistic.</li>
<li><b><code>parameters</code></b>: Python dictionary of parameters used to instantiate this <code>Distribution</code>.</li>
<li><b><code>graph_parents</code></b>: Python list of graph prerequisites of this <code>Distribution</code>.</li>
<li><b><code>name</code></b>: A name for this distribution. Default: subclass name.</li>
</ul>
<h5 id="raises">Raises:</h5>
<ul>
<li><b><code>ValueError</code></b>: if any member of graph_parents is <code>None</code> or not a <code>Tensor</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.distribution.allow_nan_stats"><code id="Distribution.allow_nan_stats">tf.contrib.distributions.Distribution.allow_nan_stats</code></h4>
<p>Python boolean describing behavior when a stat is undefined.</p>
<p>Stats return +/- infinity when it makes sense. E.g., the variance of a Cauchy distribution is infinity. However, sometimes the statistic is undefined, e.g., if a distribution's pdf does not achieve a maximum within the support of the distribution, the mode is undefined. If the mean is undefined, then by definition the variance is undefined. E.g. the mean for Student's T for df = 1 is undefined (no clear way to say it is either + or - infinity), so the variance = E[(X - mean)^2] is also undefined.</p>
<h5 id="returns">Returns:</h5>
<ul>
<li><b><code>allow_nan_stats</code></b>: Python boolean.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.distribution.batch_shapenamebatch_shape"><code id="Distribution.batch_shape">tf.contrib.distributions.Distribution.batch_shape(name='batch_shape')</code></h4>
<p>Shape of a single sample from a single event index as a 1-D <code>Tensor</code>.</p>
<p>The product of the dimensions of the <code>batch_shape</code> is the number of independent distributions of this kind the instance represents.</p>
<h5 id="args-1">Args:</h5>
<ul>
<li><b><code>name</code></b>: name to give to the op</li>
</ul>
<h5 id="returns-1">Returns:</h5>
<ul>
<li><b><code>batch_shape</code></b>: <code>Tensor</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.distribution.cdfvalue-namecdf-condition_kwargs"><code id="Distribution.cdf">tf.contrib.distributions.Distribution.cdf(value, name='cdf', **condition_kwargs)</code></h4>
<p>Cumulative distribution function.</p>
<p>Given random variable <code>X</code>, the cumulative distribution function <code>cdf</code> is:</p>
<pre><code>cdf(x) := P[X &lt;= x]</code></pre>
<h5 id="args-2">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-2">Returns:</h5>
<ul>
<li><b><code>cdf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.distribution.copyoverride_parameters_kwargs"><code id="Distribution.copy">tf.contrib.distributions.Distribution.copy(**override_parameters_kwargs)</code></h4>
<p>Creates a deep copy of the distribution.</p>
<p>Note: the copy distribution may continue to depend on the original intialization arguments.</p>
<h5 id="args-3">Args:</h5>
<ul>
<li><b><code>**override_parameters_kwargs</code></b>: String/value dictionary of initialization arguments to override with new values.</li>
</ul>
<h5 id="returns-3">Returns:</h5>
<ul>
<li><b><code>distribution</code></b>: A new instance of <code>type(self)</code> intitialized from the union of self.parameters and override_parameters_kwargs, i.e., <code>dict(self.parameters, **override_parameters_kwargs)</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.distribution.dtype"><code id="Distribution.dtype">tf.contrib.distributions.Distribution.dtype</code></h4>
<p>The <code>DType</code> of <code>Tensor</code>s handled by this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.distribution.entropynameentropy"><code id="Distribution.entropy">tf.contrib.distributions.Distribution.entropy(name='entropy')</code></h4>
<p>Shannon entropy in nats.</p>
<hr />
<h4 id="tf.contrib.distributions.distribution.event_shapenameevent_shape"><code id="Distribution.event_shape">tf.contrib.distributions.Distribution.event_shape(name='event_shape')</code></h4>
<p>Shape of a single sample from a single batch as a 1-D int32 <code>Tensor</code>.</p>
<h5 id="args-4">Args:</h5>
<ul>
<li><b><code>name</code></b>: name to give to the op</li>
</ul>
<h5 id="returns-4">Returns:</h5>
<ul>
<li><b><code>event_shape</code></b>: <code>Tensor</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.distribution.get_batch_shape"><code id="Distribution.get_batch_shape">tf.contrib.distributions.Distribution.get_batch_shape()</code></h4>
<p>Shape of a single sample from a single event index as a <code>TensorShape</code>.</p>
<p>Same meaning as <code>batch_shape</code>. May be only partially defined.</p>
<h5 id="returns-5">Returns:</h5>
<ul>
<li><b><code>batch_shape</code></b>: <code>TensorShape</code>, possibly unknown.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.distribution.get_event_shape"><code id="Distribution.get_event_shape">tf.contrib.distributions.Distribution.get_event_shape()</code></h4>
<p>Shape of a single sample from a single batch as a <code>TensorShape</code>.</p>
<p>Same meaning as <code>event_shape</code>. May be only partially defined.</p>
<h5 id="returns-6">Returns:</h5>
<ul>
<li><b><code>event_shape</code></b>: <code>TensorShape</code>, possibly unknown.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.distribution.is_continuous"><code id="Distribution.is_continuous">tf.contrib.distributions.Distribution.is_continuous</code></h4>
<hr />
<h4 id="tf.contrib.distributions.distribution.is_reparameterized"><code id="Distribution.is_reparameterized">tf.contrib.distributions.Distribution.is_reparameterized</code></h4>
<hr />
<h4 id="tf.contrib.distributions.distribution.log_cdfvalue-namelog_cdf-condition_kwargs"><code id="Distribution.log_cdf">tf.contrib.distributions.Distribution.log_cdf(value, name='log_cdf', **condition_kwargs)</code></h4>
<p>Log cumulative distribution function.</p>
<p>Given random variable <code>X</code>, the cumulative distribution function <code>cdf</code> is:</p>
<pre><code>log_cdf(x) := Log[ P[X &lt;= x] ]</code></pre>
<p>Often, a numerical approximation can be used for <code>log_cdf(x)</code> that yields a more accurate answer than simply taking the logarithm of the <code>cdf</code> when <code>x &lt;&lt; -1</code>.</p>
<h5 id="args-5">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-7">Returns:</h5>
<ul>
<li><b><code>logcdf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.distribution.log_pdfvalue-namelog_pdf-condition_kwargs"><code id="Distribution.log_pdf">tf.contrib.distributions.Distribution.log_pdf(value, name='log_pdf', **condition_kwargs)</code></h4>
<p>Log probability density function.</p>
<h5 id="args-6">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-8">Returns:</h5>
<ul>
<li><b><code>log_prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-1">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if not <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.distribution.log_pmfvalue-namelog_pmf-condition_kwargs"><code id="Distribution.log_pmf">tf.contrib.distributions.Distribution.log_pmf(value, name='log_pmf', **condition_kwargs)</code></h4>
<p>Log probability mass function.</p>
<h5 id="args-7">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-9">Returns:</h5>
<ul>
<li><b><code>log_pmf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-2">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.distribution.log_probvalue-namelog_prob-condition_kwargs"><code id="Distribution.log_prob">tf.contrib.distributions.Distribution.log_prob(value, name='log_prob', **condition_kwargs)</code></h4>
<p>Log probability density/mass function (depending on <code>is_continuous</code>).</p>
<h5 id="args-8">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-10">Returns:</h5>
<ul>
<li><b><code>log_prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.distribution.log_survival_functionvalue-namelog_survival_function-condition_kwargs"><code id="Distribution.log_survival_function">tf.contrib.distributions.Distribution.log_survival_function(value, name='log_survival_function', **condition_kwargs)</code></h4>
<p>Log survival function.</p>
<p>Given random variable <code>X</code>, the survival function is defined:</p>
<pre><code>log_survival_function(x) = Log[ P[X &gt; x] ]
                         = Log[ 1 - P[X &lt;= x] ]
                         = Log[ 1 - cdf(x) ]</code></pre>
<p>Typically, different numerical approximations can be used for the log survival function, which are more accurate than <code>1 - cdf(x)</code> when <code>x &gt;&gt; 1</code>.</p>
<h5 id="args-9">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-11">Returns:</h5>
<p><code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.distribution.meannamemean"><code id="Distribution.mean">tf.contrib.distributions.Distribution.mean(name='mean')</code></h4>
<p>Mean.</p>
<hr />
<h4 id="tf.contrib.distributions.distribution.modenamemode"><code id="Distribution.mode">tf.contrib.distributions.Distribution.mode(name='mode')</code></h4>
<p>Mode.</p>
<hr />
<h4 id="tf.contrib.distributions.distribution.name"><code id="Distribution.name">tf.contrib.distributions.Distribution.name</code></h4>
<p>Name prepended to all ops created by this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.distribution.param_shapescls-sample_shape-namedistributionparamshapes"><code id="Distribution.param_shapes">tf.contrib.distributions.Distribution.param_shapes(cls, sample_shape, name='DistributionParamShapes')</code></h4>
<p>Shapes of parameters given the desired shape of a call to <code>sample()</code>.</p>
<p>Subclasses should override static method <code>_param_shapes</code>.</p>
<h5 id="args-10">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: <code>Tensor</code> or python list/tuple. Desired shape of a call to <code>sample()</code>.</li>
<li><b><code>name</code></b>: name to prepend ops with.</li>
</ul>
<h5 id="returns-12">Returns:</h5>
<p><code>dict</code> of parameter name to <code>Tensor</code> shapes.</p>
<hr />
<h4 id="tf.contrib.distributions.distribution.param_static_shapescls-sample_shape"><code id="Distribution.param_static_shapes">tf.contrib.distributions.Distribution.param_static_shapes(cls, sample_shape)</code></h4>
<p>param_shapes with static (i.e. TensorShape) shapes.</p>
<h5 id="args-11">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: <code>TensorShape</code> or python list/tuple. Desired shape of a call to <code>sample()</code>.</li>
</ul>
<h5 id="returns-13">Returns:</h5>
<p><code>dict</code> of parameter name to <code>TensorShape</code>.</p>
<h5 id="raises-3">Raises:</h5>
<ul>
<li><b><code>ValueError</code></b>: if <code>sample_shape</code> is a <code>TensorShape</code> and is not fully defined.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.distribution.parameters"><code id="Distribution.parameters">tf.contrib.distributions.Distribution.parameters</code></h4>
<p>Dictionary of parameters used to instantiate this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.distribution.pdfvalue-namepdf-condition_kwargs"><code id="Distribution.pdf">tf.contrib.distributions.Distribution.pdf(value, name='pdf', **condition_kwargs)</code></h4>
<p>Probability density function.</p>
<h5 id="args-12">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-14">Returns:</h5>
<ul>
<li><b><code>prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-4">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if not <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.distribution.pmfvalue-namepmf-condition_kwargs"><code id="Distribution.pmf">tf.contrib.distributions.Distribution.pmf(value, name='pmf', **condition_kwargs)</code></h4>
<p>Probability mass function.</p>
<h5 id="args-13">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-15">Returns:</h5>
<ul>
<li><b><code>pmf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-5">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.distribution.probvalue-nameprob-condition_kwargs"><code id="Distribution.prob">tf.contrib.distributions.Distribution.prob(value, name='prob', **condition_kwargs)</code></h4>
<p>Probability density/mass function (depending on <code>is_continuous</code>).</p>
<h5 id="args-14">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-16">Returns:</h5>
<ul>
<li><b><code>prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.distribution.samplesample_shape-seednone-namesample-condition_kwargs"><code id="Distribution.sample">tf.contrib.distributions.Distribution.sample(sample_shape=(), seed=None, name='sample', **condition_kwargs)</code></h4>
<p>Generate samples of the specified shape.</p>
<p>Note that a call to <code>sample()</code> without arguments will generate a single sample.</p>
<h5 id="args-15">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: 0D or 1D <code>int32</code> <code>Tensor</code>. Shape of the generated samples.</li>
<li><b><code>seed</code></b>: Python integer seed for RNG</li>
<li><b><code>name</code></b>: name to give to the op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-17">Returns:</h5>
<ul>
<li><b><code>samples</code></b>: a <code>Tensor</code> with prepended dimensions <code>sample_shape</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.distribution.sample_nn-seednone-namesample_n-condition_kwargs"><code id="Distribution.sample_n">tf.contrib.distributions.Distribution.sample_n(n, seed=None, name='sample_n', **condition_kwargs)</code></h4>
<p>Generate <code>n</code> samples.</p>
<h5 id="args-16">Args:</h5>
<ul>
<li><b><code>n</code></b>: <code>Scalar</code> <code>Tensor</code> of type <code>int32</code> or <code>int64</code>, the number of observations to sample.</li>
<li><b><code>seed</code></b>: Python integer seed for RNG</li>
<li><b><code>name</code></b>: name to give to the op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-18">Returns:</h5>
<ul>
<li><b><code>samples</code></b>: a <code>Tensor</code> with a prepended dimension (n,).</li>
</ul>
<h5 id="raises-6">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>n</code> is not an integer type.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.distribution.stdnamestd"><code id="Distribution.std">tf.contrib.distributions.Distribution.std(name='std')</code></h4>
<p>Standard deviation.</p>
<hr />
<h4 id="tf.contrib.distributions.distribution.survival_functionvalue-namesurvival_function-condition_kwargs"><code id="Distribution.survival_function">tf.contrib.distributions.Distribution.survival_function(value, name='survival_function', **condition_kwargs)</code></h4>
<p>Survival function.</p>
<p>Given random variable <code>X</code>, the survival function is defined:</p>
<pre><code>survival_function(x) = P[X &gt; x]
                     = 1 - P[X &lt;= x]
                     = 1 - cdf(x).</code></pre>
<h5 id="args-17">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-19">Returns:</h5>
<p>Tensor<code>of shape</code>sample_shape(x) + self.batch_shape<code>with values of type</code>self.dtype`.</p>
<hr />
<h4 id="tf.contrib.distributions.distribution.validate_args"><code id="Distribution.validate_args">tf.contrib.distributions.Distribution.validate_args</code></h4>
<p>Python boolean indicated possibly expensive checks are enabled.</p>
<hr />
<h4 id="tf.contrib.distributions.distribution.variancenamevariance"><code id="Distribution.variance">tf.contrib.distributions.Distribution.variance(name='variance')</code></h4>
<p>Variance.</p>
<h2 id="univariate-scalar-distributions">Univariate (scalar) distributions</h2>
<hr />
<h3 id="class-tf.contrib.distributions.binomial"><a name="//apple_ref/cpp/Class/Binomial" class="dashAnchor"></a><code id="Binomial">class tf.contrib.distributions.Binomial</code></h3>
<p>Binomial distribution.</p>
<p>This distribution is parameterized by a vector <code>p</code> of probabilities and <code>n</code>, the total counts.</p>
<h4 id="mathematical-details">Mathematical details</h4>
<p>The Binomial is a distribution over the number of successes in <code>n</code> independent trials, with each trial having the same probability of success <code>p</code>. The probability mass function (pmf):</p>
<p><code>pmf(k) = n! / (k! * (n - k)!) * (p)^k * (1 - p)^(n - k)</code></p>
<h4 id="examples">Examples</h4>
<p>Create a single distribution, corresponding to 5 coin flips.</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">dist <span class="op">=</span> Binomial(n<span class="op">=</span><span class="dv">5</span>., p<span class="op">=</span>.<span class="dv">5</span>)</code></pre></div>
<p>Create a single distribution (using logits), corresponding to 5 coin flips.</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">dist <span class="op">=</span> Binomial(n<span class="op">=</span><span class="dv">5</span>., logits<span class="op">=</span><span class="dv">0</span>.)</code></pre></div>
<p>Creates 3 distributions with the third distribution most likely to have successes.</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">p <span class="op">=</span> [.<span class="dv">2</span>, .<span class="dv">3</span>, .<span class="dv">8</span>]
<span class="co"># n will be broadcast to [4., 4., 4.], to match p.</span>
dist <span class="op">=</span> Binomial(n<span class="op">=</span><span class="dv">4</span>., p<span class="op">=</span>p)</code></pre></div>
<p>The distribution functions can be evaluated on counts.</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="co"># counts same shape as p.</span>
counts <span class="op">=</span> [<span class="dv">1</span>., <span class="dv">2</span>, <span class="dv">3</span>]
dist.prob(counts)  <span class="co"># Shape [3]</span>

<span class="co"># p will be broadcast to [[.2, .3, .8], [.2, .3, .8]] to match counts.</span>
counts <span class="op">=</span> [[<span class="dv">1</span>., <span class="dv">2</span>, <span class="dv">1</span>], [<span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">4</span>]]
dist.prob(counts)  <span class="co"># Shape [2, 3]</span>

<span class="co"># p will be broadcast to shape [5, 7, 3] to match counts.</span>
counts <span class="op">=</span> [[...]]  <span class="co"># Shape [5, 7, 3]</span>
dist.prob(counts)  <span class="co"># Shape [5, 7, 3]</span></code></pre></div>
<hr />
<h4 id="tf.contrib.distributions.binomial.__init__n-logitsnone-pnone-validate_argsfalse-allow_nan_statstrue-namebinomial"><code id="Binomial.__init__">tf.contrib.distributions.Binomial.__init__(n, logits=None, p=None, validate_args=False, allow_nan_stats=True, name='Binomial')</code></h4>
<p>Initialize a batch of Binomial distributions.</p>
<h5 id="args-18">Args:</h5>
<ul>
<li><b><code>n</code></b>: Non-negative floating point tensor with shape broadcastable to <code>[N1,..., Nm]</code> with <code>m &gt;= 0</code> and the same dtype as <code>p</code> or <code>logits</code>. Defines this as a batch of <code>N1 x ... x Nm</code> different Binomial distributions. Its components should be equal to integer values.</li>
<li><b><code>logits</code></b>: Floating point tensor representing the log-odds of a positive event with shape broadcastable to <code>[N1,..., Nm]</code> <code>m &gt;= 0</code>, and the same dtype as <code>n</code>. Each entry represents logits for the probability of success for independent Binomial distributions. Only one of <code>logits</code> or <code>p</code> should be passed in.</li>
<li><b><code>p</code></b>: Positive floating point tensor with shape broadcastable to <code>[N1,..., Nm]</code> <code>m &gt;= 0</code>, <code>p in [0, 1]</code>. Each entry represents the probability of success for independent Binomial distributions. Only one of <code>logits</code> or <code>p</code> should be passed in.</li>
<li><b><code>validate_args</code></b>: <code>Boolean</code>, default <code>False</code>. Whether to assert valid values for parameters <code>n</code>, <code>p</code>, and <code>x</code> in <code>prob</code> and <code>log_prob</code>. If <code>False</code> and inputs are invalid, correct behavior is not guaranteed.</li>
<li><b><code>allow_nan_stats</code></b>: <code>Boolean</code>, default <code>True</code>. If <code>False</code>, raise an exception if a statistic (e.g. mean/mode/etc...) is undefined for any batch member. If <code>True</code>, batch members with valid parameters leading to undefined statistics will return NaN for this statistic.</li>
<li><p><b><code>name</code></b>: The name to prefix Ops created by this distribution class.</p></li>
<li><p><b><code>Examples</code></b>:</p></li>
</ul>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="co"># Define 1-batch of a binomial distribution.</span>
dist <span class="op">=</span> Binomial(n<span class="op">=</span><span class="dv">2</span>., p<span class="op">=</span>.<span class="dv">9</span>)

<span class="co"># Define a 2-batch.</span>
dist <span class="op">=</span> Binomial(n<span class="op">=</span>[<span class="dv">4</span>., <span class="dv">5</span>], p<span class="op">=</span>[.<span class="dv">1</span>, .<span class="dv">3</span>])</code></pre></div>
<hr />
<h4 id="tf.contrib.distributions.binomial.allow_nan_stats"><code id="Binomial.allow_nan_stats">tf.contrib.distributions.Binomial.allow_nan_stats</code></h4>
<p>Python boolean describing behavior when a stat is undefined.</p>
<p>Stats return +/- infinity when it makes sense. E.g., the variance of a Cauchy distribution is infinity. However, sometimes the statistic is undefined, e.g., if a distribution's pdf does not achieve a maximum within the support of the distribution, the mode is undefined. If the mean is undefined, then by definition the variance is undefined. E.g. the mean for Student's T for df = 1 is undefined (no clear way to say it is either + or - infinity), so the variance = E[(X - mean)^2] is also undefined.</p>
<h5 id="returns-20">Returns:</h5>
<ul>
<li><b><code>allow_nan_stats</code></b>: Python boolean.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.binomial.batch_shapenamebatch_shape"><code id="Binomial.batch_shape">tf.contrib.distributions.Binomial.batch_shape(name='batch_shape')</code></h4>
<p>Shape of a single sample from a single event index as a 1-D <code>Tensor</code>.</p>
<p>The product of the dimensions of the <code>batch_shape</code> is the number of independent distributions of this kind the instance represents.</p>
<h5 id="args-19">Args:</h5>
<ul>
<li><b><code>name</code></b>: name to give to the op</li>
</ul>
<h5 id="returns-21">Returns:</h5>
<ul>
<li><b><code>batch_shape</code></b>: <code>Tensor</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.binomial.cdfvalue-namecdf-condition_kwargs"><code id="Binomial.cdf">tf.contrib.distributions.Binomial.cdf(value, name='cdf', **condition_kwargs)</code></h4>
<p>Cumulative distribution function.</p>
<p>Given random variable <code>X</code>, the cumulative distribution function <code>cdf</code> is:</p>
<pre><code>cdf(x) := P[X &lt;= x]</code></pre>
<h5 id="args-20">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-22">Returns:</h5>
<ul>
<li><b><code>cdf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.binomial.copyoverride_parameters_kwargs"><code id="Binomial.copy">tf.contrib.distributions.Binomial.copy(**override_parameters_kwargs)</code></h4>
<p>Creates a deep copy of the distribution.</p>
<p>Note: the copy distribution may continue to depend on the original intialization arguments.</p>
<h5 id="args-21">Args:</h5>
<ul>
<li><b><code>**override_parameters_kwargs</code></b>: String/value dictionary of initialization arguments to override with new values.</li>
</ul>
<h5 id="returns-23">Returns:</h5>
<ul>
<li><b><code>distribution</code></b>: A new instance of <code>type(self)</code> intitialized from the union of self.parameters and override_parameters_kwargs, i.e., <code>dict(self.parameters, **override_parameters_kwargs)</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.binomial.dtype"><code id="Binomial.dtype">tf.contrib.distributions.Binomial.dtype</code></h4>
<p>The <code>DType</code> of <code>Tensor</code>s handled by this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.binomial.entropynameentropy"><code id="Binomial.entropy">tf.contrib.distributions.Binomial.entropy(name='entropy')</code></h4>
<p>Shannon entropy in nats.</p>
<hr />
<h4 id="tf.contrib.distributions.binomial.event_shapenameevent_shape"><code id="Binomial.event_shape">tf.contrib.distributions.Binomial.event_shape(name='event_shape')</code></h4>
<p>Shape of a single sample from a single batch as a 1-D int32 <code>Tensor</code>.</p>
<h5 id="args-22">Args:</h5>
<ul>
<li><b><code>name</code></b>: name to give to the op</li>
</ul>
<h5 id="returns-24">Returns:</h5>
<ul>
<li><b><code>event_shape</code></b>: <code>Tensor</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.binomial.get_batch_shape"><code id="Binomial.get_batch_shape">tf.contrib.distributions.Binomial.get_batch_shape()</code></h4>
<p>Shape of a single sample from a single event index as a <code>TensorShape</code>.</p>
<p>Same meaning as <code>batch_shape</code>. May be only partially defined.</p>
<h5 id="returns-25">Returns:</h5>
<ul>
<li><b><code>batch_shape</code></b>: <code>TensorShape</code>, possibly unknown.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.binomial.get_event_shape"><code id="Binomial.get_event_shape">tf.contrib.distributions.Binomial.get_event_shape()</code></h4>
<p>Shape of a single sample from a single batch as a <code>TensorShape</code>.</p>
<p>Same meaning as <code>event_shape</code>. May be only partially defined.</p>
<h5 id="returns-26">Returns:</h5>
<ul>
<li><b><code>event_shape</code></b>: <code>TensorShape</code>, possibly unknown.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.binomial.is_continuous"><code id="Binomial.is_continuous">tf.contrib.distributions.Binomial.is_continuous</code></h4>
<hr />
<h4 id="tf.contrib.distributions.binomial.is_reparameterized"><code id="Binomial.is_reparameterized">tf.contrib.distributions.Binomial.is_reparameterized</code></h4>
<hr />
<h4 id="tf.contrib.distributions.binomial.log_cdfvalue-namelog_cdf-condition_kwargs"><code id="Binomial.log_cdf">tf.contrib.distributions.Binomial.log_cdf(value, name='log_cdf', **condition_kwargs)</code></h4>
<p>Log cumulative distribution function.</p>
<p>Given random variable <code>X</code>, the cumulative distribution function <code>cdf</code> is:</p>
<pre><code>log_cdf(x) := Log[ P[X &lt;= x] ]</code></pre>
<p>Often, a numerical approximation can be used for <code>log_cdf(x)</code> that yields a more accurate answer than simply taking the logarithm of the <code>cdf</code> when <code>x &lt;&lt; -1</code>.</p>
<h5 id="args-23">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-27">Returns:</h5>
<ul>
<li><b><code>logcdf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.binomial.log_pdfvalue-namelog_pdf-condition_kwargs"><code id="Binomial.log_pdf">tf.contrib.distributions.Binomial.log_pdf(value, name='log_pdf', **condition_kwargs)</code></h4>
<p>Log probability density function.</p>
<h5 id="args-24">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-28">Returns:</h5>
<ul>
<li><b><code>log_prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-7">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if not <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.binomial.log_pmfvalue-namelog_pmf-condition_kwargs"><code id="Binomial.log_pmf">tf.contrib.distributions.Binomial.log_pmf(value, name='log_pmf', **condition_kwargs)</code></h4>
<p>Log probability mass function.</p>
<h5 id="args-25">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-29">Returns:</h5>
<ul>
<li><b><code>log_pmf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-8">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.binomial.log_probvalue-namelog_prob-condition_kwargs"><code id="Binomial.log_prob">tf.contrib.distributions.Binomial.log_prob(value, name='log_prob', **condition_kwargs)</code></h4>
<p>Log probability density/mass function (depending on <code>is_continuous</code>).</p>
<p>Additional documentation from <code>Binomial</code>:</p>
<p>For each batch member of counts <code>value</code>, <code>P[counts]</code> is the probability that after sampling <code>n</code> draws from this Binomial distribution, the number of successes is <code>k</code>. Note that different sequences of draws can result in the same counts, thus the probability includes a combinatorial coefficient.</p>
<p><code>value</code> must be a non-negative tensor with dtype <code>dtype</code> and whose shape can be broadcast with <code>self.p</code> and <code>self.n</code>. <code>counts</code> is only legal if it is less than or equal to <code>n</code> and its components are equal to integer values.</p>
<h5 id="args-26">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-30">Returns:</h5>
<ul>
<li><b><code>log_prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.binomial.log_survival_functionvalue-namelog_survival_function-condition_kwargs"><code id="Binomial.log_survival_function">tf.contrib.distributions.Binomial.log_survival_function(value, name='log_survival_function', **condition_kwargs)</code></h4>
<p>Log survival function.</p>
<p>Given random variable <code>X</code>, the survival function is defined:</p>
<pre><code>log_survival_function(x) = Log[ P[X &gt; x] ]
                         = Log[ 1 - P[X &lt;= x] ]
                         = Log[ 1 - cdf(x) ]</code></pre>
<p>Typically, different numerical approximations can be used for the log survival function, which are more accurate than <code>1 - cdf(x)</code> when <code>x &gt;&gt; 1</code>.</p>
<h5 id="args-27">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-31">Returns:</h5>
<p><code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.binomial.logits"><code id="Binomial.logits">tf.contrib.distributions.Binomial.logits</code></h4>
<p>Log-odds of success.</p>
<hr />
<h4 id="tf.contrib.distributions.binomial.meannamemean"><code id="Binomial.mean">tf.contrib.distributions.Binomial.mean(name='mean')</code></h4>
<p>Mean.</p>
<hr />
<h4 id="tf.contrib.distributions.binomial.modenamemode"><code id="Binomial.mode">tf.contrib.distributions.Binomial.mode(name='mode')</code></h4>
<p>Mode.</p>
<p>Additional documentation from <code>Binomial</code>:</p>
<p>Note that when <code>(n + 1) * p</code> is an integer, there are actually two modes. Namely, <code>(n + 1) * p</code> and <code>(n + 1) * p - 1</code> are both modes. Here we return only the larger of the two modes.</p>
<hr />
<h4 id="tf.contrib.distributions.binomial.n"><code id="Binomial.n">tf.contrib.distributions.Binomial.n</code></h4>
<p>Number of trials.</p>
<hr />
<h4 id="tf.contrib.distributions.binomial.name"><code id="Binomial.name">tf.contrib.distributions.Binomial.name</code></h4>
<p>Name prepended to all ops created by this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.binomial.p"><code id="Binomial.p">tf.contrib.distributions.Binomial.p</code></h4>
<p>Probability of success.</p>
<hr />
<h4 id="tf.contrib.distributions.binomial.param_shapescls-sample_shape-namedistributionparamshapes"><code id="Binomial.param_shapes">tf.contrib.distributions.Binomial.param_shapes(cls, sample_shape, name='DistributionParamShapes')</code></h4>
<p>Shapes of parameters given the desired shape of a call to <code>sample()</code>.</p>
<p>Subclasses should override static method <code>_param_shapes</code>.</p>
<h5 id="args-28">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: <code>Tensor</code> or python list/tuple. Desired shape of a call to <code>sample()</code>.</li>
<li><b><code>name</code></b>: name to prepend ops with.</li>
</ul>
<h5 id="returns-32">Returns:</h5>
<p><code>dict</code> of parameter name to <code>Tensor</code> shapes.</p>
<hr />
<h4 id="tf.contrib.distributions.binomial.param_static_shapescls-sample_shape"><code id="Binomial.param_static_shapes">tf.contrib.distributions.Binomial.param_static_shapes(cls, sample_shape)</code></h4>
<p>param_shapes with static (i.e. TensorShape) shapes.</p>
<h5 id="args-29">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: <code>TensorShape</code> or python list/tuple. Desired shape of a call to <code>sample()</code>.</li>
</ul>
<h5 id="returns-33">Returns:</h5>
<p><code>dict</code> of parameter name to <code>TensorShape</code>.</p>
<h5 id="raises-9">Raises:</h5>
<ul>
<li><b><code>ValueError</code></b>: if <code>sample_shape</code> is a <code>TensorShape</code> and is not fully defined.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.binomial.parameters"><code id="Binomial.parameters">tf.contrib.distributions.Binomial.parameters</code></h4>
<p>Dictionary of parameters used to instantiate this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.binomial.pdfvalue-namepdf-condition_kwargs"><code id="Binomial.pdf">tf.contrib.distributions.Binomial.pdf(value, name='pdf', **condition_kwargs)</code></h4>
<p>Probability density function.</p>
<h5 id="args-30">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-34">Returns:</h5>
<ul>
<li><b><code>prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-10">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if not <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.binomial.pmfvalue-namepmf-condition_kwargs"><code id="Binomial.pmf">tf.contrib.distributions.Binomial.pmf(value, name='pmf', **condition_kwargs)</code></h4>
<p>Probability mass function.</p>
<h5 id="args-31">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-35">Returns:</h5>
<ul>
<li><b><code>pmf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-11">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.binomial.probvalue-nameprob-condition_kwargs"><code id="Binomial.prob">tf.contrib.distributions.Binomial.prob(value, name='prob', **condition_kwargs)</code></h4>
<p>Probability density/mass function (depending on <code>is_continuous</code>).</p>
<p>Additional documentation from <code>Binomial</code>:</p>
<p>For each batch member of counts <code>value</code>, <code>P[counts]</code> is the probability that after sampling <code>n</code> draws from this Binomial distribution, the number of successes is <code>k</code>. Note that different sequences of draws can result in the same counts, thus the probability includes a combinatorial coefficient.</p>
<p><code>value</code> must be a non-negative tensor with dtype <code>dtype</code> and whose shape can be broadcast with <code>self.p</code> and <code>self.n</code>. <code>counts</code> is only legal if it is less than or equal to <code>n</code> and its components are equal to integer values.</p>
<h5 id="args-32">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-36">Returns:</h5>
<ul>
<li><b><code>prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.binomial.samplesample_shape-seednone-namesample-condition_kwargs"><code id="Binomial.sample">tf.contrib.distributions.Binomial.sample(sample_shape=(), seed=None, name='sample', **condition_kwargs)</code></h4>
<p>Generate samples of the specified shape.</p>
<p>Note that a call to <code>sample()</code> without arguments will generate a single sample.</p>
<h5 id="args-33">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: 0D or 1D <code>int32</code> <code>Tensor</code>. Shape of the generated samples.</li>
<li><b><code>seed</code></b>: Python integer seed for RNG</li>
<li><b><code>name</code></b>: name to give to the op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-37">Returns:</h5>
<ul>
<li><b><code>samples</code></b>: a <code>Tensor</code> with prepended dimensions <code>sample_shape</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.binomial.sample_nn-seednone-namesample_n-condition_kwargs"><code id="Binomial.sample_n">tf.contrib.distributions.Binomial.sample_n(n, seed=None, name='sample_n', **condition_kwargs)</code></h4>
<p>Generate <code>n</code> samples.</p>
<h5 id="args-34">Args:</h5>
<ul>
<li><b><code>n</code></b>: <code>Scalar</code> <code>Tensor</code> of type <code>int32</code> or <code>int64</code>, the number of observations to sample.</li>
<li><b><code>seed</code></b>: Python integer seed for RNG</li>
<li><b><code>name</code></b>: name to give to the op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-38">Returns:</h5>
<ul>
<li><b><code>samples</code></b>: a <code>Tensor</code> with a prepended dimension (n,).</li>
</ul>
<h5 id="raises-12">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>n</code> is not an integer type.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.binomial.stdnamestd"><code id="Binomial.std">tf.contrib.distributions.Binomial.std(name='std')</code></h4>
<p>Standard deviation.</p>
<hr />
<h4 id="tf.contrib.distributions.binomial.survival_functionvalue-namesurvival_function-condition_kwargs"><code id="Binomial.survival_function">tf.contrib.distributions.Binomial.survival_function(value, name='survival_function', **condition_kwargs)</code></h4>
<p>Survival function.</p>
<p>Given random variable <code>X</code>, the survival function is defined:</p>
<pre><code>survival_function(x) = P[X &gt; x]
                     = 1 - P[X &lt;= x]
                     = 1 - cdf(x).</code></pre>
<h5 id="args-35">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-39">Returns:</h5>
<p>Tensor<code>of shape</code>sample_shape(x) + self.batch_shape<code>with values of type</code>self.dtype`.</p>
<hr />
<h4 id="tf.contrib.distributions.binomial.validate_args"><code id="Binomial.validate_args">tf.contrib.distributions.Binomial.validate_args</code></h4>
<p>Python boolean indicated possibly expensive checks are enabled.</p>
<hr />
<h4 id="tf.contrib.distributions.binomial.variancenamevariance"><code id="Binomial.variance">tf.contrib.distributions.Binomial.variance(name='variance')</code></h4>
<p>Variance.</p>
<hr />
<h3 id="class-tf.contrib.distributions.bernoulli"><a name="//apple_ref/cpp/Class/Bernoulli" class="dashAnchor"></a><code id="Bernoulli">class tf.contrib.distributions.Bernoulli</code></h3>
<p>Bernoulli distribution.</p>
<p>The Bernoulli distribution is parameterized by p, the probability of a positive event. - - -</p>
<h4 id="tf.contrib.distributions.bernoulli.__init__logitsnone-pnone-dtypetf.int32-validate_argsfalse-allow_nan_statstrue-namebernoulli"><code id="Bernoulli.__init__">tf.contrib.distributions.Bernoulli.__init__(logits=None, p=None, dtype=tf.int32, validate_args=False, allow_nan_stats=True, name='Bernoulli')</code></h4>
<p>Construct Bernoulli distributions.</p>
<h5 id="args-36">Args:</h5>
<ul>
<li><b><code>logits</code></b>: An N-D <code>Tensor</code> representing the log-odds of a positive event. Each entry in the <code>Tensor</code> parametrizes an independent Bernoulli distribution where the probability of an event is sigmoid(logits). Only one of <code>logits</code> or <code>p</code> should be passed in.</li>
<li><b><code>p</code></b>: An N-D <code>Tensor</code> representing the probability of a positive event. Each entry in the <code>Tensor</code> parameterizes an independent Bernoulli distribution. Only one of <code>logits</code> or <code>p</code> should be passed in.</li>
<li><b><code>dtype</code></b>: dtype for samples.</li>
<li><b><code>validate_args</code></b>: <code>Boolean</code>, default <code>False</code>. Whether to validate that <code>0 &lt;= p &lt;= 1</code>. If <code>validate_args</code> is <code>False</code>, and the inputs are invalid, methods like <code>log_pmf</code> may return <code>NaN</code> values.</li>
<li><b><code>allow_nan_stats</code></b>: <code>Boolean</code>, default <code>True</code>. If <code>False</code>, raise an exception if a statistic (e.g. mean/mode/etc...) is undefined for any batch member. If <code>True</code>, batch members with valid parameters leading to undefined statistics will return NaN for this statistic.</li>
<li><b><code>name</code></b>: A name for this distribution.</li>
</ul>
<h5 id="raises-13">Raises:</h5>
<ul>
<li><b><code>ValueError</code></b>: If p and logits are passed, or if neither are passed.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.bernoulli.allow_nan_stats"><code id="Bernoulli.allow_nan_stats">tf.contrib.distributions.Bernoulli.allow_nan_stats</code></h4>
<p>Python boolean describing behavior when a stat is undefined.</p>
<p>Stats return +/- infinity when it makes sense. E.g., the variance of a Cauchy distribution is infinity. However, sometimes the statistic is undefined, e.g., if a distribution's pdf does not achieve a maximum within the support of the distribution, the mode is undefined. If the mean is undefined, then by definition the variance is undefined. E.g. the mean for Student's T for df = 1 is undefined (no clear way to say it is either + or - infinity), so the variance = E[(X - mean)^2] is also undefined.</p>
<h5 id="returns-40">Returns:</h5>
<ul>
<li><b><code>allow_nan_stats</code></b>: Python boolean.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.bernoulli.batch_shapenamebatch_shape"><code id="Bernoulli.batch_shape">tf.contrib.distributions.Bernoulli.batch_shape(name='batch_shape')</code></h4>
<p>Shape of a single sample from a single event index as a 1-D <code>Tensor</code>.</p>
<p>The product of the dimensions of the <code>batch_shape</code> is the number of independent distributions of this kind the instance represents.</p>
<h5 id="args-37">Args:</h5>
<ul>
<li><b><code>name</code></b>: name to give to the op</li>
</ul>
<h5 id="returns-41">Returns:</h5>
<ul>
<li><b><code>batch_shape</code></b>: <code>Tensor</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.bernoulli.cdfvalue-namecdf-condition_kwargs"><code id="Bernoulli.cdf">tf.contrib.distributions.Bernoulli.cdf(value, name='cdf', **condition_kwargs)</code></h4>
<p>Cumulative distribution function.</p>
<p>Given random variable <code>X</code>, the cumulative distribution function <code>cdf</code> is:</p>
<pre><code>cdf(x) := P[X &lt;= x]</code></pre>
<h5 id="args-38">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-42">Returns:</h5>
<ul>
<li><b><code>cdf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.bernoulli.copyoverride_parameters_kwargs"><code id="Bernoulli.copy">tf.contrib.distributions.Bernoulli.copy(**override_parameters_kwargs)</code></h4>
<p>Creates a deep copy of the distribution.</p>
<p>Note: the copy distribution may continue to depend on the original intialization arguments.</p>
<h5 id="args-39">Args:</h5>
<ul>
<li><b><code>**override_parameters_kwargs</code></b>: String/value dictionary of initialization arguments to override with new values.</li>
</ul>
<h5 id="returns-43">Returns:</h5>
<ul>
<li><b><code>distribution</code></b>: A new instance of <code>type(self)</code> intitialized from the union of self.parameters and override_parameters_kwargs, i.e., <code>dict(self.parameters, **override_parameters_kwargs)</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.bernoulli.dtype"><code id="Bernoulli.dtype">tf.contrib.distributions.Bernoulli.dtype</code></h4>
<p>The <code>DType</code> of <code>Tensor</code>s handled by this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.bernoulli.entropynameentropy"><code id="Bernoulli.entropy">tf.contrib.distributions.Bernoulli.entropy(name='entropy')</code></h4>
<p>Shannon entropy in nats.</p>
<hr />
<h4 id="tf.contrib.distributions.bernoulli.event_shapenameevent_shape"><code id="Bernoulli.event_shape">tf.contrib.distributions.Bernoulli.event_shape(name='event_shape')</code></h4>
<p>Shape of a single sample from a single batch as a 1-D int32 <code>Tensor</code>.</p>
<h5 id="args-40">Args:</h5>
<ul>
<li><b><code>name</code></b>: name to give to the op</li>
</ul>
<h5 id="returns-44">Returns:</h5>
<ul>
<li><b><code>event_shape</code></b>: <code>Tensor</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.bernoulli.get_batch_shape"><code id="Bernoulli.get_batch_shape">tf.contrib.distributions.Bernoulli.get_batch_shape()</code></h4>
<p>Shape of a single sample from a single event index as a <code>TensorShape</code>.</p>
<p>Same meaning as <code>batch_shape</code>. May be only partially defined.</p>
<h5 id="returns-45">Returns:</h5>
<ul>
<li><b><code>batch_shape</code></b>: <code>TensorShape</code>, possibly unknown.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.bernoulli.get_event_shape"><code id="Bernoulli.get_event_shape">tf.contrib.distributions.Bernoulli.get_event_shape()</code></h4>
<p>Shape of a single sample from a single batch as a <code>TensorShape</code>.</p>
<p>Same meaning as <code>event_shape</code>. May be only partially defined.</p>
<h5 id="returns-46">Returns:</h5>
<ul>
<li><b><code>event_shape</code></b>: <code>TensorShape</code>, possibly unknown.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.bernoulli.is_continuous"><code id="Bernoulli.is_continuous">tf.contrib.distributions.Bernoulli.is_continuous</code></h4>
<hr />
<h4 id="tf.contrib.distributions.bernoulli.is_reparameterized"><code id="Bernoulli.is_reparameterized">tf.contrib.distributions.Bernoulli.is_reparameterized</code></h4>
<hr />
<h4 id="tf.contrib.distributions.bernoulli.log_cdfvalue-namelog_cdf-condition_kwargs"><code id="Bernoulli.log_cdf">tf.contrib.distributions.Bernoulli.log_cdf(value, name='log_cdf', **condition_kwargs)</code></h4>
<p>Log cumulative distribution function.</p>
<p>Given random variable <code>X</code>, the cumulative distribution function <code>cdf</code> is:</p>
<pre><code>log_cdf(x) := Log[ P[X &lt;= x] ]</code></pre>
<p>Often, a numerical approximation can be used for <code>log_cdf(x)</code> that yields a more accurate answer than simply taking the logarithm of the <code>cdf</code> when <code>x &lt;&lt; -1</code>.</p>
<h5 id="args-41">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-47">Returns:</h5>
<ul>
<li><b><code>logcdf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.bernoulli.log_pdfvalue-namelog_pdf-condition_kwargs"><code id="Bernoulli.log_pdf">tf.contrib.distributions.Bernoulli.log_pdf(value, name='log_pdf', **condition_kwargs)</code></h4>
<p>Log probability density function.</p>
<h5 id="args-42">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-48">Returns:</h5>
<ul>
<li><b><code>log_prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-14">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if not <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.bernoulli.log_pmfvalue-namelog_pmf-condition_kwargs"><code id="Bernoulli.log_pmf">tf.contrib.distributions.Bernoulli.log_pmf(value, name='log_pmf', **condition_kwargs)</code></h4>
<p>Log probability mass function.</p>
<h5 id="args-43">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-49">Returns:</h5>
<ul>
<li><b><code>log_pmf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-15">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.bernoulli.log_probvalue-namelog_prob-condition_kwargs"><code id="Bernoulli.log_prob">tf.contrib.distributions.Bernoulli.log_prob(value, name='log_prob', **condition_kwargs)</code></h4>
<p>Log probability density/mass function (depending on <code>is_continuous</code>).</p>
<h5 id="args-44">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-50">Returns:</h5>
<ul>
<li><b><code>log_prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.bernoulli.log_survival_functionvalue-namelog_survival_function-condition_kwargs"><code id="Bernoulli.log_survival_function">tf.contrib.distributions.Bernoulli.log_survival_function(value, name='log_survival_function', **condition_kwargs)</code></h4>
<p>Log survival function.</p>
<p>Given random variable <code>X</code>, the survival function is defined:</p>
<pre><code>log_survival_function(x) = Log[ P[X &gt; x] ]
                         = Log[ 1 - P[X &lt;= x] ]
                         = Log[ 1 - cdf(x) ]</code></pre>
<p>Typically, different numerical approximations can be used for the log survival function, which are more accurate than <code>1 - cdf(x)</code> when <code>x &gt;&gt; 1</code>.</p>
<h5 id="args-45">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-51">Returns:</h5>
<p><code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.bernoulli.logits"><code id="Bernoulli.logits">tf.contrib.distributions.Bernoulli.logits</code></h4>
<p>Log-odds of success.</p>
<hr />
<h4 id="tf.contrib.distributions.bernoulli.meannamemean"><code id="Bernoulli.mean">tf.contrib.distributions.Bernoulli.mean(name='mean')</code></h4>
<p>Mean.</p>
<hr />
<h4 id="tf.contrib.distributions.bernoulli.modenamemode"><code id="Bernoulli.mode">tf.contrib.distributions.Bernoulli.mode(name='mode')</code></h4>
<p>Mode.</p>
<p>Additional documentation from <code>Bernoulli</code>:</p>
<p>Returns <code>1</code> if <code>p &gt; 1-p</code> and <code>0</code> otherwise.</p>
<hr />
<h4 id="tf.contrib.distributions.bernoulli.name"><code id="Bernoulli.name">tf.contrib.distributions.Bernoulli.name</code></h4>
<p>Name prepended to all ops created by this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.bernoulli.p"><code id="Bernoulli.p">tf.contrib.distributions.Bernoulli.p</code></h4>
<p>Probability of success.</p>
<hr />
<h4 id="tf.contrib.distributions.bernoulli.param_shapescls-sample_shape-namedistributionparamshapes"><code id="Bernoulli.param_shapes">tf.contrib.distributions.Bernoulli.param_shapes(cls, sample_shape, name='DistributionParamShapes')</code></h4>
<p>Shapes of parameters given the desired shape of a call to <code>sample()</code>.</p>
<p>Subclasses should override static method <code>_param_shapes</code>.</p>
<h5 id="args-46">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: <code>Tensor</code> or python list/tuple. Desired shape of a call to <code>sample()</code>.</li>
<li><b><code>name</code></b>: name to prepend ops with.</li>
</ul>
<h5 id="returns-52">Returns:</h5>
<p><code>dict</code> of parameter name to <code>Tensor</code> shapes.</p>
<hr />
<h4 id="tf.contrib.distributions.bernoulli.param_static_shapescls-sample_shape"><code id="Bernoulli.param_static_shapes">tf.contrib.distributions.Bernoulli.param_static_shapes(cls, sample_shape)</code></h4>
<p>param_shapes with static (i.e. TensorShape) shapes.</p>
<h5 id="args-47">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: <code>TensorShape</code> or python list/tuple. Desired shape of a call to <code>sample()</code>.</li>
</ul>
<h5 id="returns-53">Returns:</h5>
<p><code>dict</code> of parameter name to <code>TensorShape</code>.</p>
<h5 id="raises-16">Raises:</h5>
<ul>
<li><b><code>ValueError</code></b>: if <code>sample_shape</code> is a <code>TensorShape</code> and is not fully defined.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.bernoulli.parameters"><code id="Bernoulli.parameters">tf.contrib.distributions.Bernoulli.parameters</code></h4>
<p>Dictionary of parameters used to instantiate this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.bernoulli.pdfvalue-namepdf-condition_kwargs"><code id="Bernoulli.pdf">tf.contrib.distributions.Bernoulli.pdf(value, name='pdf', **condition_kwargs)</code></h4>
<p>Probability density function.</p>
<h5 id="args-48">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-54">Returns:</h5>
<ul>
<li><b><code>prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-17">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if not <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.bernoulli.pmfvalue-namepmf-condition_kwargs"><code id="Bernoulli.pmf">tf.contrib.distributions.Bernoulli.pmf(value, name='pmf', **condition_kwargs)</code></h4>
<p>Probability mass function.</p>
<h5 id="args-49">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-55">Returns:</h5>
<ul>
<li><b><code>pmf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-18">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.bernoulli.probvalue-nameprob-condition_kwargs"><code id="Bernoulli.prob">tf.contrib.distributions.Bernoulli.prob(value, name='prob', **condition_kwargs)</code></h4>
<p>Probability density/mass function (depending on <code>is_continuous</code>).</p>
<h5 id="args-50">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-56">Returns:</h5>
<ul>
<li><b><code>prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.bernoulli.q"><code id="Bernoulli.q">tf.contrib.distributions.Bernoulli.q</code></h4>
<p>1-p.</p>
<hr />
<h4 id="tf.contrib.distributions.bernoulli.samplesample_shape-seednone-namesample-condition_kwargs"><code id="Bernoulli.sample">tf.contrib.distributions.Bernoulli.sample(sample_shape=(), seed=None, name='sample', **condition_kwargs)</code></h4>
<p>Generate samples of the specified shape.</p>
<p>Note that a call to <code>sample()</code> without arguments will generate a single sample.</p>
<h5 id="args-51">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: 0D or 1D <code>int32</code> <code>Tensor</code>. Shape of the generated samples.</li>
<li><b><code>seed</code></b>: Python integer seed for RNG</li>
<li><b><code>name</code></b>: name to give to the op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-57">Returns:</h5>
<ul>
<li><b><code>samples</code></b>: a <code>Tensor</code> with prepended dimensions <code>sample_shape</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.bernoulli.sample_nn-seednone-namesample_n-condition_kwargs"><code id="Bernoulli.sample_n">tf.contrib.distributions.Bernoulli.sample_n(n, seed=None, name='sample_n', **condition_kwargs)</code></h4>
<p>Generate <code>n</code> samples.</p>
<h5 id="args-52">Args:</h5>
<ul>
<li><b><code>n</code></b>: <code>Scalar</code> <code>Tensor</code> of type <code>int32</code> or <code>int64</code>, the number of observations to sample.</li>
<li><b><code>seed</code></b>: Python integer seed for RNG</li>
<li><b><code>name</code></b>: name to give to the op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-58">Returns:</h5>
<ul>
<li><b><code>samples</code></b>: a <code>Tensor</code> with a prepended dimension (n,).</li>
</ul>
<h5 id="raises-19">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>n</code> is not an integer type.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.bernoulli.stdnamestd"><code id="Bernoulli.std">tf.contrib.distributions.Bernoulli.std(name='std')</code></h4>
<p>Standard deviation.</p>
<hr />
<h4 id="tf.contrib.distributions.bernoulli.survival_functionvalue-namesurvival_function-condition_kwargs"><code id="Bernoulli.survival_function">tf.contrib.distributions.Bernoulli.survival_function(value, name='survival_function', **condition_kwargs)</code></h4>
<p>Survival function.</p>
<p>Given random variable <code>X</code>, the survival function is defined:</p>
<pre><code>survival_function(x) = P[X &gt; x]
                     = 1 - P[X &lt;= x]
                     = 1 - cdf(x).</code></pre>
<h5 id="args-53">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-59">Returns:</h5>
<p>Tensor<code>of shape</code>sample_shape(x) + self.batch_shape<code>with values of type</code>self.dtype`.</p>
<hr />
<h4 id="tf.contrib.distributions.bernoulli.validate_args"><code id="Bernoulli.validate_args">tf.contrib.distributions.Bernoulli.validate_args</code></h4>
<p>Python boolean indicated possibly expensive checks are enabled.</p>
<hr />
<h4 id="tf.contrib.distributions.bernoulli.variancenamevariance"><code id="Bernoulli.variance">tf.contrib.distributions.Bernoulli.variance(name='variance')</code></h4>
<p>Variance.</p>
<hr />
<h3 id="class-tf.contrib.distributions.bernoulliwithsigmoidp"><a name="//apple_ref/cpp/Class/BernoulliWithSigmoidP" class="dashAnchor"></a><code id="BernoulliWithSigmoidP">class tf.contrib.distributions.BernoulliWithSigmoidP</code></h3>
<p>Bernoulli with <code>p = sigmoid(p)</code>. - - -</p>
<h4 id="tf.contrib.distributions.bernoulliwithsigmoidp.__init__pnone-dtypetf.int32-validate_argsfalse-allow_nan_statstrue-namebernoulliwithsigmoidp"><code id="BernoulliWithSigmoidP.__init__">tf.contrib.distributions.BernoulliWithSigmoidP.__init__(p=None, dtype=tf.int32, validate_args=False, allow_nan_stats=True, name='BernoulliWithSigmoidP')</code></h4>
<hr />
<h4 id="tf.contrib.distributions.bernoulliwithsigmoidp.allow_nan_stats"><code id="BernoulliWithSigmoidP.allow_nan_stats">tf.contrib.distributions.BernoulliWithSigmoidP.allow_nan_stats</code></h4>
<p>Python boolean describing behavior when a stat is undefined.</p>
<p>Stats return +/- infinity when it makes sense. E.g., the variance of a Cauchy distribution is infinity. However, sometimes the statistic is undefined, e.g., if a distribution's pdf does not achieve a maximum within the support of the distribution, the mode is undefined. If the mean is undefined, then by definition the variance is undefined. E.g. the mean for Student's T for df = 1 is undefined (no clear way to say it is either + or - infinity), so the variance = E[(X - mean)^2] is also undefined.</p>
<h5 id="returns-60">Returns:</h5>
<ul>
<li><b><code>allow_nan_stats</code></b>: Python boolean.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.bernoulliwithsigmoidp.batch_shapenamebatch_shape"><code id="BernoulliWithSigmoidP.batch_shape">tf.contrib.distributions.BernoulliWithSigmoidP.batch_shape(name='batch_shape')</code></h4>
<p>Shape of a single sample from a single event index as a 1-D <code>Tensor</code>.</p>
<p>The product of the dimensions of the <code>batch_shape</code> is the number of independent distributions of this kind the instance represents.</p>
<h5 id="args-54">Args:</h5>
<ul>
<li><b><code>name</code></b>: name to give to the op</li>
</ul>
<h5 id="returns-61">Returns:</h5>
<ul>
<li><b><code>batch_shape</code></b>: <code>Tensor</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.bernoulliwithsigmoidp.cdfvalue-namecdf-condition_kwargs"><code id="BernoulliWithSigmoidP.cdf">tf.contrib.distributions.BernoulliWithSigmoidP.cdf(value, name='cdf', **condition_kwargs)</code></h4>
<p>Cumulative distribution function.</p>
<p>Given random variable <code>X</code>, the cumulative distribution function <code>cdf</code> is:</p>
<pre><code>cdf(x) := P[X &lt;= x]</code></pre>
<h5 id="args-55">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-62">Returns:</h5>
<ul>
<li><b><code>cdf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.bernoulliwithsigmoidp.copyoverride_parameters_kwargs"><code id="BernoulliWithSigmoidP.copy">tf.contrib.distributions.BernoulliWithSigmoidP.copy(**override_parameters_kwargs)</code></h4>
<p>Creates a deep copy of the distribution.</p>
<p>Note: the copy distribution may continue to depend on the original intialization arguments.</p>
<h5 id="args-56">Args:</h5>
<ul>
<li><b><code>**override_parameters_kwargs</code></b>: String/value dictionary of initialization arguments to override with new values.</li>
</ul>
<h5 id="returns-63">Returns:</h5>
<ul>
<li><b><code>distribution</code></b>: A new instance of <code>type(self)</code> intitialized from the union of self.parameters and override_parameters_kwargs, i.e., <code>dict(self.parameters, **override_parameters_kwargs)</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.bernoulliwithsigmoidp.dtype"><code id="BernoulliWithSigmoidP.dtype">tf.contrib.distributions.BernoulliWithSigmoidP.dtype</code></h4>
<p>The <code>DType</code> of <code>Tensor</code>s handled by this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.bernoulliwithsigmoidp.entropynameentropy"><code id="BernoulliWithSigmoidP.entropy">tf.contrib.distributions.BernoulliWithSigmoidP.entropy(name='entropy')</code></h4>
<p>Shannon entropy in nats.</p>
<hr />
<h4 id="tf.contrib.distributions.bernoulliwithsigmoidp.event_shapenameevent_shape"><code id="BernoulliWithSigmoidP.event_shape">tf.contrib.distributions.BernoulliWithSigmoidP.event_shape(name='event_shape')</code></h4>
<p>Shape of a single sample from a single batch as a 1-D int32 <code>Tensor</code>.</p>
<h5 id="args-57">Args:</h5>
<ul>
<li><b><code>name</code></b>: name to give to the op</li>
</ul>
<h5 id="returns-64">Returns:</h5>
<ul>
<li><b><code>event_shape</code></b>: <code>Tensor</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.bernoulliwithsigmoidp.get_batch_shape"><code id="BernoulliWithSigmoidP.get_batch_shape">tf.contrib.distributions.BernoulliWithSigmoidP.get_batch_shape()</code></h4>
<p>Shape of a single sample from a single event index as a <code>TensorShape</code>.</p>
<p>Same meaning as <code>batch_shape</code>. May be only partially defined.</p>
<h5 id="returns-65">Returns:</h5>
<ul>
<li><b><code>batch_shape</code></b>: <code>TensorShape</code>, possibly unknown.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.bernoulliwithsigmoidp.get_event_shape"><code id="BernoulliWithSigmoidP.get_event_shape">tf.contrib.distributions.BernoulliWithSigmoidP.get_event_shape()</code></h4>
<p>Shape of a single sample from a single batch as a <code>TensorShape</code>.</p>
<p>Same meaning as <code>event_shape</code>. May be only partially defined.</p>
<h5 id="returns-66">Returns:</h5>
<ul>
<li><b><code>event_shape</code></b>: <code>TensorShape</code>, possibly unknown.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.bernoulliwithsigmoidp.is_continuous"><code id="BernoulliWithSigmoidP.is_continuous">tf.contrib.distributions.BernoulliWithSigmoidP.is_continuous</code></h4>
<hr />
<h4 id="tf.contrib.distributions.bernoulliwithsigmoidp.is_reparameterized"><code id="BernoulliWithSigmoidP.is_reparameterized">tf.contrib.distributions.BernoulliWithSigmoidP.is_reparameterized</code></h4>
<hr />
<h4 id="tf.contrib.distributions.bernoulliwithsigmoidp.log_cdfvalue-namelog_cdf-condition_kwargs"><code id="BernoulliWithSigmoidP.log_cdf">tf.contrib.distributions.BernoulliWithSigmoidP.log_cdf(value, name='log_cdf', **condition_kwargs)</code></h4>
<p>Log cumulative distribution function.</p>
<p>Given random variable <code>X</code>, the cumulative distribution function <code>cdf</code> is:</p>
<pre><code>log_cdf(x) := Log[ P[X &lt;= x] ]</code></pre>
<p>Often, a numerical approximation can be used for <code>log_cdf(x)</code> that yields a more accurate answer than simply taking the logarithm of the <code>cdf</code> when <code>x &lt;&lt; -1</code>.</p>
<h5 id="args-58">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-67">Returns:</h5>
<ul>
<li><b><code>logcdf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.bernoulliwithsigmoidp.log_pdfvalue-namelog_pdf-condition_kwargs"><code id="BernoulliWithSigmoidP.log_pdf">tf.contrib.distributions.BernoulliWithSigmoidP.log_pdf(value, name='log_pdf', **condition_kwargs)</code></h4>
<p>Log probability density function.</p>
<h5 id="args-59">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-68">Returns:</h5>
<ul>
<li><b><code>log_prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-20">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if not <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.bernoulliwithsigmoidp.log_pmfvalue-namelog_pmf-condition_kwargs"><code id="BernoulliWithSigmoidP.log_pmf">tf.contrib.distributions.BernoulliWithSigmoidP.log_pmf(value, name='log_pmf', **condition_kwargs)</code></h4>
<p>Log probability mass function.</p>
<h5 id="args-60">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-69">Returns:</h5>
<ul>
<li><b><code>log_pmf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-21">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.bernoulliwithsigmoidp.log_probvalue-namelog_prob-condition_kwargs"><code id="BernoulliWithSigmoidP.log_prob">tf.contrib.distributions.BernoulliWithSigmoidP.log_prob(value, name='log_prob', **condition_kwargs)</code></h4>
<p>Log probability density/mass function (depending on <code>is_continuous</code>).</p>
<h5 id="args-61">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-70">Returns:</h5>
<ul>
<li><b><code>log_prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.bernoulliwithsigmoidp.log_survival_functionvalue-namelog_survival_function-condition_kwargs"><code id="BernoulliWithSigmoidP.log_survival_function">tf.contrib.distributions.BernoulliWithSigmoidP.log_survival_function(value, name='log_survival_function', **condition_kwargs)</code></h4>
<p>Log survival function.</p>
<p>Given random variable <code>X</code>, the survival function is defined:</p>
<pre><code>log_survival_function(x) = Log[ P[X &gt; x] ]
                         = Log[ 1 - P[X &lt;= x] ]
                         = Log[ 1 - cdf(x) ]</code></pre>
<p>Typically, different numerical approximations can be used for the log survival function, which are more accurate than <code>1 - cdf(x)</code> when <code>x &gt;&gt; 1</code>.</p>
<h5 id="args-62">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-71">Returns:</h5>
<p><code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.bernoulliwithsigmoidp.logits"><code id="BernoulliWithSigmoidP.logits">tf.contrib.distributions.BernoulliWithSigmoidP.logits</code></h4>
<p>Log-odds of success.</p>
<hr />
<h4 id="tf.contrib.distributions.bernoulliwithsigmoidp.meannamemean"><code id="BernoulliWithSigmoidP.mean">tf.contrib.distributions.BernoulliWithSigmoidP.mean(name='mean')</code></h4>
<p>Mean.</p>
<hr />
<h4 id="tf.contrib.distributions.bernoulliwithsigmoidp.modenamemode"><code id="BernoulliWithSigmoidP.mode">tf.contrib.distributions.BernoulliWithSigmoidP.mode(name='mode')</code></h4>
<p>Mode.</p>
<p>Additional documentation from <code>Bernoulli</code>:</p>
<p>Returns <code>1</code> if <code>p &gt; 1-p</code> and <code>0</code> otherwise.</p>
<hr />
<h4 id="tf.contrib.distributions.bernoulliwithsigmoidp.name"><code id="BernoulliWithSigmoidP.name">tf.contrib.distributions.BernoulliWithSigmoidP.name</code></h4>
<p>Name prepended to all ops created by this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.bernoulliwithsigmoidp.p"><code id="BernoulliWithSigmoidP.p">tf.contrib.distributions.BernoulliWithSigmoidP.p</code></h4>
<p>Probability of success.</p>
<hr />
<h4 id="tf.contrib.distributions.bernoulliwithsigmoidp.param_shapescls-sample_shape-namedistributionparamshapes"><code id="BernoulliWithSigmoidP.param_shapes">tf.contrib.distributions.BernoulliWithSigmoidP.param_shapes(cls, sample_shape, name='DistributionParamShapes')</code></h4>
<p>Shapes of parameters given the desired shape of a call to <code>sample()</code>.</p>
<p>Subclasses should override static method <code>_param_shapes</code>.</p>
<h5 id="args-63">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: <code>Tensor</code> or python list/tuple. Desired shape of a call to <code>sample()</code>.</li>
<li><b><code>name</code></b>: name to prepend ops with.</li>
</ul>
<h5 id="returns-72">Returns:</h5>
<p><code>dict</code> of parameter name to <code>Tensor</code> shapes.</p>
<hr />
<h4 id="tf.contrib.distributions.bernoulliwithsigmoidp.param_static_shapescls-sample_shape"><code id="BernoulliWithSigmoidP.param_static_shapes">tf.contrib.distributions.BernoulliWithSigmoidP.param_static_shapes(cls, sample_shape)</code></h4>
<p>param_shapes with static (i.e. TensorShape) shapes.</p>
<h5 id="args-64">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: <code>TensorShape</code> or python list/tuple. Desired shape of a call to <code>sample()</code>.</li>
</ul>
<h5 id="returns-73">Returns:</h5>
<p><code>dict</code> of parameter name to <code>TensorShape</code>.</p>
<h5 id="raises-22">Raises:</h5>
<ul>
<li><b><code>ValueError</code></b>: if <code>sample_shape</code> is a <code>TensorShape</code> and is not fully defined.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.bernoulliwithsigmoidp.parameters"><code id="BernoulliWithSigmoidP.parameters">tf.contrib.distributions.BernoulliWithSigmoidP.parameters</code></h4>
<p>Dictionary of parameters used to instantiate this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.bernoulliwithsigmoidp.pdfvalue-namepdf-condition_kwargs"><code id="BernoulliWithSigmoidP.pdf">tf.contrib.distributions.BernoulliWithSigmoidP.pdf(value, name='pdf', **condition_kwargs)</code></h4>
<p>Probability density function.</p>
<h5 id="args-65">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-74">Returns:</h5>
<ul>
<li><b><code>prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-23">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if not <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.bernoulliwithsigmoidp.pmfvalue-namepmf-condition_kwargs"><code id="BernoulliWithSigmoidP.pmf">tf.contrib.distributions.BernoulliWithSigmoidP.pmf(value, name='pmf', **condition_kwargs)</code></h4>
<p>Probability mass function.</p>
<h5 id="args-66">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-75">Returns:</h5>
<ul>
<li><b><code>pmf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-24">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.bernoulliwithsigmoidp.probvalue-nameprob-condition_kwargs"><code id="BernoulliWithSigmoidP.prob">tf.contrib.distributions.BernoulliWithSigmoidP.prob(value, name='prob', **condition_kwargs)</code></h4>
<p>Probability density/mass function (depending on <code>is_continuous</code>).</p>
<h5 id="args-67">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-76">Returns:</h5>
<ul>
<li><b><code>prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.bernoulliwithsigmoidp.q"><code id="BernoulliWithSigmoidP.q">tf.contrib.distributions.BernoulliWithSigmoidP.q</code></h4>
<p>1-p.</p>
<hr />
<h4 id="tf.contrib.distributions.bernoulliwithsigmoidp.samplesample_shape-seednone-namesample-condition_kwargs"><code id="BernoulliWithSigmoidP.sample">tf.contrib.distributions.BernoulliWithSigmoidP.sample(sample_shape=(), seed=None, name='sample', **condition_kwargs)</code></h4>
<p>Generate samples of the specified shape.</p>
<p>Note that a call to <code>sample()</code> without arguments will generate a single sample.</p>
<h5 id="args-68">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: 0D or 1D <code>int32</code> <code>Tensor</code>. Shape of the generated samples.</li>
<li><b><code>seed</code></b>: Python integer seed for RNG</li>
<li><b><code>name</code></b>: name to give to the op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-77">Returns:</h5>
<ul>
<li><b><code>samples</code></b>: a <code>Tensor</code> with prepended dimensions <code>sample_shape</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.bernoulliwithsigmoidp.sample_nn-seednone-namesample_n-condition_kwargs"><code id="BernoulliWithSigmoidP.sample_n">tf.contrib.distributions.BernoulliWithSigmoidP.sample_n(n, seed=None, name='sample_n', **condition_kwargs)</code></h4>
<p>Generate <code>n</code> samples.</p>
<h5 id="args-69">Args:</h5>
<ul>
<li><b><code>n</code></b>: <code>Scalar</code> <code>Tensor</code> of type <code>int32</code> or <code>int64</code>, the number of observations to sample.</li>
<li><b><code>seed</code></b>: Python integer seed for RNG</li>
<li><b><code>name</code></b>: name to give to the op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-78">Returns:</h5>
<ul>
<li><b><code>samples</code></b>: a <code>Tensor</code> with a prepended dimension (n,).</li>
</ul>
<h5 id="raises-25">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>n</code> is not an integer type.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.bernoulliwithsigmoidp.stdnamestd"><code id="BernoulliWithSigmoidP.std">tf.contrib.distributions.BernoulliWithSigmoidP.std(name='std')</code></h4>
<p>Standard deviation.</p>
<hr />
<h4 id="tf.contrib.distributions.bernoulliwithsigmoidp.survival_functionvalue-namesurvival_function-condition_kwargs"><code id="BernoulliWithSigmoidP.survival_function">tf.contrib.distributions.BernoulliWithSigmoidP.survival_function(value, name='survival_function', **condition_kwargs)</code></h4>
<p>Survival function.</p>
<p>Given random variable <code>X</code>, the survival function is defined:</p>
<pre><code>survival_function(x) = P[X &gt; x]
                     = 1 - P[X &lt;= x]
                     = 1 - cdf(x).</code></pre>
<h5 id="args-70">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-79">Returns:</h5>
<p>Tensor<code>of shape</code>sample_shape(x) + self.batch_shape<code>with values of type</code>self.dtype`.</p>
<hr />
<h4 id="tf.contrib.distributions.bernoulliwithsigmoidp.validate_args"><code id="BernoulliWithSigmoidP.validate_args">tf.contrib.distributions.BernoulliWithSigmoidP.validate_args</code></h4>
<p>Python boolean indicated possibly expensive checks are enabled.</p>
<hr />
<h4 id="tf.contrib.distributions.bernoulliwithsigmoidp.variancenamevariance"><code id="BernoulliWithSigmoidP.variance">tf.contrib.distributions.BernoulliWithSigmoidP.variance(name='variance')</code></h4>
<p>Variance.</p>
<hr />
<h3 id="class-tf.contrib.distributions.beta"><a name="//apple_ref/cpp/Class/Beta" class="dashAnchor"></a><code id="Beta">class tf.contrib.distributions.Beta</code></h3>
<p>Beta distribution.</p>
<p>This distribution is parameterized by <code>a</code> and <code>b</code> which are shape parameters.</p>
<h4 id="mathematical-details-1">Mathematical details</h4>
<p>The Beta is a distribution over the interval (0, 1). The distribution has hyperparameters <code>a</code> and <code>b</code> and probability mass function (pdf):</p>
<p><code>pdf(x) = 1 / Beta(a, b) * x^(a - 1) * (1 - x)^(b - 1)</code></p>
<p>where <code>Beta(a, b) = Gamma(a) * Gamma(b) / Gamma(a + b)</code> is the beta function.</p>
<p>This class provides methods to create indexed batches of Beta distributions. One entry of the broadcasted shape represents of <code>a</code> and <code>b</code> represents one single Beta distribution. When calling distribution functions (e.g. <code>dist.pdf(x)</code>), <code>a</code>, <code>b</code> and <code>x</code> are broadcast to the same shape (if possible). Every entry in a/b/x corresponds to a single Beta distribution.</p>
<h4 id="examples-1">Examples</h4>
<p>Creates 3 distributions. The distribution functions can be evaluated on x.</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">a <span class="op">=</span> [<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>]
b <span class="op">=</span> [<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>]
dist <span class="op">=</span> Beta(a, b)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="co"># x same shape as a.</span>
x <span class="op">=</span> [.<span class="dv">2</span>, .<span class="dv">3</span>, .<span class="dv">7</span>]
dist.pdf(x)  <span class="co"># Shape [3]</span>

<span class="co"># a/b will be broadcast to [[1, 2, 3], [1, 2, 3]] to match x.</span>
x <span class="op">=</span> [[.<span class="dv">1</span>, .<span class="dv">4</span>, .<span class="dv">5</span>], [.<span class="dv">2</span>, .<span class="dv">3</span>, .<span class="dv">5</span>]]
dist.pdf(x)  <span class="co"># Shape [2, 3]</span>

<span class="co"># a/b will be broadcast to shape [5, 7, 3] to match x.</span>
x <span class="op">=</span> [[...]]  <span class="co"># Shape [5, 7, 3]</span>
dist.pdf(x)  <span class="co"># Shape [5, 7, 3]</span></code></pre></div>
<p>Creates a 2-batch of 3-class distributions.</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">a <span class="op">=</span> [[<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>], [<span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">6</span>]]  <span class="co"># Shape [2, 3]</span>
b <span class="op">=</span> <span class="dv">5</span>  <span class="co"># Shape []</span>
dist <span class="op">=</span> Beta(a, b)

<span class="co"># x will be broadcast to [[.2, .3, .9], [.2, .3, .9]] to match a/b.</span>
x <span class="op">=</span> [.<span class="dv">2</span>, .<span class="dv">3</span>, .<span class="dv">9</span>]
dist.pdf(x)  <span class="co"># Shape [2]</span></code></pre></div>
<hr />
<h4 id="tf.contrib.distributions.beta.__init__a-b-validate_argsfalse-allow_nan_statstrue-namebeta"><code id="Beta.__init__">tf.contrib.distributions.Beta.__init__(a, b, validate_args=False, allow_nan_stats=True, name='Beta')</code></h4>
<p>Initialize a batch of Beta distributions.</p>
<h5 id="args-71">Args:</h5>
<ul>
<li><b><code>a</code></b>: Positive floating point tensor with shape broadcastable to <code>[N1,..., Nm]</code> <code>m &gt;= 0</code>. Defines this as a batch of <code>N1 x ... x Nm</code> different Beta distributions. This also defines the dtype of the distribution.</li>
<li><b><code>b</code></b>: Positive floating point tensor with shape broadcastable to <code>[N1,..., Nm]</code> <code>m &gt;= 0</code>. Defines this as a batch of <code>N1 x ... x Nm</code> different Beta distributions.</li>
<li><b><code>validate_args</code></b>: <code>Boolean</code>, default <code>False</code>. Whether to assert valid values for parameters <code>a</code>, <code>b</code>, and <code>x</code> in <code>prob</code> and <code>log_prob</code>. If <code>False</code> and inputs are invalid, correct behavior is not guaranteed.</li>
<li><b><code>allow_nan_stats</code></b>: <code>Boolean</code>, default <code>True</code>. If <code>False</code>, raise an exception if a statistic (e.g. mean/mode/etc...) is undefined for any batch member. If <code>True</code>, batch members with valid parameters leading to undefined statistics will return NaN for this statistic.</li>
<li><p><b><code>name</code></b>: The name to prefix Ops created by this distribution class.</p></li>
<li><p><b><code>Examples</code></b>:</p></li>
</ul>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="co"># Define 1-batch.</span>
dist <span class="op">=</span> Beta(<span class="fl">1.1</span>, <span class="fl">2.0</span>)

<span class="co"># Define a 2-batch.</span>
dist <span class="op">=</span> Beta([<span class="fl">1.0</span>, <span class="fl">2.0</span>], [<span class="fl">4.0</span>, <span class="fl">5.0</span>])</code></pre></div>
<hr />
<h4 id="tf.contrib.distributions.beta.a"><code id="Beta.a">tf.contrib.distributions.Beta.a</code></h4>
<p>Shape parameter.</p>
<hr />
<h4 id="tf.contrib.distributions.beta.a_b_sum"><code id="Beta.a_b_sum">tf.contrib.distributions.Beta.a_b_sum</code></h4>
<p>Sum of parameters.</p>
<hr />
<h4 id="tf.contrib.distributions.beta.allow_nan_stats"><code id="Beta.allow_nan_stats">tf.contrib.distributions.Beta.allow_nan_stats</code></h4>
<p>Python boolean describing behavior when a stat is undefined.</p>
<p>Stats return +/- infinity when it makes sense. E.g., the variance of a Cauchy distribution is infinity. However, sometimes the statistic is undefined, e.g., if a distribution's pdf does not achieve a maximum within the support of the distribution, the mode is undefined. If the mean is undefined, then by definition the variance is undefined. E.g. the mean for Student's T for df = 1 is undefined (no clear way to say it is either + or - infinity), so the variance = E[(X - mean)^2] is also undefined.</p>
<h5 id="returns-80">Returns:</h5>
<ul>
<li><b><code>allow_nan_stats</code></b>: Python boolean.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.beta.b"><code id="Beta.b">tf.contrib.distributions.Beta.b</code></h4>
<p>Shape parameter.</p>
<hr />
<h4 id="tf.contrib.distributions.beta.batch_shapenamebatch_shape"><code id="Beta.batch_shape">tf.contrib.distributions.Beta.batch_shape(name='batch_shape')</code></h4>
<p>Shape of a single sample from a single event index as a 1-D <code>Tensor</code>.</p>
<p>The product of the dimensions of the <code>batch_shape</code> is the number of independent distributions of this kind the instance represents.</p>
<h5 id="args-72">Args:</h5>
<ul>
<li><b><code>name</code></b>: name to give to the op</li>
</ul>
<h5 id="returns-81">Returns:</h5>
<ul>
<li><b><code>batch_shape</code></b>: <code>Tensor</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.beta.cdfvalue-namecdf-condition_kwargs"><code id="Beta.cdf">tf.contrib.distributions.Beta.cdf(value, name='cdf', **condition_kwargs)</code></h4>
<p>Cumulative distribution function.</p>
<p>Given random variable <code>X</code>, the cumulative distribution function <code>cdf</code> is:</p>
<pre><code>cdf(x) := P[X &lt;= x]</code></pre>
<h5 id="args-73">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-82">Returns:</h5>
<ul>
<li><b><code>cdf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.beta.copyoverride_parameters_kwargs"><code id="Beta.copy">tf.contrib.distributions.Beta.copy(**override_parameters_kwargs)</code></h4>
<p>Creates a deep copy of the distribution.</p>
<p>Note: the copy distribution may continue to depend on the original intialization arguments.</p>
<h5 id="args-74">Args:</h5>
<ul>
<li><b><code>**override_parameters_kwargs</code></b>: String/value dictionary of initialization arguments to override with new values.</li>
</ul>
<h5 id="returns-83">Returns:</h5>
<ul>
<li><b><code>distribution</code></b>: A new instance of <code>type(self)</code> intitialized from the union of self.parameters and override_parameters_kwargs, i.e., <code>dict(self.parameters, **override_parameters_kwargs)</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.beta.dtype"><code id="Beta.dtype">tf.contrib.distributions.Beta.dtype</code></h4>
<p>The <code>DType</code> of <code>Tensor</code>s handled by this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.beta.entropynameentropy"><code id="Beta.entropy">tf.contrib.distributions.Beta.entropy(name='entropy')</code></h4>
<p>Shannon entropy in nats.</p>
<hr />
<h4 id="tf.contrib.distributions.beta.event_shapenameevent_shape"><code id="Beta.event_shape">tf.contrib.distributions.Beta.event_shape(name='event_shape')</code></h4>
<p>Shape of a single sample from a single batch as a 1-D int32 <code>Tensor</code>.</p>
<h5 id="args-75">Args:</h5>
<ul>
<li><b><code>name</code></b>: name to give to the op</li>
</ul>
<h5 id="returns-84">Returns:</h5>
<ul>
<li><b><code>event_shape</code></b>: <code>Tensor</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.beta.get_batch_shape"><code id="Beta.get_batch_shape">tf.contrib.distributions.Beta.get_batch_shape()</code></h4>
<p>Shape of a single sample from a single event index as a <code>TensorShape</code>.</p>
<p>Same meaning as <code>batch_shape</code>. May be only partially defined.</p>
<h5 id="returns-85">Returns:</h5>
<ul>
<li><b><code>batch_shape</code></b>: <code>TensorShape</code>, possibly unknown.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.beta.get_event_shape"><code id="Beta.get_event_shape">tf.contrib.distributions.Beta.get_event_shape()</code></h4>
<p>Shape of a single sample from a single batch as a <code>TensorShape</code>.</p>
<p>Same meaning as <code>event_shape</code>. May be only partially defined.</p>
<h5 id="returns-86">Returns:</h5>
<ul>
<li><b><code>event_shape</code></b>: <code>TensorShape</code>, possibly unknown.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.beta.is_continuous"><code id="Beta.is_continuous">tf.contrib.distributions.Beta.is_continuous</code></h4>
<hr />
<h4 id="tf.contrib.distributions.beta.is_reparameterized"><code id="Beta.is_reparameterized">tf.contrib.distributions.Beta.is_reparameterized</code></h4>
<hr />
<h4 id="tf.contrib.distributions.beta.log_cdfvalue-namelog_cdf-condition_kwargs"><code id="Beta.log_cdf">tf.contrib.distributions.Beta.log_cdf(value, name='log_cdf', **condition_kwargs)</code></h4>
<p>Log cumulative distribution function.</p>
<p>Given random variable <code>X</code>, the cumulative distribution function <code>cdf</code> is:</p>
<pre><code>log_cdf(x) := Log[ P[X &lt;= x] ]</code></pre>
<p>Often, a numerical approximation can be used for <code>log_cdf(x)</code> that yields a more accurate answer than simply taking the logarithm of the <code>cdf</code> when <code>x &lt;&lt; -1</code>.</p>
<p>Additional documentation from <code>Beta</code>:</p>
<p>Note that the argument <code>x</code> must be a non-negative floating point tensor whose shape can be broadcast with <code>self.a</code> and <code>self.b</code>. For fixed leading dimensions, the last dimension represents counts for the corresponding Beta distribution in <code>self.a</code> and <code>self.b</code>. <code>x</code> is only legal if <code>0 &lt; x &lt; 1</code>.</p>
<h5 id="args-76">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-87">Returns:</h5>
<ul>
<li><b><code>logcdf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.beta.log_pdfvalue-namelog_pdf-condition_kwargs"><code id="Beta.log_pdf">tf.contrib.distributions.Beta.log_pdf(value, name='log_pdf', **condition_kwargs)</code></h4>
<p>Log probability density function.</p>
<h5 id="args-77">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-88">Returns:</h5>
<ul>
<li><b><code>log_prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-26">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if not <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.beta.log_pmfvalue-namelog_pmf-condition_kwargs"><code id="Beta.log_pmf">tf.contrib.distributions.Beta.log_pmf(value, name='log_pmf', **condition_kwargs)</code></h4>
<p>Log probability mass function.</p>
<h5 id="args-78">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-89">Returns:</h5>
<ul>
<li><b><code>log_pmf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-27">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.beta.log_probvalue-namelog_prob-condition_kwargs"><code id="Beta.log_prob">tf.contrib.distributions.Beta.log_prob(value, name='log_prob', **condition_kwargs)</code></h4>
<p>Log probability density/mass function (depending on <code>is_continuous</code>).</p>
<h5 id="args-79">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-90">Returns:</h5>
<ul>
<li><b><code>log_prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.beta.log_survival_functionvalue-namelog_survival_function-condition_kwargs"><code id="Beta.log_survival_function">tf.contrib.distributions.Beta.log_survival_function(value, name='log_survival_function', **condition_kwargs)</code></h4>
<p>Log survival function.</p>
<p>Given random variable <code>X</code>, the survival function is defined:</p>
<pre><code>log_survival_function(x) = Log[ P[X &gt; x] ]
                         = Log[ 1 - P[X &lt;= x] ]
                         = Log[ 1 - cdf(x) ]</code></pre>
<p>Typically, different numerical approximations can be used for the log survival function, which are more accurate than <code>1 - cdf(x)</code> when <code>x &gt;&gt; 1</code>.</p>
<h5 id="args-80">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-91">Returns:</h5>
<p><code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.beta.meannamemean"><code id="Beta.mean">tf.contrib.distributions.Beta.mean(name='mean')</code></h4>
<p>Mean.</p>
<hr />
<h4 id="tf.contrib.distributions.beta.modenamemode"><code id="Beta.mode">tf.contrib.distributions.Beta.mode(name='mode')</code></h4>
<p>Mode.</p>
<p>Additional documentation from <code>Beta</code>:</p>
<p>Note that the mode for the Beta distribution is only defined when <code>a &gt; 1</code>, <code>b &gt; 1</code>. This returns the mode when <code>a &gt; 1</code> and <code>b &gt; 1</code>, and <code>NaN</code> otherwise. If <code>self.allow_nan_stats</code> is <code>False</code>, an exception will be raised rather than returning <code>NaN</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.beta.name"><code id="Beta.name">tf.contrib.distributions.Beta.name</code></h4>
<p>Name prepended to all ops created by this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.beta.param_shapescls-sample_shape-namedistributionparamshapes"><code id="Beta.param_shapes">tf.contrib.distributions.Beta.param_shapes(cls, sample_shape, name='DistributionParamShapes')</code></h4>
<p>Shapes of parameters given the desired shape of a call to <code>sample()</code>.</p>
<p>Subclasses should override static method <code>_param_shapes</code>.</p>
<h5 id="args-81">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: <code>Tensor</code> or python list/tuple. Desired shape of a call to <code>sample()</code>.</li>
<li><b><code>name</code></b>: name to prepend ops with.</li>
</ul>
<h5 id="returns-92">Returns:</h5>
<p><code>dict</code> of parameter name to <code>Tensor</code> shapes.</p>
<hr />
<h4 id="tf.contrib.distributions.beta.param_static_shapescls-sample_shape"><code id="Beta.param_static_shapes">tf.contrib.distributions.Beta.param_static_shapes(cls, sample_shape)</code></h4>
<p>param_shapes with static (i.e. TensorShape) shapes.</p>
<h5 id="args-82">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: <code>TensorShape</code> or python list/tuple. Desired shape of a call to <code>sample()</code>.</li>
</ul>
<h5 id="returns-93">Returns:</h5>
<p><code>dict</code> of parameter name to <code>TensorShape</code>.</p>
<h5 id="raises-28">Raises:</h5>
<ul>
<li><b><code>ValueError</code></b>: if <code>sample_shape</code> is a <code>TensorShape</code> and is not fully defined.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.beta.parameters"><code id="Beta.parameters">tf.contrib.distributions.Beta.parameters</code></h4>
<p>Dictionary of parameters used to instantiate this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.beta.pdfvalue-namepdf-condition_kwargs"><code id="Beta.pdf">tf.contrib.distributions.Beta.pdf(value, name='pdf', **condition_kwargs)</code></h4>
<p>Probability density function.</p>
<h5 id="args-83">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-94">Returns:</h5>
<ul>
<li><b><code>prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-29">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if not <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.beta.pmfvalue-namepmf-condition_kwargs"><code id="Beta.pmf">tf.contrib.distributions.Beta.pmf(value, name='pmf', **condition_kwargs)</code></h4>
<p>Probability mass function.</p>
<h5 id="args-84">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-95">Returns:</h5>
<ul>
<li><b><code>pmf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-30">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.beta.probvalue-nameprob-condition_kwargs"><code id="Beta.prob">tf.contrib.distributions.Beta.prob(value, name='prob', **condition_kwargs)</code></h4>
<p>Probability density/mass function (depending on <code>is_continuous</code>).</p>
<p>Additional documentation from <code>Beta</code>:</p>
<p>Note that the argument <code>x</code> must be a non-negative floating point tensor whose shape can be broadcast with <code>self.a</code> and <code>self.b</code>. For fixed leading dimensions, the last dimension represents counts for the corresponding Beta distribution in <code>self.a</code> and <code>self.b</code>. <code>x</code> is only legal if <code>0 &lt; x &lt; 1</code>.</p>
<h5 id="args-85">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-96">Returns:</h5>
<ul>
<li><b><code>prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.beta.samplesample_shape-seednone-namesample-condition_kwargs"><code id="Beta.sample">tf.contrib.distributions.Beta.sample(sample_shape=(), seed=None, name='sample', **condition_kwargs)</code></h4>
<p>Generate samples of the specified shape.</p>
<p>Note that a call to <code>sample()</code> without arguments will generate a single sample.</p>
<h5 id="args-86">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: 0D or 1D <code>int32</code> <code>Tensor</code>. Shape of the generated samples.</li>
<li><b><code>seed</code></b>: Python integer seed for RNG</li>
<li><b><code>name</code></b>: name to give to the op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-97">Returns:</h5>
<ul>
<li><b><code>samples</code></b>: a <code>Tensor</code> with prepended dimensions <code>sample_shape</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.beta.sample_nn-seednone-namesample_n-condition_kwargs"><code id="Beta.sample_n">tf.contrib.distributions.Beta.sample_n(n, seed=None, name='sample_n', **condition_kwargs)</code></h4>
<p>Generate <code>n</code> samples.</p>
<h5 id="args-87">Args:</h5>
<ul>
<li><b><code>n</code></b>: <code>Scalar</code> <code>Tensor</code> of type <code>int32</code> or <code>int64</code>, the number of observations to sample.</li>
<li><b><code>seed</code></b>: Python integer seed for RNG</li>
<li><b><code>name</code></b>: name to give to the op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-98">Returns:</h5>
<ul>
<li><b><code>samples</code></b>: a <code>Tensor</code> with a prepended dimension (n,).</li>
</ul>
<h5 id="raises-31">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>n</code> is not an integer type.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.beta.stdnamestd"><code id="Beta.std">tf.contrib.distributions.Beta.std(name='std')</code></h4>
<p>Standard deviation.</p>
<hr />
<h4 id="tf.contrib.distributions.beta.survival_functionvalue-namesurvival_function-condition_kwargs"><code id="Beta.survival_function">tf.contrib.distributions.Beta.survival_function(value, name='survival_function', **condition_kwargs)</code></h4>
<p>Survival function.</p>
<p>Given random variable <code>X</code>, the survival function is defined:</p>
<pre><code>survival_function(x) = P[X &gt; x]
                     = 1 - P[X &lt;= x]
                     = 1 - cdf(x).</code></pre>
<h5 id="args-88">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-99">Returns:</h5>
<p>Tensor<code>of shape</code>sample_shape(x) + self.batch_shape<code>with values of type</code>self.dtype`.</p>
<hr />
<h4 id="tf.contrib.distributions.beta.validate_args"><code id="Beta.validate_args">tf.contrib.distributions.Beta.validate_args</code></h4>
<p>Python boolean indicated possibly expensive checks are enabled.</p>
<hr />
<h4 id="tf.contrib.distributions.beta.variancenamevariance"><code id="Beta.variance">tf.contrib.distributions.Beta.variance(name='variance')</code></h4>
<p>Variance.</p>
<hr />
<h3 id="class-tf.contrib.distributions.betawithsoftplusab"><a name="//apple_ref/cpp/Class/BetaWithSoftplusAB" class="dashAnchor"></a><code id="BetaWithSoftplusAB">class tf.contrib.distributions.BetaWithSoftplusAB</code></h3>
<p>Beta with softplus transform on <code>a</code> and <code>b</code>. - - -</p>
<h4 id="tf.contrib.distributions.betawithsoftplusab.__init__a-b-validate_argsfalse-allow_nan_statstrue-namebetawithsoftplusab"><code id="BetaWithSoftplusAB.__init__">tf.contrib.distributions.BetaWithSoftplusAB.__init__(a, b, validate_args=False, allow_nan_stats=True, name='BetaWithSoftplusAB')</code></h4>
<hr />
<h4 id="tf.contrib.distributions.betawithsoftplusab.a"><code id="BetaWithSoftplusAB.a">tf.contrib.distributions.BetaWithSoftplusAB.a</code></h4>
<p>Shape parameter.</p>
<hr />
<h4 id="tf.contrib.distributions.betawithsoftplusab.a_b_sum"><code id="BetaWithSoftplusAB.a_b_sum">tf.contrib.distributions.BetaWithSoftplusAB.a_b_sum</code></h4>
<p>Sum of parameters.</p>
<hr />
<h4 id="tf.contrib.distributions.betawithsoftplusab.allow_nan_stats"><code id="BetaWithSoftplusAB.allow_nan_stats">tf.contrib.distributions.BetaWithSoftplusAB.allow_nan_stats</code></h4>
<p>Python boolean describing behavior when a stat is undefined.</p>
<p>Stats return +/- infinity when it makes sense. E.g., the variance of a Cauchy distribution is infinity. However, sometimes the statistic is undefined, e.g., if a distribution's pdf does not achieve a maximum within the support of the distribution, the mode is undefined. If the mean is undefined, then by definition the variance is undefined. E.g. the mean for Student's T for df = 1 is undefined (no clear way to say it is either + or - infinity), so the variance = E[(X - mean)^2] is also undefined.</p>
<h5 id="returns-100">Returns:</h5>
<ul>
<li><b><code>allow_nan_stats</code></b>: Python boolean.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.betawithsoftplusab.b"><code id="BetaWithSoftplusAB.b">tf.contrib.distributions.BetaWithSoftplusAB.b</code></h4>
<p>Shape parameter.</p>
<hr />
<h4 id="tf.contrib.distributions.betawithsoftplusab.batch_shapenamebatch_shape"><code id="BetaWithSoftplusAB.batch_shape">tf.contrib.distributions.BetaWithSoftplusAB.batch_shape(name='batch_shape')</code></h4>
<p>Shape of a single sample from a single event index as a 1-D <code>Tensor</code>.</p>
<p>The product of the dimensions of the <code>batch_shape</code> is the number of independent distributions of this kind the instance represents.</p>
<h5 id="args-89">Args:</h5>
<ul>
<li><b><code>name</code></b>: name to give to the op</li>
</ul>
<h5 id="returns-101">Returns:</h5>
<ul>
<li><b><code>batch_shape</code></b>: <code>Tensor</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.betawithsoftplusab.cdfvalue-namecdf-condition_kwargs"><code id="BetaWithSoftplusAB.cdf">tf.contrib.distributions.BetaWithSoftplusAB.cdf(value, name='cdf', **condition_kwargs)</code></h4>
<p>Cumulative distribution function.</p>
<p>Given random variable <code>X</code>, the cumulative distribution function <code>cdf</code> is:</p>
<pre><code>cdf(x) := P[X &lt;= x]</code></pre>
<h5 id="args-90">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-102">Returns:</h5>
<ul>
<li><b><code>cdf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.betawithsoftplusab.copyoverride_parameters_kwargs"><code id="BetaWithSoftplusAB.copy">tf.contrib.distributions.BetaWithSoftplusAB.copy(**override_parameters_kwargs)</code></h4>
<p>Creates a deep copy of the distribution.</p>
<p>Note: the copy distribution may continue to depend on the original intialization arguments.</p>
<h5 id="args-91">Args:</h5>
<ul>
<li><b><code>**override_parameters_kwargs</code></b>: String/value dictionary of initialization arguments to override with new values.</li>
</ul>
<h5 id="returns-103">Returns:</h5>
<ul>
<li><b><code>distribution</code></b>: A new instance of <code>type(self)</code> intitialized from the union of self.parameters and override_parameters_kwargs, i.e., <code>dict(self.parameters, **override_parameters_kwargs)</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.betawithsoftplusab.dtype"><code id="BetaWithSoftplusAB.dtype">tf.contrib.distributions.BetaWithSoftplusAB.dtype</code></h4>
<p>The <code>DType</code> of <code>Tensor</code>s handled by this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.betawithsoftplusab.entropynameentropy"><code id="BetaWithSoftplusAB.entropy">tf.contrib.distributions.BetaWithSoftplusAB.entropy(name='entropy')</code></h4>
<p>Shannon entropy in nats.</p>
<hr />
<h4 id="tf.contrib.distributions.betawithsoftplusab.event_shapenameevent_shape"><code id="BetaWithSoftplusAB.event_shape">tf.contrib.distributions.BetaWithSoftplusAB.event_shape(name='event_shape')</code></h4>
<p>Shape of a single sample from a single batch as a 1-D int32 <code>Tensor</code>.</p>
<h5 id="args-92">Args:</h5>
<ul>
<li><b><code>name</code></b>: name to give to the op</li>
</ul>
<h5 id="returns-104">Returns:</h5>
<ul>
<li><b><code>event_shape</code></b>: <code>Tensor</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.betawithsoftplusab.get_batch_shape"><code id="BetaWithSoftplusAB.get_batch_shape">tf.contrib.distributions.BetaWithSoftplusAB.get_batch_shape()</code></h4>
<p>Shape of a single sample from a single event index as a <code>TensorShape</code>.</p>
<p>Same meaning as <code>batch_shape</code>. May be only partially defined.</p>
<h5 id="returns-105">Returns:</h5>
<ul>
<li><b><code>batch_shape</code></b>: <code>TensorShape</code>, possibly unknown.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.betawithsoftplusab.get_event_shape"><code id="BetaWithSoftplusAB.get_event_shape">tf.contrib.distributions.BetaWithSoftplusAB.get_event_shape()</code></h4>
<p>Shape of a single sample from a single batch as a <code>TensorShape</code>.</p>
<p>Same meaning as <code>event_shape</code>. May be only partially defined.</p>
<h5 id="returns-106">Returns:</h5>
<ul>
<li><b><code>event_shape</code></b>: <code>TensorShape</code>, possibly unknown.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.betawithsoftplusab.is_continuous"><code id="BetaWithSoftplusAB.is_continuous">tf.contrib.distributions.BetaWithSoftplusAB.is_continuous</code></h4>
<hr />
<h4 id="tf.contrib.distributions.betawithsoftplusab.is_reparameterized"><code id="BetaWithSoftplusAB.is_reparameterized">tf.contrib.distributions.BetaWithSoftplusAB.is_reparameterized</code></h4>
<hr />
<h4 id="tf.contrib.distributions.betawithsoftplusab.log_cdfvalue-namelog_cdf-condition_kwargs"><code id="BetaWithSoftplusAB.log_cdf">tf.contrib.distributions.BetaWithSoftplusAB.log_cdf(value, name='log_cdf', **condition_kwargs)</code></h4>
<p>Log cumulative distribution function.</p>
<p>Given random variable <code>X</code>, the cumulative distribution function <code>cdf</code> is:</p>
<pre><code>log_cdf(x) := Log[ P[X &lt;= x] ]</code></pre>
<p>Often, a numerical approximation can be used for <code>log_cdf(x)</code> that yields a more accurate answer than simply taking the logarithm of the <code>cdf</code> when <code>x &lt;&lt; -1</code>.</p>
<p>Additional documentation from <code>Beta</code>:</p>
<p>Note that the argument <code>x</code> must be a non-negative floating point tensor whose shape can be broadcast with <code>self.a</code> and <code>self.b</code>. For fixed leading dimensions, the last dimension represents counts for the corresponding Beta distribution in <code>self.a</code> and <code>self.b</code>. <code>x</code> is only legal if <code>0 &lt; x &lt; 1</code>.</p>
<h5 id="args-93">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-107">Returns:</h5>
<ul>
<li><b><code>logcdf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.betawithsoftplusab.log_pdfvalue-namelog_pdf-condition_kwargs"><code id="BetaWithSoftplusAB.log_pdf">tf.contrib.distributions.BetaWithSoftplusAB.log_pdf(value, name='log_pdf', **condition_kwargs)</code></h4>
<p>Log probability density function.</p>
<h5 id="args-94">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-108">Returns:</h5>
<ul>
<li><b><code>log_prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-32">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if not <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.betawithsoftplusab.log_pmfvalue-namelog_pmf-condition_kwargs"><code id="BetaWithSoftplusAB.log_pmf">tf.contrib.distributions.BetaWithSoftplusAB.log_pmf(value, name='log_pmf', **condition_kwargs)</code></h4>
<p>Log probability mass function.</p>
<h5 id="args-95">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-109">Returns:</h5>
<ul>
<li><b><code>log_pmf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-33">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.betawithsoftplusab.log_probvalue-namelog_prob-condition_kwargs"><code id="BetaWithSoftplusAB.log_prob">tf.contrib.distributions.BetaWithSoftplusAB.log_prob(value, name='log_prob', **condition_kwargs)</code></h4>
<p>Log probability density/mass function (depending on <code>is_continuous</code>).</p>
<h5 id="args-96">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-110">Returns:</h5>
<ul>
<li><b><code>log_prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.betawithsoftplusab.log_survival_functionvalue-namelog_survival_function-condition_kwargs"><code id="BetaWithSoftplusAB.log_survival_function">tf.contrib.distributions.BetaWithSoftplusAB.log_survival_function(value, name='log_survival_function', **condition_kwargs)</code></h4>
<p>Log survival function.</p>
<p>Given random variable <code>X</code>, the survival function is defined:</p>
<pre><code>log_survival_function(x) = Log[ P[X &gt; x] ]
                         = Log[ 1 - P[X &lt;= x] ]
                         = Log[ 1 - cdf(x) ]</code></pre>
<p>Typically, different numerical approximations can be used for the log survival function, which are more accurate than <code>1 - cdf(x)</code> when <code>x &gt;&gt; 1</code>.</p>
<h5 id="args-97">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-111">Returns:</h5>
<p><code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.betawithsoftplusab.meannamemean"><code id="BetaWithSoftplusAB.mean">tf.contrib.distributions.BetaWithSoftplusAB.mean(name='mean')</code></h4>
<p>Mean.</p>
<hr />
<h4 id="tf.contrib.distributions.betawithsoftplusab.modenamemode"><code id="BetaWithSoftplusAB.mode">tf.contrib.distributions.BetaWithSoftplusAB.mode(name='mode')</code></h4>
<p>Mode.</p>
<p>Additional documentation from <code>Beta</code>:</p>
<p>Note that the mode for the Beta distribution is only defined when <code>a &gt; 1</code>, <code>b &gt; 1</code>. This returns the mode when <code>a &gt; 1</code> and <code>b &gt; 1</code>, and <code>NaN</code> otherwise. If <code>self.allow_nan_stats</code> is <code>False</code>, an exception will be raised rather than returning <code>NaN</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.betawithsoftplusab.name"><code id="BetaWithSoftplusAB.name">tf.contrib.distributions.BetaWithSoftplusAB.name</code></h4>
<p>Name prepended to all ops created by this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.betawithsoftplusab.param_shapescls-sample_shape-namedistributionparamshapes"><code id="BetaWithSoftplusAB.param_shapes">tf.contrib.distributions.BetaWithSoftplusAB.param_shapes(cls, sample_shape, name='DistributionParamShapes')</code></h4>
<p>Shapes of parameters given the desired shape of a call to <code>sample()</code>.</p>
<p>Subclasses should override static method <code>_param_shapes</code>.</p>
<h5 id="args-98">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: <code>Tensor</code> or python list/tuple. Desired shape of a call to <code>sample()</code>.</li>
<li><b><code>name</code></b>: name to prepend ops with.</li>
</ul>
<h5 id="returns-112">Returns:</h5>
<p><code>dict</code> of parameter name to <code>Tensor</code> shapes.</p>
<hr />
<h4 id="tf.contrib.distributions.betawithsoftplusab.param_static_shapescls-sample_shape"><code id="BetaWithSoftplusAB.param_static_shapes">tf.contrib.distributions.BetaWithSoftplusAB.param_static_shapes(cls, sample_shape)</code></h4>
<p>param_shapes with static (i.e. TensorShape) shapes.</p>
<h5 id="args-99">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: <code>TensorShape</code> or python list/tuple. Desired shape of a call to <code>sample()</code>.</li>
</ul>
<h5 id="returns-113">Returns:</h5>
<p><code>dict</code> of parameter name to <code>TensorShape</code>.</p>
<h5 id="raises-34">Raises:</h5>
<ul>
<li><b><code>ValueError</code></b>: if <code>sample_shape</code> is a <code>TensorShape</code> and is not fully defined.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.betawithsoftplusab.parameters"><code id="BetaWithSoftplusAB.parameters">tf.contrib.distributions.BetaWithSoftplusAB.parameters</code></h4>
<p>Dictionary of parameters used to instantiate this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.betawithsoftplusab.pdfvalue-namepdf-condition_kwargs"><code id="BetaWithSoftplusAB.pdf">tf.contrib.distributions.BetaWithSoftplusAB.pdf(value, name='pdf', **condition_kwargs)</code></h4>
<p>Probability density function.</p>
<h5 id="args-100">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-114">Returns:</h5>
<ul>
<li><b><code>prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-35">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if not <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.betawithsoftplusab.pmfvalue-namepmf-condition_kwargs"><code id="BetaWithSoftplusAB.pmf">tf.contrib.distributions.BetaWithSoftplusAB.pmf(value, name='pmf', **condition_kwargs)</code></h4>
<p>Probability mass function.</p>
<h5 id="args-101">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-115">Returns:</h5>
<ul>
<li><b><code>pmf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-36">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.betawithsoftplusab.probvalue-nameprob-condition_kwargs"><code id="BetaWithSoftplusAB.prob">tf.contrib.distributions.BetaWithSoftplusAB.prob(value, name='prob', **condition_kwargs)</code></h4>
<p>Probability density/mass function (depending on <code>is_continuous</code>).</p>
<p>Additional documentation from <code>Beta</code>:</p>
<p>Note that the argument <code>x</code> must be a non-negative floating point tensor whose shape can be broadcast with <code>self.a</code> and <code>self.b</code>. For fixed leading dimensions, the last dimension represents counts for the corresponding Beta distribution in <code>self.a</code> and <code>self.b</code>. <code>x</code> is only legal if <code>0 &lt; x &lt; 1</code>.</p>
<h5 id="args-102">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-116">Returns:</h5>
<ul>
<li><b><code>prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.betawithsoftplusab.samplesample_shape-seednone-namesample-condition_kwargs"><code id="BetaWithSoftplusAB.sample">tf.contrib.distributions.BetaWithSoftplusAB.sample(sample_shape=(), seed=None, name='sample', **condition_kwargs)</code></h4>
<p>Generate samples of the specified shape.</p>
<p>Note that a call to <code>sample()</code> without arguments will generate a single sample.</p>
<h5 id="args-103">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: 0D or 1D <code>int32</code> <code>Tensor</code>. Shape of the generated samples.</li>
<li><b><code>seed</code></b>: Python integer seed for RNG</li>
<li><b><code>name</code></b>: name to give to the op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-117">Returns:</h5>
<ul>
<li><b><code>samples</code></b>: a <code>Tensor</code> with prepended dimensions <code>sample_shape</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.betawithsoftplusab.sample_nn-seednone-namesample_n-condition_kwargs"><code id="BetaWithSoftplusAB.sample_n">tf.contrib.distributions.BetaWithSoftplusAB.sample_n(n, seed=None, name='sample_n', **condition_kwargs)</code></h4>
<p>Generate <code>n</code> samples.</p>
<h5 id="args-104">Args:</h5>
<ul>
<li><b><code>n</code></b>: <code>Scalar</code> <code>Tensor</code> of type <code>int32</code> or <code>int64</code>, the number of observations to sample.</li>
<li><b><code>seed</code></b>: Python integer seed for RNG</li>
<li><b><code>name</code></b>: name to give to the op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-118">Returns:</h5>
<ul>
<li><b><code>samples</code></b>: a <code>Tensor</code> with a prepended dimension (n,).</li>
</ul>
<h5 id="raises-37">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>n</code> is not an integer type.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.betawithsoftplusab.stdnamestd"><code id="BetaWithSoftplusAB.std">tf.contrib.distributions.BetaWithSoftplusAB.std(name='std')</code></h4>
<p>Standard deviation.</p>
<hr />
<h4 id="tf.contrib.distributions.betawithsoftplusab.survival_functionvalue-namesurvival_function-condition_kwargs"><code id="BetaWithSoftplusAB.survival_function">tf.contrib.distributions.BetaWithSoftplusAB.survival_function(value, name='survival_function', **condition_kwargs)</code></h4>
<p>Survival function.</p>
<p>Given random variable <code>X</code>, the survival function is defined:</p>
<pre><code>survival_function(x) = P[X &gt; x]
                     = 1 - P[X &lt;= x]
                     = 1 - cdf(x).</code></pre>
<h5 id="args-105">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-119">Returns:</h5>
<p>Tensor<code>of shape</code>sample_shape(x) + self.batch_shape<code>with values of type</code>self.dtype`.</p>
<hr />
<h4 id="tf.contrib.distributions.betawithsoftplusab.validate_args"><code id="BetaWithSoftplusAB.validate_args">tf.contrib.distributions.BetaWithSoftplusAB.validate_args</code></h4>
<p>Python boolean indicated possibly expensive checks are enabled.</p>
<hr />
<h4 id="tf.contrib.distributions.betawithsoftplusab.variancenamevariance"><code id="BetaWithSoftplusAB.variance">tf.contrib.distributions.BetaWithSoftplusAB.variance(name='variance')</code></h4>
<p>Variance.</p>
<hr />
<h3 id="class-tf.contrib.distributions.categorical"><a name="//apple_ref/cpp/Class/Categorical" class="dashAnchor"></a><code id="Categorical">class tf.contrib.distributions.Categorical</code></h3>
<p>Categorical distribution.</p>
<p>The categorical distribution is parameterized by the log-probabilities of a set of classes.</p>
<h4 id="examples-2">Examples</h4>
<p>Creates a 3-class distiribution, with the 2nd class, the most likely to be drawn from.</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">p <span class="op">=</span> [<span class="fl">0.1</span>, <span class="fl">0.5</span>, <span class="fl">0.4</span>]
dist <span class="op">=</span> Categorical(p<span class="op">=</span>p)</code></pre></div>
<p>Creates a 3-class distiribution, with the 2nd class the most likely to be drawn from, using logits.</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">logits <span class="op">=</span> [<span class="op">-</span><span class="dv">50</span>, <span class="dv">400</span>, <span class="dv">40</span>]
dist <span class="op">=</span> Categorical(logits<span class="op">=</span>logits)</code></pre></div>
<p>Creates a 3-class distribution, with the 3rd class is most likely to be drawn. The distribution functions can be evaluated on counts.</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="co"># counts is a scalar.</span>
p <span class="op">=</span> [<span class="fl">0.1</span>, <span class="fl">0.4</span>, <span class="fl">0.5</span>]
dist <span class="op">=</span> Categorical(p<span class="op">=</span>p)
dist.pmf(<span class="dv">0</span>)  <span class="co"># Shape []</span>

<span class="co"># p will be broadcast to [[0.1, 0.4, 0.5], [0.1, 0.4, 0.5]] to match counts.</span>
counts <span class="op">=</span> [<span class="dv">1</span>, <span class="dv">0</span>]
dist.pmf(counts)  <span class="co"># Shape [2]</span>

<span class="co"># p will be broadcast to shape [3, 5, 7, 3] to match counts.</span>
counts <span class="op">=</span> [[...]] <span class="co"># Shape [5, 7, 3]</span>
dist.pmf(counts)  <span class="co"># Shape [5, 7, 3]</span></code></pre></div>
<hr />
<h4 id="tf.contrib.distributions.categorical.__init__logitsnone-pnone-dtypetf.int32-validate_argsfalse-allow_nan_statstrue-namecategorical"><code id="Categorical.__init__">tf.contrib.distributions.Categorical.__init__(logits=None, p=None, dtype=tf.int32, validate_args=False, allow_nan_stats=True, name='Categorical')</code></h4>
<p>Initialize Categorical distributions using class log-probabilities.</p>
<h5 id="args-106">Args:</h5>
<ul>
<li><b><code>logits</code></b>: An N-D <code>Tensor</code>, <code>N &gt;= 1</code>, representing the log probabilities of a set of Categorical distributions. The first <code>N - 1</code> dimensions index into a batch of independent distributions and the last dimension represents a vector of logits for each class. Only one of <code>logits</code> or <code>p</code> should be passed in.</li>
<li><b><code>p</code></b>: An N-D <code>Tensor</code>, <code>N &gt;= 1</code>, representing the probabilities of a set of Categorical distributions. The first <code>N - 1</code> dimensions index into a batch of independent distributions and the last dimension represents a vector of probabilities for each class. Only one of <code>logits</code> or <code>p</code> should be passed in.</li>
<li><b><code>dtype</code></b>: The type of the event samples (default: int32).</li>
<li><b><code>validate_args</code></b>: Unused in this distribution.</li>
<li><b><code>allow_nan_stats</code></b>: <code>Boolean</code>, default <code>True</code>. If <code>False</code>, raise an exception if a statistic (e.g. mean/mode/etc...) is undefined for any batch member. If <code>True</code>, batch members with valid parameters leading to undefined statistics will return NaN for this statistic.</li>
<li><b><code>name</code></b>: A name for this distribution (optional).</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.categorical.allow_nan_stats"><code id="Categorical.allow_nan_stats">tf.contrib.distributions.Categorical.allow_nan_stats</code></h4>
<p>Python boolean describing behavior when a stat is undefined.</p>
<p>Stats return +/- infinity when it makes sense. E.g., the variance of a Cauchy distribution is infinity. However, sometimes the statistic is undefined, e.g., if a distribution's pdf does not achieve a maximum within the support of the distribution, the mode is undefined. If the mean is undefined, then by definition the variance is undefined. E.g. the mean for Student's T for df = 1 is undefined (no clear way to say it is either + or - infinity), so the variance = E[(X - mean)^2] is also undefined.</p>
<h5 id="returns-120">Returns:</h5>
<ul>
<li><b><code>allow_nan_stats</code></b>: Python boolean.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.categorical.batch_shapenamebatch_shape"><code id="Categorical.batch_shape">tf.contrib.distributions.Categorical.batch_shape(name='batch_shape')</code></h4>
<p>Shape of a single sample from a single event index as a 1-D <code>Tensor</code>.</p>
<p>The product of the dimensions of the <code>batch_shape</code> is the number of independent distributions of this kind the instance represents.</p>
<h5 id="args-107">Args:</h5>
<ul>
<li><b><code>name</code></b>: name to give to the op</li>
</ul>
<h5 id="returns-121">Returns:</h5>
<ul>
<li><b><code>batch_shape</code></b>: <code>Tensor</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.categorical.cdfvalue-namecdf-condition_kwargs"><code id="Categorical.cdf">tf.contrib.distributions.Categorical.cdf(value, name='cdf', **condition_kwargs)</code></h4>
<p>Cumulative distribution function.</p>
<p>Given random variable <code>X</code>, the cumulative distribution function <code>cdf</code> is:</p>
<pre><code>cdf(x) := P[X &lt;= x]</code></pre>
<h5 id="args-108">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-122">Returns:</h5>
<ul>
<li><b><code>cdf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.categorical.copyoverride_parameters_kwargs"><code id="Categorical.copy">tf.contrib.distributions.Categorical.copy(**override_parameters_kwargs)</code></h4>
<p>Creates a deep copy of the distribution.</p>
<p>Note: the copy distribution may continue to depend on the original intialization arguments.</p>
<h5 id="args-109">Args:</h5>
<ul>
<li><b><code>**override_parameters_kwargs</code></b>: String/value dictionary of initialization arguments to override with new values.</li>
</ul>
<h5 id="returns-123">Returns:</h5>
<ul>
<li><b><code>distribution</code></b>: A new instance of <code>type(self)</code> intitialized from the union of self.parameters and override_parameters_kwargs, i.e., <code>dict(self.parameters, **override_parameters_kwargs)</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.categorical.dtype"><code id="Categorical.dtype">tf.contrib.distributions.Categorical.dtype</code></h4>
<p>The <code>DType</code> of <code>Tensor</code>s handled by this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.categorical.entropynameentropy"><code id="Categorical.entropy">tf.contrib.distributions.Categorical.entropy(name='entropy')</code></h4>
<p>Shannon entropy in nats.</p>
<hr />
<h4 id="tf.contrib.distributions.categorical.event_shapenameevent_shape"><code id="Categorical.event_shape">tf.contrib.distributions.Categorical.event_shape(name='event_shape')</code></h4>
<p>Shape of a single sample from a single batch as a 1-D int32 <code>Tensor</code>.</p>
<h5 id="args-110">Args:</h5>
<ul>
<li><b><code>name</code></b>: name to give to the op</li>
</ul>
<h5 id="returns-124">Returns:</h5>
<ul>
<li><b><code>event_shape</code></b>: <code>Tensor</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.categorical.get_batch_shape"><code id="Categorical.get_batch_shape">tf.contrib.distributions.Categorical.get_batch_shape()</code></h4>
<p>Shape of a single sample from a single event index as a <code>TensorShape</code>.</p>
<p>Same meaning as <code>batch_shape</code>. May be only partially defined.</p>
<h5 id="returns-125">Returns:</h5>
<ul>
<li><b><code>batch_shape</code></b>: <code>TensorShape</code>, possibly unknown.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.categorical.get_event_shape"><code id="Categorical.get_event_shape">tf.contrib.distributions.Categorical.get_event_shape()</code></h4>
<p>Shape of a single sample from a single batch as a <code>TensorShape</code>.</p>
<p>Same meaning as <code>event_shape</code>. May be only partially defined.</p>
<h5 id="returns-126">Returns:</h5>
<ul>
<li><b><code>event_shape</code></b>: <code>TensorShape</code>, possibly unknown.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.categorical.is_continuous"><code id="Categorical.is_continuous">tf.contrib.distributions.Categorical.is_continuous</code></h4>
<hr />
<h4 id="tf.contrib.distributions.categorical.is_reparameterized"><code id="Categorical.is_reparameterized">tf.contrib.distributions.Categorical.is_reparameterized</code></h4>
<hr />
<h4 id="tf.contrib.distributions.categorical.log_cdfvalue-namelog_cdf-condition_kwargs"><code id="Categorical.log_cdf">tf.contrib.distributions.Categorical.log_cdf(value, name='log_cdf', **condition_kwargs)</code></h4>
<p>Log cumulative distribution function.</p>
<p>Given random variable <code>X</code>, the cumulative distribution function <code>cdf</code> is:</p>
<pre><code>log_cdf(x) := Log[ P[X &lt;= x] ]</code></pre>
<p>Often, a numerical approximation can be used for <code>log_cdf(x)</code> that yields a more accurate answer than simply taking the logarithm of the <code>cdf</code> when <code>x &lt;&lt; -1</code>.</p>
<h5 id="args-111">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-127">Returns:</h5>
<ul>
<li><b><code>logcdf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.categorical.log_pdfvalue-namelog_pdf-condition_kwargs"><code id="Categorical.log_pdf">tf.contrib.distributions.Categorical.log_pdf(value, name='log_pdf', **condition_kwargs)</code></h4>
<p>Log probability density function.</p>
<h5 id="args-112">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-128">Returns:</h5>
<ul>
<li><b><code>log_prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-38">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if not <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.categorical.log_pmfvalue-namelog_pmf-condition_kwargs"><code id="Categorical.log_pmf">tf.contrib.distributions.Categorical.log_pmf(value, name='log_pmf', **condition_kwargs)</code></h4>
<p>Log probability mass function.</p>
<h5 id="args-113">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-129">Returns:</h5>
<ul>
<li><b><code>log_pmf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-39">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.categorical.log_probvalue-namelog_prob-condition_kwargs"><code id="Categorical.log_prob">tf.contrib.distributions.Categorical.log_prob(value, name='log_prob', **condition_kwargs)</code></h4>
<p>Log probability density/mass function (depending on <code>is_continuous</code>).</p>
<h5 id="args-114">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-130">Returns:</h5>
<ul>
<li><b><code>log_prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.categorical.log_survival_functionvalue-namelog_survival_function-condition_kwargs"><code id="Categorical.log_survival_function">tf.contrib.distributions.Categorical.log_survival_function(value, name='log_survival_function', **condition_kwargs)</code></h4>
<p>Log survival function.</p>
<p>Given random variable <code>X</code>, the survival function is defined:</p>
<pre><code>log_survival_function(x) = Log[ P[X &gt; x] ]
                         = Log[ 1 - P[X &lt;= x] ]
                         = Log[ 1 - cdf(x) ]</code></pre>
<p>Typically, different numerical approximations can be used for the log survival function, which are more accurate than <code>1 - cdf(x)</code> when <code>x &gt;&gt; 1</code>.</p>
<h5 id="args-115">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-131">Returns:</h5>
<p><code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.categorical.logits"><code id="Categorical.logits">tf.contrib.distributions.Categorical.logits</code></h4>
<p>Vector of coordinatewise logits.</p>
<hr />
<h4 id="tf.contrib.distributions.categorical.meannamemean"><code id="Categorical.mean">tf.contrib.distributions.Categorical.mean(name='mean')</code></h4>
<p>Mean.</p>
<hr />
<h4 id="tf.contrib.distributions.categorical.modenamemode"><code id="Categorical.mode">tf.contrib.distributions.Categorical.mode(name='mode')</code></h4>
<p>Mode.</p>
<hr />
<h4 id="tf.contrib.distributions.categorical.name"><code id="Categorical.name">tf.contrib.distributions.Categorical.name</code></h4>
<p>Name prepended to all ops created by this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.categorical.num_classes"><code id="Categorical.num_classes">tf.contrib.distributions.Categorical.num_classes</code></h4>
<p>Scalar <code>int32</code> tensor: the number of classes.</p>
<hr />
<h4 id="tf.contrib.distributions.categorical.p"><code id="Categorical.p">tf.contrib.distributions.Categorical.p</code></h4>
<p>Vector of probabilities summing to one.</p>
<p>Each element is the probability of drawing that coordinate.</p>
<hr />
<h4 id="tf.contrib.distributions.categorical.param_shapescls-sample_shape-namedistributionparamshapes"><code id="Categorical.param_shapes">tf.contrib.distributions.Categorical.param_shapes(cls, sample_shape, name='DistributionParamShapes')</code></h4>
<p>Shapes of parameters given the desired shape of a call to <code>sample()</code>.</p>
<p>Subclasses should override static method <code>_param_shapes</code>.</p>
<h5 id="args-116">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: <code>Tensor</code> or python list/tuple. Desired shape of a call to <code>sample()</code>.</li>
<li><b><code>name</code></b>: name to prepend ops with.</li>
</ul>
<h5 id="returns-132">Returns:</h5>
<p><code>dict</code> of parameter name to <code>Tensor</code> shapes.</p>
<hr />
<h4 id="tf.contrib.distributions.categorical.param_static_shapescls-sample_shape"><code id="Categorical.param_static_shapes">tf.contrib.distributions.Categorical.param_static_shapes(cls, sample_shape)</code></h4>
<p>param_shapes with static (i.e. TensorShape) shapes.</p>
<h5 id="args-117">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: <code>TensorShape</code> or python list/tuple. Desired shape of a call to <code>sample()</code>.</li>
</ul>
<h5 id="returns-133">Returns:</h5>
<p><code>dict</code> of parameter name to <code>TensorShape</code>.</p>
<h5 id="raises-40">Raises:</h5>
<ul>
<li><b><code>ValueError</code></b>: if <code>sample_shape</code> is a <code>TensorShape</code> and is not fully defined.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.categorical.parameters"><code id="Categorical.parameters">tf.contrib.distributions.Categorical.parameters</code></h4>
<p>Dictionary of parameters used to instantiate this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.categorical.pdfvalue-namepdf-condition_kwargs"><code id="Categorical.pdf">tf.contrib.distributions.Categorical.pdf(value, name='pdf', **condition_kwargs)</code></h4>
<p>Probability density function.</p>
<h5 id="args-118">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-134">Returns:</h5>
<ul>
<li><b><code>prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-41">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if not <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.categorical.pmfvalue-namepmf-condition_kwargs"><code id="Categorical.pmf">tf.contrib.distributions.Categorical.pmf(value, name='pmf', **condition_kwargs)</code></h4>
<p>Probability mass function.</p>
<h5 id="args-119">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-135">Returns:</h5>
<ul>
<li><b><code>pmf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-42">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.categorical.probvalue-nameprob-condition_kwargs"><code id="Categorical.prob">tf.contrib.distributions.Categorical.prob(value, name='prob', **condition_kwargs)</code></h4>
<p>Probability density/mass function (depending on <code>is_continuous</code>).</p>
<h5 id="args-120">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-136">Returns:</h5>
<ul>
<li><b><code>prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.categorical.samplesample_shape-seednone-namesample-condition_kwargs"><code id="Categorical.sample">tf.contrib.distributions.Categorical.sample(sample_shape=(), seed=None, name='sample', **condition_kwargs)</code></h4>
<p>Generate samples of the specified shape.</p>
<p>Note that a call to <code>sample()</code> without arguments will generate a single sample.</p>
<h5 id="args-121">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: 0D or 1D <code>int32</code> <code>Tensor</code>. Shape of the generated samples.</li>
<li><b><code>seed</code></b>: Python integer seed for RNG</li>
<li><b><code>name</code></b>: name to give to the op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-137">Returns:</h5>
<ul>
<li><b><code>samples</code></b>: a <code>Tensor</code> with prepended dimensions <code>sample_shape</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.categorical.sample_nn-seednone-namesample_n-condition_kwargs"><code id="Categorical.sample_n">tf.contrib.distributions.Categorical.sample_n(n, seed=None, name='sample_n', **condition_kwargs)</code></h4>
<p>Generate <code>n</code> samples.</p>
<h5 id="args-122">Args:</h5>
<ul>
<li><b><code>n</code></b>: <code>Scalar</code> <code>Tensor</code> of type <code>int32</code> or <code>int64</code>, the number of observations to sample.</li>
<li><b><code>seed</code></b>: Python integer seed for RNG</li>
<li><b><code>name</code></b>: name to give to the op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-138">Returns:</h5>
<ul>
<li><b><code>samples</code></b>: a <code>Tensor</code> with a prepended dimension (n,).</li>
</ul>
<h5 id="raises-43">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>n</code> is not an integer type.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.categorical.stdnamestd"><code id="Categorical.std">tf.contrib.distributions.Categorical.std(name='std')</code></h4>
<p>Standard deviation.</p>
<hr />
<h4 id="tf.contrib.distributions.categorical.survival_functionvalue-namesurvival_function-condition_kwargs"><code id="Categorical.survival_function">tf.contrib.distributions.Categorical.survival_function(value, name='survival_function', **condition_kwargs)</code></h4>
<p>Survival function.</p>
<p>Given random variable <code>X</code>, the survival function is defined:</p>
<pre><code>survival_function(x) = P[X &gt; x]
                     = 1 - P[X &lt;= x]
                     = 1 - cdf(x).</code></pre>
<h5 id="args-123">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-139">Returns:</h5>
<p>Tensor<code>of shape</code>sample_shape(x) + self.batch_shape<code>with values of type</code>self.dtype`.</p>
<hr />
<h4 id="tf.contrib.distributions.categorical.validate_args"><code id="Categorical.validate_args">tf.contrib.distributions.Categorical.validate_args</code></h4>
<p>Python boolean indicated possibly expensive checks are enabled.</p>
<hr />
<h4 id="tf.contrib.distributions.categorical.variancenamevariance"><code id="Categorical.variance">tf.contrib.distributions.Categorical.variance(name='variance')</code></h4>
<p>Variance.</p>
<hr />
<h3 id="class-tf.contrib.distributions.chi2"><a name="//apple_ref/cpp/Class/Chi2" class="dashAnchor"></a><code id="Chi2">class tf.contrib.distributions.Chi2</code></h3>
<p>The Chi2 distribution with degrees of freedom df.</p>
<p>The PDF of this distribution is:</p>
<p><code>pdf(x) = (x^(df/2 - 1)e^(-x/2))/(2^(df/2)Gamma(df/2)), x &gt; 0</code></p>
<p>Note that the Chi2 distribution is a special case of the Gamma distribution, with Chi2(df) = Gamma(df/2, 1/2). - - -</p>
<h4 id="tf.contrib.distributions.chi2.__init__df-validate_argsfalse-allow_nan_statstrue-namechi2"><code id="Chi2.__init__">tf.contrib.distributions.Chi2.__init__(df, validate_args=False, allow_nan_stats=True, name='Chi2')</code></h4>
<p>Construct Chi2 distributions with parameter <code>df</code>.</p>
<h5 id="args-124">Args:</h5>
<ul>
<li><b><code>df</code></b>: Floating point tensor, the degrees of freedom of the distribution(s). <code>df</code> must contain only positive values.</li>
<li><b><code>validate_args</code></b>: <code>Boolean</code>, default <code>False</code>. Whether to assert that <code>df &gt; 0</code>, and that <code>x &gt; 0</code> in the methods <code>prob(x)</code> and <code>log_prob(x)</code>. If <code>validate_args</code> is <code>False</code> and the inputs are invalid, correct behavior is not guaranteed.</li>
<li><b><code>allow_nan_stats</code></b>: <code>Boolean</code>, default <code>True</code>. If <code>False</code>, raise an exception if a statistic (e.g. mean/mode/etc...) is undefined for any batch member. If <code>True</code>, batch members with valid parameters leading to undefined statistics will return NaN for this statistic.</li>
<li><b><code>name</code></b>: The name to prepend to all ops created by this distribution.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.chi2.allow_nan_stats"><code id="Chi2.allow_nan_stats">tf.contrib.distributions.Chi2.allow_nan_stats</code></h4>
<p>Python boolean describing behavior when a stat is undefined.</p>
<p>Stats return +/- infinity when it makes sense. E.g., the variance of a Cauchy distribution is infinity. However, sometimes the statistic is undefined, e.g., if a distribution's pdf does not achieve a maximum within the support of the distribution, the mode is undefined. If the mean is undefined, then by definition the variance is undefined. E.g. the mean for Student's T for df = 1 is undefined (no clear way to say it is either + or - infinity), so the variance = E[(X - mean)^2] is also undefined.</p>
<h5 id="returns-140">Returns:</h5>
<ul>
<li><b><code>allow_nan_stats</code></b>: Python boolean.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.chi2.alpha"><code id="Chi2.alpha">tf.contrib.distributions.Chi2.alpha</code></h4>
<p>Shape parameter.</p>
<hr />
<h4 id="tf.contrib.distributions.chi2.batch_shapenamebatch_shape"><code id="Chi2.batch_shape">tf.contrib.distributions.Chi2.batch_shape(name='batch_shape')</code></h4>
<p>Shape of a single sample from a single event index as a 1-D <code>Tensor</code>.</p>
<p>The product of the dimensions of the <code>batch_shape</code> is the number of independent distributions of this kind the instance represents.</p>
<h5 id="args-125">Args:</h5>
<ul>
<li><b><code>name</code></b>: name to give to the op</li>
</ul>
<h5 id="returns-141">Returns:</h5>
<ul>
<li><b><code>batch_shape</code></b>: <code>Tensor</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.chi2.beta"><code id="Chi2.beta">tf.contrib.distributions.Chi2.beta</code></h4>
<p>Inverse scale parameter.</p>
<hr />
<h4 id="tf.contrib.distributions.chi2.cdfvalue-namecdf-condition_kwargs"><code id="Chi2.cdf">tf.contrib.distributions.Chi2.cdf(value, name='cdf', **condition_kwargs)</code></h4>
<p>Cumulative distribution function.</p>
<p>Given random variable <code>X</code>, the cumulative distribution function <code>cdf</code> is:</p>
<pre><code>cdf(x) := P[X &lt;= x]</code></pre>
<h5 id="args-126">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-142">Returns:</h5>
<ul>
<li><b><code>cdf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.chi2.copyoverride_parameters_kwargs"><code id="Chi2.copy">tf.contrib.distributions.Chi2.copy(**override_parameters_kwargs)</code></h4>
<p>Creates a deep copy of the distribution.</p>
<p>Note: the copy distribution may continue to depend on the original intialization arguments.</p>
<h5 id="args-127">Args:</h5>
<ul>
<li><b><code>**override_parameters_kwargs</code></b>: String/value dictionary of initialization arguments to override with new values.</li>
</ul>
<h5 id="returns-143">Returns:</h5>
<ul>
<li><b><code>distribution</code></b>: A new instance of <code>type(self)</code> intitialized from the union of self.parameters and override_parameters_kwargs, i.e., <code>dict(self.parameters, **override_parameters_kwargs)</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.chi2.df"><code id="Chi2.df">tf.contrib.distributions.Chi2.df</code></h4>
<hr />
<h4 id="tf.contrib.distributions.chi2.dtype"><code id="Chi2.dtype">tf.contrib.distributions.Chi2.dtype</code></h4>
<p>The <code>DType</code> of <code>Tensor</code>s handled by this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.chi2.entropynameentropy"><code id="Chi2.entropy">tf.contrib.distributions.Chi2.entropy(name='entropy')</code></h4>
<p>Shannon entropy in nats.</p>
<p>Additional documentation from <code>Gamma</code>:</p>
<p>This is defined to be</p>
<pre><code>entropy = alpha - log(beta) + log(Gamma(alpha))
+ (1-alpha)digamma(alpha)</code></pre>
<p>where digamma(alpha) is the digamma function.</p>
<hr />
<h4 id="tf.contrib.distributions.chi2.event_shapenameevent_shape"><code id="Chi2.event_shape">tf.contrib.distributions.Chi2.event_shape(name='event_shape')</code></h4>
<p>Shape of a single sample from a single batch as a 1-D int32 <code>Tensor</code>.</p>
<h5 id="args-128">Args:</h5>
<ul>
<li><b><code>name</code></b>: name to give to the op</li>
</ul>
<h5 id="returns-144">Returns:</h5>
<ul>
<li><b><code>event_shape</code></b>: <code>Tensor</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.chi2.get_batch_shape"><code id="Chi2.get_batch_shape">tf.contrib.distributions.Chi2.get_batch_shape()</code></h4>
<p>Shape of a single sample from a single event index as a <code>TensorShape</code>.</p>
<p>Same meaning as <code>batch_shape</code>. May be only partially defined.</p>
<h5 id="returns-145">Returns:</h5>
<ul>
<li><b><code>batch_shape</code></b>: <code>TensorShape</code>, possibly unknown.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.chi2.get_event_shape"><code id="Chi2.get_event_shape">tf.contrib.distributions.Chi2.get_event_shape()</code></h4>
<p>Shape of a single sample from a single batch as a <code>TensorShape</code>.</p>
<p>Same meaning as <code>event_shape</code>. May be only partially defined.</p>
<h5 id="returns-146">Returns:</h5>
<ul>
<li><b><code>event_shape</code></b>: <code>TensorShape</code>, possibly unknown.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.chi2.is_continuous"><code id="Chi2.is_continuous">tf.contrib.distributions.Chi2.is_continuous</code></h4>
<hr />
<h4 id="tf.contrib.distributions.chi2.is_reparameterized"><code id="Chi2.is_reparameterized">tf.contrib.distributions.Chi2.is_reparameterized</code></h4>
<hr />
<h4 id="tf.contrib.distributions.chi2.log_cdfvalue-namelog_cdf-condition_kwargs"><code id="Chi2.log_cdf">tf.contrib.distributions.Chi2.log_cdf(value, name='log_cdf', **condition_kwargs)</code></h4>
<p>Log cumulative distribution function.</p>
<p>Given random variable <code>X</code>, the cumulative distribution function <code>cdf</code> is:</p>
<pre><code>log_cdf(x) := Log[ P[X &lt;= x] ]</code></pre>
<p>Often, a numerical approximation can be used for <code>log_cdf(x)</code> that yields a more accurate answer than simply taking the logarithm of the <code>cdf</code> when <code>x &lt;&lt; -1</code>.</p>
<h5 id="args-129">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-147">Returns:</h5>
<ul>
<li><b><code>logcdf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.chi2.log_pdfvalue-namelog_pdf-condition_kwargs"><code id="Chi2.log_pdf">tf.contrib.distributions.Chi2.log_pdf(value, name='log_pdf', **condition_kwargs)</code></h4>
<p>Log probability density function.</p>
<h5 id="args-130">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-148">Returns:</h5>
<ul>
<li><b><code>log_prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-44">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if not <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.chi2.log_pmfvalue-namelog_pmf-condition_kwargs"><code id="Chi2.log_pmf">tf.contrib.distributions.Chi2.log_pmf(value, name='log_pmf', **condition_kwargs)</code></h4>
<p>Log probability mass function.</p>
<h5 id="args-131">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-149">Returns:</h5>
<ul>
<li><b><code>log_pmf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-45">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.chi2.log_probvalue-namelog_prob-condition_kwargs"><code id="Chi2.log_prob">tf.contrib.distributions.Chi2.log_prob(value, name='log_prob', **condition_kwargs)</code></h4>
<p>Log probability density/mass function (depending on <code>is_continuous</code>).</p>
<h5 id="args-132">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-150">Returns:</h5>
<ul>
<li><b><code>log_prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.chi2.log_survival_functionvalue-namelog_survival_function-condition_kwargs"><code id="Chi2.log_survival_function">tf.contrib.distributions.Chi2.log_survival_function(value, name='log_survival_function', **condition_kwargs)</code></h4>
<p>Log survival function.</p>
<p>Given random variable <code>X</code>, the survival function is defined:</p>
<pre><code>log_survival_function(x) = Log[ P[X &gt; x] ]
                         = Log[ 1 - P[X &lt;= x] ]
                         = Log[ 1 - cdf(x) ]</code></pre>
<p>Typically, different numerical approximations can be used for the log survival function, which are more accurate than <code>1 - cdf(x)</code> when <code>x &gt;&gt; 1</code>.</p>
<h5 id="args-133">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-151">Returns:</h5>
<p><code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.chi2.meannamemean"><code id="Chi2.mean">tf.contrib.distributions.Chi2.mean(name='mean')</code></h4>
<p>Mean.</p>
<hr />
<h4 id="tf.contrib.distributions.chi2.modenamemode"><code id="Chi2.mode">tf.contrib.distributions.Chi2.mode(name='mode')</code></h4>
<p>Mode.</p>
<p>Additional documentation from <code>Gamma</code>:</p>
<p>The mode of a gamma distribution is <code>(alpha - 1) / beta</code> when <code>alpha &gt; 1</code>, and <code>NaN</code> otherwise. If <code>self.allow_nan_stats</code> is <code>False</code>, an exception will be raised rather than returning <code>NaN</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.chi2.name"><code id="Chi2.name">tf.contrib.distributions.Chi2.name</code></h4>
<p>Name prepended to all ops created by this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.chi2.param_shapescls-sample_shape-namedistributionparamshapes"><code id="Chi2.param_shapes">tf.contrib.distributions.Chi2.param_shapes(cls, sample_shape, name='DistributionParamShapes')</code></h4>
<p>Shapes of parameters given the desired shape of a call to <code>sample()</code>.</p>
<p>Subclasses should override static method <code>_param_shapes</code>.</p>
<h5 id="args-134">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: <code>Tensor</code> or python list/tuple. Desired shape of a call to <code>sample()</code>.</li>
<li><b><code>name</code></b>: name to prepend ops with.</li>
</ul>
<h5 id="returns-152">Returns:</h5>
<p><code>dict</code> of parameter name to <code>Tensor</code> shapes.</p>
<hr />
<h4 id="tf.contrib.distributions.chi2.param_static_shapescls-sample_shape"><code id="Chi2.param_static_shapes">tf.contrib.distributions.Chi2.param_static_shapes(cls, sample_shape)</code></h4>
<p>param_shapes with static (i.e. TensorShape) shapes.</p>
<h5 id="args-135">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: <code>TensorShape</code> or python list/tuple. Desired shape of a call to <code>sample()</code>.</li>
</ul>
<h5 id="returns-153">Returns:</h5>
<p><code>dict</code> of parameter name to <code>TensorShape</code>.</p>
<h5 id="raises-46">Raises:</h5>
<ul>
<li><b><code>ValueError</code></b>: if <code>sample_shape</code> is a <code>TensorShape</code> and is not fully defined.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.chi2.parameters"><code id="Chi2.parameters">tf.contrib.distributions.Chi2.parameters</code></h4>
<p>Dictionary of parameters used to instantiate this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.chi2.pdfvalue-namepdf-condition_kwargs"><code id="Chi2.pdf">tf.contrib.distributions.Chi2.pdf(value, name='pdf', **condition_kwargs)</code></h4>
<p>Probability density function.</p>
<h5 id="args-136">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-154">Returns:</h5>
<ul>
<li><b><code>prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-47">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if not <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.chi2.pmfvalue-namepmf-condition_kwargs"><code id="Chi2.pmf">tf.contrib.distributions.Chi2.pmf(value, name='pmf', **condition_kwargs)</code></h4>
<p>Probability mass function.</p>
<h5 id="args-137">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-155">Returns:</h5>
<ul>
<li><b><code>pmf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-48">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.chi2.probvalue-nameprob-condition_kwargs"><code id="Chi2.prob">tf.contrib.distributions.Chi2.prob(value, name='prob', **condition_kwargs)</code></h4>
<p>Probability density/mass function (depending on <code>is_continuous</code>).</p>
<h5 id="args-138">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-156">Returns:</h5>
<ul>
<li><b><code>prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.chi2.samplesample_shape-seednone-namesample-condition_kwargs"><code id="Chi2.sample">tf.contrib.distributions.Chi2.sample(sample_shape=(), seed=None, name='sample', **condition_kwargs)</code></h4>
<p>Generate samples of the specified shape.</p>
<p>Note that a call to <code>sample()</code> without arguments will generate a single sample.</p>
<h5 id="args-139">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: 0D or 1D <code>int32</code> <code>Tensor</code>. Shape of the generated samples.</li>
<li><b><code>seed</code></b>: Python integer seed for RNG</li>
<li><b><code>name</code></b>: name to give to the op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-157">Returns:</h5>
<ul>
<li><b><code>samples</code></b>: a <code>Tensor</code> with prepended dimensions <code>sample_shape</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.chi2.sample_nn-seednone-namesample_n-condition_kwargs"><code id="Chi2.sample_n">tf.contrib.distributions.Chi2.sample_n(n, seed=None, name='sample_n', **condition_kwargs)</code></h4>
<p>Generate <code>n</code> samples.</p>
<p>Additional documentation from <code>Gamma</code>:</p>
<p>See the documentation for tf.random_gamma for more details.</p>
<h5 id="args-140">Args:</h5>
<ul>
<li><b><code>n</code></b>: <code>Scalar</code> <code>Tensor</code> of type <code>int32</code> or <code>int64</code>, the number of observations to sample.</li>
<li><b><code>seed</code></b>: Python integer seed for RNG</li>
<li><b><code>name</code></b>: name to give to the op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-158">Returns:</h5>
<ul>
<li><b><code>samples</code></b>: a <code>Tensor</code> with a prepended dimension (n,).</li>
</ul>
<h5 id="raises-49">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>n</code> is not an integer type.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.chi2.stdnamestd"><code id="Chi2.std">tf.contrib.distributions.Chi2.std(name='std')</code></h4>
<p>Standard deviation.</p>
<hr />
<h4 id="tf.contrib.distributions.chi2.survival_functionvalue-namesurvival_function-condition_kwargs"><code id="Chi2.survival_function">tf.contrib.distributions.Chi2.survival_function(value, name='survival_function', **condition_kwargs)</code></h4>
<p>Survival function.</p>
<p>Given random variable <code>X</code>, the survival function is defined:</p>
<pre><code>survival_function(x) = P[X &gt; x]
                     = 1 - P[X &lt;= x]
                     = 1 - cdf(x).</code></pre>
<h5 id="args-141">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-159">Returns:</h5>
<p>Tensor<code>of shape</code>sample_shape(x) + self.batch_shape<code>with values of type</code>self.dtype`.</p>
<hr />
<h4 id="tf.contrib.distributions.chi2.validate_args"><code id="Chi2.validate_args">tf.contrib.distributions.Chi2.validate_args</code></h4>
<p>Python boolean indicated possibly expensive checks are enabled.</p>
<hr />
<h4 id="tf.contrib.distributions.chi2.variancenamevariance"><code id="Chi2.variance">tf.contrib.distributions.Chi2.variance(name='variance')</code></h4>
<p>Variance.</p>
<hr />
<h3 id="class-tf.contrib.distributions.chi2withabsdf"><a name="//apple_ref/cpp/Class/Chi2WithAbsDf" class="dashAnchor"></a><code id="Chi2WithAbsDf">class tf.contrib.distributions.Chi2WithAbsDf</code></h3>
<p>Chi2 with parameter transform <code>df = floor(abs(df))</code>. - - -</p>
<h4 id="tf.contrib.distributions.chi2withabsdf.__init__df-validate_argsfalse-allow_nan_statstrue-namechi2withabsdf"><code id="Chi2WithAbsDf.__init__">tf.contrib.distributions.Chi2WithAbsDf.__init__(df, validate_args=False, allow_nan_stats=True, name='Chi2WithAbsDf')</code></h4>
<hr />
<h4 id="tf.contrib.distributions.chi2withabsdf.allow_nan_stats"><code id="Chi2WithAbsDf.allow_nan_stats">tf.contrib.distributions.Chi2WithAbsDf.allow_nan_stats</code></h4>
<p>Python boolean describing behavior when a stat is undefined.</p>
<p>Stats return +/- infinity when it makes sense. E.g., the variance of a Cauchy distribution is infinity. However, sometimes the statistic is undefined, e.g., if a distribution's pdf does not achieve a maximum within the support of the distribution, the mode is undefined. If the mean is undefined, then by definition the variance is undefined. E.g. the mean for Student's T for df = 1 is undefined (no clear way to say it is either + or - infinity), so the variance = E[(X - mean)^2] is also undefined.</p>
<h5 id="returns-160">Returns:</h5>
<ul>
<li><b><code>allow_nan_stats</code></b>: Python boolean.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.chi2withabsdf.alpha"><code id="Chi2WithAbsDf.alpha">tf.contrib.distributions.Chi2WithAbsDf.alpha</code></h4>
<p>Shape parameter.</p>
<hr />
<h4 id="tf.contrib.distributions.chi2withabsdf.batch_shapenamebatch_shape"><code id="Chi2WithAbsDf.batch_shape">tf.contrib.distributions.Chi2WithAbsDf.batch_shape(name='batch_shape')</code></h4>
<p>Shape of a single sample from a single event index as a 1-D <code>Tensor</code>.</p>
<p>The product of the dimensions of the <code>batch_shape</code> is the number of independent distributions of this kind the instance represents.</p>
<h5 id="args-142">Args:</h5>
<ul>
<li><b><code>name</code></b>: name to give to the op</li>
</ul>
<h5 id="returns-161">Returns:</h5>
<ul>
<li><b><code>batch_shape</code></b>: <code>Tensor</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.chi2withabsdf.beta"><code id="Chi2WithAbsDf.beta">tf.contrib.distributions.Chi2WithAbsDf.beta</code></h4>
<p>Inverse scale parameter.</p>
<hr />
<h4 id="tf.contrib.distributions.chi2withabsdf.cdfvalue-namecdf-condition_kwargs"><code id="Chi2WithAbsDf.cdf">tf.contrib.distributions.Chi2WithAbsDf.cdf(value, name='cdf', **condition_kwargs)</code></h4>
<p>Cumulative distribution function.</p>
<p>Given random variable <code>X</code>, the cumulative distribution function <code>cdf</code> is:</p>
<pre><code>cdf(x) := P[X &lt;= x]</code></pre>
<h5 id="args-143">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-162">Returns:</h5>
<ul>
<li><b><code>cdf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.chi2withabsdf.copyoverride_parameters_kwargs"><code id="Chi2WithAbsDf.copy">tf.contrib.distributions.Chi2WithAbsDf.copy(**override_parameters_kwargs)</code></h4>
<p>Creates a deep copy of the distribution.</p>
<p>Note: the copy distribution may continue to depend on the original intialization arguments.</p>
<h5 id="args-144">Args:</h5>
<ul>
<li><b><code>**override_parameters_kwargs</code></b>: String/value dictionary of initialization arguments to override with new values.</li>
</ul>
<h5 id="returns-163">Returns:</h5>
<ul>
<li><b><code>distribution</code></b>: A new instance of <code>type(self)</code> intitialized from the union of self.parameters and override_parameters_kwargs, i.e., <code>dict(self.parameters, **override_parameters_kwargs)</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.chi2withabsdf.df"><code id="Chi2WithAbsDf.df">tf.contrib.distributions.Chi2WithAbsDf.df</code></h4>
<hr />
<h4 id="tf.contrib.distributions.chi2withabsdf.dtype"><code id="Chi2WithAbsDf.dtype">tf.contrib.distributions.Chi2WithAbsDf.dtype</code></h4>
<p>The <code>DType</code> of <code>Tensor</code>s handled by this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.chi2withabsdf.entropynameentropy"><code id="Chi2WithAbsDf.entropy">tf.contrib.distributions.Chi2WithAbsDf.entropy(name='entropy')</code></h4>
<p>Shannon entropy in nats.</p>
<p>Additional documentation from <code>Gamma</code>:</p>
<p>This is defined to be</p>
<pre><code>entropy = alpha - log(beta) + log(Gamma(alpha))
+ (1-alpha)digamma(alpha)</code></pre>
<p>where digamma(alpha) is the digamma function.</p>
<hr />
<h4 id="tf.contrib.distributions.chi2withabsdf.event_shapenameevent_shape"><code id="Chi2WithAbsDf.event_shape">tf.contrib.distributions.Chi2WithAbsDf.event_shape(name='event_shape')</code></h4>
<p>Shape of a single sample from a single batch as a 1-D int32 <code>Tensor</code>.</p>
<h5 id="args-145">Args:</h5>
<ul>
<li><b><code>name</code></b>: name to give to the op</li>
</ul>
<h5 id="returns-164">Returns:</h5>
<ul>
<li><b><code>event_shape</code></b>: <code>Tensor</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.chi2withabsdf.get_batch_shape"><code id="Chi2WithAbsDf.get_batch_shape">tf.contrib.distributions.Chi2WithAbsDf.get_batch_shape()</code></h4>
<p>Shape of a single sample from a single event index as a <code>TensorShape</code>.</p>
<p>Same meaning as <code>batch_shape</code>. May be only partially defined.</p>
<h5 id="returns-165">Returns:</h5>
<ul>
<li><b><code>batch_shape</code></b>: <code>TensorShape</code>, possibly unknown.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.chi2withabsdf.get_event_shape"><code id="Chi2WithAbsDf.get_event_shape">tf.contrib.distributions.Chi2WithAbsDf.get_event_shape()</code></h4>
<p>Shape of a single sample from a single batch as a <code>TensorShape</code>.</p>
<p>Same meaning as <code>event_shape</code>. May be only partially defined.</p>
<h5 id="returns-166">Returns:</h5>
<ul>
<li><b><code>event_shape</code></b>: <code>TensorShape</code>, possibly unknown.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.chi2withabsdf.is_continuous"><code id="Chi2WithAbsDf.is_continuous">tf.contrib.distributions.Chi2WithAbsDf.is_continuous</code></h4>
<hr />
<h4 id="tf.contrib.distributions.chi2withabsdf.is_reparameterized"><code id="Chi2WithAbsDf.is_reparameterized">tf.contrib.distributions.Chi2WithAbsDf.is_reparameterized</code></h4>
<hr />
<h4 id="tf.contrib.distributions.chi2withabsdf.log_cdfvalue-namelog_cdf-condition_kwargs"><code id="Chi2WithAbsDf.log_cdf">tf.contrib.distributions.Chi2WithAbsDf.log_cdf(value, name='log_cdf', **condition_kwargs)</code></h4>
<p>Log cumulative distribution function.</p>
<p>Given random variable <code>X</code>, the cumulative distribution function <code>cdf</code> is:</p>
<pre><code>log_cdf(x) := Log[ P[X &lt;= x] ]</code></pre>
<p>Often, a numerical approximation can be used for <code>log_cdf(x)</code> that yields a more accurate answer than simply taking the logarithm of the <code>cdf</code> when <code>x &lt;&lt; -1</code>.</p>
<h5 id="args-146">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-167">Returns:</h5>
<ul>
<li><b><code>logcdf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.chi2withabsdf.log_pdfvalue-namelog_pdf-condition_kwargs"><code id="Chi2WithAbsDf.log_pdf">tf.contrib.distributions.Chi2WithAbsDf.log_pdf(value, name='log_pdf', **condition_kwargs)</code></h4>
<p>Log probability density function.</p>
<h5 id="args-147">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-168">Returns:</h5>
<ul>
<li><b><code>log_prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-50">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if not <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.chi2withabsdf.log_pmfvalue-namelog_pmf-condition_kwargs"><code id="Chi2WithAbsDf.log_pmf">tf.contrib.distributions.Chi2WithAbsDf.log_pmf(value, name='log_pmf', **condition_kwargs)</code></h4>
<p>Log probability mass function.</p>
<h5 id="args-148">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-169">Returns:</h5>
<ul>
<li><b><code>log_pmf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-51">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.chi2withabsdf.log_probvalue-namelog_prob-condition_kwargs"><code id="Chi2WithAbsDf.log_prob">tf.contrib.distributions.Chi2WithAbsDf.log_prob(value, name='log_prob', **condition_kwargs)</code></h4>
<p>Log probability density/mass function (depending on <code>is_continuous</code>).</p>
<h5 id="args-149">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-170">Returns:</h5>
<ul>
<li><b><code>log_prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.chi2withabsdf.log_survival_functionvalue-namelog_survival_function-condition_kwargs"><code id="Chi2WithAbsDf.log_survival_function">tf.contrib.distributions.Chi2WithAbsDf.log_survival_function(value, name='log_survival_function', **condition_kwargs)</code></h4>
<p>Log survival function.</p>
<p>Given random variable <code>X</code>, the survival function is defined:</p>
<pre><code>log_survival_function(x) = Log[ P[X &gt; x] ]
                         = Log[ 1 - P[X &lt;= x] ]
                         = Log[ 1 - cdf(x) ]</code></pre>
<p>Typically, different numerical approximations can be used for the log survival function, which are more accurate than <code>1 - cdf(x)</code> when <code>x &gt;&gt; 1</code>.</p>
<h5 id="args-150">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-171">Returns:</h5>
<p><code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.chi2withabsdf.meannamemean"><code id="Chi2WithAbsDf.mean">tf.contrib.distributions.Chi2WithAbsDf.mean(name='mean')</code></h4>
<p>Mean.</p>
<hr />
<h4 id="tf.contrib.distributions.chi2withabsdf.modenamemode"><code id="Chi2WithAbsDf.mode">tf.contrib.distributions.Chi2WithAbsDf.mode(name='mode')</code></h4>
<p>Mode.</p>
<p>Additional documentation from <code>Gamma</code>:</p>
<p>The mode of a gamma distribution is <code>(alpha - 1) / beta</code> when <code>alpha &gt; 1</code>, and <code>NaN</code> otherwise. If <code>self.allow_nan_stats</code> is <code>False</code>, an exception will be raised rather than returning <code>NaN</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.chi2withabsdf.name"><code id="Chi2WithAbsDf.name">tf.contrib.distributions.Chi2WithAbsDf.name</code></h4>
<p>Name prepended to all ops created by this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.chi2withabsdf.param_shapescls-sample_shape-namedistributionparamshapes"><code id="Chi2WithAbsDf.param_shapes">tf.contrib.distributions.Chi2WithAbsDf.param_shapes(cls, sample_shape, name='DistributionParamShapes')</code></h4>
<p>Shapes of parameters given the desired shape of a call to <code>sample()</code>.</p>
<p>Subclasses should override static method <code>_param_shapes</code>.</p>
<h5 id="args-151">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: <code>Tensor</code> or python list/tuple. Desired shape of a call to <code>sample()</code>.</li>
<li><b><code>name</code></b>: name to prepend ops with.</li>
</ul>
<h5 id="returns-172">Returns:</h5>
<p><code>dict</code> of parameter name to <code>Tensor</code> shapes.</p>
<hr />
<h4 id="tf.contrib.distributions.chi2withabsdf.param_static_shapescls-sample_shape"><code id="Chi2WithAbsDf.param_static_shapes">tf.contrib.distributions.Chi2WithAbsDf.param_static_shapes(cls, sample_shape)</code></h4>
<p>param_shapes with static (i.e. TensorShape) shapes.</p>
<h5 id="args-152">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: <code>TensorShape</code> or python list/tuple. Desired shape of a call to <code>sample()</code>.</li>
</ul>
<h5 id="returns-173">Returns:</h5>
<p><code>dict</code> of parameter name to <code>TensorShape</code>.</p>
<h5 id="raises-52">Raises:</h5>
<ul>
<li><b><code>ValueError</code></b>: if <code>sample_shape</code> is a <code>TensorShape</code> and is not fully defined.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.chi2withabsdf.parameters"><code id="Chi2WithAbsDf.parameters">tf.contrib.distributions.Chi2WithAbsDf.parameters</code></h4>
<p>Dictionary of parameters used to instantiate this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.chi2withabsdf.pdfvalue-namepdf-condition_kwargs"><code id="Chi2WithAbsDf.pdf">tf.contrib.distributions.Chi2WithAbsDf.pdf(value, name='pdf', **condition_kwargs)</code></h4>
<p>Probability density function.</p>
<h5 id="args-153">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-174">Returns:</h5>
<ul>
<li><b><code>prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-53">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if not <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.chi2withabsdf.pmfvalue-namepmf-condition_kwargs"><code id="Chi2WithAbsDf.pmf">tf.contrib.distributions.Chi2WithAbsDf.pmf(value, name='pmf', **condition_kwargs)</code></h4>
<p>Probability mass function.</p>
<h5 id="args-154">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-175">Returns:</h5>
<ul>
<li><b><code>pmf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-54">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.chi2withabsdf.probvalue-nameprob-condition_kwargs"><code id="Chi2WithAbsDf.prob">tf.contrib.distributions.Chi2WithAbsDf.prob(value, name='prob', **condition_kwargs)</code></h4>
<p>Probability density/mass function (depending on <code>is_continuous</code>).</p>
<h5 id="args-155">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-176">Returns:</h5>
<ul>
<li><b><code>prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.chi2withabsdf.samplesample_shape-seednone-namesample-condition_kwargs"><code id="Chi2WithAbsDf.sample">tf.contrib.distributions.Chi2WithAbsDf.sample(sample_shape=(), seed=None, name='sample', **condition_kwargs)</code></h4>
<p>Generate samples of the specified shape.</p>
<p>Note that a call to <code>sample()</code> without arguments will generate a single sample.</p>
<h5 id="args-156">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: 0D or 1D <code>int32</code> <code>Tensor</code>. Shape of the generated samples.</li>
<li><b><code>seed</code></b>: Python integer seed for RNG</li>
<li><b><code>name</code></b>: name to give to the op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-177">Returns:</h5>
<ul>
<li><b><code>samples</code></b>: a <code>Tensor</code> with prepended dimensions <code>sample_shape</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.chi2withabsdf.sample_nn-seednone-namesample_n-condition_kwargs"><code id="Chi2WithAbsDf.sample_n">tf.contrib.distributions.Chi2WithAbsDf.sample_n(n, seed=None, name='sample_n', **condition_kwargs)</code></h4>
<p>Generate <code>n</code> samples.</p>
<p>Additional documentation from <code>Gamma</code>:</p>
<p>See the documentation for tf.random_gamma for more details.</p>
<h5 id="args-157">Args:</h5>
<ul>
<li><b><code>n</code></b>: <code>Scalar</code> <code>Tensor</code> of type <code>int32</code> or <code>int64</code>, the number of observations to sample.</li>
<li><b><code>seed</code></b>: Python integer seed for RNG</li>
<li><b><code>name</code></b>: name to give to the op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-178">Returns:</h5>
<ul>
<li><b><code>samples</code></b>: a <code>Tensor</code> with a prepended dimension (n,).</li>
</ul>
<h5 id="raises-55">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>n</code> is not an integer type.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.chi2withabsdf.stdnamestd"><code id="Chi2WithAbsDf.std">tf.contrib.distributions.Chi2WithAbsDf.std(name='std')</code></h4>
<p>Standard deviation.</p>
<hr />
<h4 id="tf.contrib.distributions.chi2withabsdf.survival_functionvalue-namesurvival_function-condition_kwargs"><code id="Chi2WithAbsDf.survival_function">tf.contrib.distributions.Chi2WithAbsDf.survival_function(value, name='survival_function', **condition_kwargs)</code></h4>
<p>Survival function.</p>
<p>Given random variable <code>X</code>, the survival function is defined:</p>
<pre><code>survival_function(x) = P[X &gt; x]
                     = 1 - P[X &lt;= x]
                     = 1 - cdf(x).</code></pre>
<h5 id="args-158">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-179">Returns:</h5>
<p>Tensor<code>of shape</code>sample_shape(x) + self.batch_shape<code>with values of type</code>self.dtype`.</p>
<hr />
<h4 id="tf.contrib.distributions.chi2withabsdf.validate_args"><code id="Chi2WithAbsDf.validate_args">tf.contrib.distributions.Chi2WithAbsDf.validate_args</code></h4>
<p>Python boolean indicated possibly expensive checks are enabled.</p>
<hr />
<h4 id="tf.contrib.distributions.chi2withabsdf.variancenamevariance"><code id="Chi2WithAbsDf.variance">tf.contrib.distributions.Chi2WithAbsDf.variance(name='variance')</code></h4>
<p>Variance.</p>
<hr />
<h3 id="class-tf.contrib.distributions.exponential"><a name="//apple_ref/cpp/Class/Exponential" class="dashAnchor"></a><code id="Exponential">class tf.contrib.distributions.Exponential</code></h3>
<p>The Exponential distribution with rate parameter lam.</p>
<p>The PDF of this distribution is:</p>
<p><code>prob(x) = (lam * e^(-lam * x)), x &gt; 0</code></p>
<p>Note that the Exponential distribution is a special case of the Gamma distribution, with Exponential(lam) = Gamma(1, lam). - - -</p>
<h4 id="tf.contrib.distributions.exponential.__init__lam-validate_argsfalse-allow_nan_statstrue-nameexponential"><code id="Exponential.__init__">tf.contrib.distributions.Exponential.__init__(lam, validate_args=False, allow_nan_stats=True, name='Exponential')</code></h4>
<p>Construct Exponential distribution with parameter <code>lam</code>.</p>
<h5 id="args-159">Args:</h5>
<ul>
<li><b><code>lam</code></b>: Floating point tensor, the rate of the distribution(s). <code>lam</code> must contain only positive values.</li>
<li><b><code>validate_args</code></b>: <code>Boolean</code>, default <code>False</code>. Whether to assert that <code>lam &gt; 0</code>, and that <code>x &gt; 0</code> in the methods <code>prob(x)</code> and <code>log_prob(x)</code>. If <code>validate_args</code> is <code>False</code> and the inputs are invalid, correct behavior is not guaranteed.</li>
<li><b><code>allow_nan_stats</code></b>: <code>Boolean</code>, default <code>True</code>. If <code>False</code>, raise an exception if a statistic (e.g. mean/mode/etc...) is undefined for any batch member. If <code>True</code>, batch members with valid parameters leading to undefined statistics will return NaN for this statistic.</li>
<li><b><code>name</code></b>: The name to prepend to all ops created by this distribution.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.exponential.allow_nan_stats"><code id="Exponential.allow_nan_stats">tf.contrib.distributions.Exponential.allow_nan_stats</code></h4>
<p>Python boolean describing behavior when a stat is undefined.</p>
<p>Stats return +/- infinity when it makes sense. E.g., the variance of a Cauchy distribution is infinity. However, sometimes the statistic is undefined, e.g., if a distribution's pdf does not achieve a maximum within the support of the distribution, the mode is undefined. If the mean is undefined, then by definition the variance is undefined. E.g. the mean for Student's T for df = 1 is undefined (no clear way to say it is either + or - infinity), so the variance = E[(X - mean)^2] is also undefined.</p>
<h5 id="returns-180">Returns:</h5>
<ul>
<li><b><code>allow_nan_stats</code></b>: Python boolean.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.exponential.alpha"><code id="Exponential.alpha">tf.contrib.distributions.Exponential.alpha</code></h4>
<p>Shape parameter.</p>
<hr />
<h4 id="tf.contrib.distributions.exponential.batch_shapenamebatch_shape"><code id="Exponential.batch_shape">tf.contrib.distributions.Exponential.batch_shape(name='batch_shape')</code></h4>
<p>Shape of a single sample from a single event index as a 1-D <code>Tensor</code>.</p>
<p>The product of the dimensions of the <code>batch_shape</code> is the number of independent distributions of this kind the instance represents.</p>
<h5 id="args-160">Args:</h5>
<ul>
<li><b><code>name</code></b>: name to give to the op</li>
</ul>
<h5 id="returns-181">Returns:</h5>
<ul>
<li><b><code>batch_shape</code></b>: <code>Tensor</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.exponential.beta"><code id="Exponential.beta">tf.contrib.distributions.Exponential.beta</code></h4>
<p>Inverse scale parameter.</p>
<hr />
<h4 id="tf.contrib.distributions.exponential.cdfvalue-namecdf-condition_kwargs"><code id="Exponential.cdf">tf.contrib.distributions.Exponential.cdf(value, name='cdf', **condition_kwargs)</code></h4>
<p>Cumulative distribution function.</p>
<p>Given random variable <code>X</code>, the cumulative distribution function <code>cdf</code> is:</p>
<pre><code>cdf(x) := P[X &lt;= x]</code></pre>
<h5 id="args-161">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-182">Returns:</h5>
<ul>
<li><b><code>cdf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.exponential.copyoverride_parameters_kwargs"><code id="Exponential.copy">tf.contrib.distributions.Exponential.copy(**override_parameters_kwargs)</code></h4>
<p>Creates a deep copy of the distribution.</p>
<p>Note: the copy distribution may continue to depend on the original intialization arguments.</p>
<h5 id="args-162">Args:</h5>
<ul>
<li><b><code>**override_parameters_kwargs</code></b>: String/value dictionary of initialization arguments to override with new values.</li>
</ul>
<h5 id="returns-183">Returns:</h5>
<ul>
<li><b><code>distribution</code></b>: A new instance of <code>type(self)</code> intitialized from the union of self.parameters and override_parameters_kwargs, i.e., <code>dict(self.parameters, **override_parameters_kwargs)</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.exponential.dtype"><code id="Exponential.dtype">tf.contrib.distributions.Exponential.dtype</code></h4>
<p>The <code>DType</code> of <code>Tensor</code>s handled by this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.exponential.entropynameentropy"><code id="Exponential.entropy">tf.contrib.distributions.Exponential.entropy(name='entropy')</code></h4>
<p>Shannon entropy in nats.</p>
<p>Additional documentation from <code>Gamma</code>:</p>
<p>This is defined to be</p>
<pre><code>entropy = alpha - log(beta) + log(Gamma(alpha))
+ (1-alpha)digamma(alpha)</code></pre>
<p>where digamma(alpha) is the digamma function.</p>
<hr />
<h4 id="tf.contrib.distributions.exponential.event_shapenameevent_shape"><code id="Exponential.event_shape">tf.contrib.distributions.Exponential.event_shape(name='event_shape')</code></h4>
<p>Shape of a single sample from a single batch as a 1-D int32 <code>Tensor</code>.</p>
<h5 id="args-163">Args:</h5>
<ul>
<li><b><code>name</code></b>: name to give to the op</li>
</ul>
<h5 id="returns-184">Returns:</h5>
<ul>
<li><b><code>event_shape</code></b>: <code>Tensor</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.exponential.get_batch_shape"><code id="Exponential.get_batch_shape">tf.contrib.distributions.Exponential.get_batch_shape()</code></h4>
<p>Shape of a single sample from a single event index as a <code>TensorShape</code>.</p>
<p>Same meaning as <code>batch_shape</code>. May be only partially defined.</p>
<h5 id="returns-185">Returns:</h5>
<ul>
<li><b><code>batch_shape</code></b>: <code>TensorShape</code>, possibly unknown.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.exponential.get_event_shape"><code id="Exponential.get_event_shape">tf.contrib.distributions.Exponential.get_event_shape()</code></h4>
<p>Shape of a single sample from a single batch as a <code>TensorShape</code>.</p>
<p>Same meaning as <code>event_shape</code>. May be only partially defined.</p>
<h5 id="returns-186">Returns:</h5>
<ul>
<li><b><code>event_shape</code></b>: <code>TensorShape</code>, possibly unknown.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.exponential.is_continuous"><code id="Exponential.is_continuous">tf.contrib.distributions.Exponential.is_continuous</code></h4>
<hr />
<h4 id="tf.contrib.distributions.exponential.is_reparameterized"><code id="Exponential.is_reparameterized">tf.contrib.distributions.Exponential.is_reparameterized</code></h4>
<hr />
<h4 id="tf.contrib.distributions.exponential.lam"><code id="Exponential.lam">tf.contrib.distributions.Exponential.lam</code></h4>
<hr />
<h4 id="tf.contrib.distributions.exponential.log_cdfvalue-namelog_cdf-condition_kwargs"><code id="Exponential.log_cdf">tf.contrib.distributions.Exponential.log_cdf(value, name='log_cdf', **condition_kwargs)</code></h4>
<p>Log cumulative distribution function.</p>
<p>Given random variable <code>X</code>, the cumulative distribution function <code>cdf</code> is:</p>
<pre><code>log_cdf(x) := Log[ P[X &lt;= x] ]</code></pre>
<p>Often, a numerical approximation can be used for <code>log_cdf(x)</code> that yields a more accurate answer than simply taking the logarithm of the <code>cdf</code> when <code>x &lt;&lt; -1</code>.</p>
<h5 id="args-164">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-187">Returns:</h5>
<ul>
<li><b><code>logcdf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.exponential.log_pdfvalue-namelog_pdf-condition_kwargs"><code id="Exponential.log_pdf">tf.contrib.distributions.Exponential.log_pdf(value, name='log_pdf', **condition_kwargs)</code></h4>
<p>Log probability density function.</p>
<h5 id="args-165">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-188">Returns:</h5>
<ul>
<li><b><code>log_prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-56">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if not <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.exponential.log_pmfvalue-namelog_pmf-condition_kwargs"><code id="Exponential.log_pmf">tf.contrib.distributions.Exponential.log_pmf(value, name='log_pmf', **condition_kwargs)</code></h4>
<p>Log probability mass function.</p>
<h5 id="args-166">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-189">Returns:</h5>
<ul>
<li><b><code>log_pmf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-57">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.exponential.log_probvalue-namelog_prob-condition_kwargs"><code id="Exponential.log_prob">tf.contrib.distributions.Exponential.log_prob(value, name='log_prob', **condition_kwargs)</code></h4>
<p>Log probability density/mass function (depending on <code>is_continuous</code>).</p>
<h5 id="args-167">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-190">Returns:</h5>
<ul>
<li><b><code>log_prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.exponential.log_survival_functionvalue-namelog_survival_function-condition_kwargs"><code id="Exponential.log_survival_function">tf.contrib.distributions.Exponential.log_survival_function(value, name='log_survival_function', **condition_kwargs)</code></h4>
<p>Log survival function.</p>
<p>Given random variable <code>X</code>, the survival function is defined:</p>
<pre><code>log_survival_function(x) = Log[ P[X &gt; x] ]
                         = Log[ 1 - P[X &lt;= x] ]
                         = Log[ 1 - cdf(x) ]</code></pre>
<p>Typically, different numerical approximations can be used for the log survival function, which are more accurate than <code>1 - cdf(x)</code> when <code>x &gt;&gt; 1</code>.</p>
<h5 id="args-168">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-191">Returns:</h5>
<p><code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.exponential.meannamemean"><code id="Exponential.mean">tf.contrib.distributions.Exponential.mean(name='mean')</code></h4>
<p>Mean.</p>
<hr />
<h4 id="tf.contrib.distributions.exponential.modenamemode"><code id="Exponential.mode">tf.contrib.distributions.Exponential.mode(name='mode')</code></h4>
<p>Mode.</p>
<p>Additional documentation from <code>Gamma</code>:</p>
<p>The mode of a gamma distribution is <code>(alpha - 1) / beta</code> when <code>alpha &gt; 1</code>, and <code>NaN</code> otherwise. If <code>self.allow_nan_stats</code> is <code>False</code>, an exception will be raised rather than returning <code>NaN</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.exponential.name"><code id="Exponential.name">tf.contrib.distributions.Exponential.name</code></h4>
<p>Name prepended to all ops created by this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.exponential.param_shapescls-sample_shape-namedistributionparamshapes"><code id="Exponential.param_shapes">tf.contrib.distributions.Exponential.param_shapes(cls, sample_shape, name='DistributionParamShapes')</code></h4>
<p>Shapes of parameters given the desired shape of a call to <code>sample()</code>.</p>
<p>Subclasses should override static method <code>_param_shapes</code>.</p>
<h5 id="args-169">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: <code>Tensor</code> or python list/tuple. Desired shape of a call to <code>sample()</code>.</li>
<li><b><code>name</code></b>: name to prepend ops with.</li>
</ul>
<h5 id="returns-192">Returns:</h5>
<p><code>dict</code> of parameter name to <code>Tensor</code> shapes.</p>
<hr />
<h4 id="tf.contrib.distributions.exponential.param_static_shapescls-sample_shape"><code id="Exponential.param_static_shapes">tf.contrib.distributions.Exponential.param_static_shapes(cls, sample_shape)</code></h4>
<p>param_shapes with static (i.e. TensorShape) shapes.</p>
<h5 id="args-170">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: <code>TensorShape</code> or python list/tuple. Desired shape of a call to <code>sample()</code>.</li>
</ul>
<h5 id="returns-193">Returns:</h5>
<p><code>dict</code> of parameter name to <code>TensorShape</code>.</p>
<h5 id="raises-58">Raises:</h5>
<ul>
<li><b><code>ValueError</code></b>: if <code>sample_shape</code> is a <code>TensorShape</code> and is not fully defined.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.exponential.parameters"><code id="Exponential.parameters">tf.contrib.distributions.Exponential.parameters</code></h4>
<p>Dictionary of parameters used to instantiate this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.exponential.pdfvalue-namepdf-condition_kwargs"><code id="Exponential.pdf">tf.contrib.distributions.Exponential.pdf(value, name='pdf', **condition_kwargs)</code></h4>
<p>Probability density function.</p>
<h5 id="args-171">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-194">Returns:</h5>
<ul>
<li><b><code>prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-59">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if not <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.exponential.pmfvalue-namepmf-condition_kwargs"><code id="Exponential.pmf">tf.contrib.distributions.Exponential.pmf(value, name='pmf', **condition_kwargs)</code></h4>
<p>Probability mass function.</p>
<h5 id="args-172">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-195">Returns:</h5>
<ul>
<li><b><code>pmf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-60">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.exponential.probvalue-nameprob-condition_kwargs"><code id="Exponential.prob">tf.contrib.distributions.Exponential.prob(value, name='prob', **condition_kwargs)</code></h4>
<p>Probability density/mass function (depending on <code>is_continuous</code>).</p>
<h5 id="args-173">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-196">Returns:</h5>
<ul>
<li><b><code>prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.exponential.samplesample_shape-seednone-namesample-condition_kwargs"><code id="Exponential.sample">tf.contrib.distributions.Exponential.sample(sample_shape=(), seed=None, name='sample', **condition_kwargs)</code></h4>
<p>Generate samples of the specified shape.</p>
<p>Note that a call to <code>sample()</code> without arguments will generate a single sample.</p>
<h5 id="args-174">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: 0D or 1D <code>int32</code> <code>Tensor</code>. Shape of the generated samples.</li>
<li><b><code>seed</code></b>: Python integer seed for RNG</li>
<li><b><code>name</code></b>: name to give to the op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-197">Returns:</h5>
<ul>
<li><b><code>samples</code></b>: a <code>Tensor</code> with prepended dimensions <code>sample_shape</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.exponential.sample_nn-seednone-namesample_n-condition_kwargs"><code id="Exponential.sample_n">tf.contrib.distributions.Exponential.sample_n(n, seed=None, name='sample_n', **condition_kwargs)</code></h4>
<p>Generate <code>n</code> samples.</p>
<p>Additional documentation from <code>Gamma</code>:</p>
<p>See the documentation for tf.random_gamma for more details.</p>
<h5 id="args-175">Args:</h5>
<ul>
<li><b><code>n</code></b>: <code>Scalar</code> <code>Tensor</code> of type <code>int32</code> or <code>int64</code>, the number of observations to sample.</li>
<li><b><code>seed</code></b>: Python integer seed for RNG</li>
<li><b><code>name</code></b>: name to give to the op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-198">Returns:</h5>
<ul>
<li><b><code>samples</code></b>: a <code>Tensor</code> with a prepended dimension (n,).</li>
</ul>
<h5 id="raises-61">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>n</code> is not an integer type.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.exponential.stdnamestd"><code id="Exponential.std">tf.contrib.distributions.Exponential.std(name='std')</code></h4>
<p>Standard deviation.</p>
<hr />
<h4 id="tf.contrib.distributions.exponential.survival_functionvalue-namesurvival_function-condition_kwargs"><code id="Exponential.survival_function">tf.contrib.distributions.Exponential.survival_function(value, name='survival_function', **condition_kwargs)</code></h4>
<p>Survival function.</p>
<p>Given random variable <code>X</code>, the survival function is defined:</p>
<pre><code>survival_function(x) = P[X &gt; x]
                     = 1 - P[X &lt;= x]
                     = 1 - cdf(x).</code></pre>
<h5 id="args-176">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-199">Returns:</h5>
<p>Tensor<code>of shape</code>sample_shape(x) + self.batch_shape<code>with values of type</code>self.dtype`.</p>
<hr />
<h4 id="tf.contrib.distributions.exponential.validate_args"><code id="Exponential.validate_args">tf.contrib.distributions.Exponential.validate_args</code></h4>
<p>Python boolean indicated possibly expensive checks are enabled.</p>
<hr />
<h4 id="tf.contrib.distributions.exponential.variancenamevariance"><code id="Exponential.variance">tf.contrib.distributions.Exponential.variance(name='variance')</code></h4>
<p>Variance.</p>
<hr />
<h3 id="class-tf.contrib.distributions.exponentialwithsoftpluslam"><a name="//apple_ref/cpp/Class/ExponentialWithSoftplusLam" class="dashAnchor"></a><code id="ExponentialWithSoftplusLam">class tf.contrib.distributions.ExponentialWithSoftplusLam</code></h3>
<p>Exponential with softplus transform on <code>lam</code>. - - -</p>
<h4 id="tf.contrib.distributions.exponentialwithsoftpluslam.__init__lam-validate_argsfalse-allow_nan_statstrue-nameexponentialwithsoftpluslam"><code id="ExponentialWithSoftplusLam.__init__">tf.contrib.distributions.ExponentialWithSoftplusLam.__init__(lam, validate_args=False, allow_nan_stats=True, name='ExponentialWithSoftplusLam')</code></h4>
<hr />
<h4 id="tf.contrib.distributions.exponentialwithsoftpluslam.allow_nan_stats"><code id="ExponentialWithSoftplusLam.allow_nan_stats">tf.contrib.distributions.ExponentialWithSoftplusLam.allow_nan_stats</code></h4>
<p>Python boolean describing behavior when a stat is undefined.</p>
<p>Stats return +/- infinity when it makes sense. E.g., the variance of a Cauchy distribution is infinity. However, sometimes the statistic is undefined, e.g., if a distribution's pdf does not achieve a maximum within the support of the distribution, the mode is undefined. If the mean is undefined, then by definition the variance is undefined. E.g. the mean for Student's T for df = 1 is undefined (no clear way to say it is either + or - infinity), so the variance = E[(X - mean)^2] is also undefined.</p>
<h5 id="returns-200">Returns:</h5>
<ul>
<li><b><code>allow_nan_stats</code></b>: Python boolean.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.exponentialwithsoftpluslam.alpha"><code id="ExponentialWithSoftplusLam.alpha">tf.contrib.distributions.ExponentialWithSoftplusLam.alpha</code></h4>
<p>Shape parameter.</p>
<hr />
<h4 id="tf.contrib.distributions.exponentialwithsoftpluslam.batch_shapenamebatch_shape"><code id="ExponentialWithSoftplusLam.batch_shape">tf.contrib.distributions.ExponentialWithSoftplusLam.batch_shape(name='batch_shape')</code></h4>
<p>Shape of a single sample from a single event index as a 1-D <code>Tensor</code>.</p>
<p>The product of the dimensions of the <code>batch_shape</code> is the number of independent distributions of this kind the instance represents.</p>
<h5 id="args-177">Args:</h5>
<ul>
<li><b><code>name</code></b>: name to give to the op</li>
</ul>
<h5 id="returns-201">Returns:</h5>
<ul>
<li><b><code>batch_shape</code></b>: <code>Tensor</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.exponentialwithsoftpluslam.beta"><code id="ExponentialWithSoftplusLam.beta">tf.contrib.distributions.ExponentialWithSoftplusLam.beta</code></h4>
<p>Inverse scale parameter.</p>
<hr />
<h4 id="tf.contrib.distributions.exponentialwithsoftpluslam.cdfvalue-namecdf-condition_kwargs"><code id="ExponentialWithSoftplusLam.cdf">tf.contrib.distributions.ExponentialWithSoftplusLam.cdf(value, name='cdf', **condition_kwargs)</code></h4>
<p>Cumulative distribution function.</p>
<p>Given random variable <code>X</code>, the cumulative distribution function <code>cdf</code> is:</p>
<pre><code>cdf(x) := P[X &lt;= x]</code></pre>
<h5 id="args-178">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-202">Returns:</h5>
<ul>
<li><b><code>cdf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.exponentialwithsoftpluslam.copyoverride_parameters_kwargs"><code id="ExponentialWithSoftplusLam.copy">tf.contrib.distributions.ExponentialWithSoftplusLam.copy(**override_parameters_kwargs)</code></h4>
<p>Creates a deep copy of the distribution.</p>
<p>Note: the copy distribution may continue to depend on the original intialization arguments.</p>
<h5 id="args-179">Args:</h5>
<ul>
<li><b><code>**override_parameters_kwargs</code></b>: String/value dictionary of initialization arguments to override with new values.</li>
</ul>
<h5 id="returns-203">Returns:</h5>
<ul>
<li><b><code>distribution</code></b>: A new instance of <code>type(self)</code> intitialized from the union of self.parameters and override_parameters_kwargs, i.e., <code>dict(self.parameters, **override_parameters_kwargs)</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.exponentialwithsoftpluslam.dtype"><code id="ExponentialWithSoftplusLam.dtype">tf.contrib.distributions.ExponentialWithSoftplusLam.dtype</code></h4>
<p>The <code>DType</code> of <code>Tensor</code>s handled by this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.exponentialwithsoftpluslam.entropynameentropy"><code id="ExponentialWithSoftplusLam.entropy">tf.contrib.distributions.ExponentialWithSoftplusLam.entropy(name='entropy')</code></h4>
<p>Shannon entropy in nats.</p>
<p>Additional documentation from <code>Gamma</code>:</p>
<p>This is defined to be</p>
<pre><code>entropy = alpha - log(beta) + log(Gamma(alpha))
+ (1-alpha)digamma(alpha)</code></pre>
<p>where digamma(alpha) is the digamma function.</p>
<hr />
<h4 id="tf.contrib.distributions.exponentialwithsoftpluslam.event_shapenameevent_shape"><code id="ExponentialWithSoftplusLam.event_shape">tf.contrib.distributions.ExponentialWithSoftplusLam.event_shape(name='event_shape')</code></h4>
<p>Shape of a single sample from a single batch as a 1-D int32 <code>Tensor</code>.</p>
<h5 id="args-180">Args:</h5>
<ul>
<li><b><code>name</code></b>: name to give to the op</li>
</ul>
<h5 id="returns-204">Returns:</h5>
<ul>
<li><b><code>event_shape</code></b>: <code>Tensor</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.exponentialwithsoftpluslam.get_batch_shape"><code id="ExponentialWithSoftplusLam.get_batch_shape">tf.contrib.distributions.ExponentialWithSoftplusLam.get_batch_shape()</code></h4>
<p>Shape of a single sample from a single event index as a <code>TensorShape</code>.</p>
<p>Same meaning as <code>batch_shape</code>. May be only partially defined.</p>
<h5 id="returns-205">Returns:</h5>
<ul>
<li><b><code>batch_shape</code></b>: <code>TensorShape</code>, possibly unknown.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.exponentialwithsoftpluslam.get_event_shape"><code id="ExponentialWithSoftplusLam.get_event_shape">tf.contrib.distributions.ExponentialWithSoftplusLam.get_event_shape()</code></h4>
<p>Shape of a single sample from a single batch as a <code>TensorShape</code>.</p>
<p>Same meaning as <code>event_shape</code>. May be only partially defined.</p>
<h5 id="returns-206">Returns:</h5>
<ul>
<li><b><code>event_shape</code></b>: <code>TensorShape</code>, possibly unknown.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.exponentialwithsoftpluslam.is_continuous"><code id="ExponentialWithSoftplusLam.is_continuous">tf.contrib.distributions.ExponentialWithSoftplusLam.is_continuous</code></h4>
<hr />
<h4 id="tf.contrib.distributions.exponentialwithsoftpluslam.is_reparameterized"><code id="ExponentialWithSoftplusLam.is_reparameterized">tf.contrib.distributions.ExponentialWithSoftplusLam.is_reparameterized</code></h4>
<hr />
<h4 id="tf.contrib.distributions.exponentialwithsoftpluslam.lam"><code id="ExponentialWithSoftplusLam.lam">tf.contrib.distributions.ExponentialWithSoftplusLam.lam</code></h4>
<hr />
<h4 id="tf.contrib.distributions.exponentialwithsoftpluslam.log_cdfvalue-namelog_cdf-condition_kwargs"><code id="ExponentialWithSoftplusLam.log_cdf">tf.contrib.distributions.ExponentialWithSoftplusLam.log_cdf(value, name='log_cdf', **condition_kwargs)</code></h4>
<p>Log cumulative distribution function.</p>
<p>Given random variable <code>X</code>, the cumulative distribution function <code>cdf</code> is:</p>
<pre><code>log_cdf(x) := Log[ P[X &lt;= x] ]</code></pre>
<p>Often, a numerical approximation can be used for <code>log_cdf(x)</code> that yields a more accurate answer than simply taking the logarithm of the <code>cdf</code> when <code>x &lt;&lt; -1</code>.</p>
<h5 id="args-181">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-207">Returns:</h5>
<ul>
<li><b><code>logcdf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.exponentialwithsoftpluslam.log_pdfvalue-namelog_pdf-condition_kwargs"><code id="ExponentialWithSoftplusLam.log_pdf">tf.contrib.distributions.ExponentialWithSoftplusLam.log_pdf(value, name='log_pdf', **condition_kwargs)</code></h4>
<p>Log probability density function.</p>
<h5 id="args-182">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-208">Returns:</h5>
<ul>
<li><b><code>log_prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-62">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if not <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.exponentialwithsoftpluslam.log_pmfvalue-namelog_pmf-condition_kwargs"><code id="ExponentialWithSoftplusLam.log_pmf">tf.contrib.distributions.ExponentialWithSoftplusLam.log_pmf(value, name='log_pmf', **condition_kwargs)</code></h4>
<p>Log probability mass function.</p>
<h5 id="args-183">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-209">Returns:</h5>
<ul>
<li><b><code>log_pmf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-63">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.exponentialwithsoftpluslam.log_probvalue-namelog_prob-condition_kwargs"><code id="ExponentialWithSoftplusLam.log_prob">tf.contrib.distributions.ExponentialWithSoftplusLam.log_prob(value, name='log_prob', **condition_kwargs)</code></h4>
<p>Log probability density/mass function (depending on <code>is_continuous</code>).</p>
<h5 id="args-184">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-210">Returns:</h5>
<ul>
<li><b><code>log_prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.exponentialwithsoftpluslam.log_survival_functionvalue-namelog_survival_function-condition_kwargs"><code id="ExponentialWithSoftplusLam.log_survival_function">tf.contrib.distributions.ExponentialWithSoftplusLam.log_survival_function(value, name='log_survival_function', **condition_kwargs)</code></h4>
<p>Log survival function.</p>
<p>Given random variable <code>X</code>, the survival function is defined:</p>
<pre><code>log_survival_function(x) = Log[ P[X &gt; x] ]
                         = Log[ 1 - P[X &lt;= x] ]
                         = Log[ 1 - cdf(x) ]</code></pre>
<p>Typically, different numerical approximations can be used for the log survival function, which are more accurate than <code>1 - cdf(x)</code> when <code>x &gt;&gt; 1</code>.</p>
<h5 id="args-185">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-211">Returns:</h5>
<p><code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.exponentialwithsoftpluslam.meannamemean"><code id="ExponentialWithSoftplusLam.mean">tf.contrib.distributions.ExponentialWithSoftplusLam.mean(name='mean')</code></h4>
<p>Mean.</p>
<hr />
<h4 id="tf.contrib.distributions.exponentialwithsoftpluslam.modenamemode"><code id="ExponentialWithSoftplusLam.mode">tf.contrib.distributions.ExponentialWithSoftplusLam.mode(name='mode')</code></h4>
<p>Mode.</p>
<p>Additional documentation from <code>Gamma</code>:</p>
<p>The mode of a gamma distribution is <code>(alpha - 1) / beta</code> when <code>alpha &gt; 1</code>, and <code>NaN</code> otherwise. If <code>self.allow_nan_stats</code> is <code>False</code>, an exception will be raised rather than returning <code>NaN</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.exponentialwithsoftpluslam.name"><code id="ExponentialWithSoftplusLam.name">tf.contrib.distributions.ExponentialWithSoftplusLam.name</code></h4>
<p>Name prepended to all ops created by this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.exponentialwithsoftpluslam.param_shapescls-sample_shape-namedistributionparamshapes"><code id="ExponentialWithSoftplusLam.param_shapes">tf.contrib.distributions.ExponentialWithSoftplusLam.param_shapes(cls, sample_shape, name='DistributionParamShapes')</code></h4>
<p>Shapes of parameters given the desired shape of a call to <code>sample()</code>.</p>
<p>Subclasses should override static method <code>_param_shapes</code>.</p>
<h5 id="args-186">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: <code>Tensor</code> or python list/tuple. Desired shape of a call to <code>sample()</code>.</li>
<li><b><code>name</code></b>: name to prepend ops with.</li>
</ul>
<h5 id="returns-212">Returns:</h5>
<p><code>dict</code> of parameter name to <code>Tensor</code> shapes.</p>
<hr />
<h4 id="tf.contrib.distributions.exponentialwithsoftpluslam.param_static_shapescls-sample_shape"><code id="ExponentialWithSoftplusLam.param_static_shapes">tf.contrib.distributions.ExponentialWithSoftplusLam.param_static_shapes(cls, sample_shape)</code></h4>
<p>param_shapes with static (i.e. TensorShape) shapes.</p>
<h5 id="args-187">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: <code>TensorShape</code> or python list/tuple. Desired shape of a call to <code>sample()</code>.</li>
</ul>
<h5 id="returns-213">Returns:</h5>
<p><code>dict</code> of parameter name to <code>TensorShape</code>.</p>
<h5 id="raises-64">Raises:</h5>
<ul>
<li><b><code>ValueError</code></b>: if <code>sample_shape</code> is a <code>TensorShape</code> and is not fully defined.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.exponentialwithsoftpluslam.parameters"><code id="ExponentialWithSoftplusLam.parameters">tf.contrib.distributions.ExponentialWithSoftplusLam.parameters</code></h4>
<p>Dictionary of parameters used to instantiate this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.exponentialwithsoftpluslam.pdfvalue-namepdf-condition_kwargs"><code id="ExponentialWithSoftplusLam.pdf">tf.contrib.distributions.ExponentialWithSoftplusLam.pdf(value, name='pdf', **condition_kwargs)</code></h4>
<p>Probability density function.</p>
<h5 id="args-188">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-214">Returns:</h5>
<ul>
<li><b><code>prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-65">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if not <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.exponentialwithsoftpluslam.pmfvalue-namepmf-condition_kwargs"><code id="ExponentialWithSoftplusLam.pmf">tf.contrib.distributions.ExponentialWithSoftplusLam.pmf(value, name='pmf', **condition_kwargs)</code></h4>
<p>Probability mass function.</p>
<h5 id="args-189">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-215">Returns:</h5>
<ul>
<li><b><code>pmf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-66">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.exponentialwithsoftpluslam.probvalue-nameprob-condition_kwargs"><code id="ExponentialWithSoftplusLam.prob">tf.contrib.distributions.ExponentialWithSoftplusLam.prob(value, name='prob', **condition_kwargs)</code></h4>
<p>Probability density/mass function (depending on <code>is_continuous</code>).</p>
<h5 id="args-190">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-216">Returns:</h5>
<ul>
<li><b><code>prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.exponentialwithsoftpluslam.samplesample_shape-seednone-namesample-condition_kwargs"><code id="ExponentialWithSoftplusLam.sample">tf.contrib.distributions.ExponentialWithSoftplusLam.sample(sample_shape=(), seed=None, name='sample', **condition_kwargs)</code></h4>
<p>Generate samples of the specified shape.</p>
<p>Note that a call to <code>sample()</code> without arguments will generate a single sample.</p>
<h5 id="args-191">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: 0D or 1D <code>int32</code> <code>Tensor</code>. Shape of the generated samples.</li>
<li><b><code>seed</code></b>: Python integer seed for RNG</li>
<li><b><code>name</code></b>: name to give to the op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-217">Returns:</h5>
<ul>
<li><b><code>samples</code></b>: a <code>Tensor</code> with prepended dimensions <code>sample_shape</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.exponentialwithsoftpluslam.sample_nn-seednone-namesample_n-condition_kwargs"><code id="ExponentialWithSoftplusLam.sample_n">tf.contrib.distributions.ExponentialWithSoftplusLam.sample_n(n, seed=None, name='sample_n', **condition_kwargs)</code></h4>
<p>Generate <code>n</code> samples.</p>
<p>Additional documentation from <code>Gamma</code>:</p>
<p>See the documentation for tf.random_gamma for more details.</p>
<h5 id="args-192">Args:</h5>
<ul>
<li><b><code>n</code></b>: <code>Scalar</code> <code>Tensor</code> of type <code>int32</code> or <code>int64</code>, the number of observations to sample.</li>
<li><b><code>seed</code></b>: Python integer seed for RNG</li>
<li><b><code>name</code></b>: name to give to the op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-218">Returns:</h5>
<ul>
<li><b><code>samples</code></b>: a <code>Tensor</code> with a prepended dimension (n,).</li>
</ul>
<h5 id="raises-67">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>n</code> is not an integer type.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.exponentialwithsoftpluslam.stdnamestd"><code id="ExponentialWithSoftplusLam.std">tf.contrib.distributions.ExponentialWithSoftplusLam.std(name='std')</code></h4>
<p>Standard deviation.</p>
<hr />
<h4 id="tf.contrib.distributions.exponentialwithsoftpluslam.survival_functionvalue-namesurvival_function-condition_kwargs"><code id="ExponentialWithSoftplusLam.survival_function">tf.contrib.distributions.ExponentialWithSoftplusLam.survival_function(value, name='survival_function', **condition_kwargs)</code></h4>
<p>Survival function.</p>
<p>Given random variable <code>X</code>, the survival function is defined:</p>
<pre><code>survival_function(x) = P[X &gt; x]
                     = 1 - P[X &lt;= x]
                     = 1 - cdf(x).</code></pre>
<h5 id="args-193">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-219">Returns:</h5>
<p>Tensor<code>of shape</code>sample_shape(x) + self.batch_shape<code>with values of type</code>self.dtype`.</p>
<hr />
<h4 id="tf.contrib.distributions.exponentialwithsoftpluslam.validate_args"><code id="ExponentialWithSoftplusLam.validate_args">tf.contrib.distributions.ExponentialWithSoftplusLam.validate_args</code></h4>
<p>Python boolean indicated possibly expensive checks are enabled.</p>
<hr />
<h4 id="tf.contrib.distributions.exponentialwithsoftpluslam.variancenamevariance"><code id="ExponentialWithSoftplusLam.variance">tf.contrib.distributions.ExponentialWithSoftplusLam.variance(name='variance')</code></h4>
<p>Variance.</p>
<hr />
<h3 id="class-tf.contrib.distributions.gamma"><a name="//apple_ref/cpp/Class/Gamma" class="dashAnchor"></a><code id="Gamma">class tf.contrib.distributions.Gamma</code></h3>
<p>The <code>Gamma</code> distribution with parameter alpha and beta.</p>
<p>The parameters are the shape and inverse scale parameters alpha, beta.</p>
<p>The PDF of this distribution is:</p>
<p><code>pdf(x) = (beta^alpha)(x^(alpha-1))e^(-x*beta)/Gamma(alpha), x &gt; 0</code></p>
<p>and the CDF of this distribution is:</p>
<p><code>cdf(x) =  GammaInc(alpha, beta * x) / Gamma(alpha), x &gt; 0</code></p>
<p>where GammaInc is the incomplete lower Gamma function.</p>
<p>WARNING: This distribution may draw 0-valued samples for small alpha values. See the note on <code>tf.random_gamma</code>.</p>
<p>Examples:</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">dist <span class="op">=</span> Gamma(alpha<span class="op">=</span><span class="fl">3.0</span>, beta<span class="op">=</span><span class="fl">2.0</span>)
dist2 <span class="op">=</span> Gamma(alpha<span class="op">=</span>[<span class="fl">3.0</span>, <span class="fl">4.0</span>], beta<span class="op">=</span>[<span class="fl">2.0</span>, <span class="fl">3.0</span>])</code></pre></div>
<hr />
<h4 id="tf.contrib.distributions.gamma.__init__alpha-beta-validate_argsfalse-allow_nan_statstrue-namegamma"><code id="Gamma.__init__">tf.contrib.distributions.Gamma.__init__(alpha, beta, validate_args=False, allow_nan_stats=True, name='Gamma')</code></h4>
<p>Construct Gamma distributions with parameters <code>alpha</code> and <code>beta</code>.</p>
<p>The parameters <code>alpha</code> and <code>beta</code> must be shaped in a way that supports broadcasting (e.g. <code>alpha + beta</code> is a valid operation).</p>
<h5 id="args-194">Args:</h5>
<ul>
<li><b><code>alpha</code></b>: Floating point tensor, the shape params of the distribution(s). alpha must contain only positive values.</li>
<li><b><code>beta</code></b>: Floating point tensor, the inverse scale params of the distribution(s). beta must contain only positive values.</li>
<li><b><code>validate_args</code></b>: <code>Boolean</code>, default <code>False</code>. Whether to assert that <code>a &gt; 0</code>, <code>b &gt; 0</code>, and that <code>x &gt; 0</code> in the methods <code>prob(x)</code> and <code>log_prob(x)</code>. If <code>validate_args</code> is <code>False</code> and the inputs are invalid, correct behavior is not guaranteed.</li>
<li><b><code>allow_nan_stats</code></b>: <code>Boolean</code>, default <code>True</code>. If <code>False</code>, raise an exception if a statistic (e.g. mean/mode/etc...) is undefined for any batch member. If <code>True</code>, batch members with valid parameters leading to undefined statistics will return NaN for this statistic.</li>
<li><b><code>name</code></b>: The name to prepend to all ops created by this distribution.</li>
</ul>
<h5 id="raises-68">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>alpha</code> and <code>beta</code> are different dtypes.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.gamma.allow_nan_stats"><code id="Gamma.allow_nan_stats">tf.contrib.distributions.Gamma.allow_nan_stats</code></h4>
<p>Python boolean describing behavior when a stat is undefined.</p>
<p>Stats return +/- infinity when it makes sense. E.g., the variance of a Cauchy distribution is infinity. However, sometimes the statistic is undefined, e.g., if a distribution's pdf does not achieve a maximum within the support of the distribution, the mode is undefined. If the mean is undefined, then by definition the variance is undefined. E.g. the mean for Student's T for df = 1 is undefined (no clear way to say it is either + or - infinity), so the variance = E[(X - mean)^2] is also undefined.</p>
<h5 id="returns-220">Returns:</h5>
<ul>
<li><b><code>allow_nan_stats</code></b>: Python boolean.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.gamma.alpha"><code id="Gamma.alpha">tf.contrib.distributions.Gamma.alpha</code></h4>
<p>Shape parameter.</p>
<hr />
<h4 id="tf.contrib.distributions.gamma.batch_shapenamebatch_shape"><code id="Gamma.batch_shape">tf.contrib.distributions.Gamma.batch_shape(name='batch_shape')</code></h4>
<p>Shape of a single sample from a single event index as a 1-D <code>Tensor</code>.</p>
<p>The product of the dimensions of the <code>batch_shape</code> is the number of independent distributions of this kind the instance represents.</p>
<h5 id="args-195">Args:</h5>
<ul>
<li><b><code>name</code></b>: name to give to the op</li>
</ul>
<h5 id="returns-221">Returns:</h5>
<ul>
<li><b><code>batch_shape</code></b>: <code>Tensor</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.gamma.beta"><code id="Gamma.beta">tf.contrib.distributions.Gamma.beta</code></h4>
<p>Inverse scale parameter.</p>
<hr />
<h4 id="tf.contrib.distributions.gamma.cdfvalue-namecdf-condition_kwargs"><code id="Gamma.cdf">tf.contrib.distributions.Gamma.cdf(value, name='cdf', **condition_kwargs)</code></h4>
<p>Cumulative distribution function.</p>
<p>Given random variable <code>X</code>, the cumulative distribution function <code>cdf</code> is:</p>
<pre><code>cdf(x) := P[X &lt;= x]</code></pre>
<h5 id="args-196">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-222">Returns:</h5>
<ul>
<li><b><code>cdf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.gamma.copyoverride_parameters_kwargs"><code id="Gamma.copy">tf.contrib.distributions.Gamma.copy(**override_parameters_kwargs)</code></h4>
<p>Creates a deep copy of the distribution.</p>
<p>Note: the copy distribution may continue to depend on the original intialization arguments.</p>
<h5 id="args-197">Args:</h5>
<ul>
<li><b><code>**override_parameters_kwargs</code></b>: String/value dictionary of initialization arguments to override with new values.</li>
</ul>
<h5 id="returns-223">Returns:</h5>
<ul>
<li><b><code>distribution</code></b>: A new instance of <code>type(self)</code> intitialized from the union of self.parameters and override_parameters_kwargs, i.e., <code>dict(self.parameters, **override_parameters_kwargs)</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.gamma.dtype"><code id="Gamma.dtype">tf.contrib.distributions.Gamma.dtype</code></h4>
<p>The <code>DType</code> of <code>Tensor</code>s handled by this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.gamma.entropynameentropy"><code id="Gamma.entropy">tf.contrib.distributions.Gamma.entropy(name='entropy')</code></h4>
<p>Shannon entropy in nats.</p>
<p>Additional documentation from <code>Gamma</code>:</p>
<p>This is defined to be</p>
<pre><code>entropy = alpha - log(beta) + log(Gamma(alpha))
+ (1-alpha)digamma(alpha)</code></pre>
<p>where digamma(alpha) is the digamma function.</p>
<hr />
<h4 id="tf.contrib.distributions.gamma.event_shapenameevent_shape"><code id="Gamma.event_shape">tf.contrib.distributions.Gamma.event_shape(name='event_shape')</code></h4>
<p>Shape of a single sample from a single batch as a 1-D int32 <code>Tensor</code>.</p>
<h5 id="args-198">Args:</h5>
<ul>
<li><b><code>name</code></b>: name to give to the op</li>
</ul>
<h5 id="returns-224">Returns:</h5>
<ul>
<li><b><code>event_shape</code></b>: <code>Tensor</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.gamma.get_batch_shape"><code id="Gamma.get_batch_shape">tf.contrib.distributions.Gamma.get_batch_shape()</code></h4>
<p>Shape of a single sample from a single event index as a <code>TensorShape</code>.</p>
<p>Same meaning as <code>batch_shape</code>. May be only partially defined.</p>
<h5 id="returns-225">Returns:</h5>
<ul>
<li><b><code>batch_shape</code></b>: <code>TensorShape</code>, possibly unknown.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.gamma.get_event_shape"><code id="Gamma.get_event_shape">tf.contrib.distributions.Gamma.get_event_shape()</code></h4>
<p>Shape of a single sample from a single batch as a <code>TensorShape</code>.</p>
<p>Same meaning as <code>event_shape</code>. May be only partially defined.</p>
<h5 id="returns-226">Returns:</h5>
<ul>
<li><b><code>event_shape</code></b>: <code>TensorShape</code>, possibly unknown.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.gamma.is_continuous"><code id="Gamma.is_continuous">tf.contrib.distributions.Gamma.is_continuous</code></h4>
<hr />
<h4 id="tf.contrib.distributions.gamma.is_reparameterized"><code id="Gamma.is_reparameterized">tf.contrib.distributions.Gamma.is_reparameterized</code></h4>
<hr />
<h4 id="tf.contrib.distributions.gamma.log_cdfvalue-namelog_cdf-condition_kwargs"><code id="Gamma.log_cdf">tf.contrib.distributions.Gamma.log_cdf(value, name='log_cdf', **condition_kwargs)</code></h4>
<p>Log cumulative distribution function.</p>
<p>Given random variable <code>X</code>, the cumulative distribution function <code>cdf</code> is:</p>
<pre><code>log_cdf(x) := Log[ P[X &lt;= x] ]</code></pre>
<p>Often, a numerical approximation can be used for <code>log_cdf(x)</code> that yields a more accurate answer than simply taking the logarithm of the <code>cdf</code> when <code>x &lt;&lt; -1</code>.</p>
<h5 id="args-199">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-227">Returns:</h5>
<ul>
<li><b><code>logcdf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.gamma.log_pdfvalue-namelog_pdf-condition_kwargs"><code id="Gamma.log_pdf">tf.contrib.distributions.Gamma.log_pdf(value, name='log_pdf', **condition_kwargs)</code></h4>
<p>Log probability density function.</p>
<h5 id="args-200">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-228">Returns:</h5>
<ul>
<li><b><code>log_prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-69">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if not <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.gamma.log_pmfvalue-namelog_pmf-condition_kwargs"><code id="Gamma.log_pmf">tf.contrib.distributions.Gamma.log_pmf(value, name='log_pmf', **condition_kwargs)</code></h4>
<p>Log probability mass function.</p>
<h5 id="args-201">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-229">Returns:</h5>
<ul>
<li><b><code>log_pmf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-70">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.gamma.log_probvalue-namelog_prob-condition_kwargs"><code id="Gamma.log_prob">tf.contrib.distributions.Gamma.log_prob(value, name='log_prob', **condition_kwargs)</code></h4>
<p>Log probability density/mass function (depending on <code>is_continuous</code>).</p>
<h5 id="args-202">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-230">Returns:</h5>
<ul>
<li><b><code>log_prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.gamma.log_survival_functionvalue-namelog_survival_function-condition_kwargs"><code id="Gamma.log_survival_function">tf.contrib.distributions.Gamma.log_survival_function(value, name='log_survival_function', **condition_kwargs)</code></h4>
<p>Log survival function.</p>
<p>Given random variable <code>X</code>, the survival function is defined:</p>
<pre><code>log_survival_function(x) = Log[ P[X &gt; x] ]
                         = Log[ 1 - P[X &lt;= x] ]
                         = Log[ 1 - cdf(x) ]</code></pre>
<p>Typically, different numerical approximations can be used for the log survival function, which are more accurate than <code>1 - cdf(x)</code> when <code>x &gt;&gt; 1</code>.</p>
<h5 id="args-203">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-231">Returns:</h5>
<p><code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.gamma.meannamemean"><code id="Gamma.mean">tf.contrib.distributions.Gamma.mean(name='mean')</code></h4>
<p>Mean.</p>
<hr />
<h4 id="tf.contrib.distributions.gamma.modenamemode"><code id="Gamma.mode">tf.contrib.distributions.Gamma.mode(name='mode')</code></h4>
<p>Mode.</p>
<p>Additional documentation from <code>Gamma</code>:</p>
<p>The mode of a gamma distribution is <code>(alpha - 1) / beta</code> when <code>alpha &gt; 1</code>, and <code>NaN</code> otherwise. If <code>self.allow_nan_stats</code> is <code>False</code>, an exception will be raised rather than returning <code>NaN</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.gamma.name"><code id="Gamma.name">tf.contrib.distributions.Gamma.name</code></h4>
<p>Name prepended to all ops created by this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.gamma.param_shapescls-sample_shape-namedistributionparamshapes"><code id="Gamma.param_shapes">tf.contrib.distributions.Gamma.param_shapes(cls, sample_shape, name='DistributionParamShapes')</code></h4>
<p>Shapes of parameters given the desired shape of a call to <code>sample()</code>.</p>
<p>Subclasses should override static method <code>_param_shapes</code>.</p>
<h5 id="args-204">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: <code>Tensor</code> or python list/tuple. Desired shape of a call to <code>sample()</code>.</li>
<li><b><code>name</code></b>: name to prepend ops with.</li>
</ul>
<h5 id="returns-232">Returns:</h5>
<p><code>dict</code> of parameter name to <code>Tensor</code> shapes.</p>
<hr />
<h4 id="tf.contrib.distributions.gamma.param_static_shapescls-sample_shape"><code id="Gamma.param_static_shapes">tf.contrib.distributions.Gamma.param_static_shapes(cls, sample_shape)</code></h4>
<p>param_shapes with static (i.e. TensorShape) shapes.</p>
<h5 id="args-205">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: <code>TensorShape</code> or python list/tuple. Desired shape of a call to <code>sample()</code>.</li>
</ul>
<h5 id="returns-233">Returns:</h5>
<p><code>dict</code> of parameter name to <code>TensorShape</code>.</p>
<h5 id="raises-71">Raises:</h5>
<ul>
<li><b><code>ValueError</code></b>: if <code>sample_shape</code> is a <code>TensorShape</code> and is not fully defined.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.gamma.parameters"><code id="Gamma.parameters">tf.contrib.distributions.Gamma.parameters</code></h4>
<p>Dictionary of parameters used to instantiate this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.gamma.pdfvalue-namepdf-condition_kwargs"><code id="Gamma.pdf">tf.contrib.distributions.Gamma.pdf(value, name='pdf', **condition_kwargs)</code></h4>
<p>Probability density function.</p>
<h5 id="args-206">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-234">Returns:</h5>
<ul>
<li><b><code>prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-72">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if not <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.gamma.pmfvalue-namepmf-condition_kwargs"><code id="Gamma.pmf">tf.contrib.distributions.Gamma.pmf(value, name='pmf', **condition_kwargs)</code></h4>
<p>Probability mass function.</p>
<h5 id="args-207">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-235">Returns:</h5>
<ul>
<li><b><code>pmf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-73">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.gamma.probvalue-nameprob-condition_kwargs"><code id="Gamma.prob">tf.contrib.distributions.Gamma.prob(value, name='prob', **condition_kwargs)</code></h4>
<p>Probability density/mass function (depending on <code>is_continuous</code>).</p>
<h5 id="args-208">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-236">Returns:</h5>
<ul>
<li><b><code>prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.gamma.samplesample_shape-seednone-namesample-condition_kwargs"><code id="Gamma.sample">tf.contrib.distributions.Gamma.sample(sample_shape=(), seed=None, name='sample', **condition_kwargs)</code></h4>
<p>Generate samples of the specified shape.</p>
<p>Note that a call to <code>sample()</code> without arguments will generate a single sample.</p>
<h5 id="args-209">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: 0D or 1D <code>int32</code> <code>Tensor</code>. Shape of the generated samples.</li>
<li><b><code>seed</code></b>: Python integer seed for RNG</li>
<li><b><code>name</code></b>: name to give to the op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-237">Returns:</h5>
<ul>
<li><b><code>samples</code></b>: a <code>Tensor</code> with prepended dimensions <code>sample_shape</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.gamma.sample_nn-seednone-namesample_n-condition_kwargs"><code id="Gamma.sample_n">tf.contrib.distributions.Gamma.sample_n(n, seed=None, name='sample_n', **condition_kwargs)</code></h4>
<p>Generate <code>n</code> samples.</p>
<p>Additional documentation from <code>Gamma</code>:</p>
<p>See the documentation for tf.random_gamma for more details.</p>
<h5 id="args-210">Args:</h5>
<ul>
<li><b><code>n</code></b>: <code>Scalar</code> <code>Tensor</code> of type <code>int32</code> or <code>int64</code>, the number of observations to sample.</li>
<li><b><code>seed</code></b>: Python integer seed for RNG</li>
<li><b><code>name</code></b>: name to give to the op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-238">Returns:</h5>
<ul>
<li><b><code>samples</code></b>: a <code>Tensor</code> with a prepended dimension (n,).</li>
</ul>
<h5 id="raises-74">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>n</code> is not an integer type.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.gamma.stdnamestd"><code id="Gamma.std">tf.contrib.distributions.Gamma.std(name='std')</code></h4>
<p>Standard deviation.</p>
<hr />
<h4 id="tf.contrib.distributions.gamma.survival_functionvalue-namesurvival_function-condition_kwargs"><code id="Gamma.survival_function">tf.contrib.distributions.Gamma.survival_function(value, name='survival_function', **condition_kwargs)</code></h4>
<p>Survival function.</p>
<p>Given random variable <code>X</code>, the survival function is defined:</p>
<pre><code>survival_function(x) = P[X &gt; x]
                     = 1 - P[X &lt;= x]
                     = 1 - cdf(x).</code></pre>
<h5 id="args-211">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-239">Returns:</h5>
<p>Tensor<code>of shape</code>sample_shape(x) + self.batch_shape<code>with values of type</code>self.dtype`.</p>
<hr />
<h4 id="tf.contrib.distributions.gamma.validate_args"><code id="Gamma.validate_args">tf.contrib.distributions.Gamma.validate_args</code></h4>
<p>Python boolean indicated possibly expensive checks are enabled.</p>
<hr />
<h4 id="tf.contrib.distributions.gamma.variancenamevariance"><code id="Gamma.variance">tf.contrib.distributions.Gamma.variance(name='variance')</code></h4>
<p>Variance.</p>
<hr />
<h3 id="class-tf.contrib.distributions.gammawithsoftplusalphabeta"><a name="//apple_ref/cpp/Class/GammaWithSoftplusAlphaBeta" class="dashAnchor"></a><code id="GammaWithSoftplusAlphaBeta">class tf.contrib.distributions.GammaWithSoftplusAlphaBeta</code></h3>
<p>Gamma with softplus transform on <code>alpha</code> and <code>beta</code>. - - -</p>
<h4 id="tf.contrib.distributions.gammawithsoftplusalphabeta.__init__alpha-beta-validate_argsfalse-allow_nan_statstrue-namegammawithsoftplusalphabeta"><code id="GammaWithSoftplusAlphaBeta.__init__">tf.contrib.distributions.GammaWithSoftplusAlphaBeta.__init__(alpha, beta, validate_args=False, allow_nan_stats=True, name='GammaWithSoftplusAlphaBeta')</code></h4>
<hr />
<h4 id="tf.contrib.distributions.gammawithsoftplusalphabeta.allow_nan_stats"><code id="GammaWithSoftplusAlphaBeta.allow_nan_stats">tf.contrib.distributions.GammaWithSoftplusAlphaBeta.allow_nan_stats</code></h4>
<p>Python boolean describing behavior when a stat is undefined.</p>
<p>Stats return +/- infinity when it makes sense. E.g., the variance of a Cauchy distribution is infinity. However, sometimes the statistic is undefined, e.g., if a distribution's pdf does not achieve a maximum within the support of the distribution, the mode is undefined. If the mean is undefined, then by definition the variance is undefined. E.g. the mean for Student's T for df = 1 is undefined (no clear way to say it is either + or - infinity), so the variance = E[(X - mean)^2] is also undefined.</p>
<h5 id="returns-240">Returns:</h5>
<ul>
<li><b><code>allow_nan_stats</code></b>: Python boolean.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.gammawithsoftplusalphabeta.alpha"><code id="GammaWithSoftplusAlphaBeta.alpha">tf.contrib.distributions.GammaWithSoftplusAlphaBeta.alpha</code></h4>
<p>Shape parameter.</p>
<hr />
<h4 id="tf.contrib.distributions.gammawithsoftplusalphabeta.batch_shapenamebatch_shape"><code id="GammaWithSoftplusAlphaBeta.batch_shape">tf.contrib.distributions.GammaWithSoftplusAlphaBeta.batch_shape(name='batch_shape')</code></h4>
<p>Shape of a single sample from a single event index as a 1-D <code>Tensor</code>.</p>
<p>The product of the dimensions of the <code>batch_shape</code> is the number of independent distributions of this kind the instance represents.</p>
<h5 id="args-212">Args:</h5>
<ul>
<li><b><code>name</code></b>: name to give to the op</li>
</ul>
<h5 id="returns-241">Returns:</h5>
<ul>
<li><b><code>batch_shape</code></b>: <code>Tensor</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.gammawithsoftplusalphabeta.beta"><code id="GammaWithSoftplusAlphaBeta.beta">tf.contrib.distributions.GammaWithSoftplusAlphaBeta.beta</code></h4>
<p>Inverse scale parameter.</p>
<hr />
<h4 id="tf.contrib.distributions.gammawithsoftplusalphabeta.cdfvalue-namecdf-condition_kwargs"><code id="GammaWithSoftplusAlphaBeta.cdf">tf.contrib.distributions.GammaWithSoftplusAlphaBeta.cdf(value, name='cdf', **condition_kwargs)</code></h4>
<p>Cumulative distribution function.</p>
<p>Given random variable <code>X</code>, the cumulative distribution function <code>cdf</code> is:</p>
<pre><code>cdf(x) := P[X &lt;= x]</code></pre>
<h5 id="args-213">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-242">Returns:</h5>
<ul>
<li><b><code>cdf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.gammawithsoftplusalphabeta.copyoverride_parameters_kwargs"><code id="GammaWithSoftplusAlphaBeta.copy">tf.contrib.distributions.GammaWithSoftplusAlphaBeta.copy(**override_parameters_kwargs)</code></h4>
<p>Creates a deep copy of the distribution.</p>
<p>Note: the copy distribution may continue to depend on the original intialization arguments.</p>
<h5 id="args-214">Args:</h5>
<ul>
<li><b><code>**override_parameters_kwargs</code></b>: String/value dictionary of initialization arguments to override with new values.</li>
</ul>
<h5 id="returns-243">Returns:</h5>
<ul>
<li><b><code>distribution</code></b>: A new instance of <code>type(self)</code> intitialized from the union of self.parameters and override_parameters_kwargs, i.e., <code>dict(self.parameters, **override_parameters_kwargs)</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.gammawithsoftplusalphabeta.dtype"><code id="GammaWithSoftplusAlphaBeta.dtype">tf.contrib.distributions.GammaWithSoftplusAlphaBeta.dtype</code></h4>
<p>The <code>DType</code> of <code>Tensor</code>s handled by this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.gammawithsoftplusalphabeta.entropynameentropy"><code id="GammaWithSoftplusAlphaBeta.entropy">tf.contrib.distributions.GammaWithSoftplusAlphaBeta.entropy(name='entropy')</code></h4>
<p>Shannon entropy in nats.</p>
<p>Additional documentation from <code>Gamma</code>:</p>
<p>This is defined to be</p>
<pre><code>entropy = alpha - log(beta) + log(Gamma(alpha))
+ (1-alpha)digamma(alpha)</code></pre>
<p>where digamma(alpha) is the digamma function.</p>
<hr />
<h4 id="tf.contrib.distributions.gammawithsoftplusalphabeta.event_shapenameevent_shape"><code id="GammaWithSoftplusAlphaBeta.event_shape">tf.contrib.distributions.GammaWithSoftplusAlphaBeta.event_shape(name='event_shape')</code></h4>
<p>Shape of a single sample from a single batch as a 1-D int32 <code>Tensor</code>.</p>
<h5 id="args-215">Args:</h5>
<ul>
<li><b><code>name</code></b>: name to give to the op</li>
</ul>
<h5 id="returns-244">Returns:</h5>
<ul>
<li><b><code>event_shape</code></b>: <code>Tensor</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.gammawithsoftplusalphabeta.get_batch_shape"><code id="GammaWithSoftplusAlphaBeta.get_batch_shape">tf.contrib.distributions.GammaWithSoftplusAlphaBeta.get_batch_shape()</code></h4>
<p>Shape of a single sample from a single event index as a <code>TensorShape</code>.</p>
<p>Same meaning as <code>batch_shape</code>. May be only partially defined.</p>
<h5 id="returns-245">Returns:</h5>
<ul>
<li><b><code>batch_shape</code></b>: <code>TensorShape</code>, possibly unknown.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.gammawithsoftplusalphabeta.get_event_shape"><code id="GammaWithSoftplusAlphaBeta.get_event_shape">tf.contrib.distributions.GammaWithSoftplusAlphaBeta.get_event_shape()</code></h4>
<p>Shape of a single sample from a single batch as a <code>TensorShape</code>.</p>
<p>Same meaning as <code>event_shape</code>. May be only partially defined.</p>
<h5 id="returns-246">Returns:</h5>
<ul>
<li><b><code>event_shape</code></b>: <code>TensorShape</code>, possibly unknown.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.gammawithsoftplusalphabeta.is_continuous"><code id="GammaWithSoftplusAlphaBeta.is_continuous">tf.contrib.distributions.GammaWithSoftplusAlphaBeta.is_continuous</code></h4>
<hr />
<h4 id="tf.contrib.distributions.gammawithsoftplusalphabeta.is_reparameterized"><code id="GammaWithSoftplusAlphaBeta.is_reparameterized">tf.contrib.distributions.GammaWithSoftplusAlphaBeta.is_reparameterized</code></h4>
<hr />
<h4 id="tf.contrib.distributions.gammawithsoftplusalphabeta.log_cdfvalue-namelog_cdf-condition_kwargs"><code id="GammaWithSoftplusAlphaBeta.log_cdf">tf.contrib.distributions.GammaWithSoftplusAlphaBeta.log_cdf(value, name='log_cdf', **condition_kwargs)</code></h4>
<p>Log cumulative distribution function.</p>
<p>Given random variable <code>X</code>, the cumulative distribution function <code>cdf</code> is:</p>
<pre><code>log_cdf(x) := Log[ P[X &lt;= x] ]</code></pre>
<p>Often, a numerical approximation can be used for <code>log_cdf(x)</code> that yields a more accurate answer than simply taking the logarithm of the <code>cdf</code> when <code>x &lt;&lt; -1</code>.</p>
<h5 id="args-216">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-247">Returns:</h5>
<ul>
<li><b><code>logcdf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.gammawithsoftplusalphabeta.log_pdfvalue-namelog_pdf-condition_kwargs"><code id="GammaWithSoftplusAlphaBeta.log_pdf">tf.contrib.distributions.GammaWithSoftplusAlphaBeta.log_pdf(value, name='log_pdf', **condition_kwargs)</code></h4>
<p>Log probability density function.</p>
<h5 id="args-217">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-248">Returns:</h5>
<ul>
<li><b><code>log_prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-75">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if not <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.gammawithsoftplusalphabeta.log_pmfvalue-namelog_pmf-condition_kwargs"><code id="GammaWithSoftplusAlphaBeta.log_pmf">tf.contrib.distributions.GammaWithSoftplusAlphaBeta.log_pmf(value, name='log_pmf', **condition_kwargs)</code></h4>
<p>Log probability mass function.</p>
<h5 id="args-218">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-249">Returns:</h5>
<ul>
<li><b><code>log_pmf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-76">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.gammawithsoftplusalphabeta.log_probvalue-namelog_prob-condition_kwargs"><code id="GammaWithSoftplusAlphaBeta.log_prob">tf.contrib.distributions.GammaWithSoftplusAlphaBeta.log_prob(value, name='log_prob', **condition_kwargs)</code></h4>
<p>Log probability density/mass function (depending on <code>is_continuous</code>).</p>
<h5 id="args-219">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-250">Returns:</h5>
<ul>
<li><b><code>log_prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.gammawithsoftplusalphabeta.log_survival_functionvalue-namelog_survival_function-condition_kwargs"><code id="GammaWithSoftplusAlphaBeta.log_survival_function">tf.contrib.distributions.GammaWithSoftplusAlphaBeta.log_survival_function(value, name='log_survival_function', **condition_kwargs)</code></h4>
<p>Log survival function.</p>
<p>Given random variable <code>X</code>, the survival function is defined:</p>
<pre><code>log_survival_function(x) = Log[ P[X &gt; x] ]
                         = Log[ 1 - P[X &lt;= x] ]
                         = Log[ 1 - cdf(x) ]</code></pre>
<p>Typically, different numerical approximations can be used for the log survival function, which are more accurate than <code>1 - cdf(x)</code> when <code>x &gt;&gt; 1</code>.</p>
<h5 id="args-220">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-251">Returns:</h5>
<p><code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.gammawithsoftplusalphabeta.meannamemean"><code id="GammaWithSoftplusAlphaBeta.mean">tf.contrib.distributions.GammaWithSoftplusAlphaBeta.mean(name='mean')</code></h4>
<p>Mean.</p>
<hr />
<h4 id="tf.contrib.distributions.gammawithsoftplusalphabeta.modenamemode"><code id="GammaWithSoftplusAlphaBeta.mode">tf.contrib.distributions.GammaWithSoftplusAlphaBeta.mode(name='mode')</code></h4>
<p>Mode.</p>
<p>Additional documentation from <code>Gamma</code>:</p>
<p>The mode of a gamma distribution is <code>(alpha - 1) / beta</code> when <code>alpha &gt; 1</code>, and <code>NaN</code> otherwise. If <code>self.allow_nan_stats</code> is <code>False</code>, an exception will be raised rather than returning <code>NaN</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.gammawithsoftplusalphabeta.name"><code id="GammaWithSoftplusAlphaBeta.name">tf.contrib.distributions.GammaWithSoftplusAlphaBeta.name</code></h4>
<p>Name prepended to all ops created by this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.gammawithsoftplusalphabeta.param_shapescls-sample_shape-namedistributionparamshapes"><code id="GammaWithSoftplusAlphaBeta.param_shapes">tf.contrib.distributions.GammaWithSoftplusAlphaBeta.param_shapes(cls, sample_shape, name='DistributionParamShapes')</code></h4>
<p>Shapes of parameters given the desired shape of a call to <code>sample()</code>.</p>
<p>Subclasses should override static method <code>_param_shapes</code>.</p>
<h5 id="args-221">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: <code>Tensor</code> or python list/tuple. Desired shape of a call to <code>sample()</code>.</li>
<li><b><code>name</code></b>: name to prepend ops with.</li>
</ul>
<h5 id="returns-252">Returns:</h5>
<p><code>dict</code> of parameter name to <code>Tensor</code> shapes.</p>
<hr />
<h4 id="tf.contrib.distributions.gammawithsoftplusalphabeta.param_static_shapescls-sample_shape"><code id="GammaWithSoftplusAlphaBeta.param_static_shapes">tf.contrib.distributions.GammaWithSoftplusAlphaBeta.param_static_shapes(cls, sample_shape)</code></h4>
<p>param_shapes with static (i.e. TensorShape) shapes.</p>
<h5 id="args-222">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: <code>TensorShape</code> or python list/tuple. Desired shape of a call to <code>sample()</code>.</li>
</ul>
<h5 id="returns-253">Returns:</h5>
<p><code>dict</code> of parameter name to <code>TensorShape</code>.</p>
<h5 id="raises-77">Raises:</h5>
<ul>
<li><b><code>ValueError</code></b>: if <code>sample_shape</code> is a <code>TensorShape</code> and is not fully defined.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.gammawithsoftplusalphabeta.parameters"><code id="GammaWithSoftplusAlphaBeta.parameters">tf.contrib.distributions.GammaWithSoftplusAlphaBeta.parameters</code></h4>
<p>Dictionary of parameters used to instantiate this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.gammawithsoftplusalphabeta.pdfvalue-namepdf-condition_kwargs"><code id="GammaWithSoftplusAlphaBeta.pdf">tf.contrib.distributions.GammaWithSoftplusAlphaBeta.pdf(value, name='pdf', **condition_kwargs)</code></h4>
<p>Probability density function.</p>
<h5 id="args-223">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-254">Returns:</h5>
<ul>
<li><b><code>prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-78">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if not <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.gammawithsoftplusalphabeta.pmfvalue-namepmf-condition_kwargs"><code id="GammaWithSoftplusAlphaBeta.pmf">tf.contrib.distributions.GammaWithSoftplusAlphaBeta.pmf(value, name='pmf', **condition_kwargs)</code></h4>
<p>Probability mass function.</p>
<h5 id="args-224">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-255">Returns:</h5>
<ul>
<li><b><code>pmf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-79">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.gammawithsoftplusalphabeta.probvalue-nameprob-condition_kwargs"><code id="GammaWithSoftplusAlphaBeta.prob">tf.contrib.distributions.GammaWithSoftplusAlphaBeta.prob(value, name='prob', **condition_kwargs)</code></h4>
<p>Probability density/mass function (depending on <code>is_continuous</code>).</p>
<h5 id="args-225">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-256">Returns:</h5>
<ul>
<li><b><code>prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.gammawithsoftplusalphabeta.samplesample_shape-seednone-namesample-condition_kwargs"><code id="GammaWithSoftplusAlphaBeta.sample">tf.contrib.distributions.GammaWithSoftplusAlphaBeta.sample(sample_shape=(), seed=None, name='sample', **condition_kwargs)</code></h4>
<p>Generate samples of the specified shape.</p>
<p>Note that a call to <code>sample()</code> without arguments will generate a single sample.</p>
<h5 id="args-226">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: 0D or 1D <code>int32</code> <code>Tensor</code>. Shape of the generated samples.</li>
<li><b><code>seed</code></b>: Python integer seed for RNG</li>
<li><b><code>name</code></b>: name to give to the op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-257">Returns:</h5>
<ul>
<li><b><code>samples</code></b>: a <code>Tensor</code> with prepended dimensions <code>sample_shape</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.gammawithsoftplusalphabeta.sample_nn-seednone-namesample_n-condition_kwargs"><code id="GammaWithSoftplusAlphaBeta.sample_n">tf.contrib.distributions.GammaWithSoftplusAlphaBeta.sample_n(n, seed=None, name='sample_n', **condition_kwargs)</code></h4>
<p>Generate <code>n</code> samples.</p>
<p>Additional documentation from <code>Gamma</code>:</p>
<p>See the documentation for tf.random_gamma for more details.</p>
<h5 id="args-227">Args:</h5>
<ul>
<li><b><code>n</code></b>: <code>Scalar</code> <code>Tensor</code> of type <code>int32</code> or <code>int64</code>, the number of observations to sample.</li>
<li><b><code>seed</code></b>: Python integer seed for RNG</li>
<li><b><code>name</code></b>: name to give to the op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-258">Returns:</h5>
<ul>
<li><b><code>samples</code></b>: a <code>Tensor</code> with a prepended dimension (n,).</li>
</ul>
<h5 id="raises-80">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>n</code> is not an integer type.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.gammawithsoftplusalphabeta.stdnamestd"><code id="GammaWithSoftplusAlphaBeta.std">tf.contrib.distributions.GammaWithSoftplusAlphaBeta.std(name='std')</code></h4>
<p>Standard deviation.</p>
<hr />
<h4 id="tf.contrib.distributions.gammawithsoftplusalphabeta.survival_functionvalue-namesurvival_function-condition_kwargs"><code id="GammaWithSoftplusAlphaBeta.survival_function">tf.contrib.distributions.GammaWithSoftplusAlphaBeta.survival_function(value, name='survival_function', **condition_kwargs)</code></h4>
<p>Survival function.</p>
<p>Given random variable <code>X</code>, the survival function is defined:</p>
<pre><code>survival_function(x) = P[X &gt; x]
                     = 1 - P[X &lt;= x]
                     = 1 - cdf(x).</code></pre>
<h5 id="args-228">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-259">Returns:</h5>
<p>Tensor<code>of shape</code>sample_shape(x) + self.batch_shape<code>with values of type</code>self.dtype`.</p>
<hr />
<h4 id="tf.contrib.distributions.gammawithsoftplusalphabeta.validate_args"><code id="GammaWithSoftplusAlphaBeta.validate_args">tf.contrib.distributions.GammaWithSoftplusAlphaBeta.validate_args</code></h4>
<p>Python boolean indicated possibly expensive checks are enabled.</p>
<hr />
<h4 id="tf.contrib.distributions.gammawithsoftplusalphabeta.variancenamevariance"><code id="GammaWithSoftplusAlphaBeta.variance">tf.contrib.distributions.GammaWithSoftplusAlphaBeta.variance(name='variance')</code></h4>
<p>Variance.</p>
<hr />
<h3 id="class-tf.contrib.distributions.inversegamma"><a name="//apple_ref/cpp/Class/InverseGamma" class="dashAnchor"></a><code id="InverseGamma">class tf.contrib.distributions.InverseGamma</code></h3>
<p>The <code>InverseGamma</code> distribution with parameter alpha and beta.</p>
<p>The parameters are the shape and inverse scale parameters alpha, beta.</p>
<p>The PDF of this distribution is:</p>
<p><code>pdf(x) = (beta^alpha)/Gamma(alpha)(x^(-alpha-1))e^(-beta/x), x &gt; 0</code></p>
<p>and the CDF of this distribution is:</p>
<p><code>cdf(x) =  GammaInc(alpha, beta / x) / Gamma(alpha), x &gt; 0</code></p>
<p>where GammaInc is the upper incomplete Gamma function.</p>
<p>Examples:</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">dist <span class="op">=</span> InverseGamma(alpha<span class="op">=</span><span class="fl">3.0</span>, beta<span class="op">=</span><span class="fl">2.0</span>)
dist2 <span class="op">=</span> InverseGamma(alpha<span class="op">=</span>[<span class="fl">3.0</span>, <span class="fl">4.0</span>], beta<span class="op">=</span>[<span class="fl">2.0</span>, <span class="fl">3.0</span>])</code></pre></div>
<hr />
<h4 id="tf.contrib.distributions.inversegamma.__init__alpha-beta-validate_argsfalse-allow_nan_statstrue-nameinversegamma"><code id="InverseGamma.__init__">tf.contrib.distributions.InverseGamma.__init__(alpha, beta, validate_args=False, allow_nan_stats=True, name='InverseGamma')</code></h4>
<p>Construct InverseGamma distributions with parameters <code>alpha</code> and <code>beta</code>.</p>
<p>The parameters <code>alpha</code> and <code>beta</code> must be shaped in a way that supports broadcasting (e.g. <code>alpha + beta</code> is a valid operation).</p>
<h5 id="args-229">Args:</h5>
<ul>
<li><b><code>alpha</code></b>: Floating point tensor, the shape params of the distribution(s). alpha must contain only positive values.</li>
<li><b><code>beta</code></b>: Floating point tensor, the scale params of the distribution(s). beta must contain only positive values.</li>
<li><b><code>validate_args</code></b>: <code>Boolean</code>, default <code>False</code>. Whether to assert that <code>a &gt; 0</code>, <code>b &gt; 0</code>, and that <code>x &gt; 0</code> in the methods <code>prob(x)</code> and <code>log_prob(x)</code>. If <code>validate_args</code> is <code>False</code> and the inputs are invalid, correct behavior is not guaranteed.</li>
<li><b><code>allow_nan_stats</code></b>: <code>Boolean</code>, default <code>True</code>. If <code>False</code>, raise an exception if a statistic (e.g. mean/mode/etc...) is undefined for any batch member. If <code>True</code>, batch members with valid parameters leading to undefined statistics will return NaN for this statistic.</li>
<li><b><code>name</code></b>: The name to prepend to all ops created by this distribution.</li>
</ul>
<h5 id="raises-81">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>alpha</code> and <code>beta</code> are different dtypes.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.inversegamma.allow_nan_stats"><code id="InverseGamma.allow_nan_stats">tf.contrib.distributions.InverseGamma.allow_nan_stats</code></h4>
<p>Python boolean describing behavior when a stat is undefined.</p>
<p>Stats return +/- infinity when it makes sense. E.g., the variance of a Cauchy distribution is infinity. However, sometimes the statistic is undefined, e.g., if a distribution's pdf does not achieve a maximum within the support of the distribution, the mode is undefined. If the mean is undefined, then by definition the variance is undefined. E.g. the mean for Student's T for df = 1 is undefined (no clear way to say it is either + or - infinity), so the variance = E[(X - mean)^2] is also undefined.</p>
<h5 id="returns-260">Returns:</h5>
<ul>
<li><b><code>allow_nan_stats</code></b>: Python boolean.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.inversegamma.alpha"><code id="InverseGamma.alpha">tf.contrib.distributions.InverseGamma.alpha</code></h4>
<p>Shape parameter.</p>
<hr />
<h4 id="tf.contrib.distributions.inversegamma.batch_shapenamebatch_shape"><code id="InverseGamma.batch_shape">tf.contrib.distributions.InverseGamma.batch_shape(name='batch_shape')</code></h4>
<p>Shape of a single sample from a single event index as a 1-D <code>Tensor</code>.</p>
<p>The product of the dimensions of the <code>batch_shape</code> is the number of independent distributions of this kind the instance represents.</p>
<h5 id="args-230">Args:</h5>
<ul>
<li><b><code>name</code></b>: name to give to the op</li>
</ul>
<h5 id="returns-261">Returns:</h5>
<ul>
<li><b><code>batch_shape</code></b>: <code>Tensor</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.inversegamma.beta"><code id="InverseGamma.beta">tf.contrib.distributions.InverseGamma.beta</code></h4>
<p>Scale parameter.</p>
<hr />
<h4 id="tf.contrib.distributions.inversegamma.cdfvalue-namecdf-condition_kwargs"><code id="InverseGamma.cdf">tf.contrib.distributions.InverseGamma.cdf(value, name='cdf', **condition_kwargs)</code></h4>
<p>Cumulative distribution function.</p>
<p>Given random variable <code>X</code>, the cumulative distribution function <code>cdf</code> is:</p>
<pre><code>cdf(x) := P[X &lt;= x]</code></pre>
<h5 id="args-231">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-262">Returns:</h5>
<ul>
<li><b><code>cdf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.inversegamma.copyoverride_parameters_kwargs"><code id="InverseGamma.copy">tf.contrib.distributions.InverseGamma.copy(**override_parameters_kwargs)</code></h4>
<p>Creates a deep copy of the distribution.</p>
<p>Note: the copy distribution may continue to depend on the original intialization arguments.</p>
<h5 id="args-232">Args:</h5>
<ul>
<li><b><code>**override_parameters_kwargs</code></b>: String/value dictionary of initialization arguments to override with new values.</li>
</ul>
<h5 id="returns-263">Returns:</h5>
<ul>
<li><b><code>distribution</code></b>: A new instance of <code>type(self)</code> intitialized from the union of self.parameters and override_parameters_kwargs, i.e., <code>dict(self.parameters, **override_parameters_kwargs)</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.inversegamma.dtype"><code id="InverseGamma.dtype">tf.contrib.distributions.InverseGamma.dtype</code></h4>
<p>The <code>DType</code> of <code>Tensor</code>s handled by this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.inversegamma.entropynameentropy"><code id="InverseGamma.entropy">tf.contrib.distributions.InverseGamma.entropy(name='entropy')</code></h4>
<p>Shannon entropy in nats.</p>
<p>Additional documentation from <code>InverseGamma</code>:</p>
<p>This is defined to be</p>
<pre><code>entropy = alpha - log(beta) + log(Gamma(alpha))
+ (1-alpha)digamma(alpha)</code></pre>
<p>where digamma(alpha) is the digamma function.</p>
<hr />
<h4 id="tf.contrib.distributions.inversegamma.event_shapenameevent_shape"><code id="InverseGamma.event_shape">tf.contrib.distributions.InverseGamma.event_shape(name='event_shape')</code></h4>
<p>Shape of a single sample from a single batch as a 1-D int32 <code>Tensor</code>.</p>
<h5 id="args-233">Args:</h5>
<ul>
<li><b><code>name</code></b>: name to give to the op</li>
</ul>
<h5 id="returns-264">Returns:</h5>
<ul>
<li><b><code>event_shape</code></b>: <code>Tensor</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.inversegamma.get_batch_shape"><code id="InverseGamma.get_batch_shape">tf.contrib.distributions.InverseGamma.get_batch_shape()</code></h4>
<p>Shape of a single sample from a single event index as a <code>TensorShape</code>.</p>
<p>Same meaning as <code>batch_shape</code>. May be only partially defined.</p>
<h5 id="returns-265">Returns:</h5>
<ul>
<li><b><code>batch_shape</code></b>: <code>TensorShape</code>, possibly unknown.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.inversegamma.get_event_shape"><code id="InverseGamma.get_event_shape">tf.contrib.distributions.InverseGamma.get_event_shape()</code></h4>
<p>Shape of a single sample from a single batch as a <code>TensorShape</code>.</p>
<p>Same meaning as <code>event_shape</code>. May be only partially defined.</p>
<h5 id="returns-266">Returns:</h5>
<ul>
<li><b><code>event_shape</code></b>: <code>TensorShape</code>, possibly unknown.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.inversegamma.is_continuous"><code id="InverseGamma.is_continuous">tf.contrib.distributions.InverseGamma.is_continuous</code></h4>
<hr />
<h4 id="tf.contrib.distributions.inversegamma.is_reparameterized"><code id="InverseGamma.is_reparameterized">tf.contrib.distributions.InverseGamma.is_reparameterized</code></h4>
<hr />
<h4 id="tf.contrib.distributions.inversegamma.log_cdfvalue-namelog_cdf-condition_kwargs"><code id="InverseGamma.log_cdf">tf.contrib.distributions.InverseGamma.log_cdf(value, name='log_cdf', **condition_kwargs)</code></h4>
<p>Log cumulative distribution function.</p>
<p>Given random variable <code>X</code>, the cumulative distribution function <code>cdf</code> is:</p>
<pre><code>log_cdf(x) := Log[ P[X &lt;= x] ]</code></pre>
<p>Often, a numerical approximation can be used for <code>log_cdf(x)</code> that yields a more accurate answer than simply taking the logarithm of the <code>cdf</code> when <code>x &lt;&lt; -1</code>.</p>
<h5 id="args-234">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-267">Returns:</h5>
<ul>
<li><b><code>logcdf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.inversegamma.log_pdfvalue-namelog_pdf-condition_kwargs"><code id="InverseGamma.log_pdf">tf.contrib.distributions.InverseGamma.log_pdf(value, name='log_pdf', **condition_kwargs)</code></h4>
<p>Log probability density function.</p>
<h5 id="args-235">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-268">Returns:</h5>
<ul>
<li><b><code>log_prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-82">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if not <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.inversegamma.log_pmfvalue-namelog_pmf-condition_kwargs"><code id="InverseGamma.log_pmf">tf.contrib.distributions.InverseGamma.log_pmf(value, name='log_pmf', **condition_kwargs)</code></h4>
<p>Log probability mass function.</p>
<h5 id="args-236">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-269">Returns:</h5>
<ul>
<li><b><code>log_pmf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-83">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.inversegamma.log_probvalue-namelog_prob-condition_kwargs"><code id="InverseGamma.log_prob">tf.contrib.distributions.InverseGamma.log_prob(value, name='log_prob', **condition_kwargs)</code></h4>
<p>Log probability density/mass function (depending on <code>is_continuous</code>).</p>
<h5 id="args-237">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-270">Returns:</h5>
<ul>
<li><b><code>log_prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.inversegamma.log_survival_functionvalue-namelog_survival_function-condition_kwargs"><code id="InverseGamma.log_survival_function">tf.contrib.distributions.InverseGamma.log_survival_function(value, name='log_survival_function', **condition_kwargs)</code></h4>
<p>Log survival function.</p>
<p>Given random variable <code>X</code>, the survival function is defined:</p>
<pre><code>log_survival_function(x) = Log[ P[X &gt; x] ]
                         = Log[ 1 - P[X &lt;= x] ]
                         = Log[ 1 - cdf(x) ]</code></pre>
<p>Typically, different numerical approximations can be used for the log survival function, which are more accurate than <code>1 - cdf(x)</code> when <code>x &gt;&gt; 1</code>.</p>
<h5 id="args-238">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-271">Returns:</h5>
<p><code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.inversegamma.meannamemean"><code id="InverseGamma.mean">tf.contrib.distributions.InverseGamma.mean(name='mean')</code></h4>
<p>Mean.</p>
<p>Additional documentation from <code>InverseGamma</code>:</p>
<p>The mean of an inverse gamma distribution is <code>beta / (alpha - 1)</code>, when <code>alpha &gt; 1</code>, and <code>NaN</code> otherwise. If <code>self.allow_nan_stats</code> is <code>False</code>, an exception will be raised rather than returning <code>NaN</code></p>
<hr />
<h4 id="tf.contrib.distributions.inversegamma.modenamemode"><code id="InverseGamma.mode">tf.contrib.distributions.InverseGamma.mode(name='mode')</code></h4>
<p>Mode.</p>
<p>Additional documentation from <code>InverseGamma</code>:</p>
<p>The mode of an inverse gamma distribution is <code>beta / (alpha + 1)</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.inversegamma.name"><code id="InverseGamma.name">tf.contrib.distributions.InverseGamma.name</code></h4>
<p>Name prepended to all ops created by this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.inversegamma.param_shapescls-sample_shape-namedistributionparamshapes"><code id="InverseGamma.param_shapes">tf.contrib.distributions.InverseGamma.param_shapes(cls, sample_shape, name='DistributionParamShapes')</code></h4>
<p>Shapes of parameters given the desired shape of a call to <code>sample()</code>.</p>
<p>Subclasses should override static method <code>_param_shapes</code>.</p>
<h5 id="args-239">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: <code>Tensor</code> or python list/tuple. Desired shape of a call to <code>sample()</code>.</li>
<li><b><code>name</code></b>: name to prepend ops with.</li>
</ul>
<h5 id="returns-272">Returns:</h5>
<p><code>dict</code> of parameter name to <code>Tensor</code> shapes.</p>
<hr />
<h4 id="tf.contrib.distributions.inversegamma.param_static_shapescls-sample_shape"><code id="InverseGamma.param_static_shapes">tf.contrib.distributions.InverseGamma.param_static_shapes(cls, sample_shape)</code></h4>
<p>param_shapes with static (i.e. TensorShape) shapes.</p>
<h5 id="args-240">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: <code>TensorShape</code> or python list/tuple. Desired shape of a call to <code>sample()</code>.</li>
</ul>
<h5 id="returns-273">Returns:</h5>
<p><code>dict</code> of parameter name to <code>TensorShape</code>.</p>
<h5 id="raises-84">Raises:</h5>
<ul>
<li><b><code>ValueError</code></b>: if <code>sample_shape</code> is a <code>TensorShape</code> and is not fully defined.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.inversegamma.parameters"><code id="InverseGamma.parameters">tf.contrib.distributions.InverseGamma.parameters</code></h4>
<p>Dictionary of parameters used to instantiate this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.inversegamma.pdfvalue-namepdf-condition_kwargs"><code id="InverseGamma.pdf">tf.contrib.distributions.InverseGamma.pdf(value, name='pdf', **condition_kwargs)</code></h4>
<p>Probability density function.</p>
<h5 id="args-241">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-274">Returns:</h5>
<ul>
<li><b><code>prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-85">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if not <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.inversegamma.pmfvalue-namepmf-condition_kwargs"><code id="InverseGamma.pmf">tf.contrib.distributions.InverseGamma.pmf(value, name='pmf', **condition_kwargs)</code></h4>
<p>Probability mass function.</p>
<h5 id="args-242">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-275">Returns:</h5>
<ul>
<li><b><code>pmf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-86">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.inversegamma.probvalue-nameprob-condition_kwargs"><code id="InverseGamma.prob">tf.contrib.distributions.InverseGamma.prob(value, name='prob', **condition_kwargs)</code></h4>
<p>Probability density/mass function (depending on <code>is_continuous</code>).</p>
<h5 id="args-243">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-276">Returns:</h5>
<ul>
<li><b><code>prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.inversegamma.samplesample_shape-seednone-namesample-condition_kwargs"><code id="InverseGamma.sample">tf.contrib.distributions.InverseGamma.sample(sample_shape=(), seed=None, name='sample', **condition_kwargs)</code></h4>
<p>Generate samples of the specified shape.</p>
<p>Note that a call to <code>sample()</code> without arguments will generate a single sample.</p>
<h5 id="args-244">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: 0D or 1D <code>int32</code> <code>Tensor</code>. Shape of the generated samples.</li>
<li><b><code>seed</code></b>: Python integer seed for RNG</li>
<li><b><code>name</code></b>: name to give to the op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-277">Returns:</h5>
<ul>
<li><b><code>samples</code></b>: a <code>Tensor</code> with prepended dimensions <code>sample_shape</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.inversegamma.sample_nn-seednone-namesample_n-condition_kwargs"><code id="InverseGamma.sample_n">tf.contrib.distributions.InverseGamma.sample_n(n, seed=None, name='sample_n', **condition_kwargs)</code></h4>
<p>Generate <code>n</code> samples.</p>
<p>Additional documentation from <code>InverseGamma</code>:</p>
<p>See the documentation for tf.random_gamma for more details.</p>
<h5 id="args-245">Args:</h5>
<ul>
<li><b><code>n</code></b>: <code>Scalar</code> <code>Tensor</code> of type <code>int32</code> or <code>int64</code>, the number of observations to sample.</li>
<li><b><code>seed</code></b>: Python integer seed for RNG</li>
<li><b><code>name</code></b>: name to give to the op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-278">Returns:</h5>
<ul>
<li><b><code>samples</code></b>: a <code>Tensor</code> with a prepended dimension (n,).</li>
</ul>
<h5 id="raises-87">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>n</code> is not an integer type.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.inversegamma.stdnamestd"><code id="InverseGamma.std">tf.contrib.distributions.InverseGamma.std(name='std')</code></h4>
<p>Standard deviation.</p>
<hr />
<h4 id="tf.contrib.distributions.inversegamma.survival_functionvalue-namesurvival_function-condition_kwargs"><code id="InverseGamma.survival_function">tf.contrib.distributions.InverseGamma.survival_function(value, name='survival_function', **condition_kwargs)</code></h4>
<p>Survival function.</p>
<p>Given random variable <code>X</code>, the survival function is defined:</p>
<pre><code>survival_function(x) = P[X &gt; x]
                     = 1 - P[X &lt;= x]
                     = 1 - cdf(x).</code></pre>
<h5 id="args-246">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-279">Returns:</h5>
<p>Tensor<code>of shape</code>sample_shape(x) + self.batch_shape<code>with values of type</code>self.dtype`.</p>
<hr />
<h4 id="tf.contrib.distributions.inversegamma.validate_args"><code id="InverseGamma.validate_args">tf.contrib.distributions.InverseGamma.validate_args</code></h4>
<p>Python boolean indicated possibly expensive checks are enabled.</p>
<hr />
<h4 id="tf.contrib.distributions.inversegamma.variancenamevariance"><code id="InverseGamma.variance">tf.contrib.distributions.InverseGamma.variance(name='variance')</code></h4>
<p>Variance.</p>
<p>Additional documentation from <code>InverseGamma</code>:</p>
<p>Variance for inverse gamma is defined only for <code>alpha &gt; 2</code>. If <code>self.allow_nan_stats</code> is <code>False</code>, an exception will be raised rather than returning <code>NaN</code>.</p>
<hr />
<h3 id="class-tf.contrib.distributions.inversegammawithsoftplusalphabeta"><a name="//apple_ref/cpp/Class/InverseGammaWithSoftplusAlphaBeta" class="dashAnchor"></a><code id="InverseGammaWithSoftplusAlphaBeta">class tf.contrib.distributions.InverseGammaWithSoftplusAlphaBeta</code></h3>
<p>Inverse Gamma with softplus applied to <code>alpha</code> and <code>beta</code>. - - -</p>
<h4 id="tf.contrib.distributions.inversegammawithsoftplusalphabeta.__init__alpha-beta-validate_argsfalse-allow_nan_statstrue-nameinversegammawithsoftplusalphabeta"><code id="InverseGammaWithSoftplusAlphaBeta.__init__">tf.contrib.distributions.InverseGammaWithSoftplusAlphaBeta.__init__(alpha, beta, validate_args=False, allow_nan_stats=True, name='InverseGammaWithSoftplusAlphaBeta')</code></h4>
<hr />
<h4 id="tf.contrib.distributions.inversegammawithsoftplusalphabeta.allow_nan_stats"><code id="InverseGammaWithSoftplusAlphaBeta.allow_nan_stats">tf.contrib.distributions.InverseGammaWithSoftplusAlphaBeta.allow_nan_stats</code></h4>
<p>Python boolean describing behavior when a stat is undefined.</p>
<p>Stats return +/- infinity when it makes sense. E.g., the variance of a Cauchy distribution is infinity. However, sometimes the statistic is undefined, e.g., if a distribution's pdf does not achieve a maximum within the support of the distribution, the mode is undefined. If the mean is undefined, then by definition the variance is undefined. E.g. the mean for Student's T for df = 1 is undefined (no clear way to say it is either + or - infinity), so the variance = E[(X - mean)^2] is also undefined.</p>
<h5 id="returns-280">Returns:</h5>
<ul>
<li><b><code>allow_nan_stats</code></b>: Python boolean.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.inversegammawithsoftplusalphabeta.alpha"><code id="InverseGammaWithSoftplusAlphaBeta.alpha">tf.contrib.distributions.InverseGammaWithSoftplusAlphaBeta.alpha</code></h4>
<p>Shape parameter.</p>
<hr />
<h4 id="tf.contrib.distributions.inversegammawithsoftplusalphabeta.batch_shapenamebatch_shape"><code id="InverseGammaWithSoftplusAlphaBeta.batch_shape">tf.contrib.distributions.InverseGammaWithSoftplusAlphaBeta.batch_shape(name='batch_shape')</code></h4>
<p>Shape of a single sample from a single event index as a 1-D <code>Tensor</code>.</p>
<p>The product of the dimensions of the <code>batch_shape</code> is the number of independent distributions of this kind the instance represents.</p>
<h5 id="args-247">Args:</h5>
<ul>
<li><b><code>name</code></b>: name to give to the op</li>
</ul>
<h5 id="returns-281">Returns:</h5>
<ul>
<li><b><code>batch_shape</code></b>: <code>Tensor</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.inversegammawithsoftplusalphabeta.beta"><code id="InverseGammaWithSoftplusAlphaBeta.beta">tf.contrib.distributions.InverseGammaWithSoftplusAlphaBeta.beta</code></h4>
<p>Scale parameter.</p>
<hr />
<h4 id="tf.contrib.distributions.inversegammawithsoftplusalphabeta.cdfvalue-namecdf-condition_kwargs"><code id="InverseGammaWithSoftplusAlphaBeta.cdf">tf.contrib.distributions.InverseGammaWithSoftplusAlphaBeta.cdf(value, name='cdf', **condition_kwargs)</code></h4>
<p>Cumulative distribution function.</p>
<p>Given random variable <code>X</code>, the cumulative distribution function <code>cdf</code> is:</p>
<pre><code>cdf(x) := P[X &lt;= x]</code></pre>
<h5 id="args-248">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-282">Returns:</h5>
<ul>
<li><b><code>cdf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.inversegammawithsoftplusalphabeta.copyoverride_parameters_kwargs"><code id="InverseGammaWithSoftplusAlphaBeta.copy">tf.contrib.distributions.InverseGammaWithSoftplusAlphaBeta.copy(**override_parameters_kwargs)</code></h4>
<p>Creates a deep copy of the distribution.</p>
<p>Note: the copy distribution may continue to depend on the original intialization arguments.</p>
<h5 id="args-249">Args:</h5>
<ul>
<li><b><code>**override_parameters_kwargs</code></b>: String/value dictionary of initialization arguments to override with new values.</li>
</ul>
<h5 id="returns-283">Returns:</h5>
<ul>
<li><b><code>distribution</code></b>: A new instance of <code>type(self)</code> intitialized from the union of self.parameters and override_parameters_kwargs, i.e., <code>dict(self.parameters, **override_parameters_kwargs)</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.inversegammawithsoftplusalphabeta.dtype"><code id="InverseGammaWithSoftplusAlphaBeta.dtype">tf.contrib.distributions.InverseGammaWithSoftplusAlphaBeta.dtype</code></h4>
<p>The <code>DType</code> of <code>Tensor</code>s handled by this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.inversegammawithsoftplusalphabeta.entropynameentropy"><code id="InverseGammaWithSoftplusAlphaBeta.entropy">tf.contrib.distributions.InverseGammaWithSoftplusAlphaBeta.entropy(name='entropy')</code></h4>
<p>Shannon entropy in nats.</p>
<p>Additional documentation from <code>InverseGamma</code>:</p>
<p>This is defined to be</p>
<pre><code>entropy = alpha - log(beta) + log(Gamma(alpha))
+ (1-alpha)digamma(alpha)</code></pre>
<p>where digamma(alpha) is the digamma function.</p>
<hr />
<h4 id="tf.contrib.distributions.inversegammawithsoftplusalphabeta.event_shapenameevent_shape"><code id="InverseGammaWithSoftplusAlphaBeta.event_shape">tf.contrib.distributions.InverseGammaWithSoftplusAlphaBeta.event_shape(name='event_shape')</code></h4>
<p>Shape of a single sample from a single batch as a 1-D int32 <code>Tensor</code>.</p>
<h5 id="args-250">Args:</h5>
<ul>
<li><b><code>name</code></b>: name to give to the op</li>
</ul>
<h5 id="returns-284">Returns:</h5>
<ul>
<li><b><code>event_shape</code></b>: <code>Tensor</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.inversegammawithsoftplusalphabeta.get_batch_shape"><code id="InverseGammaWithSoftplusAlphaBeta.get_batch_shape">tf.contrib.distributions.InverseGammaWithSoftplusAlphaBeta.get_batch_shape()</code></h4>
<p>Shape of a single sample from a single event index as a <code>TensorShape</code>.</p>
<p>Same meaning as <code>batch_shape</code>. May be only partially defined.</p>
<h5 id="returns-285">Returns:</h5>
<ul>
<li><b><code>batch_shape</code></b>: <code>TensorShape</code>, possibly unknown.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.inversegammawithsoftplusalphabeta.get_event_shape"><code id="InverseGammaWithSoftplusAlphaBeta.get_event_shape">tf.contrib.distributions.InverseGammaWithSoftplusAlphaBeta.get_event_shape()</code></h4>
<p>Shape of a single sample from a single batch as a <code>TensorShape</code>.</p>
<p>Same meaning as <code>event_shape</code>. May be only partially defined.</p>
<h5 id="returns-286">Returns:</h5>
<ul>
<li><b><code>event_shape</code></b>: <code>TensorShape</code>, possibly unknown.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.inversegammawithsoftplusalphabeta.is_continuous"><code id="InverseGammaWithSoftplusAlphaBeta.is_continuous">tf.contrib.distributions.InverseGammaWithSoftplusAlphaBeta.is_continuous</code></h4>
<hr />
<h4 id="tf.contrib.distributions.inversegammawithsoftplusalphabeta.is_reparameterized"><code id="InverseGammaWithSoftplusAlphaBeta.is_reparameterized">tf.contrib.distributions.InverseGammaWithSoftplusAlphaBeta.is_reparameterized</code></h4>
<hr />
<h4 id="tf.contrib.distributions.inversegammawithsoftplusalphabeta.log_cdfvalue-namelog_cdf-condition_kwargs"><code id="InverseGammaWithSoftplusAlphaBeta.log_cdf">tf.contrib.distributions.InverseGammaWithSoftplusAlphaBeta.log_cdf(value, name='log_cdf', **condition_kwargs)</code></h4>
<p>Log cumulative distribution function.</p>
<p>Given random variable <code>X</code>, the cumulative distribution function <code>cdf</code> is:</p>
<pre><code>log_cdf(x) := Log[ P[X &lt;= x] ]</code></pre>
<p>Often, a numerical approximation can be used for <code>log_cdf(x)</code> that yields a more accurate answer than simply taking the logarithm of the <code>cdf</code> when <code>x &lt;&lt; -1</code>.</p>
<h5 id="args-251">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-287">Returns:</h5>
<ul>
<li><b><code>logcdf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.inversegammawithsoftplusalphabeta.log_pdfvalue-namelog_pdf-condition_kwargs"><code id="InverseGammaWithSoftplusAlphaBeta.log_pdf">tf.contrib.distributions.InverseGammaWithSoftplusAlphaBeta.log_pdf(value, name='log_pdf', **condition_kwargs)</code></h4>
<p>Log probability density function.</p>
<h5 id="args-252">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-288">Returns:</h5>
<ul>
<li><b><code>log_prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-88">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if not <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.inversegammawithsoftplusalphabeta.log_pmfvalue-namelog_pmf-condition_kwargs"><code id="InverseGammaWithSoftplusAlphaBeta.log_pmf">tf.contrib.distributions.InverseGammaWithSoftplusAlphaBeta.log_pmf(value, name='log_pmf', **condition_kwargs)</code></h4>
<p>Log probability mass function.</p>
<h5 id="args-253">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-289">Returns:</h5>
<ul>
<li><b><code>log_pmf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-89">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.inversegammawithsoftplusalphabeta.log_probvalue-namelog_prob-condition_kwargs"><code id="InverseGammaWithSoftplusAlphaBeta.log_prob">tf.contrib.distributions.InverseGammaWithSoftplusAlphaBeta.log_prob(value, name='log_prob', **condition_kwargs)</code></h4>
<p>Log probability density/mass function (depending on <code>is_continuous</code>).</p>
<h5 id="args-254">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-290">Returns:</h5>
<ul>
<li><b><code>log_prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.inversegammawithsoftplusalphabeta.log_survival_functionvalue-namelog_survival_function-condition_kwargs"><code id="InverseGammaWithSoftplusAlphaBeta.log_survival_function">tf.contrib.distributions.InverseGammaWithSoftplusAlphaBeta.log_survival_function(value, name='log_survival_function', **condition_kwargs)</code></h4>
<p>Log survival function.</p>
<p>Given random variable <code>X</code>, the survival function is defined:</p>
<pre><code>log_survival_function(x) = Log[ P[X &gt; x] ]
                         = Log[ 1 - P[X &lt;= x] ]
                         = Log[ 1 - cdf(x) ]</code></pre>
<p>Typically, different numerical approximations can be used for the log survival function, which are more accurate than <code>1 - cdf(x)</code> when <code>x &gt;&gt; 1</code>.</p>
<h5 id="args-255">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-291">Returns:</h5>
<p><code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.inversegammawithsoftplusalphabeta.meannamemean"><code id="InverseGammaWithSoftplusAlphaBeta.mean">tf.contrib.distributions.InverseGammaWithSoftplusAlphaBeta.mean(name='mean')</code></h4>
<p>Mean.</p>
<p>Additional documentation from <code>InverseGamma</code>:</p>
<p>The mean of an inverse gamma distribution is <code>beta / (alpha - 1)</code>, when <code>alpha &gt; 1</code>, and <code>NaN</code> otherwise. If <code>self.allow_nan_stats</code> is <code>False</code>, an exception will be raised rather than returning <code>NaN</code></p>
<hr />
<h4 id="tf.contrib.distributions.inversegammawithsoftplusalphabeta.modenamemode"><code id="InverseGammaWithSoftplusAlphaBeta.mode">tf.contrib.distributions.InverseGammaWithSoftplusAlphaBeta.mode(name='mode')</code></h4>
<p>Mode.</p>
<p>Additional documentation from <code>InverseGamma</code>:</p>
<p>The mode of an inverse gamma distribution is <code>beta / (alpha + 1)</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.inversegammawithsoftplusalphabeta.name"><code id="InverseGammaWithSoftplusAlphaBeta.name">tf.contrib.distributions.InverseGammaWithSoftplusAlphaBeta.name</code></h4>
<p>Name prepended to all ops created by this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.inversegammawithsoftplusalphabeta.param_shapescls-sample_shape-namedistributionparamshapes"><code id="InverseGammaWithSoftplusAlphaBeta.param_shapes">tf.contrib.distributions.InverseGammaWithSoftplusAlphaBeta.param_shapes(cls, sample_shape, name='DistributionParamShapes')</code></h4>
<p>Shapes of parameters given the desired shape of a call to <code>sample()</code>.</p>
<p>Subclasses should override static method <code>_param_shapes</code>.</p>
<h5 id="args-256">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: <code>Tensor</code> or python list/tuple. Desired shape of a call to <code>sample()</code>.</li>
<li><b><code>name</code></b>: name to prepend ops with.</li>
</ul>
<h5 id="returns-292">Returns:</h5>
<p><code>dict</code> of parameter name to <code>Tensor</code> shapes.</p>
<hr />
<h4 id="tf.contrib.distributions.inversegammawithsoftplusalphabeta.param_static_shapescls-sample_shape"><code id="InverseGammaWithSoftplusAlphaBeta.param_static_shapes">tf.contrib.distributions.InverseGammaWithSoftplusAlphaBeta.param_static_shapes(cls, sample_shape)</code></h4>
<p>param_shapes with static (i.e. TensorShape) shapes.</p>
<h5 id="args-257">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: <code>TensorShape</code> or python list/tuple. Desired shape of a call to <code>sample()</code>.</li>
</ul>
<h5 id="returns-293">Returns:</h5>
<p><code>dict</code> of parameter name to <code>TensorShape</code>.</p>
<h5 id="raises-90">Raises:</h5>
<ul>
<li><b><code>ValueError</code></b>: if <code>sample_shape</code> is a <code>TensorShape</code> and is not fully defined.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.inversegammawithsoftplusalphabeta.parameters"><code id="InverseGammaWithSoftplusAlphaBeta.parameters">tf.contrib.distributions.InverseGammaWithSoftplusAlphaBeta.parameters</code></h4>
<p>Dictionary of parameters used to instantiate this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.inversegammawithsoftplusalphabeta.pdfvalue-namepdf-condition_kwargs"><code id="InverseGammaWithSoftplusAlphaBeta.pdf">tf.contrib.distributions.InverseGammaWithSoftplusAlphaBeta.pdf(value, name='pdf', **condition_kwargs)</code></h4>
<p>Probability density function.</p>
<h5 id="args-258">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-294">Returns:</h5>
<ul>
<li><b><code>prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-91">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if not <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.inversegammawithsoftplusalphabeta.pmfvalue-namepmf-condition_kwargs"><code id="InverseGammaWithSoftplusAlphaBeta.pmf">tf.contrib.distributions.InverseGammaWithSoftplusAlphaBeta.pmf(value, name='pmf', **condition_kwargs)</code></h4>
<p>Probability mass function.</p>
<h5 id="args-259">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-295">Returns:</h5>
<ul>
<li><b><code>pmf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-92">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.inversegammawithsoftplusalphabeta.probvalue-nameprob-condition_kwargs"><code id="InverseGammaWithSoftplusAlphaBeta.prob">tf.contrib.distributions.InverseGammaWithSoftplusAlphaBeta.prob(value, name='prob', **condition_kwargs)</code></h4>
<p>Probability density/mass function (depending on <code>is_continuous</code>).</p>
<h5 id="args-260">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-296">Returns:</h5>
<ul>
<li><b><code>prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.inversegammawithsoftplusalphabeta.samplesample_shape-seednone-namesample-condition_kwargs"><code id="InverseGammaWithSoftplusAlphaBeta.sample">tf.contrib.distributions.InverseGammaWithSoftplusAlphaBeta.sample(sample_shape=(), seed=None, name='sample', **condition_kwargs)</code></h4>
<p>Generate samples of the specified shape.</p>
<p>Note that a call to <code>sample()</code> without arguments will generate a single sample.</p>
<h5 id="args-261">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: 0D or 1D <code>int32</code> <code>Tensor</code>. Shape of the generated samples.</li>
<li><b><code>seed</code></b>: Python integer seed for RNG</li>
<li><b><code>name</code></b>: name to give to the op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-297">Returns:</h5>
<ul>
<li><b><code>samples</code></b>: a <code>Tensor</code> with prepended dimensions <code>sample_shape</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.inversegammawithsoftplusalphabeta.sample_nn-seednone-namesample_n-condition_kwargs"><code id="InverseGammaWithSoftplusAlphaBeta.sample_n">tf.contrib.distributions.InverseGammaWithSoftplusAlphaBeta.sample_n(n, seed=None, name='sample_n', **condition_kwargs)</code></h4>
<p>Generate <code>n</code> samples.</p>
<p>Additional documentation from <code>InverseGamma</code>:</p>
<p>See the documentation for tf.random_gamma for more details.</p>
<h5 id="args-262">Args:</h5>
<ul>
<li><b><code>n</code></b>: <code>Scalar</code> <code>Tensor</code> of type <code>int32</code> or <code>int64</code>, the number of observations to sample.</li>
<li><b><code>seed</code></b>: Python integer seed for RNG</li>
<li><b><code>name</code></b>: name to give to the op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-298">Returns:</h5>
<ul>
<li><b><code>samples</code></b>: a <code>Tensor</code> with a prepended dimension (n,).</li>
</ul>
<h5 id="raises-93">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>n</code> is not an integer type.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.inversegammawithsoftplusalphabeta.stdnamestd"><code id="InverseGammaWithSoftplusAlphaBeta.std">tf.contrib.distributions.InverseGammaWithSoftplusAlphaBeta.std(name='std')</code></h4>
<p>Standard deviation.</p>
<hr />
<h4 id="tf.contrib.distributions.inversegammawithsoftplusalphabeta.survival_functionvalue-namesurvival_function-condition_kwargs"><code id="InverseGammaWithSoftplusAlphaBeta.survival_function">tf.contrib.distributions.InverseGammaWithSoftplusAlphaBeta.survival_function(value, name='survival_function', **condition_kwargs)</code></h4>
<p>Survival function.</p>
<p>Given random variable <code>X</code>, the survival function is defined:</p>
<pre><code>survival_function(x) = P[X &gt; x]
                     = 1 - P[X &lt;= x]
                     = 1 - cdf(x).</code></pre>
<h5 id="args-263">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-299">Returns:</h5>
<p>Tensor<code>of shape</code>sample_shape(x) + self.batch_shape<code>with values of type</code>self.dtype`.</p>
<hr />
<h4 id="tf.contrib.distributions.inversegammawithsoftplusalphabeta.validate_args"><code id="InverseGammaWithSoftplusAlphaBeta.validate_args">tf.contrib.distributions.InverseGammaWithSoftplusAlphaBeta.validate_args</code></h4>
<p>Python boolean indicated possibly expensive checks are enabled.</p>
<hr />
<h4 id="tf.contrib.distributions.inversegammawithsoftplusalphabeta.variancenamevariance"><code id="InverseGammaWithSoftplusAlphaBeta.variance">tf.contrib.distributions.InverseGammaWithSoftplusAlphaBeta.variance(name='variance')</code></h4>
<p>Variance.</p>
<p>Additional documentation from <code>InverseGamma</code>:</p>
<p>Variance for inverse gamma is defined only for <code>alpha &gt; 2</code>. If <code>self.allow_nan_stats</code> is <code>False</code>, an exception will be raised rather than returning <code>NaN</code>.</p>
<hr />
<h3 id="class-tf.contrib.distributions.laplace"><a name="//apple_ref/cpp/Class/Laplace" class="dashAnchor"></a><code id="Laplace">class tf.contrib.distributions.Laplace</code></h3>
<p>The Laplace distribution with location and scale &gt; 0 parameters.</p>
<h4 id="mathematical-details-2">Mathematical details</h4>
<p>The PDF of this distribution is:</p>
<p><code>f(x | mu, b, b &gt; 0) = 0.5 / b exp(-|x - mu| / b)</code></p>
<p>Note that the Laplace distribution can be thought of two exponential distributions spliced together &quot;back-to-back.&quot; - - -</p>
<h4 id="tf.contrib.distributions.laplace.__init__loc-scale-validate_argsfalse-allow_nan_statstrue-namelaplace"><code id="Laplace.__init__">tf.contrib.distributions.Laplace.__init__(loc, scale, validate_args=False, allow_nan_stats=True, name='Laplace')</code></h4>
<p>Construct Laplace distribution with parameters <code>loc</code> and <code>scale</code>.</p>
<p>The parameters <code>loc</code> and <code>scale</code> must be shaped in a way that supports broadcasting (e.g., <code>loc / scale</code> is a valid operation).</p>
<h5 id="args-264">Args:</h5>
<ul>
<li><b><code>loc</code></b>: Floating point tensor which characterizes the location (center) of the distribution.</li>
<li><b><code>scale</code></b>: Positive floating point tensor which characterizes the spread of the distribution.</li>
<li><b><code>validate_args</code></b>: <code>Boolean</code>, default <code>False</code>. Whether to validate input with asserts. If <code>validate_args</code> is <code>False</code>, and the inputs are invalid, correct behavior is not guaranteed.</li>
<li><b><code>allow_nan_stats</code></b>: <code>Boolean</code>, default <code>True</code>. If <code>False</code>, raise an exception if a statistic (e.g. mean/mode/etc...) is undefined for any batch member. If <code>True</code>, batch members with valid parameters leading to undefined statistics will return NaN for this statistic.</li>
<li><b><code>name</code></b>: The name to give Ops created by the initializer.</li>
</ul>
<h5 id="raises-94">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>loc</code> and <code>scale</code> are of different dtype.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.laplace.allow_nan_stats"><code id="Laplace.allow_nan_stats">tf.contrib.distributions.Laplace.allow_nan_stats</code></h4>
<p>Python boolean describing behavior when a stat is undefined.</p>
<p>Stats return +/- infinity when it makes sense. E.g., the variance of a Cauchy distribution is infinity. However, sometimes the statistic is undefined, e.g., if a distribution's pdf does not achieve a maximum within the support of the distribution, the mode is undefined. If the mean is undefined, then by definition the variance is undefined. E.g. the mean for Student's T for df = 1 is undefined (no clear way to say it is either + or - infinity), so the variance = E[(X - mean)^2] is also undefined.</p>
<h5 id="returns-300">Returns:</h5>
<ul>
<li><b><code>allow_nan_stats</code></b>: Python boolean.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.laplace.batch_shapenamebatch_shape"><code id="Laplace.batch_shape">tf.contrib.distributions.Laplace.batch_shape(name='batch_shape')</code></h4>
<p>Shape of a single sample from a single event index as a 1-D <code>Tensor</code>.</p>
<p>The product of the dimensions of the <code>batch_shape</code> is the number of independent distributions of this kind the instance represents.</p>
<h5 id="args-265">Args:</h5>
<ul>
<li><b><code>name</code></b>: name to give to the op</li>
</ul>
<h5 id="returns-301">Returns:</h5>
<ul>
<li><b><code>batch_shape</code></b>: <code>Tensor</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.laplace.cdfvalue-namecdf-condition_kwargs"><code id="Laplace.cdf">tf.contrib.distributions.Laplace.cdf(value, name='cdf', **condition_kwargs)</code></h4>
<p>Cumulative distribution function.</p>
<p>Given random variable <code>X</code>, the cumulative distribution function <code>cdf</code> is:</p>
<pre><code>cdf(x) := P[X &lt;= x]</code></pre>
<h5 id="args-266">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-302">Returns:</h5>
<ul>
<li><b><code>cdf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.laplace.copyoverride_parameters_kwargs"><code id="Laplace.copy">tf.contrib.distributions.Laplace.copy(**override_parameters_kwargs)</code></h4>
<p>Creates a deep copy of the distribution.</p>
<p>Note: the copy distribution may continue to depend on the original intialization arguments.</p>
<h5 id="args-267">Args:</h5>
<ul>
<li><b><code>**override_parameters_kwargs</code></b>: String/value dictionary of initialization arguments to override with new values.</li>
</ul>
<h5 id="returns-303">Returns:</h5>
<ul>
<li><b><code>distribution</code></b>: A new instance of <code>type(self)</code> intitialized from the union of self.parameters and override_parameters_kwargs, i.e., <code>dict(self.parameters, **override_parameters_kwargs)</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.laplace.dtype"><code id="Laplace.dtype">tf.contrib.distributions.Laplace.dtype</code></h4>
<p>The <code>DType</code> of <code>Tensor</code>s handled by this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.laplace.entropynameentropy"><code id="Laplace.entropy">tf.contrib.distributions.Laplace.entropy(name='entropy')</code></h4>
<p>Shannon entropy in nats.</p>
<hr />
<h4 id="tf.contrib.distributions.laplace.event_shapenameevent_shape"><code id="Laplace.event_shape">tf.contrib.distributions.Laplace.event_shape(name='event_shape')</code></h4>
<p>Shape of a single sample from a single batch as a 1-D int32 <code>Tensor</code>.</p>
<h5 id="args-268">Args:</h5>
<ul>
<li><b><code>name</code></b>: name to give to the op</li>
</ul>
<h5 id="returns-304">Returns:</h5>
<ul>
<li><b><code>event_shape</code></b>: <code>Tensor</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.laplace.get_batch_shape"><code id="Laplace.get_batch_shape">tf.contrib.distributions.Laplace.get_batch_shape()</code></h4>
<p>Shape of a single sample from a single event index as a <code>TensorShape</code>.</p>
<p>Same meaning as <code>batch_shape</code>. May be only partially defined.</p>
<h5 id="returns-305">Returns:</h5>
<ul>
<li><b><code>batch_shape</code></b>: <code>TensorShape</code>, possibly unknown.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.laplace.get_event_shape"><code id="Laplace.get_event_shape">tf.contrib.distributions.Laplace.get_event_shape()</code></h4>
<p>Shape of a single sample from a single batch as a <code>TensorShape</code>.</p>
<p>Same meaning as <code>event_shape</code>. May be only partially defined.</p>
<h5 id="returns-306">Returns:</h5>
<ul>
<li><b><code>event_shape</code></b>: <code>TensorShape</code>, possibly unknown.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.laplace.is_continuous"><code id="Laplace.is_continuous">tf.contrib.distributions.Laplace.is_continuous</code></h4>
<hr />
<h4 id="tf.contrib.distributions.laplace.is_reparameterized"><code id="Laplace.is_reparameterized">tf.contrib.distributions.Laplace.is_reparameterized</code></h4>
<hr />
<h4 id="tf.contrib.distributions.laplace.loc"><code id="Laplace.loc">tf.contrib.distributions.Laplace.loc</code></h4>
<p>Distribution parameter for the location.</p>
<hr />
<h4 id="tf.contrib.distributions.laplace.log_cdfvalue-namelog_cdf-condition_kwargs"><code id="Laplace.log_cdf">tf.contrib.distributions.Laplace.log_cdf(value, name='log_cdf', **condition_kwargs)</code></h4>
<p>Log cumulative distribution function.</p>
<p>Given random variable <code>X</code>, the cumulative distribution function <code>cdf</code> is:</p>
<pre><code>log_cdf(x) := Log[ P[X &lt;= x] ]</code></pre>
<p>Often, a numerical approximation can be used for <code>log_cdf(x)</code> that yields a more accurate answer than simply taking the logarithm of the <code>cdf</code> when <code>x &lt;&lt; -1</code>.</p>
<h5 id="args-269">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-307">Returns:</h5>
<ul>
<li><b><code>logcdf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.laplace.log_pdfvalue-namelog_pdf-condition_kwargs"><code id="Laplace.log_pdf">tf.contrib.distributions.Laplace.log_pdf(value, name='log_pdf', **condition_kwargs)</code></h4>
<p>Log probability density function.</p>
<h5 id="args-270">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-308">Returns:</h5>
<ul>
<li><b><code>log_prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-95">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if not <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.laplace.log_pmfvalue-namelog_pmf-condition_kwargs"><code id="Laplace.log_pmf">tf.contrib.distributions.Laplace.log_pmf(value, name='log_pmf', **condition_kwargs)</code></h4>
<p>Log probability mass function.</p>
<h5 id="args-271">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-309">Returns:</h5>
<ul>
<li><b><code>log_pmf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-96">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.laplace.log_probvalue-namelog_prob-condition_kwargs"><code id="Laplace.log_prob">tf.contrib.distributions.Laplace.log_prob(value, name='log_prob', **condition_kwargs)</code></h4>
<p>Log probability density/mass function (depending on <code>is_continuous</code>).</p>
<h5 id="args-272">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-310">Returns:</h5>
<ul>
<li><b><code>log_prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.laplace.log_survival_functionvalue-namelog_survival_function-condition_kwargs"><code id="Laplace.log_survival_function">tf.contrib.distributions.Laplace.log_survival_function(value, name='log_survival_function', **condition_kwargs)</code></h4>
<p>Log survival function.</p>
<p>Given random variable <code>X</code>, the survival function is defined:</p>
<pre><code>log_survival_function(x) = Log[ P[X &gt; x] ]
                         = Log[ 1 - P[X &lt;= x] ]
                         = Log[ 1 - cdf(x) ]</code></pre>
<p>Typically, different numerical approximations can be used for the log survival function, which are more accurate than <code>1 - cdf(x)</code> when <code>x &gt;&gt; 1</code>.</p>
<h5 id="args-273">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-311">Returns:</h5>
<p><code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.laplace.meannamemean"><code id="Laplace.mean">tf.contrib.distributions.Laplace.mean(name='mean')</code></h4>
<p>Mean.</p>
<hr />
<h4 id="tf.contrib.distributions.laplace.modenamemode"><code id="Laplace.mode">tf.contrib.distributions.Laplace.mode(name='mode')</code></h4>
<p>Mode.</p>
<hr />
<h4 id="tf.contrib.distributions.laplace.name"><code id="Laplace.name">tf.contrib.distributions.Laplace.name</code></h4>
<p>Name prepended to all ops created by this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.laplace.param_shapescls-sample_shape-namedistributionparamshapes"><code id="Laplace.param_shapes">tf.contrib.distributions.Laplace.param_shapes(cls, sample_shape, name='DistributionParamShapes')</code></h4>
<p>Shapes of parameters given the desired shape of a call to <code>sample()</code>.</p>
<p>Subclasses should override static method <code>_param_shapes</code>.</p>
<h5 id="args-274">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: <code>Tensor</code> or python list/tuple. Desired shape of a call to <code>sample()</code>.</li>
<li><b><code>name</code></b>: name to prepend ops with.</li>
</ul>
<h5 id="returns-312">Returns:</h5>
<p><code>dict</code> of parameter name to <code>Tensor</code> shapes.</p>
<hr />
<h4 id="tf.contrib.distributions.laplace.param_static_shapescls-sample_shape"><code id="Laplace.param_static_shapes">tf.contrib.distributions.Laplace.param_static_shapes(cls, sample_shape)</code></h4>
<p>param_shapes with static (i.e. TensorShape) shapes.</p>
<h5 id="args-275">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: <code>TensorShape</code> or python list/tuple. Desired shape of a call to <code>sample()</code>.</li>
</ul>
<h5 id="returns-313">Returns:</h5>
<p><code>dict</code> of parameter name to <code>TensorShape</code>.</p>
<h5 id="raises-97">Raises:</h5>
<ul>
<li><b><code>ValueError</code></b>: if <code>sample_shape</code> is a <code>TensorShape</code> and is not fully defined.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.laplace.parameters"><code id="Laplace.parameters">tf.contrib.distributions.Laplace.parameters</code></h4>
<p>Dictionary of parameters used to instantiate this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.laplace.pdfvalue-namepdf-condition_kwargs"><code id="Laplace.pdf">tf.contrib.distributions.Laplace.pdf(value, name='pdf', **condition_kwargs)</code></h4>
<p>Probability density function.</p>
<h5 id="args-276">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-314">Returns:</h5>
<ul>
<li><b><code>prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-98">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if not <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.laplace.pmfvalue-namepmf-condition_kwargs"><code id="Laplace.pmf">tf.contrib.distributions.Laplace.pmf(value, name='pmf', **condition_kwargs)</code></h4>
<p>Probability mass function.</p>
<h5 id="args-277">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-315">Returns:</h5>
<ul>
<li><b><code>pmf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-99">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.laplace.probvalue-nameprob-condition_kwargs"><code id="Laplace.prob">tf.contrib.distributions.Laplace.prob(value, name='prob', **condition_kwargs)</code></h4>
<p>Probability density/mass function (depending on <code>is_continuous</code>).</p>
<h5 id="args-278">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-316">Returns:</h5>
<ul>
<li><b><code>prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.laplace.samplesample_shape-seednone-namesample-condition_kwargs"><code id="Laplace.sample">tf.contrib.distributions.Laplace.sample(sample_shape=(), seed=None, name='sample', **condition_kwargs)</code></h4>
<p>Generate samples of the specified shape.</p>
<p>Note that a call to <code>sample()</code> without arguments will generate a single sample.</p>
<h5 id="args-279">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: 0D or 1D <code>int32</code> <code>Tensor</code>. Shape of the generated samples.</li>
<li><b><code>seed</code></b>: Python integer seed for RNG</li>
<li><b><code>name</code></b>: name to give to the op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-317">Returns:</h5>
<ul>
<li><b><code>samples</code></b>: a <code>Tensor</code> with prepended dimensions <code>sample_shape</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.laplace.sample_nn-seednone-namesample_n-condition_kwargs"><code id="Laplace.sample_n">tf.contrib.distributions.Laplace.sample_n(n, seed=None, name='sample_n', **condition_kwargs)</code></h4>
<p>Generate <code>n</code> samples.</p>
<h5 id="args-280">Args:</h5>
<ul>
<li><b><code>n</code></b>: <code>Scalar</code> <code>Tensor</code> of type <code>int32</code> or <code>int64</code>, the number of observations to sample.</li>
<li><b><code>seed</code></b>: Python integer seed for RNG</li>
<li><b><code>name</code></b>: name to give to the op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-318">Returns:</h5>
<ul>
<li><b><code>samples</code></b>: a <code>Tensor</code> with a prepended dimension (n,).</li>
</ul>
<h5 id="raises-100">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>n</code> is not an integer type.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.laplace.scale"><code id="Laplace.scale">tf.contrib.distributions.Laplace.scale</code></h4>
<p>Distribution parameter for scale.</p>
<hr />
<h4 id="tf.contrib.distributions.laplace.stdnamestd"><code id="Laplace.std">tf.contrib.distributions.Laplace.std(name='std')</code></h4>
<p>Standard deviation.</p>
<hr />
<h4 id="tf.contrib.distributions.laplace.survival_functionvalue-namesurvival_function-condition_kwargs"><code id="Laplace.survival_function">tf.contrib.distributions.Laplace.survival_function(value, name='survival_function', **condition_kwargs)</code></h4>
<p>Survival function.</p>
<p>Given random variable <code>X</code>, the survival function is defined:</p>
<pre><code>survival_function(x) = P[X &gt; x]
                     = 1 - P[X &lt;= x]
                     = 1 - cdf(x).</code></pre>
<h5 id="args-281">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-319">Returns:</h5>
<p>Tensor<code>of shape</code>sample_shape(x) + self.batch_shape<code>with values of type</code>self.dtype`.</p>
<hr />
<h4 id="tf.contrib.distributions.laplace.validate_args"><code id="Laplace.validate_args">tf.contrib.distributions.Laplace.validate_args</code></h4>
<p>Python boolean indicated possibly expensive checks are enabled.</p>
<hr />
<h4 id="tf.contrib.distributions.laplace.variancenamevariance"><code id="Laplace.variance">tf.contrib.distributions.Laplace.variance(name='variance')</code></h4>
<p>Variance.</p>
<hr />
<h3 id="class-tf.contrib.distributions.laplacewithsoftplusscale"><a name="//apple_ref/cpp/Class/LaplaceWithSoftplusScale" class="dashAnchor"></a><code id="LaplaceWithSoftplusScale">class tf.contrib.distributions.LaplaceWithSoftplusScale</code></h3>
<p>Laplace with softplus applied to <code>scale</code>. - - -</p>
<h4 id="tf.contrib.distributions.laplacewithsoftplusscale.__init__loc-scale-validate_argsfalse-allow_nan_statstrue-namelaplacewithsoftplusscale"><code id="LaplaceWithSoftplusScale.__init__">tf.contrib.distributions.LaplaceWithSoftplusScale.__init__(loc, scale, validate_args=False, allow_nan_stats=True, name='LaplaceWithSoftplusScale')</code></h4>
<hr />
<h4 id="tf.contrib.distributions.laplacewithsoftplusscale.allow_nan_stats"><code id="LaplaceWithSoftplusScale.allow_nan_stats">tf.contrib.distributions.LaplaceWithSoftplusScale.allow_nan_stats</code></h4>
<p>Python boolean describing behavior when a stat is undefined.</p>
<p>Stats return +/- infinity when it makes sense. E.g., the variance of a Cauchy distribution is infinity. However, sometimes the statistic is undefined, e.g., if a distribution's pdf does not achieve a maximum within the support of the distribution, the mode is undefined. If the mean is undefined, then by definition the variance is undefined. E.g. the mean for Student's T for df = 1 is undefined (no clear way to say it is either + or - infinity), so the variance = E[(X - mean)^2] is also undefined.</p>
<h5 id="returns-320">Returns:</h5>
<ul>
<li><b><code>allow_nan_stats</code></b>: Python boolean.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.laplacewithsoftplusscale.batch_shapenamebatch_shape"><code id="LaplaceWithSoftplusScale.batch_shape">tf.contrib.distributions.LaplaceWithSoftplusScale.batch_shape(name='batch_shape')</code></h4>
<p>Shape of a single sample from a single event index as a 1-D <code>Tensor</code>.</p>
<p>The product of the dimensions of the <code>batch_shape</code> is the number of independent distributions of this kind the instance represents.</p>
<h5 id="args-282">Args:</h5>
<ul>
<li><b><code>name</code></b>: name to give to the op</li>
</ul>
<h5 id="returns-321">Returns:</h5>
<ul>
<li><b><code>batch_shape</code></b>: <code>Tensor</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.laplacewithsoftplusscale.cdfvalue-namecdf-condition_kwargs"><code id="LaplaceWithSoftplusScale.cdf">tf.contrib.distributions.LaplaceWithSoftplusScale.cdf(value, name='cdf', **condition_kwargs)</code></h4>
<p>Cumulative distribution function.</p>
<p>Given random variable <code>X</code>, the cumulative distribution function <code>cdf</code> is:</p>
<pre><code>cdf(x) := P[X &lt;= x]</code></pre>
<h5 id="args-283">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-322">Returns:</h5>
<ul>
<li><b><code>cdf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.laplacewithsoftplusscale.copyoverride_parameters_kwargs"><code id="LaplaceWithSoftplusScale.copy">tf.contrib.distributions.LaplaceWithSoftplusScale.copy(**override_parameters_kwargs)</code></h4>
<p>Creates a deep copy of the distribution.</p>
<p>Note: the copy distribution may continue to depend on the original intialization arguments.</p>
<h5 id="args-284">Args:</h5>
<ul>
<li><b><code>**override_parameters_kwargs</code></b>: String/value dictionary of initialization arguments to override with new values.</li>
</ul>
<h5 id="returns-323">Returns:</h5>
<ul>
<li><b><code>distribution</code></b>: A new instance of <code>type(self)</code> intitialized from the union of self.parameters and override_parameters_kwargs, i.e., <code>dict(self.parameters, **override_parameters_kwargs)</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.laplacewithsoftplusscale.dtype"><code id="LaplaceWithSoftplusScale.dtype">tf.contrib.distributions.LaplaceWithSoftplusScale.dtype</code></h4>
<p>The <code>DType</code> of <code>Tensor</code>s handled by this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.laplacewithsoftplusscale.entropynameentropy"><code id="LaplaceWithSoftplusScale.entropy">tf.contrib.distributions.LaplaceWithSoftplusScale.entropy(name='entropy')</code></h4>
<p>Shannon entropy in nats.</p>
<hr />
<h4 id="tf.contrib.distributions.laplacewithsoftplusscale.event_shapenameevent_shape"><code id="LaplaceWithSoftplusScale.event_shape">tf.contrib.distributions.LaplaceWithSoftplusScale.event_shape(name='event_shape')</code></h4>
<p>Shape of a single sample from a single batch as a 1-D int32 <code>Tensor</code>.</p>
<h5 id="args-285">Args:</h5>
<ul>
<li><b><code>name</code></b>: name to give to the op</li>
</ul>
<h5 id="returns-324">Returns:</h5>
<ul>
<li><b><code>event_shape</code></b>: <code>Tensor</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.laplacewithsoftplusscale.get_batch_shape"><code id="LaplaceWithSoftplusScale.get_batch_shape">tf.contrib.distributions.LaplaceWithSoftplusScale.get_batch_shape()</code></h4>
<p>Shape of a single sample from a single event index as a <code>TensorShape</code>.</p>
<p>Same meaning as <code>batch_shape</code>. May be only partially defined.</p>
<h5 id="returns-325">Returns:</h5>
<ul>
<li><b><code>batch_shape</code></b>: <code>TensorShape</code>, possibly unknown.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.laplacewithsoftplusscale.get_event_shape"><code id="LaplaceWithSoftplusScale.get_event_shape">tf.contrib.distributions.LaplaceWithSoftplusScale.get_event_shape()</code></h4>
<p>Shape of a single sample from a single batch as a <code>TensorShape</code>.</p>
<p>Same meaning as <code>event_shape</code>. May be only partially defined.</p>
<h5 id="returns-326">Returns:</h5>
<ul>
<li><b><code>event_shape</code></b>: <code>TensorShape</code>, possibly unknown.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.laplacewithsoftplusscale.is_continuous"><code id="LaplaceWithSoftplusScale.is_continuous">tf.contrib.distributions.LaplaceWithSoftplusScale.is_continuous</code></h4>
<hr />
<h4 id="tf.contrib.distributions.laplacewithsoftplusscale.is_reparameterized"><code id="LaplaceWithSoftplusScale.is_reparameterized">tf.contrib.distributions.LaplaceWithSoftplusScale.is_reparameterized</code></h4>
<hr />
<h4 id="tf.contrib.distributions.laplacewithsoftplusscale.loc"><code id="LaplaceWithSoftplusScale.loc">tf.contrib.distributions.LaplaceWithSoftplusScale.loc</code></h4>
<p>Distribution parameter for the location.</p>
<hr />
<h4 id="tf.contrib.distributions.laplacewithsoftplusscale.log_cdfvalue-namelog_cdf-condition_kwargs"><code id="LaplaceWithSoftplusScale.log_cdf">tf.contrib.distributions.LaplaceWithSoftplusScale.log_cdf(value, name='log_cdf', **condition_kwargs)</code></h4>
<p>Log cumulative distribution function.</p>
<p>Given random variable <code>X</code>, the cumulative distribution function <code>cdf</code> is:</p>
<pre><code>log_cdf(x) := Log[ P[X &lt;= x] ]</code></pre>
<p>Often, a numerical approximation can be used for <code>log_cdf(x)</code> that yields a more accurate answer than simply taking the logarithm of the <code>cdf</code> when <code>x &lt;&lt; -1</code>.</p>
<h5 id="args-286">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-327">Returns:</h5>
<ul>
<li><b><code>logcdf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.laplacewithsoftplusscale.log_pdfvalue-namelog_pdf-condition_kwargs"><code id="LaplaceWithSoftplusScale.log_pdf">tf.contrib.distributions.LaplaceWithSoftplusScale.log_pdf(value, name='log_pdf', **condition_kwargs)</code></h4>
<p>Log probability density function.</p>
<h5 id="args-287">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-328">Returns:</h5>
<ul>
<li><b><code>log_prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-101">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if not <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.laplacewithsoftplusscale.log_pmfvalue-namelog_pmf-condition_kwargs"><code id="LaplaceWithSoftplusScale.log_pmf">tf.contrib.distributions.LaplaceWithSoftplusScale.log_pmf(value, name='log_pmf', **condition_kwargs)</code></h4>
<p>Log probability mass function.</p>
<h5 id="args-288">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-329">Returns:</h5>
<ul>
<li><b><code>log_pmf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-102">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.laplacewithsoftplusscale.log_probvalue-namelog_prob-condition_kwargs"><code id="LaplaceWithSoftplusScale.log_prob">tf.contrib.distributions.LaplaceWithSoftplusScale.log_prob(value, name='log_prob', **condition_kwargs)</code></h4>
<p>Log probability density/mass function (depending on <code>is_continuous</code>).</p>
<h5 id="args-289">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-330">Returns:</h5>
<ul>
<li><b><code>log_prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.laplacewithsoftplusscale.log_survival_functionvalue-namelog_survival_function-condition_kwargs"><code id="LaplaceWithSoftplusScale.log_survival_function">tf.contrib.distributions.LaplaceWithSoftplusScale.log_survival_function(value, name='log_survival_function', **condition_kwargs)</code></h4>
<p>Log survival function.</p>
<p>Given random variable <code>X</code>, the survival function is defined:</p>
<pre><code>log_survival_function(x) = Log[ P[X &gt; x] ]
                         = Log[ 1 - P[X &lt;= x] ]
                         = Log[ 1 - cdf(x) ]</code></pre>
<p>Typically, different numerical approximations can be used for the log survival function, which are more accurate than <code>1 - cdf(x)</code> when <code>x &gt;&gt; 1</code>.</p>
<h5 id="args-290">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-331">Returns:</h5>
<p><code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.laplacewithsoftplusscale.meannamemean"><code id="LaplaceWithSoftplusScale.mean">tf.contrib.distributions.LaplaceWithSoftplusScale.mean(name='mean')</code></h4>
<p>Mean.</p>
<hr />
<h4 id="tf.contrib.distributions.laplacewithsoftplusscale.modenamemode"><code id="LaplaceWithSoftplusScale.mode">tf.contrib.distributions.LaplaceWithSoftplusScale.mode(name='mode')</code></h4>
<p>Mode.</p>
<hr />
<h4 id="tf.contrib.distributions.laplacewithsoftplusscale.name"><code id="LaplaceWithSoftplusScale.name">tf.contrib.distributions.LaplaceWithSoftplusScale.name</code></h4>
<p>Name prepended to all ops created by this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.laplacewithsoftplusscale.param_shapescls-sample_shape-namedistributionparamshapes"><code id="LaplaceWithSoftplusScale.param_shapes">tf.contrib.distributions.LaplaceWithSoftplusScale.param_shapes(cls, sample_shape, name='DistributionParamShapes')</code></h4>
<p>Shapes of parameters given the desired shape of a call to <code>sample()</code>.</p>
<p>Subclasses should override static method <code>_param_shapes</code>.</p>
<h5 id="args-291">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: <code>Tensor</code> or python list/tuple. Desired shape of a call to <code>sample()</code>.</li>
<li><b><code>name</code></b>: name to prepend ops with.</li>
</ul>
<h5 id="returns-332">Returns:</h5>
<p><code>dict</code> of parameter name to <code>Tensor</code> shapes.</p>
<hr />
<h4 id="tf.contrib.distributions.laplacewithsoftplusscale.param_static_shapescls-sample_shape"><code id="LaplaceWithSoftplusScale.param_static_shapes">tf.contrib.distributions.LaplaceWithSoftplusScale.param_static_shapes(cls, sample_shape)</code></h4>
<p>param_shapes with static (i.e. TensorShape) shapes.</p>
<h5 id="args-292">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: <code>TensorShape</code> or python list/tuple. Desired shape of a call to <code>sample()</code>.</li>
</ul>
<h5 id="returns-333">Returns:</h5>
<p><code>dict</code> of parameter name to <code>TensorShape</code>.</p>
<h5 id="raises-103">Raises:</h5>
<ul>
<li><b><code>ValueError</code></b>: if <code>sample_shape</code> is a <code>TensorShape</code> and is not fully defined.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.laplacewithsoftplusscale.parameters"><code id="LaplaceWithSoftplusScale.parameters">tf.contrib.distributions.LaplaceWithSoftplusScale.parameters</code></h4>
<p>Dictionary of parameters used to instantiate this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.laplacewithsoftplusscale.pdfvalue-namepdf-condition_kwargs"><code id="LaplaceWithSoftplusScale.pdf">tf.contrib.distributions.LaplaceWithSoftplusScale.pdf(value, name='pdf', **condition_kwargs)</code></h4>
<p>Probability density function.</p>
<h5 id="args-293">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-334">Returns:</h5>
<ul>
<li><b><code>prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-104">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if not <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.laplacewithsoftplusscale.pmfvalue-namepmf-condition_kwargs"><code id="LaplaceWithSoftplusScale.pmf">tf.contrib.distributions.LaplaceWithSoftplusScale.pmf(value, name='pmf', **condition_kwargs)</code></h4>
<p>Probability mass function.</p>
<h5 id="args-294">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-335">Returns:</h5>
<ul>
<li><b><code>pmf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-105">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.laplacewithsoftplusscale.probvalue-nameprob-condition_kwargs"><code id="LaplaceWithSoftplusScale.prob">tf.contrib.distributions.LaplaceWithSoftplusScale.prob(value, name='prob', **condition_kwargs)</code></h4>
<p>Probability density/mass function (depending on <code>is_continuous</code>).</p>
<h5 id="args-295">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-336">Returns:</h5>
<ul>
<li><b><code>prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.laplacewithsoftplusscale.samplesample_shape-seednone-namesample-condition_kwargs"><code id="LaplaceWithSoftplusScale.sample">tf.contrib.distributions.LaplaceWithSoftplusScale.sample(sample_shape=(), seed=None, name='sample', **condition_kwargs)</code></h4>
<p>Generate samples of the specified shape.</p>
<p>Note that a call to <code>sample()</code> without arguments will generate a single sample.</p>
<h5 id="args-296">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: 0D or 1D <code>int32</code> <code>Tensor</code>. Shape of the generated samples.</li>
<li><b><code>seed</code></b>: Python integer seed for RNG</li>
<li><b><code>name</code></b>: name to give to the op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-337">Returns:</h5>
<ul>
<li><b><code>samples</code></b>: a <code>Tensor</code> with prepended dimensions <code>sample_shape</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.laplacewithsoftplusscale.sample_nn-seednone-namesample_n-condition_kwargs"><code id="LaplaceWithSoftplusScale.sample_n">tf.contrib.distributions.LaplaceWithSoftplusScale.sample_n(n, seed=None, name='sample_n', **condition_kwargs)</code></h4>
<p>Generate <code>n</code> samples.</p>
<h5 id="args-297">Args:</h5>
<ul>
<li><b><code>n</code></b>: <code>Scalar</code> <code>Tensor</code> of type <code>int32</code> or <code>int64</code>, the number of observations to sample.</li>
<li><b><code>seed</code></b>: Python integer seed for RNG</li>
<li><b><code>name</code></b>: name to give to the op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-338">Returns:</h5>
<ul>
<li><b><code>samples</code></b>: a <code>Tensor</code> with a prepended dimension (n,).</li>
</ul>
<h5 id="raises-106">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>n</code> is not an integer type.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.laplacewithsoftplusscale.scale"><code id="LaplaceWithSoftplusScale.scale">tf.contrib.distributions.LaplaceWithSoftplusScale.scale</code></h4>
<p>Distribution parameter for scale.</p>
<hr />
<h4 id="tf.contrib.distributions.laplacewithsoftplusscale.stdnamestd"><code id="LaplaceWithSoftplusScale.std">tf.contrib.distributions.LaplaceWithSoftplusScale.std(name='std')</code></h4>
<p>Standard deviation.</p>
<hr />
<h4 id="tf.contrib.distributions.laplacewithsoftplusscale.survival_functionvalue-namesurvival_function-condition_kwargs"><code id="LaplaceWithSoftplusScale.survival_function">tf.contrib.distributions.LaplaceWithSoftplusScale.survival_function(value, name='survival_function', **condition_kwargs)</code></h4>
<p>Survival function.</p>
<p>Given random variable <code>X</code>, the survival function is defined:</p>
<pre><code>survival_function(x) = P[X &gt; x]
                     = 1 - P[X &lt;= x]
                     = 1 - cdf(x).</code></pre>
<h5 id="args-298">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-339">Returns:</h5>
<p>Tensor<code>of shape</code>sample_shape(x) + self.batch_shape<code>with values of type</code>self.dtype`.</p>
<hr />
<h4 id="tf.contrib.distributions.laplacewithsoftplusscale.validate_args"><code id="LaplaceWithSoftplusScale.validate_args">tf.contrib.distributions.LaplaceWithSoftplusScale.validate_args</code></h4>
<p>Python boolean indicated possibly expensive checks are enabled.</p>
<hr />
<h4 id="tf.contrib.distributions.laplacewithsoftplusscale.variancenamevariance"><code id="LaplaceWithSoftplusScale.variance">tf.contrib.distributions.LaplaceWithSoftplusScale.variance(name='variance')</code></h4>
<p>Variance.</p>
<hr />
<h3 id="class-tf.contrib.distributions.normal"><a name="//apple_ref/cpp/Class/Normal" class="dashAnchor"></a><code id="Normal">class tf.contrib.distributions.Normal</code></h3>
<p>The scalar Normal distribution with mean and stddev parameters mu, sigma.</p>
<h4 id="mathematical-details-3">Mathematical details</h4>
<p>The PDF of this distribution is:</p>
<p><code>f(x) = sqrt(1/(2*pi*sigma^2)) exp(-(x-mu)^2/(2*sigma^2))</code></p>
<h4 id="examples-3">Examples</h4>
<p>Examples of initialization of one or a batch of distributions.</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="co"># Define a single scalar Normal distribution.</span>
dist <span class="op">=</span> tf.contrib.distributions.Normal(mu<span class="op">=</span><span class="dv">0</span>., sigma<span class="op">=</span><span class="dv">3</span>.)

<span class="co"># Evaluate the cdf at 1, returning a scalar.</span>
dist.cdf(<span class="dv">1</span>.)

<span class="co"># Define a batch of two scalar valued Normals.</span>
<span class="co"># The first has mean 1 and standard deviation 11, the second 2 and 22.</span>
dist <span class="op">=</span> tf.contrib.distributions.Normal(mu<span class="op">=</span>[<span class="dv">1</span>, <span class="dv">2</span>.], sigma<span class="op">=</span>[<span class="dv">11</span>, <span class="dv">22</span>.])

<span class="co"># Evaluate the pdf of the first distribution on 0, and the second on 1.5,</span>
<span class="co"># returning a length two tensor.</span>
dist.pdf([<span class="dv">0</span>, <span class="fl">1.5</span>])

<span class="co"># Get 3 samples, returning a 3 x 2 tensor.</span>
dist.sample([<span class="dv">3</span>])</code></pre></div>
<p>Arguments are broadcast when possible.</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="co"># Define a batch of two scalar valued Normals.</span>
<span class="co"># Both have mean 1, but different standard deviations.</span>
dist <span class="op">=</span> tf.contrib.distributions.Normal(mu<span class="op">=</span><span class="dv">1</span>., sigma<span class="op">=</span>[<span class="dv">11</span>, <span class="dv">22</span>.])

<span class="co"># Evaluate the pdf of both distributions on the same point, 3.0,</span>
<span class="co"># returning a length 2 tensor.</span>
dist.pdf(<span class="fl">3.0</span>)</code></pre></div>
<hr />
<h4 id="tf.contrib.distributions.normal.__init__mu-sigma-validate_argsfalse-allow_nan_statstrue-namenormal"><code id="Normal.__init__">tf.contrib.distributions.Normal.__init__(mu, sigma, validate_args=False, allow_nan_stats=True, name='Normal')</code></h4>
<p>Construct Normal distributions with mean and stddev <code>mu</code> and <code>sigma</code>.</p>
<p>The parameters <code>mu</code> and <code>sigma</code> must be shaped in a way that supports broadcasting (e.g. <code>mu + sigma</code> is a valid operation).</p>
<h5 id="args-299">Args:</h5>
<ul>
<li><b><code>mu</code></b>: Floating point tensor, the means of the distribution(s).</li>
<li><b><code>sigma</code></b>: Floating point tensor, the stddevs of the distribution(s). sigma must contain only positive values.</li>
<li><b><code>validate_args</code></b>: <code>Boolean</code>, default <code>False</code>. Whether to assert that <code>sigma &gt; 0</code>. If <code>validate_args</code> is <code>False</code>, correct output is not guaranteed when input is invalid.</li>
<li><b><code>allow_nan_stats</code></b>: <code>Boolean</code>, default <code>True</code>. If <code>False</code>, raise an exception if a statistic (e.g. mean/mode/etc...) is undefined for any batch member. If <code>True</code>, batch members with valid parameters leading to undefined statistics will return NaN for this statistic.</li>
<li><b><code>name</code></b>: The name to give Ops created by the initializer.</li>
</ul>
<h5 id="raises-107">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if mu and sigma are different dtypes.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.normal.allow_nan_stats"><code id="Normal.allow_nan_stats">tf.contrib.distributions.Normal.allow_nan_stats</code></h4>
<p>Python boolean describing behavior when a stat is undefined.</p>
<p>Stats return +/- infinity when it makes sense. E.g., the variance of a Cauchy distribution is infinity. However, sometimes the statistic is undefined, e.g., if a distribution's pdf does not achieve a maximum within the support of the distribution, the mode is undefined. If the mean is undefined, then by definition the variance is undefined. E.g. the mean for Student's T for df = 1 is undefined (no clear way to say it is either + or - infinity), so the variance = E[(X - mean)^2] is also undefined.</p>
<h5 id="returns-340">Returns:</h5>
<ul>
<li><b><code>allow_nan_stats</code></b>: Python boolean.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.normal.batch_shapenamebatch_shape"><code id="Normal.batch_shape">tf.contrib.distributions.Normal.batch_shape(name='batch_shape')</code></h4>
<p>Shape of a single sample from a single event index as a 1-D <code>Tensor</code>.</p>
<p>The product of the dimensions of the <code>batch_shape</code> is the number of independent distributions of this kind the instance represents.</p>
<h5 id="args-300">Args:</h5>
<ul>
<li><b><code>name</code></b>: name to give to the op</li>
</ul>
<h5 id="returns-341">Returns:</h5>
<ul>
<li><b><code>batch_shape</code></b>: <code>Tensor</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.normal.cdfvalue-namecdf-condition_kwargs"><code id="Normal.cdf">tf.contrib.distributions.Normal.cdf(value, name='cdf', **condition_kwargs)</code></h4>
<p>Cumulative distribution function.</p>
<p>Given random variable <code>X</code>, the cumulative distribution function <code>cdf</code> is:</p>
<pre><code>cdf(x) := P[X &lt;= x]</code></pre>
<h5 id="args-301">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-342">Returns:</h5>
<ul>
<li><b><code>cdf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.normal.copyoverride_parameters_kwargs"><code id="Normal.copy">tf.contrib.distributions.Normal.copy(**override_parameters_kwargs)</code></h4>
<p>Creates a deep copy of the distribution.</p>
<p>Note: the copy distribution may continue to depend on the original intialization arguments.</p>
<h5 id="args-302">Args:</h5>
<ul>
<li><b><code>**override_parameters_kwargs</code></b>: String/value dictionary of initialization arguments to override with new values.</li>
</ul>
<h5 id="returns-343">Returns:</h5>
<ul>
<li><b><code>distribution</code></b>: A new instance of <code>type(self)</code> intitialized from the union of self.parameters and override_parameters_kwargs, i.e., <code>dict(self.parameters, **override_parameters_kwargs)</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.normal.dtype"><code id="Normal.dtype">tf.contrib.distributions.Normal.dtype</code></h4>
<p>The <code>DType</code> of <code>Tensor</code>s handled by this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.normal.entropynameentropy"><code id="Normal.entropy">tf.contrib.distributions.Normal.entropy(name='entropy')</code></h4>
<p>Shannon entropy in nats.</p>
<hr />
<h4 id="tf.contrib.distributions.normal.event_shapenameevent_shape"><code id="Normal.event_shape">tf.contrib.distributions.Normal.event_shape(name='event_shape')</code></h4>
<p>Shape of a single sample from a single batch as a 1-D int32 <code>Tensor</code>.</p>
<h5 id="args-303">Args:</h5>
<ul>
<li><b><code>name</code></b>: name to give to the op</li>
</ul>
<h5 id="returns-344">Returns:</h5>
<ul>
<li><b><code>event_shape</code></b>: <code>Tensor</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.normal.get_batch_shape"><code id="Normal.get_batch_shape">tf.contrib.distributions.Normal.get_batch_shape()</code></h4>
<p>Shape of a single sample from a single event index as a <code>TensorShape</code>.</p>
<p>Same meaning as <code>batch_shape</code>. May be only partially defined.</p>
<h5 id="returns-345">Returns:</h5>
<ul>
<li><b><code>batch_shape</code></b>: <code>TensorShape</code>, possibly unknown.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.normal.get_event_shape"><code id="Normal.get_event_shape">tf.contrib.distributions.Normal.get_event_shape()</code></h4>
<p>Shape of a single sample from a single batch as a <code>TensorShape</code>.</p>
<p>Same meaning as <code>event_shape</code>. May be only partially defined.</p>
<h5 id="returns-346">Returns:</h5>
<ul>
<li><b><code>event_shape</code></b>: <code>TensorShape</code>, possibly unknown.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.normal.is_continuous"><code id="Normal.is_continuous">tf.contrib.distributions.Normal.is_continuous</code></h4>
<hr />
<h4 id="tf.contrib.distributions.normal.is_reparameterized"><code id="Normal.is_reparameterized">tf.contrib.distributions.Normal.is_reparameterized</code></h4>
<hr />
<h4 id="tf.contrib.distributions.normal.log_cdfvalue-namelog_cdf-condition_kwargs"><code id="Normal.log_cdf">tf.contrib.distributions.Normal.log_cdf(value, name='log_cdf', **condition_kwargs)</code></h4>
<p>Log cumulative distribution function.</p>
<p>Given random variable <code>X</code>, the cumulative distribution function <code>cdf</code> is:</p>
<pre><code>log_cdf(x) := Log[ P[X &lt;= x] ]</code></pre>
<p>Often, a numerical approximation can be used for <code>log_cdf(x)</code> that yields a more accurate answer than simply taking the logarithm of the <code>cdf</code> when <code>x &lt;&lt; -1</code>.</p>
<h5 id="args-304">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-347">Returns:</h5>
<ul>
<li><b><code>logcdf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.normal.log_pdfvalue-namelog_pdf-condition_kwargs"><code id="Normal.log_pdf">tf.contrib.distributions.Normal.log_pdf(value, name='log_pdf', **condition_kwargs)</code></h4>
<p>Log probability density function.</p>
<h5 id="args-305">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-348">Returns:</h5>
<ul>
<li><b><code>log_prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-108">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if not <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.normal.log_pmfvalue-namelog_pmf-condition_kwargs"><code id="Normal.log_pmf">tf.contrib.distributions.Normal.log_pmf(value, name='log_pmf', **condition_kwargs)</code></h4>
<p>Log probability mass function.</p>
<h5 id="args-306">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-349">Returns:</h5>
<ul>
<li><b><code>log_pmf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-109">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.normal.log_probvalue-namelog_prob-condition_kwargs"><code id="Normal.log_prob">tf.contrib.distributions.Normal.log_prob(value, name='log_prob', **condition_kwargs)</code></h4>
<p>Log probability density/mass function (depending on <code>is_continuous</code>).</p>
<h5 id="args-307">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-350">Returns:</h5>
<ul>
<li><b><code>log_prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.normal.log_survival_functionvalue-namelog_survival_function-condition_kwargs"><code id="Normal.log_survival_function">tf.contrib.distributions.Normal.log_survival_function(value, name='log_survival_function', **condition_kwargs)</code></h4>
<p>Log survival function.</p>
<p>Given random variable <code>X</code>, the survival function is defined:</p>
<pre><code>log_survival_function(x) = Log[ P[X &gt; x] ]
                         = Log[ 1 - P[X &lt;= x] ]
                         = Log[ 1 - cdf(x) ]</code></pre>
<p>Typically, different numerical approximations can be used for the log survival function, which are more accurate than <code>1 - cdf(x)</code> when <code>x &gt;&gt; 1</code>.</p>
<h5 id="args-308">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-351">Returns:</h5>
<p><code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.normal.meannamemean"><code id="Normal.mean">tf.contrib.distributions.Normal.mean(name='mean')</code></h4>
<p>Mean.</p>
<hr />
<h4 id="tf.contrib.distributions.normal.modenamemode"><code id="Normal.mode">tf.contrib.distributions.Normal.mode(name='mode')</code></h4>
<p>Mode.</p>
<hr />
<h4 id="tf.contrib.distributions.normal.mu"><code id="Normal.mu">tf.contrib.distributions.Normal.mu</code></h4>
<p>Distribution parameter for the mean.</p>
<hr />
<h4 id="tf.contrib.distributions.normal.name"><code id="Normal.name">tf.contrib.distributions.Normal.name</code></h4>
<p>Name prepended to all ops created by this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.normal.param_shapescls-sample_shape-namedistributionparamshapes"><code id="Normal.param_shapes">tf.contrib.distributions.Normal.param_shapes(cls, sample_shape, name='DistributionParamShapes')</code></h4>
<p>Shapes of parameters given the desired shape of a call to <code>sample()</code>.</p>
<p>Subclasses should override static method <code>_param_shapes</code>.</p>
<h5 id="args-309">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: <code>Tensor</code> or python list/tuple. Desired shape of a call to <code>sample()</code>.</li>
<li><b><code>name</code></b>: name to prepend ops with.</li>
</ul>
<h5 id="returns-352">Returns:</h5>
<p><code>dict</code> of parameter name to <code>Tensor</code> shapes.</p>
<hr />
<h4 id="tf.contrib.distributions.normal.param_static_shapescls-sample_shape"><code id="Normal.param_static_shapes">tf.contrib.distributions.Normal.param_static_shapes(cls, sample_shape)</code></h4>
<p>param_shapes with static (i.e. TensorShape) shapes.</p>
<h5 id="args-310">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: <code>TensorShape</code> or python list/tuple. Desired shape of a call to <code>sample()</code>.</li>
</ul>
<h5 id="returns-353">Returns:</h5>
<p><code>dict</code> of parameter name to <code>TensorShape</code>.</p>
<h5 id="raises-110">Raises:</h5>
<ul>
<li><b><code>ValueError</code></b>: if <code>sample_shape</code> is a <code>TensorShape</code> and is not fully defined.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.normal.parameters"><code id="Normal.parameters">tf.contrib.distributions.Normal.parameters</code></h4>
<p>Dictionary of parameters used to instantiate this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.normal.pdfvalue-namepdf-condition_kwargs"><code id="Normal.pdf">tf.contrib.distributions.Normal.pdf(value, name='pdf', **condition_kwargs)</code></h4>
<p>Probability density function.</p>
<h5 id="args-311">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-354">Returns:</h5>
<ul>
<li><b><code>prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-111">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if not <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.normal.pmfvalue-namepmf-condition_kwargs"><code id="Normal.pmf">tf.contrib.distributions.Normal.pmf(value, name='pmf', **condition_kwargs)</code></h4>
<p>Probability mass function.</p>
<h5 id="args-312">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-355">Returns:</h5>
<ul>
<li><b><code>pmf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-112">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.normal.probvalue-nameprob-condition_kwargs"><code id="Normal.prob">tf.contrib.distributions.Normal.prob(value, name='prob', **condition_kwargs)</code></h4>
<p>Probability density/mass function (depending on <code>is_continuous</code>).</p>
<h5 id="args-313">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-356">Returns:</h5>
<ul>
<li><b><code>prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.normal.samplesample_shape-seednone-namesample-condition_kwargs"><code id="Normal.sample">tf.contrib.distributions.Normal.sample(sample_shape=(), seed=None, name='sample', **condition_kwargs)</code></h4>
<p>Generate samples of the specified shape.</p>
<p>Note that a call to <code>sample()</code> without arguments will generate a single sample.</p>
<h5 id="args-314">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: 0D or 1D <code>int32</code> <code>Tensor</code>. Shape of the generated samples.</li>
<li><b><code>seed</code></b>: Python integer seed for RNG</li>
<li><b><code>name</code></b>: name to give to the op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-357">Returns:</h5>
<ul>
<li><b><code>samples</code></b>: a <code>Tensor</code> with prepended dimensions <code>sample_shape</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.normal.sample_nn-seednone-namesample_n-condition_kwargs"><code id="Normal.sample_n">tf.contrib.distributions.Normal.sample_n(n, seed=None, name='sample_n', **condition_kwargs)</code></h4>
<p>Generate <code>n</code> samples.</p>
<h5 id="args-315">Args:</h5>
<ul>
<li><b><code>n</code></b>: <code>Scalar</code> <code>Tensor</code> of type <code>int32</code> or <code>int64</code>, the number of observations to sample.</li>
<li><b><code>seed</code></b>: Python integer seed for RNG</li>
<li><b><code>name</code></b>: name to give to the op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-358">Returns:</h5>
<ul>
<li><b><code>samples</code></b>: a <code>Tensor</code> with a prepended dimension (n,).</li>
</ul>
<h5 id="raises-113">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>n</code> is not an integer type.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.normal.sigma"><code id="Normal.sigma">tf.contrib.distributions.Normal.sigma</code></h4>
<p>Distribution parameter for standard deviation.</p>
<hr />
<h4 id="tf.contrib.distributions.normal.stdnamestd"><code id="Normal.std">tf.contrib.distributions.Normal.std(name='std')</code></h4>
<p>Standard deviation.</p>
<hr />
<h4 id="tf.contrib.distributions.normal.survival_functionvalue-namesurvival_function-condition_kwargs"><code id="Normal.survival_function">tf.contrib.distributions.Normal.survival_function(value, name='survival_function', **condition_kwargs)</code></h4>
<p>Survival function.</p>
<p>Given random variable <code>X</code>, the survival function is defined:</p>
<pre><code>survival_function(x) = P[X &gt; x]
                     = 1 - P[X &lt;= x]
                     = 1 - cdf(x).</code></pre>
<h5 id="args-316">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-359">Returns:</h5>
<p>Tensor<code>of shape</code>sample_shape(x) + self.batch_shape<code>with values of type</code>self.dtype`.</p>
<hr />
<h4 id="tf.contrib.distributions.normal.validate_args"><code id="Normal.validate_args">tf.contrib.distributions.Normal.validate_args</code></h4>
<p>Python boolean indicated possibly expensive checks are enabled.</p>
<hr />
<h4 id="tf.contrib.distributions.normal.variancenamevariance"><code id="Normal.variance">tf.contrib.distributions.Normal.variance(name='variance')</code></h4>
<p>Variance.</p>
<hr />
<h3 id="class-tf.contrib.distributions.normalwithsoftplussigma"><a name="//apple_ref/cpp/Class/NormalWithSoftplusSigma" class="dashAnchor"></a><code id="NormalWithSoftplusSigma">class tf.contrib.distributions.NormalWithSoftplusSigma</code></h3>
<p>Normal with softplus applied to <code>sigma</code>. - - -</p>
<h4 id="tf.contrib.distributions.normalwithsoftplussigma.__init__mu-sigma-validate_argsfalse-allow_nan_statstrue-namenormalwithsoftplussigma"><code id="NormalWithSoftplusSigma.__init__">tf.contrib.distributions.NormalWithSoftplusSigma.__init__(mu, sigma, validate_args=False, allow_nan_stats=True, name='NormalWithSoftplusSigma')</code></h4>
<hr />
<h4 id="tf.contrib.distributions.normalwithsoftplussigma.allow_nan_stats"><code id="NormalWithSoftplusSigma.allow_nan_stats">tf.contrib.distributions.NormalWithSoftplusSigma.allow_nan_stats</code></h4>
<p>Python boolean describing behavior when a stat is undefined.</p>
<p>Stats return +/- infinity when it makes sense. E.g., the variance of a Cauchy distribution is infinity. However, sometimes the statistic is undefined, e.g., if a distribution's pdf does not achieve a maximum within the support of the distribution, the mode is undefined. If the mean is undefined, then by definition the variance is undefined. E.g. the mean for Student's T for df = 1 is undefined (no clear way to say it is either + or - infinity), so the variance = E[(X - mean)^2] is also undefined.</p>
<h5 id="returns-360">Returns:</h5>
<ul>
<li><b><code>allow_nan_stats</code></b>: Python boolean.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.normalwithsoftplussigma.batch_shapenamebatch_shape"><code id="NormalWithSoftplusSigma.batch_shape">tf.contrib.distributions.NormalWithSoftplusSigma.batch_shape(name='batch_shape')</code></h4>
<p>Shape of a single sample from a single event index as a 1-D <code>Tensor</code>.</p>
<p>The product of the dimensions of the <code>batch_shape</code> is the number of independent distributions of this kind the instance represents.</p>
<h5 id="args-317">Args:</h5>
<ul>
<li><b><code>name</code></b>: name to give to the op</li>
</ul>
<h5 id="returns-361">Returns:</h5>
<ul>
<li><b><code>batch_shape</code></b>: <code>Tensor</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.normalwithsoftplussigma.cdfvalue-namecdf-condition_kwargs"><code id="NormalWithSoftplusSigma.cdf">tf.contrib.distributions.NormalWithSoftplusSigma.cdf(value, name='cdf', **condition_kwargs)</code></h4>
<p>Cumulative distribution function.</p>
<p>Given random variable <code>X</code>, the cumulative distribution function <code>cdf</code> is:</p>
<pre><code>cdf(x) := P[X &lt;= x]</code></pre>
<h5 id="args-318">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-362">Returns:</h5>
<ul>
<li><b><code>cdf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.normalwithsoftplussigma.copyoverride_parameters_kwargs"><code id="NormalWithSoftplusSigma.copy">tf.contrib.distributions.NormalWithSoftplusSigma.copy(**override_parameters_kwargs)</code></h4>
<p>Creates a deep copy of the distribution.</p>
<p>Note: the copy distribution may continue to depend on the original intialization arguments.</p>
<h5 id="args-319">Args:</h5>
<ul>
<li><b><code>**override_parameters_kwargs</code></b>: String/value dictionary of initialization arguments to override with new values.</li>
</ul>
<h5 id="returns-363">Returns:</h5>
<ul>
<li><b><code>distribution</code></b>: A new instance of <code>type(self)</code> intitialized from the union of self.parameters and override_parameters_kwargs, i.e., <code>dict(self.parameters, **override_parameters_kwargs)</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.normalwithsoftplussigma.dtype"><code id="NormalWithSoftplusSigma.dtype">tf.contrib.distributions.NormalWithSoftplusSigma.dtype</code></h4>
<p>The <code>DType</code> of <code>Tensor</code>s handled by this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.normalwithsoftplussigma.entropynameentropy"><code id="NormalWithSoftplusSigma.entropy">tf.contrib.distributions.NormalWithSoftplusSigma.entropy(name='entropy')</code></h4>
<p>Shannon entropy in nats.</p>
<hr />
<h4 id="tf.contrib.distributions.normalwithsoftplussigma.event_shapenameevent_shape"><code id="NormalWithSoftplusSigma.event_shape">tf.contrib.distributions.NormalWithSoftplusSigma.event_shape(name='event_shape')</code></h4>
<p>Shape of a single sample from a single batch as a 1-D int32 <code>Tensor</code>.</p>
<h5 id="args-320">Args:</h5>
<ul>
<li><b><code>name</code></b>: name to give to the op</li>
</ul>
<h5 id="returns-364">Returns:</h5>
<ul>
<li><b><code>event_shape</code></b>: <code>Tensor</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.normalwithsoftplussigma.get_batch_shape"><code id="NormalWithSoftplusSigma.get_batch_shape">tf.contrib.distributions.NormalWithSoftplusSigma.get_batch_shape()</code></h4>
<p>Shape of a single sample from a single event index as a <code>TensorShape</code>.</p>
<p>Same meaning as <code>batch_shape</code>. May be only partially defined.</p>
<h5 id="returns-365">Returns:</h5>
<ul>
<li><b><code>batch_shape</code></b>: <code>TensorShape</code>, possibly unknown.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.normalwithsoftplussigma.get_event_shape"><code id="NormalWithSoftplusSigma.get_event_shape">tf.contrib.distributions.NormalWithSoftplusSigma.get_event_shape()</code></h4>
<p>Shape of a single sample from a single batch as a <code>TensorShape</code>.</p>
<p>Same meaning as <code>event_shape</code>. May be only partially defined.</p>
<h5 id="returns-366">Returns:</h5>
<ul>
<li><b><code>event_shape</code></b>: <code>TensorShape</code>, possibly unknown.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.normalwithsoftplussigma.is_continuous"><code id="NormalWithSoftplusSigma.is_continuous">tf.contrib.distributions.NormalWithSoftplusSigma.is_continuous</code></h4>
<hr />
<h4 id="tf.contrib.distributions.normalwithsoftplussigma.is_reparameterized"><code id="NormalWithSoftplusSigma.is_reparameterized">tf.contrib.distributions.NormalWithSoftplusSigma.is_reparameterized</code></h4>
<hr />
<h4 id="tf.contrib.distributions.normalwithsoftplussigma.log_cdfvalue-namelog_cdf-condition_kwargs"><code id="NormalWithSoftplusSigma.log_cdf">tf.contrib.distributions.NormalWithSoftplusSigma.log_cdf(value, name='log_cdf', **condition_kwargs)</code></h4>
<p>Log cumulative distribution function.</p>
<p>Given random variable <code>X</code>, the cumulative distribution function <code>cdf</code> is:</p>
<pre><code>log_cdf(x) := Log[ P[X &lt;= x] ]</code></pre>
<p>Often, a numerical approximation can be used for <code>log_cdf(x)</code> that yields a more accurate answer than simply taking the logarithm of the <code>cdf</code> when <code>x &lt;&lt; -1</code>.</p>
<h5 id="args-321">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-367">Returns:</h5>
<ul>
<li><b><code>logcdf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.normalwithsoftplussigma.log_pdfvalue-namelog_pdf-condition_kwargs"><code id="NormalWithSoftplusSigma.log_pdf">tf.contrib.distributions.NormalWithSoftplusSigma.log_pdf(value, name='log_pdf', **condition_kwargs)</code></h4>
<p>Log probability density function.</p>
<h5 id="args-322">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-368">Returns:</h5>
<ul>
<li><b><code>log_prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-114">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if not <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.normalwithsoftplussigma.log_pmfvalue-namelog_pmf-condition_kwargs"><code id="NormalWithSoftplusSigma.log_pmf">tf.contrib.distributions.NormalWithSoftplusSigma.log_pmf(value, name='log_pmf', **condition_kwargs)</code></h4>
<p>Log probability mass function.</p>
<h5 id="args-323">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-369">Returns:</h5>
<ul>
<li><b><code>log_pmf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-115">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.normalwithsoftplussigma.log_probvalue-namelog_prob-condition_kwargs"><code id="NormalWithSoftplusSigma.log_prob">tf.contrib.distributions.NormalWithSoftplusSigma.log_prob(value, name='log_prob', **condition_kwargs)</code></h4>
<p>Log probability density/mass function (depending on <code>is_continuous</code>).</p>
<h5 id="args-324">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-370">Returns:</h5>
<ul>
<li><b><code>log_prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.normalwithsoftplussigma.log_survival_functionvalue-namelog_survival_function-condition_kwargs"><code id="NormalWithSoftplusSigma.log_survival_function">tf.contrib.distributions.NormalWithSoftplusSigma.log_survival_function(value, name='log_survival_function', **condition_kwargs)</code></h4>
<p>Log survival function.</p>
<p>Given random variable <code>X</code>, the survival function is defined:</p>
<pre><code>log_survival_function(x) = Log[ P[X &gt; x] ]
                         = Log[ 1 - P[X &lt;= x] ]
                         = Log[ 1 - cdf(x) ]</code></pre>
<p>Typically, different numerical approximations can be used for the log survival function, which are more accurate than <code>1 - cdf(x)</code> when <code>x &gt;&gt; 1</code>.</p>
<h5 id="args-325">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-371">Returns:</h5>
<p><code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.normalwithsoftplussigma.meannamemean"><code id="NormalWithSoftplusSigma.mean">tf.contrib.distributions.NormalWithSoftplusSigma.mean(name='mean')</code></h4>
<p>Mean.</p>
<hr />
<h4 id="tf.contrib.distributions.normalwithsoftplussigma.modenamemode"><code id="NormalWithSoftplusSigma.mode">tf.contrib.distributions.NormalWithSoftplusSigma.mode(name='mode')</code></h4>
<p>Mode.</p>
<hr />
<h4 id="tf.contrib.distributions.normalwithsoftplussigma.mu"><code id="NormalWithSoftplusSigma.mu">tf.contrib.distributions.NormalWithSoftplusSigma.mu</code></h4>
<p>Distribution parameter for the mean.</p>
<hr />
<h4 id="tf.contrib.distributions.normalwithsoftplussigma.name"><code id="NormalWithSoftplusSigma.name">tf.contrib.distributions.NormalWithSoftplusSigma.name</code></h4>
<p>Name prepended to all ops created by this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.normalwithsoftplussigma.param_shapescls-sample_shape-namedistributionparamshapes"><code id="NormalWithSoftplusSigma.param_shapes">tf.contrib.distributions.NormalWithSoftplusSigma.param_shapes(cls, sample_shape, name='DistributionParamShapes')</code></h4>
<p>Shapes of parameters given the desired shape of a call to <code>sample()</code>.</p>
<p>Subclasses should override static method <code>_param_shapes</code>.</p>
<h5 id="args-326">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: <code>Tensor</code> or python list/tuple. Desired shape of a call to <code>sample()</code>.</li>
<li><b><code>name</code></b>: name to prepend ops with.</li>
</ul>
<h5 id="returns-372">Returns:</h5>
<p><code>dict</code> of parameter name to <code>Tensor</code> shapes.</p>
<hr />
<h4 id="tf.contrib.distributions.normalwithsoftplussigma.param_static_shapescls-sample_shape"><code id="NormalWithSoftplusSigma.param_static_shapes">tf.contrib.distributions.NormalWithSoftplusSigma.param_static_shapes(cls, sample_shape)</code></h4>
<p>param_shapes with static (i.e. TensorShape) shapes.</p>
<h5 id="args-327">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: <code>TensorShape</code> or python list/tuple. Desired shape of a call to <code>sample()</code>.</li>
</ul>
<h5 id="returns-373">Returns:</h5>
<p><code>dict</code> of parameter name to <code>TensorShape</code>.</p>
<h5 id="raises-116">Raises:</h5>
<ul>
<li><b><code>ValueError</code></b>: if <code>sample_shape</code> is a <code>TensorShape</code> and is not fully defined.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.normalwithsoftplussigma.parameters"><code id="NormalWithSoftplusSigma.parameters">tf.contrib.distributions.NormalWithSoftplusSigma.parameters</code></h4>
<p>Dictionary of parameters used to instantiate this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.normalwithsoftplussigma.pdfvalue-namepdf-condition_kwargs"><code id="NormalWithSoftplusSigma.pdf">tf.contrib.distributions.NormalWithSoftplusSigma.pdf(value, name='pdf', **condition_kwargs)</code></h4>
<p>Probability density function.</p>
<h5 id="args-328">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-374">Returns:</h5>
<ul>
<li><b><code>prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-117">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if not <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.normalwithsoftplussigma.pmfvalue-namepmf-condition_kwargs"><code id="NormalWithSoftplusSigma.pmf">tf.contrib.distributions.NormalWithSoftplusSigma.pmf(value, name='pmf', **condition_kwargs)</code></h4>
<p>Probability mass function.</p>
<h5 id="args-329">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-375">Returns:</h5>
<ul>
<li><b><code>pmf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-118">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.normalwithsoftplussigma.probvalue-nameprob-condition_kwargs"><code id="NormalWithSoftplusSigma.prob">tf.contrib.distributions.NormalWithSoftplusSigma.prob(value, name='prob', **condition_kwargs)</code></h4>
<p>Probability density/mass function (depending on <code>is_continuous</code>).</p>
<h5 id="args-330">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-376">Returns:</h5>
<ul>
<li><b><code>prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.normalwithsoftplussigma.samplesample_shape-seednone-namesample-condition_kwargs"><code id="NormalWithSoftplusSigma.sample">tf.contrib.distributions.NormalWithSoftplusSigma.sample(sample_shape=(), seed=None, name='sample', **condition_kwargs)</code></h4>
<p>Generate samples of the specified shape.</p>
<p>Note that a call to <code>sample()</code> without arguments will generate a single sample.</p>
<h5 id="args-331">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: 0D or 1D <code>int32</code> <code>Tensor</code>. Shape of the generated samples.</li>
<li><b><code>seed</code></b>: Python integer seed for RNG</li>
<li><b><code>name</code></b>: name to give to the op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-377">Returns:</h5>
<ul>
<li><b><code>samples</code></b>: a <code>Tensor</code> with prepended dimensions <code>sample_shape</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.normalwithsoftplussigma.sample_nn-seednone-namesample_n-condition_kwargs"><code id="NormalWithSoftplusSigma.sample_n">tf.contrib.distributions.NormalWithSoftplusSigma.sample_n(n, seed=None, name='sample_n', **condition_kwargs)</code></h4>
<p>Generate <code>n</code> samples.</p>
<h5 id="args-332">Args:</h5>
<ul>
<li><b><code>n</code></b>: <code>Scalar</code> <code>Tensor</code> of type <code>int32</code> or <code>int64</code>, the number of observations to sample.</li>
<li><b><code>seed</code></b>: Python integer seed for RNG</li>
<li><b><code>name</code></b>: name to give to the op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-378">Returns:</h5>
<ul>
<li><b><code>samples</code></b>: a <code>Tensor</code> with a prepended dimension (n,).</li>
</ul>
<h5 id="raises-119">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>n</code> is not an integer type.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.normalwithsoftplussigma.sigma"><code id="NormalWithSoftplusSigma.sigma">tf.contrib.distributions.NormalWithSoftplusSigma.sigma</code></h4>
<p>Distribution parameter for standard deviation.</p>
<hr />
<h4 id="tf.contrib.distributions.normalwithsoftplussigma.stdnamestd"><code id="NormalWithSoftplusSigma.std">tf.contrib.distributions.NormalWithSoftplusSigma.std(name='std')</code></h4>
<p>Standard deviation.</p>
<hr />
<h4 id="tf.contrib.distributions.normalwithsoftplussigma.survival_functionvalue-namesurvival_function-condition_kwargs"><code id="NormalWithSoftplusSigma.survival_function">tf.contrib.distributions.NormalWithSoftplusSigma.survival_function(value, name='survival_function', **condition_kwargs)</code></h4>
<p>Survival function.</p>
<p>Given random variable <code>X</code>, the survival function is defined:</p>
<pre><code>survival_function(x) = P[X &gt; x]
                     = 1 - P[X &lt;= x]
                     = 1 - cdf(x).</code></pre>
<h5 id="args-333">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-379">Returns:</h5>
<p>Tensor<code>of shape</code>sample_shape(x) + self.batch_shape<code>with values of type</code>self.dtype`.</p>
<hr />
<h4 id="tf.contrib.distributions.normalwithsoftplussigma.validate_args"><code id="NormalWithSoftplusSigma.validate_args">tf.contrib.distributions.NormalWithSoftplusSigma.validate_args</code></h4>
<p>Python boolean indicated possibly expensive checks are enabled.</p>
<hr />
<h4 id="tf.contrib.distributions.normalwithsoftplussigma.variancenamevariance"><code id="NormalWithSoftplusSigma.variance">tf.contrib.distributions.NormalWithSoftplusSigma.variance(name='variance')</code></h4>
<p>Variance.</p>
<hr />
<h3 id="class-tf.contrib.distributions.poisson"><a name="//apple_ref/cpp/Class/Poisson" class="dashAnchor"></a><code id="Poisson">class tf.contrib.distributions.Poisson</code></h3>
<p>Poisson distribution.</p>
<p>The Poisson distribution is parameterized by <code>lam</code>, the rate parameter.</p>
<p>The pmf of this distribution is:</p>
<pre><code>
pmf(k) = e^(-lam) * lam^k / k!,  k &gt;= 0</code></pre>
<hr />
<h4 id="tf.contrib.distributions.poisson.__init__lam-validate_argsfalse-allow_nan_statstrue-namepoisson"><code id="Poisson.__init__">tf.contrib.distributions.Poisson.__init__(lam, validate_args=False, allow_nan_stats=True, name='Poisson')</code></h4>
<p>Construct Poisson distributions.</p>
<h5 id="args-334">Args:</h5>
<ul>
<li><b><code>lam</code></b>: Floating point tensor, the rate parameter of the distribution(s). <code>lam</code> must be positive.</li>
<li><b><code>validate_args</code></b>: <code>Boolean</code>, default <code>False</code>. Whether to assert that <code>lam &gt; 0</code> as well as inputs to pmf computations are non-negative integers. If validate_args is <code>False</code>, then <code>pmf</code> computations might return <code>NaN</code>, but can be evaluated at any real value.</li>
<li><b><code>allow_nan_stats</code></b>: <code>Boolean</code>, default <code>True</code>. If <code>False</code>, raise an exception if a statistic (e.g. mean/mode/etc...) is undefined for any batch member. If <code>True</code>, batch members with valid parameters leading to undefined statistics will return NaN for this statistic.</li>
<li><b><code>name</code></b>: A name for this distribution.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.poisson.allow_nan_stats"><code id="Poisson.allow_nan_stats">tf.contrib.distributions.Poisson.allow_nan_stats</code></h4>
<p>Python boolean describing behavior when a stat is undefined.</p>
<p>Stats return +/- infinity when it makes sense. E.g., the variance of a Cauchy distribution is infinity. However, sometimes the statistic is undefined, e.g., if a distribution's pdf does not achieve a maximum within the support of the distribution, the mode is undefined. If the mean is undefined, then by definition the variance is undefined. E.g. the mean for Student's T for df = 1 is undefined (no clear way to say it is either + or - infinity), so the variance = E[(X - mean)^2] is also undefined.</p>
<h5 id="returns-380">Returns:</h5>
<ul>
<li><b><code>allow_nan_stats</code></b>: Python boolean.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.poisson.batch_shapenamebatch_shape"><code id="Poisson.batch_shape">tf.contrib.distributions.Poisson.batch_shape(name='batch_shape')</code></h4>
<p>Shape of a single sample from a single event index as a 1-D <code>Tensor</code>.</p>
<p>The product of the dimensions of the <code>batch_shape</code> is the number of independent distributions of this kind the instance represents.</p>
<h5 id="args-335">Args:</h5>
<ul>
<li><b><code>name</code></b>: name to give to the op</li>
</ul>
<h5 id="returns-381">Returns:</h5>
<ul>
<li><b><code>batch_shape</code></b>: <code>Tensor</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.poisson.cdfvalue-namecdf-condition_kwargs"><code id="Poisson.cdf">tf.contrib.distributions.Poisson.cdf(value, name='cdf', **condition_kwargs)</code></h4>
<p>Cumulative distribution function.</p>
<p>Given random variable <code>X</code>, the cumulative distribution function <code>cdf</code> is:</p>
<pre><code>cdf(x) := P[X &lt;= x]</code></pre>
<h5 id="args-336">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-382">Returns:</h5>
<ul>
<li><b><code>cdf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.poisson.copyoverride_parameters_kwargs"><code id="Poisson.copy">tf.contrib.distributions.Poisson.copy(**override_parameters_kwargs)</code></h4>
<p>Creates a deep copy of the distribution.</p>
<p>Note: the copy distribution may continue to depend on the original intialization arguments.</p>
<h5 id="args-337">Args:</h5>
<ul>
<li><b><code>**override_parameters_kwargs</code></b>: String/value dictionary of initialization arguments to override with new values.</li>
</ul>
<h5 id="returns-383">Returns:</h5>
<ul>
<li><b><code>distribution</code></b>: A new instance of <code>type(self)</code> intitialized from the union of self.parameters and override_parameters_kwargs, i.e., <code>dict(self.parameters, **override_parameters_kwargs)</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.poisson.dtype"><code id="Poisson.dtype">tf.contrib.distributions.Poisson.dtype</code></h4>
<p>The <code>DType</code> of <code>Tensor</code>s handled by this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.poisson.entropynameentropy"><code id="Poisson.entropy">tf.contrib.distributions.Poisson.entropy(name='entropy')</code></h4>
<p>Shannon entropy in nats.</p>
<hr />
<h4 id="tf.contrib.distributions.poisson.event_shapenameevent_shape"><code id="Poisson.event_shape">tf.contrib.distributions.Poisson.event_shape(name='event_shape')</code></h4>
<p>Shape of a single sample from a single batch as a 1-D int32 <code>Tensor</code>.</p>
<h5 id="args-338">Args:</h5>
<ul>
<li><b><code>name</code></b>: name to give to the op</li>
</ul>
<h5 id="returns-384">Returns:</h5>
<ul>
<li><b><code>event_shape</code></b>: <code>Tensor</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.poisson.get_batch_shape"><code id="Poisson.get_batch_shape">tf.contrib.distributions.Poisson.get_batch_shape()</code></h4>
<p>Shape of a single sample from a single event index as a <code>TensorShape</code>.</p>
<p>Same meaning as <code>batch_shape</code>. May be only partially defined.</p>
<h5 id="returns-385">Returns:</h5>
<ul>
<li><b><code>batch_shape</code></b>: <code>TensorShape</code>, possibly unknown.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.poisson.get_event_shape"><code id="Poisson.get_event_shape">tf.contrib.distributions.Poisson.get_event_shape()</code></h4>
<p>Shape of a single sample from a single batch as a <code>TensorShape</code>.</p>
<p>Same meaning as <code>event_shape</code>. May be only partially defined.</p>
<h5 id="returns-386">Returns:</h5>
<ul>
<li><b><code>event_shape</code></b>: <code>TensorShape</code>, possibly unknown.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.poisson.is_continuous"><code id="Poisson.is_continuous">tf.contrib.distributions.Poisson.is_continuous</code></h4>
<hr />
<h4 id="tf.contrib.distributions.poisson.is_reparameterized"><code id="Poisson.is_reparameterized">tf.contrib.distributions.Poisson.is_reparameterized</code></h4>
<hr />
<h4 id="tf.contrib.distributions.poisson.lam"><code id="Poisson.lam">tf.contrib.distributions.Poisson.lam</code></h4>
<p>Rate parameter.</p>
<hr />
<h4 id="tf.contrib.distributions.poisson.log_cdfvalue-namelog_cdf-condition_kwargs"><code id="Poisson.log_cdf">tf.contrib.distributions.Poisson.log_cdf(value, name='log_cdf', **condition_kwargs)</code></h4>
<p>Log cumulative distribution function.</p>
<p>Given random variable <code>X</code>, the cumulative distribution function <code>cdf</code> is:</p>
<pre><code>log_cdf(x) := Log[ P[X &lt;= x] ]</code></pre>
<p>Often, a numerical approximation can be used for <code>log_cdf(x)</code> that yields a more accurate answer than simply taking the logarithm of the <code>cdf</code> when <code>x &lt;&lt; -1</code>.</p>
<h5 id="args-339">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-387">Returns:</h5>
<ul>
<li><b><code>logcdf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.poisson.log_pdfvalue-namelog_pdf-condition_kwargs"><code id="Poisson.log_pdf">tf.contrib.distributions.Poisson.log_pdf(value, name='log_pdf', **condition_kwargs)</code></h4>
<p>Log probability density function.</p>
<h5 id="args-340">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-388">Returns:</h5>
<ul>
<li><b><code>log_prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-120">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if not <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.poisson.log_pmfvalue-namelog_pmf-condition_kwargs"><code id="Poisson.log_pmf">tf.contrib.distributions.Poisson.log_pmf(value, name='log_pmf', **condition_kwargs)</code></h4>
<p>Log probability mass function.</p>
<h5 id="args-341">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-389">Returns:</h5>
<ul>
<li><b><code>log_pmf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-121">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.poisson.log_probvalue-namelog_prob-condition_kwargs"><code id="Poisson.log_prob">tf.contrib.distributions.Poisson.log_prob(value, name='log_prob', **condition_kwargs)</code></h4>
<p>Log probability density/mass function (depending on <code>is_continuous</code>).</p>
<p>Additional documentation from <code>Poisson</code>:</p>
<p>Note thet the input value must be a non-negative floating point tensor with dtype <code>dtype</code> and whose shape can be broadcast with <code>self.lam</code>. <code>x</code> is only legal if it is non-negative and its components are equal to integer values.</p>
<h5 id="args-342">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-390">Returns:</h5>
<ul>
<li><b><code>log_prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.poisson.log_survival_functionvalue-namelog_survival_function-condition_kwargs"><code id="Poisson.log_survival_function">tf.contrib.distributions.Poisson.log_survival_function(value, name='log_survival_function', **condition_kwargs)</code></h4>
<p>Log survival function.</p>
<p>Given random variable <code>X</code>, the survival function is defined:</p>
<pre><code>log_survival_function(x) = Log[ P[X &gt; x] ]
                         = Log[ 1 - P[X &lt;= x] ]
                         = Log[ 1 - cdf(x) ]</code></pre>
<p>Typically, different numerical approximations can be used for the log survival function, which are more accurate than <code>1 - cdf(x)</code> when <code>x &gt;&gt; 1</code>.</p>
<h5 id="args-343">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-391">Returns:</h5>
<p><code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.poisson.meannamemean"><code id="Poisson.mean">tf.contrib.distributions.Poisson.mean(name='mean')</code></h4>
<p>Mean.</p>
<hr />
<h4 id="tf.contrib.distributions.poisson.modenamemode"><code id="Poisson.mode">tf.contrib.distributions.Poisson.mode(name='mode')</code></h4>
<p>Mode.</p>
<p>Additional documentation from <code>Poisson</code>:</p>
<p>Note that when <code>lam</code> is an integer, there are actually two modes. Namely, <code>lam</code> and <code>lam - 1</code> are both modes. Here we return only the larger of the two modes.</p>
<hr />
<h4 id="tf.contrib.distributions.poisson.name"><code id="Poisson.name">tf.contrib.distributions.Poisson.name</code></h4>
<p>Name prepended to all ops created by this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.poisson.param_shapescls-sample_shape-namedistributionparamshapes"><code id="Poisson.param_shapes">tf.contrib.distributions.Poisson.param_shapes(cls, sample_shape, name='DistributionParamShapes')</code></h4>
<p>Shapes of parameters given the desired shape of a call to <code>sample()</code>.</p>
<p>Subclasses should override static method <code>_param_shapes</code>.</p>
<h5 id="args-344">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: <code>Tensor</code> or python list/tuple. Desired shape of a call to <code>sample()</code>.</li>
<li><b><code>name</code></b>: name to prepend ops with.</li>
</ul>
<h5 id="returns-392">Returns:</h5>
<p><code>dict</code> of parameter name to <code>Tensor</code> shapes.</p>
<hr />
<h4 id="tf.contrib.distributions.poisson.param_static_shapescls-sample_shape"><code id="Poisson.param_static_shapes">tf.contrib.distributions.Poisson.param_static_shapes(cls, sample_shape)</code></h4>
<p>param_shapes with static (i.e. TensorShape) shapes.</p>
<h5 id="args-345">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: <code>TensorShape</code> or python list/tuple. Desired shape of a call to <code>sample()</code>.</li>
</ul>
<h5 id="returns-393">Returns:</h5>
<p><code>dict</code> of parameter name to <code>TensorShape</code>.</p>
<h5 id="raises-122">Raises:</h5>
<ul>
<li><b><code>ValueError</code></b>: if <code>sample_shape</code> is a <code>TensorShape</code> and is not fully defined.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.poisson.parameters"><code id="Poisson.parameters">tf.contrib.distributions.Poisson.parameters</code></h4>
<p>Dictionary of parameters used to instantiate this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.poisson.pdfvalue-namepdf-condition_kwargs"><code id="Poisson.pdf">tf.contrib.distributions.Poisson.pdf(value, name='pdf', **condition_kwargs)</code></h4>
<p>Probability density function.</p>
<h5 id="args-346">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-394">Returns:</h5>
<ul>
<li><b><code>prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-123">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if not <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.poisson.pmfvalue-namepmf-condition_kwargs"><code id="Poisson.pmf">tf.contrib.distributions.Poisson.pmf(value, name='pmf', **condition_kwargs)</code></h4>
<p>Probability mass function.</p>
<h5 id="args-347">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-395">Returns:</h5>
<ul>
<li><b><code>pmf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-124">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.poisson.probvalue-nameprob-condition_kwargs"><code id="Poisson.prob">tf.contrib.distributions.Poisson.prob(value, name='prob', **condition_kwargs)</code></h4>
<p>Probability density/mass function (depending on <code>is_continuous</code>).</p>
<p>Additional documentation from <code>Poisson</code>:</p>
<p>Note thet the input value must be a non-negative floating point tensor with dtype <code>dtype</code> and whose shape can be broadcast with <code>self.lam</code>. <code>x</code> is only legal if it is non-negative and its components are equal to integer values.</p>
<h5 id="args-348">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-396">Returns:</h5>
<ul>
<li><b><code>prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.poisson.samplesample_shape-seednone-namesample-condition_kwargs"><code id="Poisson.sample">tf.contrib.distributions.Poisson.sample(sample_shape=(), seed=None, name='sample', **condition_kwargs)</code></h4>
<p>Generate samples of the specified shape.</p>
<p>Note that a call to <code>sample()</code> without arguments will generate a single sample.</p>
<h5 id="args-349">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: 0D or 1D <code>int32</code> <code>Tensor</code>. Shape of the generated samples.</li>
<li><b><code>seed</code></b>: Python integer seed for RNG</li>
<li><b><code>name</code></b>: name to give to the op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-397">Returns:</h5>
<ul>
<li><b><code>samples</code></b>: a <code>Tensor</code> with prepended dimensions <code>sample_shape</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.poisson.sample_nn-seednone-namesample_n-condition_kwargs"><code id="Poisson.sample_n">tf.contrib.distributions.Poisson.sample_n(n, seed=None, name='sample_n', **condition_kwargs)</code></h4>
<p>Generate <code>n</code> samples.</p>
<h5 id="args-350">Args:</h5>
<ul>
<li><b><code>n</code></b>: <code>Scalar</code> <code>Tensor</code> of type <code>int32</code> or <code>int64</code>, the number of observations to sample.</li>
<li><b><code>seed</code></b>: Python integer seed for RNG</li>
<li><b><code>name</code></b>: name to give to the op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-398">Returns:</h5>
<ul>
<li><b><code>samples</code></b>: a <code>Tensor</code> with a prepended dimension (n,).</li>
</ul>
<h5 id="raises-125">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>n</code> is not an integer type.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.poisson.stdnamestd"><code id="Poisson.std">tf.contrib.distributions.Poisson.std(name='std')</code></h4>
<p>Standard deviation.</p>
<hr />
<h4 id="tf.contrib.distributions.poisson.survival_functionvalue-namesurvival_function-condition_kwargs"><code id="Poisson.survival_function">tf.contrib.distributions.Poisson.survival_function(value, name='survival_function', **condition_kwargs)</code></h4>
<p>Survival function.</p>
<p>Given random variable <code>X</code>, the survival function is defined:</p>
<pre><code>survival_function(x) = P[X &gt; x]
                     = 1 - P[X &lt;= x]
                     = 1 - cdf(x).</code></pre>
<h5 id="args-351">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-399">Returns:</h5>
<p>Tensor<code>of shape</code>sample_shape(x) + self.batch_shape<code>with values of type</code>self.dtype`.</p>
<hr />
<h4 id="tf.contrib.distributions.poisson.validate_args"><code id="Poisson.validate_args">tf.contrib.distributions.Poisson.validate_args</code></h4>
<p>Python boolean indicated possibly expensive checks are enabled.</p>
<hr />
<h4 id="tf.contrib.distributions.poisson.variancenamevariance"><code id="Poisson.variance">tf.contrib.distributions.Poisson.variance(name='variance')</code></h4>
<p>Variance.</p>
<hr />
<h3 id="class-tf.contrib.distributions.studentt"><a name="//apple_ref/cpp/Class/StudentT" class="dashAnchor"></a><code id="StudentT">class tf.contrib.distributions.StudentT</code></h3>
<p>Student's t distribution with degree-of-freedom parameter df.</p>
<h4 id="mathematical-details-4">Mathematical details</h4>
<p>The PDF of this distribution is:</p>
<p><code>f(t) = gamma((df+1)/2)/sqrt(df*pi)/gamma(df/2)*(1+t^2/df)^(-(df+1)/2)</code></p>
<h4 id="examples-4">Examples</h4>
<p>Examples of initialization of one or a batch of distributions.</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="co"># Define a single scalar Student t distribution.</span>
single_dist <span class="op">=</span> tf.contrib.distributions.StudentT(df<span class="op">=</span><span class="dv">3</span>)

<span class="co"># Evaluate the pdf at 1, returning a scalar Tensor.</span>
single_dist.pdf(<span class="dv">1</span>.)

<span class="co"># Define a batch of two scalar valued Student t&#39;s.</span>
<span class="co"># The first has degrees of freedom 2, mean 1, and scale 11.</span>
<span class="co"># The second 3, 2 and 22.</span>
multi_dist <span class="op">=</span> tf.contrib.distributions.StudentT(df<span class="op">=</span>[<span class="dv">2</span>, <span class="dv">3</span>],
                                               mu<span class="op">=</span>[<span class="dv">1</span>, <span class="dv">2</span>.],
                                               sigma<span class="op">=</span>[<span class="dv">11</span>, <span class="dv">22</span>.])

<span class="co"># Evaluate the pdf of the first distribution on 0, and the second on 1.5,</span>
<span class="co"># returning a length two tensor.</span>
multi_dist.pdf([<span class="dv">0</span>, <span class="fl">1.5</span>])

<span class="co"># Get 3 samples, returning a 3 x 2 tensor.</span>
multi_dist.sample(<span class="dv">3</span>)</code></pre></div>
<p>Arguments are broadcast when possible.</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="co"># Define a batch of two Student&#39;s t distributions.</span>
<span class="co"># Both have df 2 and mean 1, but different scales.</span>
dist <span class="op">=</span> tf.contrib.distributions.StudentT(df<span class="op">=</span><span class="dv">2</span>, mu<span class="op">=</span><span class="dv">1</span>, sigma<span class="op">=</span>[<span class="dv">11</span>, <span class="dv">22</span>.])

<span class="co"># Evaluate the pdf of both distributions on the same point, 3.0,</span>
<span class="co"># returning a length 2 tensor.</span>
dist.pdf(<span class="fl">3.0</span>)</code></pre></div>
<hr />
<h4 id="tf.contrib.distributions.studentt.__init__df-mu-sigma-validate_argsfalse-allow_nan_statstrue-namestudentt"><code id="StudentT.__init__">tf.contrib.distributions.StudentT.__init__(df, mu, sigma, validate_args=False, allow_nan_stats=True, name='StudentT')</code></h4>
<p>Construct Student's t distributions.</p>
<p>The distributions have degree of freedom <code>df</code>, mean <code>mu</code>, and scale <code>sigma</code>.</p>
<p>The parameters <code>df</code>, <code>mu</code>, and <code>sigma</code> must be shaped in a way that supports broadcasting (e.g. <code>df + mu + sigma</code> is a valid operation).</p>
<h5 id="args-352">Args:</h5>
<ul>
<li><b><code>df</code></b>: Floating point tensor, the degrees of freedom of the distribution(s). <code>df</code> must contain only positive values.</li>
<li><b><code>mu</code></b>: Floating point tensor, the means of the distribution(s).</li>
<li><b><code>sigma</code></b>: Floating point tensor, the scaling factor for the distribution(s). <code>sigma</code> must contain only positive values. Note that <code>sigma</code> is not the standard deviation of this distribution.</li>
<li><b><code>validate_args</code></b>: <code>Boolean</code>, default <code>False</code>. Whether to assert that <code>df &gt; 0</code> and <code>sigma &gt; 0</code>. If <code>validate_args</code> is <code>False</code> and inputs are invalid, correct behavior is not guaranteed.</li>
<li><b><code>allow_nan_stats</code></b>: <code>Boolean</code>, default <code>True</code>. If <code>False</code>, raise an exception if a statistic (e.g. mean/mode/etc...) is undefined for any batch member. If <code>True</code>, batch members with valid parameters leading to undefined statistics will return NaN for this statistic.</li>
<li><b><code>name</code></b>: The name to give Ops created by the initializer.</li>
</ul>
<h5 id="raises-126">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if mu and sigma are different dtypes.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.studentt.allow_nan_stats"><code id="StudentT.allow_nan_stats">tf.contrib.distributions.StudentT.allow_nan_stats</code></h4>
<p>Python boolean describing behavior when a stat is undefined.</p>
<p>Stats return +/- infinity when it makes sense. E.g., the variance of a Cauchy distribution is infinity. However, sometimes the statistic is undefined, e.g., if a distribution's pdf does not achieve a maximum within the support of the distribution, the mode is undefined. If the mean is undefined, then by definition the variance is undefined. E.g. the mean for Student's T for df = 1 is undefined (no clear way to say it is either + or - infinity), so the variance = E[(X - mean)^2] is also undefined.</p>
<h5 id="returns-400">Returns:</h5>
<ul>
<li><b><code>allow_nan_stats</code></b>: Python boolean.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.studentt.batch_shapenamebatch_shape"><code id="StudentT.batch_shape">tf.contrib.distributions.StudentT.batch_shape(name='batch_shape')</code></h4>
<p>Shape of a single sample from a single event index as a 1-D <code>Tensor</code>.</p>
<p>The product of the dimensions of the <code>batch_shape</code> is the number of independent distributions of this kind the instance represents.</p>
<h5 id="args-353">Args:</h5>
<ul>
<li><b><code>name</code></b>: name to give to the op</li>
</ul>
<h5 id="returns-401">Returns:</h5>
<ul>
<li><b><code>batch_shape</code></b>: <code>Tensor</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.studentt.cdfvalue-namecdf-condition_kwargs"><code id="StudentT.cdf">tf.contrib.distributions.StudentT.cdf(value, name='cdf', **condition_kwargs)</code></h4>
<p>Cumulative distribution function.</p>
<p>Given random variable <code>X</code>, the cumulative distribution function <code>cdf</code> is:</p>
<pre><code>cdf(x) := P[X &lt;= x]</code></pre>
<h5 id="args-354">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-402">Returns:</h5>
<ul>
<li><b><code>cdf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.studentt.copyoverride_parameters_kwargs"><code id="StudentT.copy">tf.contrib.distributions.StudentT.copy(**override_parameters_kwargs)</code></h4>
<p>Creates a deep copy of the distribution.</p>
<p>Note: the copy distribution may continue to depend on the original intialization arguments.</p>
<h5 id="args-355">Args:</h5>
<ul>
<li><b><code>**override_parameters_kwargs</code></b>: String/value dictionary of initialization arguments to override with new values.</li>
</ul>
<h5 id="returns-403">Returns:</h5>
<ul>
<li><b><code>distribution</code></b>: A new instance of <code>type(self)</code> intitialized from the union of self.parameters and override_parameters_kwargs, i.e., <code>dict(self.parameters, **override_parameters_kwargs)</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.studentt.df"><code id="StudentT.df">tf.contrib.distributions.StudentT.df</code></h4>
<p>Degrees of freedom in these Student's t distribution(s).</p>
<hr />
<h4 id="tf.contrib.distributions.studentt.dtype"><code id="StudentT.dtype">tf.contrib.distributions.StudentT.dtype</code></h4>
<p>The <code>DType</code> of <code>Tensor</code>s handled by this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.studentt.entropynameentropy"><code id="StudentT.entropy">tf.contrib.distributions.StudentT.entropy(name='entropy')</code></h4>
<p>Shannon entropy in nats.</p>
<hr />
<h4 id="tf.contrib.distributions.studentt.event_shapenameevent_shape"><code id="StudentT.event_shape">tf.contrib.distributions.StudentT.event_shape(name='event_shape')</code></h4>
<p>Shape of a single sample from a single batch as a 1-D int32 <code>Tensor</code>.</p>
<h5 id="args-356">Args:</h5>
<ul>
<li><b><code>name</code></b>: name to give to the op</li>
</ul>
<h5 id="returns-404">Returns:</h5>
<ul>
<li><b><code>event_shape</code></b>: <code>Tensor</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.studentt.get_batch_shape"><code id="StudentT.get_batch_shape">tf.contrib.distributions.StudentT.get_batch_shape()</code></h4>
<p>Shape of a single sample from a single event index as a <code>TensorShape</code>.</p>
<p>Same meaning as <code>batch_shape</code>. May be only partially defined.</p>
<h5 id="returns-405">Returns:</h5>
<ul>
<li><b><code>batch_shape</code></b>: <code>TensorShape</code>, possibly unknown.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.studentt.get_event_shape"><code id="StudentT.get_event_shape">tf.contrib.distributions.StudentT.get_event_shape()</code></h4>
<p>Shape of a single sample from a single batch as a <code>TensorShape</code>.</p>
<p>Same meaning as <code>event_shape</code>. May be only partially defined.</p>
<h5 id="returns-406">Returns:</h5>
<ul>
<li><b><code>event_shape</code></b>: <code>TensorShape</code>, possibly unknown.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.studentt.is_continuous"><code id="StudentT.is_continuous">tf.contrib.distributions.StudentT.is_continuous</code></h4>
<hr />
<h4 id="tf.contrib.distributions.studentt.is_reparameterized"><code id="StudentT.is_reparameterized">tf.contrib.distributions.StudentT.is_reparameterized</code></h4>
<hr />
<h4 id="tf.contrib.distributions.studentt.log_cdfvalue-namelog_cdf-condition_kwargs"><code id="StudentT.log_cdf">tf.contrib.distributions.StudentT.log_cdf(value, name='log_cdf', **condition_kwargs)</code></h4>
<p>Log cumulative distribution function.</p>
<p>Given random variable <code>X</code>, the cumulative distribution function <code>cdf</code> is:</p>
<pre><code>log_cdf(x) := Log[ P[X &lt;= x] ]</code></pre>
<p>Often, a numerical approximation can be used for <code>log_cdf(x)</code> that yields a more accurate answer than simply taking the logarithm of the <code>cdf</code> when <code>x &lt;&lt; -1</code>.</p>
<h5 id="args-357">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-407">Returns:</h5>
<ul>
<li><b><code>logcdf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.studentt.log_pdfvalue-namelog_pdf-condition_kwargs"><code id="StudentT.log_pdf">tf.contrib.distributions.StudentT.log_pdf(value, name='log_pdf', **condition_kwargs)</code></h4>
<p>Log probability density function.</p>
<h5 id="args-358">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-408">Returns:</h5>
<ul>
<li><b><code>log_prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-127">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if not <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.studentt.log_pmfvalue-namelog_pmf-condition_kwargs"><code id="StudentT.log_pmf">tf.contrib.distributions.StudentT.log_pmf(value, name='log_pmf', **condition_kwargs)</code></h4>
<p>Log probability mass function.</p>
<h5 id="args-359">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-409">Returns:</h5>
<ul>
<li><b><code>log_pmf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-128">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.studentt.log_probvalue-namelog_prob-condition_kwargs"><code id="StudentT.log_prob">tf.contrib.distributions.StudentT.log_prob(value, name='log_prob', **condition_kwargs)</code></h4>
<p>Log probability density/mass function (depending on <code>is_continuous</code>).</p>
<h5 id="args-360">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-410">Returns:</h5>
<ul>
<li><b><code>log_prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.studentt.log_survival_functionvalue-namelog_survival_function-condition_kwargs"><code id="StudentT.log_survival_function">tf.contrib.distributions.StudentT.log_survival_function(value, name='log_survival_function', **condition_kwargs)</code></h4>
<p>Log survival function.</p>
<p>Given random variable <code>X</code>, the survival function is defined:</p>
<pre><code>log_survival_function(x) = Log[ P[X &gt; x] ]
                         = Log[ 1 - P[X &lt;= x] ]
                         = Log[ 1 - cdf(x) ]</code></pre>
<p>Typically, different numerical approximations can be used for the log survival function, which are more accurate than <code>1 - cdf(x)</code> when <code>x &gt;&gt; 1</code>.</p>
<h5 id="args-361">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-411">Returns:</h5>
<p><code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.studentt.meannamemean"><code id="StudentT.mean">tf.contrib.distributions.StudentT.mean(name='mean')</code></h4>
<p>Mean.</p>
<p>Additional documentation from <code>StudentT</code>:</p>
<p>The mean of Student's T equals <code>mu</code> if <code>df &gt; 1</code>, otherwise it is <code>NaN</code>. If <code>self.allow_nan_stats=True</code>, then an exception will be raised rather than returning <code>NaN</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.studentt.modenamemode"><code id="StudentT.mode">tf.contrib.distributions.StudentT.mode(name='mode')</code></h4>
<p>Mode.</p>
<hr />
<h4 id="tf.contrib.distributions.studentt.mu"><code id="StudentT.mu">tf.contrib.distributions.StudentT.mu</code></h4>
<p>Locations of these Student's t distribution(s).</p>
<hr />
<h4 id="tf.contrib.distributions.studentt.name"><code id="StudentT.name">tf.contrib.distributions.StudentT.name</code></h4>
<p>Name prepended to all ops created by this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.studentt.param_shapescls-sample_shape-namedistributionparamshapes"><code id="StudentT.param_shapes">tf.contrib.distributions.StudentT.param_shapes(cls, sample_shape, name='DistributionParamShapes')</code></h4>
<p>Shapes of parameters given the desired shape of a call to <code>sample()</code>.</p>
<p>Subclasses should override static method <code>_param_shapes</code>.</p>
<h5 id="args-362">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: <code>Tensor</code> or python list/tuple. Desired shape of a call to <code>sample()</code>.</li>
<li><b><code>name</code></b>: name to prepend ops with.</li>
</ul>
<h5 id="returns-412">Returns:</h5>
<p><code>dict</code> of parameter name to <code>Tensor</code> shapes.</p>
<hr />
<h4 id="tf.contrib.distributions.studentt.param_static_shapescls-sample_shape"><code id="StudentT.param_static_shapes">tf.contrib.distributions.StudentT.param_static_shapes(cls, sample_shape)</code></h4>
<p>param_shapes with static (i.e. TensorShape) shapes.</p>
<h5 id="args-363">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: <code>TensorShape</code> or python list/tuple. Desired shape of a call to <code>sample()</code>.</li>
</ul>
<h5 id="returns-413">Returns:</h5>
<p><code>dict</code> of parameter name to <code>TensorShape</code>.</p>
<h5 id="raises-129">Raises:</h5>
<ul>
<li><b><code>ValueError</code></b>: if <code>sample_shape</code> is a <code>TensorShape</code> and is not fully defined.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.studentt.parameters"><code id="StudentT.parameters">tf.contrib.distributions.StudentT.parameters</code></h4>
<p>Dictionary of parameters used to instantiate this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.studentt.pdfvalue-namepdf-condition_kwargs"><code id="StudentT.pdf">tf.contrib.distributions.StudentT.pdf(value, name='pdf', **condition_kwargs)</code></h4>
<p>Probability density function.</p>
<h5 id="args-364">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-414">Returns:</h5>
<ul>
<li><b><code>prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-130">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if not <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.studentt.pmfvalue-namepmf-condition_kwargs"><code id="StudentT.pmf">tf.contrib.distributions.StudentT.pmf(value, name='pmf', **condition_kwargs)</code></h4>
<p>Probability mass function.</p>
<h5 id="args-365">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-415">Returns:</h5>
<ul>
<li><b><code>pmf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-131">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.studentt.probvalue-nameprob-condition_kwargs"><code id="StudentT.prob">tf.contrib.distributions.StudentT.prob(value, name='prob', **condition_kwargs)</code></h4>
<p>Probability density/mass function (depending on <code>is_continuous</code>).</p>
<h5 id="args-366">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-416">Returns:</h5>
<ul>
<li><b><code>prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.studentt.samplesample_shape-seednone-namesample-condition_kwargs"><code id="StudentT.sample">tf.contrib.distributions.StudentT.sample(sample_shape=(), seed=None, name='sample', **condition_kwargs)</code></h4>
<p>Generate samples of the specified shape.</p>
<p>Note that a call to <code>sample()</code> without arguments will generate a single sample.</p>
<h5 id="args-367">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: 0D or 1D <code>int32</code> <code>Tensor</code>. Shape of the generated samples.</li>
<li><b><code>seed</code></b>: Python integer seed for RNG</li>
<li><b><code>name</code></b>: name to give to the op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-417">Returns:</h5>
<ul>
<li><b><code>samples</code></b>: a <code>Tensor</code> with prepended dimensions <code>sample_shape</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.studentt.sample_nn-seednone-namesample_n-condition_kwargs"><code id="StudentT.sample_n">tf.contrib.distributions.StudentT.sample_n(n, seed=None, name='sample_n', **condition_kwargs)</code></h4>
<p>Generate <code>n</code> samples.</p>
<h5 id="args-368">Args:</h5>
<ul>
<li><b><code>n</code></b>: <code>Scalar</code> <code>Tensor</code> of type <code>int32</code> or <code>int64</code>, the number of observations to sample.</li>
<li><b><code>seed</code></b>: Python integer seed for RNG</li>
<li><b><code>name</code></b>: name to give to the op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-418">Returns:</h5>
<ul>
<li><b><code>samples</code></b>: a <code>Tensor</code> with a prepended dimension (n,).</li>
</ul>
<h5 id="raises-132">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>n</code> is not an integer type.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.studentt.sigma"><code id="StudentT.sigma">tf.contrib.distributions.StudentT.sigma</code></h4>
<p>Scaling factors of these Student's t distribution(s).</p>
<hr />
<h4 id="tf.contrib.distributions.studentt.stdnamestd"><code id="StudentT.std">tf.contrib.distributions.StudentT.std(name='std')</code></h4>
<p>Standard deviation.</p>
<hr />
<h4 id="tf.contrib.distributions.studentt.survival_functionvalue-namesurvival_function-condition_kwargs"><code id="StudentT.survival_function">tf.contrib.distributions.StudentT.survival_function(value, name='survival_function', **condition_kwargs)</code></h4>
<p>Survival function.</p>
<p>Given random variable <code>X</code>, the survival function is defined:</p>
<pre><code>survival_function(x) = P[X &gt; x]
                     = 1 - P[X &lt;= x]
                     = 1 - cdf(x).</code></pre>
<h5 id="args-369">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-419">Returns:</h5>
<p>Tensor<code>of shape</code>sample_shape(x) + self.batch_shape<code>with values of type</code>self.dtype`.</p>
<hr />
<h4 id="tf.contrib.distributions.studentt.validate_args"><code id="StudentT.validate_args">tf.contrib.distributions.StudentT.validate_args</code></h4>
<p>Python boolean indicated possibly expensive checks are enabled.</p>
<hr />
<h4 id="tf.contrib.distributions.studentt.variancenamevariance"><code id="StudentT.variance">tf.contrib.distributions.StudentT.variance(name='variance')</code></h4>
<p>Variance.</p>
<p>Additional documentation from <code>StudentT</code>:</p>
<p>The variance for Student's T equals</p>
<pre><code>df / (df - 2), when df &gt; 2
infinity, when 1 &lt; df &lt;= 2
NaN, when df &lt;= 1</code></pre>
<hr />
<h3 id="class-tf.contrib.distributions.studenttwithabsdfsoftplussigma"><a name="//apple_ref/cpp/Class/StudentTWithAbsDfSoftplusSigma" class="dashAnchor"></a><code id="StudentTWithAbsDfSoftplusSigma">class tf.contrib.distributions.StudentTWithAbsDfSoftplusSigma</code></h3>
<p>StudentT with <code>df = floor(abs(df))</code> and <code>sigma = softplus(sigma)</code>. - - -</p>
<h4 id="tf.contrib.distributions.studenttwithabsdfsoftplussigma.__init__df-mu-sigma-validate_argsfalse-allow_nan_statstrue-namestudenttwithabsdfsoftplussigma"><code id="StudentTWithAbsDfSoftplusSigma.__init__">tf.contrib.distributions.StudentTWithAbsDfSoftplusSigma.__init__(df, mu, sigma, validate_args=False, allow_nan_stats=True, name='StudentTWithAbsDfSoftplusSigma')</code></h4>
<hr />
<h4 id="tf.contrib.distributions.studenttwithabsdfsoftplussigma.allow_nan_stats"><code id="StudentTWithAbsDfSoftplusSigma.allow_nan_stats">tf.contrib.distributions.StudentTWithAbsDfSoftplusSigma.allow_nan_stats</code></h4>
<p>Python boolean describing behavior when a stat is undefined.</p>
<p>Stats return +/- infinity when it makes sense. E.g., the variance of a Cauchy distribution is infinity. However, sometimes the statistic is undefined, e.g., if a distribution's pdf does not achieve a maximum within the support of the distribution, the mode is undefined. If the mean is undefined, then by definition the variance is undefined. E.g. the mean for Student's T for df = 1 is undefined (no clear way to say it is either + or - infinity), so the variance = E[(X - mean)^2] is also undefined.</p>
<h5 id="returns-420">Returns:</h5>
<ul>
<li><b><code>allow_nan_stats</code></b>: Python boolean.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.studenttwithabsdfsoftplussigma.batch_shapenamebatch_shape"><code id="StudentTWithAbsDfSoftplusSigma.batch_shape">tf.contrib.distributions.StudentTWithAbsDfSoftplusSigma.batch_shape(name='batch_shape')</code></h4>
<p>Shape of a single sample from a single event index as a 1-D <code>Tensor</code>.</p>
<p>The product of the dimensions of the <code>batch_shape</code> is the number of independent distributions of this kind the instance represents.</p>
<h5 id="args-370">Args:</h5>
<ul>
<li><b><code>name</code></b>: name to give to the op</li>
</ul>
<h5 id="returns-421">Returns:</h5>
<ul>
<li><b><code>batch_shape</code></b>: <code>Tensor</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.studenttwithabsdfsoftplussigma.cdfvalue-namecdf-condition_kwargs"><code id="StudentTWithAbsDfSoftplusSigma.cdf">tf.contrib.distributions.StudentTWithAbsDfSoftplusSigma.cdf(value, name='cdf', **condition_kwargs)</code></h4>
<p>Cumulative distribution function.</p>
<p>Given random variable <code>X</code>, the cumulative distribution function <code>cdf</code> is:</p>
<pre><code>cdf(x) := P[X &lt;= x]</code></pre>
<h5 id="args-371">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-422">Returns:</h5>
<ul>
<li><b><code>cdf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.studenttwithabsdfsoftplussigma.copyoverride_parameters_kwargs"><code id="StudentTWithAbsDfSoftplusSigma.copy">tf.contrib.distributions.StudentTWithAbsDfSoftplusSigma.copy(**override_parameters_kwargs)</code></h4>
<p>Creates a deep copy of the distribution.</p>
<p>Note: the copy distribution may continue to depend on the original intialization arguments.</p>
<h5 id="args-372">Args:</h5>
<ul>
<li><b><code>**override_parameters_kwargs</code></b>: String/value dictionary of initialization arguments to override with new values.</li>
</ul>
<h5 id="returns-423">Returns:</h5>
<ul>
<li><b><code>distribution</code></b>: A new instance of <code>type(self)</code> intitialized from the union of self.parameters and override_parameters_kwargs, i.e., <code>dict(self.parameters, **override_parameters_kwargs)</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.studenttwithabsdfsoftplussigma.df"><code id="StudentTWithAbsDfSoftplusSigma.df">tf.contrib.distributions.StudentTWithAbsDfSoftplusSigma.df</code></h4>
<p>Degrees of freedom in these Student's t distribution(s).</p>
<hr />
<h4 id="tf.contrib.distributions.studenttwithabsdfsoftplussigma.dtype"><code id="StudentTWithAbsDfSoftplusSigma.dtype">tf.contrib.distributions.StudentTWithAbsDfSoftplusSigma.dtype</code></h4>
<p>The <code>DType</code> of <code>Tensor</code>s handled by this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.studenttwithabsdfsoftplussigma.entropynameentropy"><code id="StudentTWithAbsDfSoftplusSigma.entropy">tf.contrib.distributions.StudentTWithAbsDfSoftplusSigma.entropy(name='entropy')</code></h4>
<p>Shannon entropy in nats.</p>
<hr />
<h4 id="tf.contrib.distributions.studenttwithabsdfsoftplussigma.event_shapenameevent_shape"><code id="StudentTWithAbsDfSoftplusSigma.event_shape">tf.contrib.distributions.StudentTWithAbsDfSoftplusSigma.event_shape(name='event_shape')</code></h4>
<p>Shape of a single sample from a single batch as a 1-D int32 <code>Tensor</code>.</p>
<h5 id="args-373">Args:</h5>
<ul>
<li><b><code>name</code></b>: name to give to the op</li>
</ul>
<h5 id="returns-424">Returns:</h5>
<ul>
<li><b><code>event_shape</code></b>: <code>Tensor</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.studenttwithabsdfsoftplussigma.get_batch_shape"><code id="StudentTWithAbsDfSoftplusSigma.get_batch_shape">tf.contrib.distributions.StudentTWithAbsDfSoftplusSigma.get_batch_shape()</code></h4>
<p>Shape of a single sample from a single event index as a <code>TensorShape</code>.</p>
<p>Same meaning as <code>batch_shape</code>. May be only partially defined.</p>
<h5 id="returns-425">Returns:</h5>
<ul>
<li><b><code>batch_shape</code></b>: <code>TensorShape</code>, possibly unknown.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.studenttwithabsdfsoftplussigma.get_event_shape"><code id="StudentTWithAbsDfSoftplusSigma.get_event_shape">tf.contrib.distributions.StudentTWithAbsDfSoftplusSigma.get_event_shape()</code></h4>
<p>Shape of a single sample from a single batch as a <code>TensorShape</code>.</p>
<p>Same meaning as <code>event_shape</code>. May be only partially defined.</p>
<h5 id="returns-426">Returns:</h5>
<ul>
<li><b><code>event_shape</code></b>: <code>TensorShape</code>, possibly unknown.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.studenttwithabsdfsoftplussigma.is_continuous"><code id="StudentTWithAbsDfSoftplusSigma.is_continuous">tf.contrib.distributions.StudentTWithAbsDfSoftplusSigma.is_continuous</code></h4>
<hr />
<h4 id="tf.contrib.distributions.studenttwithabsdfsoftplussigma.is_reparameterized"><code id="StudentTWithAbsDfSoftplusSigma.is_reparameterized">tf.contrib.distributions.StudentTWithAbsDfSoftplusSigma.is_reparameterized</code></h4>
<hr />
<h4 id="tf.contrib.distributions.studenttwithabsdfsoftplussigma.log_cdfvalue-namelog_cdf-condition_kwargs"><code id="StudentTWithAbsDfSoftplusSigma.log_cdf">tf.contrib.distributions.StudentTWithAbsDfSoftplusSigma.log_cdf(value, name='log_cdf', **condition_kwargs)</code></h4>
<p>Log cumulative distribution function.</p>
<p>Given random variable <code>X</code>, the cumulative distribution function <code>cdf</code> is:</p>
<pre><code>log_cdf(x) := Log[ P[X &lt;= x] ]</code></pre>
<p>Often, a numerical approximation can be used for <code>log_cdf(x)</code> that yields a more accurate answer than simply taking the logarithm of the <code>cdf</code> when <code>x &lt;&lt; -1</code>.</p>
<h5 id="args-374">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-427">Returns:</h5>
<ul>
<li><b><code>logcdf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.studenttwithabsdfsoftplussigma.log_pdfvalue-namelog_pdf-condition_kwargs"><code id="StudentTWithAbsDfSoftplusSigma.log_pdf">tf.contrib.distributions.StudentTWithAbsDfSoftplusSigma.log_pdf(value, name='log_pdf', **condition_kwargs)</code></h4>
<p>Log probability density function.</p>
<h5 id="args-375">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-428">Returns:</h5>
<ul>
<li><b><code>log_prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-133">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if not <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.studenttwithabsdfsoftplussigma.log_pmfvalue-namelog_pmf-condition_kwargs"><code id="StudentTWithAbsDfSoftplusSigma.log_pmf">tf.contrib.distributions.StudentTWithAbsDfSoftplusSigma.log_pmf(value, name='log_pmf', **condition_kwargs)</code></h4>
<p>Log probability mass function.</p>
<h5 id="args-376">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-429">Returns:</h5>
<ul>
<li><b><code>log_pmf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-134">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.studenttwithabsdfsoftplussigma.log_probvalue-namelog_prob-condition_kwargs"><code id="StudentTWithAbsDfSoftplusSigma.log_prob">tf.contrib.distributions.StudentTWithAbsDfSoftplusSigma.log_prob(value, name='log_prob', **condition_kwargs)</code></h4>
<p>Log probability density/mass function (depending on <code>is_continuous</code>).</p>
<h5 id="args-377">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-430">Returns:</h5>
<ul>
<li><b><code>log_prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.studenttwithabsdfsoftplussigma.log_survival_functionvalue-namelog_survival_function-condition_kwargs"><code id="StudentTWithAbsDfSoftplusSigma.log_survival_function">tf.contrib.distributions.StudentTWithAbsDfSoftplusSigma.log_survival_function(value, name='log_survival_function', **condition_kwargs)</code></h4>
<p>Log survival function.</p>
<p>Given random variable <code>X</code>, the survival function is defined:</p>
<pre><code>log_survival_function(x) = Log[ P[X &gt; x] ]
                         = Log[ 1 - P[X &lt;= x] ]
                         = Log[ 1 - cdf(x) ]</code></pre>
<p>Typically, different numerical approximations can be used for the log survival function, which are more accurate than <code>1 - cdf(x)</code> when <code>x &gt;&gt; 1</code>.</p>
<h5 id="args-378">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-431">Returns:</h5>
<p><code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.studenttwithabsdfsoftplussigma.meannamemean"><code id="StudentTWithAbsDfSoftplusSigma.mean">tf.contrib.distributions.StudentTWithAbsDfSoftplusSigma.mean(name='mean')</code></h4>
<p>Mean.</p>
<p>Additional documentation from <code>StudentT</code>:</p>
<p>The mean of Student's T equals <code>mu</code> if <code>df &gt; 1</code>, otherwise it is <code>NaN</code>. If <code>self.allow_nan_stats=True</code>, then an exception will be raised rather than returning <code>NaN</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.studenttwithabsdfsoftplussigma.modenamemode"><code id="StudentTWithAbsDfSoftplusSigma.mode">tf.contrib.distributions.StudentTWithAbsDfSoftplusSigma.mode(name='mode')</code></h4>
<p>Mode.</p>
<hr />
<h4 id="tf.contrib.distributions.studenttwithabsdfsoftplussigma.mu"><code id="StudentTWithAbsDfSoftplusSigma.mu">tf.contrib.distributions.StudentTWithAbsDfSoftplusSigma.mu</code></h4>
<p>Locations of these Student's t distribution(s).</p>
<hr />
<h4 id="tf.contrib.distributions.studenttwithabsdfsoftplussigma.name"><code id="StudentTWithAbsDfSoftplusSigma.name">tf.contrib.distributions.StudentTWithAbsDfSoftplusSigma.name</code></h4>
<p>Name prepended to all ops created by this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.studenttwithabsdfsoftplussigma.param_shapescls-sample_shape-namedistributionparamshapes"><code id="StudentTWithAbsDfSoftplusSigma.param_shapes">tf.contrib.distributions.StudentTWithAbsDfSoftplusSigma.param_shapes(cls, sample_shape, name='DistributionParamShapes')</code></h4>
<p>Shapes of parameters given the desired shape of a call to <code>sample()</code>.</p>
<p>Subclasses should override static method <code>_param_shapes</code>.</p>
<h5 id="args-379">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: <code>Tensor</code> or python list/tuple. Desired shape of a call to <code>sample()</code>.</li>
<li><b><code>name</code></b>: name to prepend ops with.</li>
</ul>
<h5 id="returns-432">Returns:</h5>
<p><code>dict</code> of parameter name to <code>Tensor</code> shapes.</p>
<hr />
<h4 id="tf.contrib.distributions.studenttwithabsdfsoftplussigma.param_static_shapescls-sample_shape"><code id="StudentTWithAbsDfSoftplusSigma.param_static_shapes">tf.contrib.distributions.StudentTWithAbsDfSoftplusSigma.param_static_shapes(cls, sample_shape)</code></h4>
<p>param_shapes with static (i.e. TensorShape) shapes.</p>
<h5 id="args-380">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: <code>TensorShape</code> or python list/tuple. Desired shape of a call to <code>sample()</code>.</li>
</ul>
<h5 id="returns-433">Returns:</h5>
<p><code>dict</code> of parameter name to <code>TensorShape</code>.</p>
<h5 id="raises-135">Raises:</h5>
<ul>
<li><b><code>ValueError</code></b>: if <code>sample_shape</code> is a <code>TensorShape</code> and is not fully defined.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.studenttwithabsdfsoftplussigma.parameters"><code id="StudentTWithAbsDfSoftplusSigma.parameters">tf.contrib.distributions.StudentTWithAbsDfSoftplusSigma.parameters</code></h4>
<p>Dictionary of parameters used to instantiate this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.studenttwithabsdfsoftplussigma.pdfvalue-namepdf-condition_kwargs"><code id="StudentTWithAbsDfSoftplusSigma.pdf">tf.contrib.distributions.StudentTWithAbsDfSoftplusSigma.pdf(value, name='pdf', **condition_kwargs)</code></h4>
<p>Probability density function.</p>
<h5 id="args-381">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-434">Returns:</h5>
<ul>
<li><b><code>prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-136">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if not <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.studenttwithabsdfsoftplussigma.pmfvalue-namepmf-condition_kwargs"><code id="StudentTWithAbsDfSoftplusSigma.pmf">tf.contrib.distributions.StudentTWithAbsDfSoftplusSigma.pmf(value, name='pmf', **condition_kwargs)</code></h4>
<p>Probability mass function.</p>
<h5 id="args-382">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-435">Returns:</h5>
<ul>
<li><b><code>pmf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-137">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.studenttwithabsdfsoftplussigma.probvalue-nameprob-condition_kwargs"><code id="StudentTWithAbsDfSoftplusSigma.prob">tf.contrib.distributions.StudentTWithAbsDfSoftplusSigma.prob(value, name='prob', **condition_kwargs)</code></h4>
<p>Probability density/mass function (depending on <code>is_continuous</code>).</p>
<h5 id="args-383">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-436">Returns:</h5>
<ul>
<li><b><code>prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.studenttwithabsdfsoftplussigma.samplesample_shape-seednone-namesample-condition_kwargs"><code id="StudentTWithAbsDfSoftplusSigma.sample">tf.contrib.distributions.StudentTWithAbsDfSoftplusSigma.sample(sample_shape=(), seed=None, name='sample', **condition_kwargs)</code></h4>
<p>Generate samples of the specified shape.</p>
<p>Note that a call to <code>sample()</code> without arguments will generate a single sample.</p>
<h5 id="args-384">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: 0D or 1D <code>int32</code> <code>Tensor</code>. Shape of the generated samples.</li>
<li><b><code>seed</code></b>: Python integer seed for RNG</li>
<li><b><code>name</code></b>: name to give to the op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-437">Returns:</h5>
<ul>
<li><b><code>samples</code></b>: a <code>Tensor</code> with prepended dimensions <code>sample_shape</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.studenttwithabsdfsoftplussigma.sample_nn-seednone-namesample_n-condition_kwargs"><code id="StudentTWithAbsDfSoftplusSigma.sample_n">tf.contrib.distributions.StudentTWithAbsDfSoftplusSigma.sample_n(n, seed=None, name='sample_n', **condition_kwargs)</code></h4>
<p>Generate <code>n</code> samples.</p>
<h5 id="args-385">Args:</h5>
<ul>
<li><b><code>n</code></b>: <code>Scalar</code> <code>Tensor</code> of type <code>int32</code> or <code>int64</code>, the number of observations to sample.</li>
<li><b><code>seed</code></b>: Python integer seed for RNG</li>
<li><b><code>name</code></b>: name to give to the op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-438">Returns:</h5>
<ul>
<li><b><code>samples</code></b>: a <code>Tensor</code> with a prepended dimension (n,).</li>
</ul>
<h5 id="raises-138">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>n</code> is not an integer type.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.studenttwithabsdfsoftplussigma.sigma"><code id="StudentTWithAbsDfSoftplusSigma.sigma">tf.contrib.distributions.StudentTWithAbsDfSoftplusSigma.sigma</code></h4>
<p>Scaling factors of these Student's t distribution(s).</p>
<hr />
<h4 id="tf.contrib.distributions.studenttwithabsdfsoftplussigma.stdnamestd"><code id="StudentTWithAbsDfSoftplusSigma.std">tf.contrib.distributions.StudentTWithAbsDfSoftplusSigma.std(name='std')</code></h4>
<p>Standard deviation.</p>
<hr />
<h4 id="tf.contrib.distributions.studenttwithabsdfsoftplussigma.survival_functionvalue-namesurvival_function-condition_kwargs"><code id="StudentTWithAbsDfSoftplusSigma.survival_function">tf.contrib.distributions.StudentTWithAbsDfSoftplusSigma.survival_function(value, name='survival_function', **condition_kwargs)</code></h4>
<p>Survival function.</p>
<p>Given random variable <code>X</code>, the survival function is defined:</p>
<pre><code>survival_function(x) = P[X &gt; x]
                     = 1 - P[X &lt;= x]
                     = 1 - cdf(x).</code></pre>
<h5 id="args-386">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-439">Returns:</h5>
<p>Tensor<code>of shape</code>sample_shape(x) + self.batch_shape<code>with values of type</code>self.dtype`.</p>
<hr />
<h4 id="tf.contrib.distributions.studenttwithabsdfsoftplussigma.validate_args"><code id="StudentTWithAbsDfSoftplusSigma.validate_args">tf.contrib.distributions.StudentTWithAbsDfSoftplusSigma.validate_args</code></h4>
<p>Python boolean indicated possibly expensive checks are enabled.</p>
<hr />
<h4 id="tf.contrib.distributions.studenttwithabsdfsoftplussigma.variancenamevariance"><code id="StudentTWithAbsDfSoftplusSigma.variance">tf.contrib.distributions.StudentTWithAbsDfSoftplusSigma.variance(name='variance')</code></h4>
<p>Variance.</p>
<p>Additional documentation from <code>StudentT</code>:</p>
<p>The variance for Student's T equals</p>
<pre><code>df / (df - 2), when df &gt; 2
infinity, when 1 &lt; df &lt;= 2
NaN, when df &lt;= 1</code></pre>
<hr />
<h3 id="class-tf.contrib.distributions.uniform"><a name="//apple_ref/cpp/Class/Uniform" class="dashAnchor"></a><code id="Uniform">class tf.contrib.distributions.Uniform</code></h3>
<p>Uniform distribution with <code>a</code> and <code>b</code> parameters.</p>
<p>The PDF of this distribution is constant between [<code>a</code>, <code>b</code>], and 0 elsewhere. - - -</p>
<h4 id="tf.contrib.distributions.uniform.__init__a0.0-b1.0-validate_argsfalse-allow_nan_statstrue-nameuniform"><code id="Uniform.__init__">tf.contrib.distributions.Uniform.__init__(a=0.0, b=1.0, validate_args=False, allow_nan_stats=True, name='Uniform')</code></h4>
<p>Construct Uniform distributions with <code>a</code> and <code>b</code>.</p>
<p>The parameters <code>a</code> and <code>b</code> must be shaped in a way that supports broadcasting (e.g. <code>b - a</code> is a valid operation).</p>
<p>Here are examples without broadcasting:</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="co"># Without broadcasting</span>
u1 <span class="op">=</span> Uniform(<span class="fl">3.0</span>, <span class="fl">4.0</span>)  <span class="co"># a single uniform distribution [3, 4]</span>
u2 <span class="op">=</span> Uniform([<span class="fl">1.0</span>, <span class="fl">2.0</span>], [<span class="fl">3.0</span>, <span class="fl">4.0</span>])  <span class="co"># 2 distributions [1, 3], [2, 4]</span>
u3 <span class="op">=</span> Uniform([[<span class="fl">1.0</span>, <span class="fl">2.0</span>],
              [<span class="fl">3.0</span>, <span class="fl">4.0</span>]],
             [[<span class="fl">1.5</span>, <span class="fl">2.5</span>],
              [<span class="fl">3.5</span>, <span class="fl">4.5</span>]])  <span class="co"># 4 distributions</span></code></pre></div>
<p>And with broadcasting:</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">u1 <span class="op">=</span> Uniform(<span class="fl">3.0</span>, [<span class="fl">5.0</span>, <span class="fl">6.0</span>, <span class="fl">7.0</span>])  <span class="co"># 3 distributions</span></code></pre></div>
<h5 id="args-387">Args:</h5>
<ul>
<li><b><code>a</code></b>: Floating point tensor, the minimum endpoint.</li>
<li><b><code>b</code></b>: Floating point tensor, the maximum endpoint. Must be &gt; <code>a</code>.</li>
<li><b><code>validate_args</code></b>: <code>Boolean</code>, default <code>False</code>. Whether to validate input with asserts. If <code>validate_args</code> is <code>False</code>, and the inputs are invalid, correct behavior is not guaranteed.</li>
<li><b><code>allow_nan_stats</code></b>: <code>Boolean</code>, default <code>True</code>. If <code>False</code>, raise an exception if a statistic (e.g. mean/mode/etc...) is undefined for any batch member. If <code>True</code>, batch members with valid parameters leading to undefined statistics will return NaN for this statistic.</li>
<li><b><code>name</code></b>: The name to prefix Ops created by this distribution class.</li>
</ul>
<h5 id="raises-139">Raises:</h5>
<ul>
<li><b><code>InvalidArgumentError</code></b>: if <code>a &gt;= b</code> and <code>validate_args=False</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.uniform.a"><code id="Uniform.a">tf.contrib.distributions.Uniform.a</code></h4>
<hr />
<h4 id="tf.contrib.distributions.uniform.allow_nan_stats"><code id="Uniform.allow_nan_stats">tf.contrib.distributions.Uniform.allow_nan_stats</code></h4>
<p>Python boolean describing behavior when a stat is undefined.</p>
<p>Stats return +/- infinity when it makes sense. E.g., the variance of a Cauchy distribution is infinity. However, sometimes the statistic is undefined, e.g., if a distribution's pdf does not achieve a maximum within the support of the distribution, the mode is undefined. If the mean is undefined, then by definition the variance is undefined. E.g. the mean for Student's T for df = 1 is undefined (no clear way to say it is either + or - infinity), so the variance = E[(X - mean)^2] is also undefined.</p>
<h5 id="returns-440">Returns:</h5>
<ul>
<li><b><code>allow_nan_stats</code></b>: Python boolean.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.uniform.b"><code id="Uniform.b">tf.contrib.distributions.Uniform.b</code></h4>
<hr />
<h4 id="tf.contrib.distributions.uniform.batch_shapenamebatch_shape"><code id="Uniform.batch_shape">tf.contrib.distributions.Uniform.batch_shape(name='batch_shape')</code></h4>
<p>Shape of a single sample from a single event index as a 1-D <code>Tensor</code>.</p>
<p>The product of the dimensions of the <code>batch_shape</code> is the number of independent distributions of this kind the instance represents.</p>
<h5 id="args-388">Args:</h5>
<ul>
<li><b><code>name</code></b>: name to give to the op</li>
</ul>
<h5 id="returns-441">Returns:</h5>
<ul>
<li><b><code>batch_shape</code></b>: <code>Tensor</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.uniform.cdfvalue-namecdf-condition_kwargs"><code id="Uniform.cdf">tf.contrib.distributions.Uniform.cdf(value, name='cdf', **condition_kwargs)</code></h4>
<p>Cumulative distribution function.</p>
<p>Given random variable <code>X</code>, the cumulative distribution function <code>cdf</code> is:</p>
<pre><code>cdf(x) := P[X &lt;= x]</code></pre>
<h5 id="args-389">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-442">Returns:</h5>
<ul>
<li><b><code>cdf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.uniform.copyoverride_parameters_kwargs"><code id="Uniform.copy">tf.contrib.distributions.Uniform.copy(**override_parameters_kwargs)</code></h4>
<p>Creates a deep copy of the distribution.</p>
<p>Note: the copy distribution may continue to depend on the original intialization arguments.</p>
<h5 id="args-390">Args:</h5>
<ul>
<li><b><code>**override_parameters_kwargs</code></b>: String/value dictionary of initialization arguments to override with new values.</li>
</ul>
<h5 id="returns-443">Returns:</h5>
<ul>
<li><b><code>distribution</code></b>: A new instance of <code>type(self)</code> intitialized from the union of self.parameters and override_parameters_kwargs, i.e., <code>dict(self.parameters, **override_parameters_kwargs)</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.uniform.dtype"><code id="Uniform.dtype">tf.contrib.distributions.Uniform.dtype</code></h4>
<p>The <code>DType</code> of <code>Tensor</code>s handled by this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.uniform.entropynameentropy"><code id="Uniform.entropy">tf.contrib.distributions.Uniform.entropy(name='entropy')</code></h4>
<p>Shannon entropy in nats.</p>
<hr />
<h4 id="tf.contrib.distributions.uniform.event_shapenameevent_shape"><code id="Uniform.event_shape">tf.contrib.distributions.Uniform.event_shape(name='event_shape')</code></h4>
<p>Shape of a single sample from a single batch as a 1-D int32 <code>Tensor</code>.</p>
<h5 id="args-391">Args:</h5>
<ul>
<li><b><code>name</code></b>: name to give to the op</li>
</ul>
<h5 id="returns-444">Returns:</h5>
<ul>
<li><b><code>event_shape</code></b>: <code>Tensor</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.uniform.get_batch_shape"><code id="Uniform.get_batch_shape">tf.contrib.distributions.Uniform.get_batch_shape()</code></h4>
<p>Shape of a single sample from a single event index as a <code>TensorShape</code>.</p>
<p>Same meaning as <code>batch_shape</code>. May be only partially defined.</p>
<h5 id="returns-445">Returns:</h5>
<ul>
<li><b><code>batch_shape</code></b>: <code>TensorShape</code>, possibly unknown.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.uniform.get_event_shape"><code id="Uniform.get_event_shape">tf.contrib.distributions.Uniform.get_event_shape()</code></h4>
<p>Shape of a single sample from a single batch as a <code>TensorShape</code>.</p>
<p>Same meaning as <code>event_shape</code>. May be only partially defined.</p>
<h5 id="returns-446">Returns:</h5>
<ul>
<li><b><code>event_shape</code></b>: <code>TensorShape</code>, possibly unknown.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.uniform.is_continuous"><code id="Uniform.is_continuous">tf.contrib.distributions.Uniform.is_continuous</code></h4>
<hr />
<h4 id="tf.contrib.distributions.uniform.is_reparameterized"><code id="Uniform.is_reparameterized">tf.contrib.distributions.Uniform.is_reparameterized</code></h4>
<hr />
<h4 id="tf.contrib.distributions.uniform.log_cdfvalue-namelog_cdf-condition_kwargs"><code id="Uniform.log_cdf">tf.contrib.distributions.Uniform.log_cdf(value, name='log_cdf', **condition_kwargs)</code></h4>
<p>Log cumulative distribution function.</p>
<p>Given random variable <code>X</code>, the cumulative distribution function <code>cdf</code> is:</p>
<pre><code>log_cdf(x) := Log[ P[X &lt;= x] ]</code></pre>
<p>Often, a numerical approximation can be used for <code>log_cdf(x)</code> that yields a more accurate answer than simply taking the logarithm of the <code>cdf</code> when <code>x &lt;&lt; -1</code>.</p>
<h5 id="args-392">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-447">Returns:</h5>
<ul>
<li><b><code>logcdf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.uniform.log_pdfvalue-namelog_pdf-condition_kwargs"><code id="Uniform.log_pdf">tf.contrib.distributions.Uniform.log_pdf(value, name='log_pdf', **condition_kwargs)</code></h4>
<p>Log probability density function.</p>
<h5 id="args-393">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-448">Returns:</h5>
<ul>
<li><b><code>log_prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-140">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if not <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.uniform.log_pmfvalue-namelog_pmf-condition_kwargs"><code id="Uniform.log_pmf">tf.contrib.distributions.Uniform.log_pmf(value, name='log_pmf', **condition_kwargs)</code></h4>
<p>Log probability mass function.</p>
<h5 id="args-394">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-449">Returns:</h5>
<ul>
<li><b><code>log_pmf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-141">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.uniform.log_probvalue-namelog_prob-condition_kwargs"><code id="Uniform.log_prob">tf.contrib.distributions.Uniform.log_prob(value, name='log_prob', **condition_kwargs)</code></h4>
<p>Log probability density/mass function (depending on <code>is_continuous</code>).</p>
<h5 id="args-395">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-450">Returns:</h5>
<ul>
<li><b><code>log_prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.uniform.log_survival_functionvalue-namelog_survival_function-condition_kwargs"><code id="Uniform.log_survival_function">tf.contrib.distributions.Uniform.log_survival_function(value, name='log_survival_function', **condition_kwargs)</code></h4>
<p>Log survival function.</p>
<p>Given random variable <code>X</code>, the survival function is defined:</p>
<pre><code>log_survival_function(x) = Log[ P[X &gt; x] ]
                         = Log[ 1 - P[X &lt;= x] ]
                         = Log[ 1 - cdf(x) ]</code></pre>
<p>Typically, different numerical approximations can be used for the log survival function, which are more accurate than <code>1 - cdf(x)</code> when <code>x &gt;&gt; 1</code>.</p>
<h5 id="args-396">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-451">Returns:</h5>
<p><code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.uniform.meannamemean"><code id="Uniform.mean">tf.contrib.distributions.Uniform.mean(name='mean')</code></h4>
<p>Mean.</p>
<hr />
<h4 id="tf.contrib.distributions.uniform.modenamemode"><code id="Uniform.mode">tf.contrib.distributions.Uniform.mode(name='mode')</code></h4>
<p>Mode.</p>
<hr />
<h4 id="tf.contrib.distributions.uniform.name"><code id="Uniform.name">tf.contrib.distributions.Uniform.name</code></h4>
<p>Name prepended to all ops created by this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.uniform.param_shapescls-sample_shape-namedistributionparamshapes"><code id="Uniform.param_shapes">tf.contrib.distributions.Uniform.param_shapes(cls, sample_shape, name='DistributionParamShapes')</code></h4>
<p>Shapes of parameters given the desired shape of a call to <code>sample()</code>.</p>
<p>Subclasses should override static method <code>_param_shapes</code>.</p>
<h5 id="args-397">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: <code>Tensor</code> or python list/tuple. Desired shape of a call to <code>sample()</code>.</li>
<li><b><code>name</code></b>: name to prepend ops with.</li>
</ul>
<h5 id="returns-452">Returns:</h5>
<p><code>dict</code> of parameter name to <code>Tensor</code> shapes.</p>
<hr />
<h4 id="tf.contrib.distributions.uniform.param_static_shapescls-sample_shape"><code id="Uniform.param_static_shapes">tf.contrib.distributions.Uniform.param_static_shapes(cls, sample_shape)</code></h4>
<p>param_shapes with static (i.e. TensorShape) shapes.</p>
<h5 id="args-398">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: <code>TensorShape</code> or python list/tuple. Desired shape of a call to <code>sample()</code>.</li>
</ul>
<h5 id="returns-453">Returns:</h5>
<p><code>dict</code> of parameter name to <code>TensorShape</code>.</p>
<h5 id="raises-142">Raises:</h5>
<ul>
<li><b><code>ValueError</code></b>: if <code>sample_shape</code> is a <code>TensorShape</code> and is not fully defined.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.uniform.parameters"><code id="Uniform.parameters">tf.contrib.distributions.Uniform.parameters</code></h4>
<p>Dictionary of parameters used to instantiate this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.uniform.pdfvalue-namepdf-condition_kwargs"><code id="Uniform.pdf">tf.contrib.distributions.Uniform.pdf(value, name='pdf', **condition_kwargs)</code></h4>
<p>Probability density function.</p>
<h5 id="args-399">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-454">Returns:</h5>
<ul>
<li><b><code>prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-143">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if not <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.uniform.pmfvalue-namepmf-condition_kwargs"><code id="Uniform.pmf">tf.contrib.distributions.Uniform.pmf(value, name='pmf', **condition_kwargs)</code></h4>
<p>Probability mass function.</p>
<h5 id="args-400">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-455">Returns:</h5>
<ul>
<li><b><code>pmf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-144">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.uniform.probvalue-nameprob-condition_kwargs"><code id="Uniform.prob">tf.contrib.distributions.Uniform.prob(value, name='prob', **condition_kwargs)</code></h4>
<p>Probability density/mass function (depending on <code>is_continuous</code>).</p>
<h5 id="args-401">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-456">Returns:</h5>
<ul>
<li><b><code>prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.uniform.rangenamerange"><code id="Uniform.range">tf.contrib.distributions.Uniform.range(name='range')</code></h4>
<p><code>b - a</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.uniform.samplesample_shape-seednone-namesample-condition_kwargs"><code id="Uniform.sample">tf.contrib.distributions.Uniform.sample(sample_shape=(), seed=None, name='sample', **condition_kwargs)</code></h4>
<p>Generate samples of the specified shape.</p>
<p>Note that a call to <code>sample()</code> without arguments will generate a single sample.</p>
<h5 id="args-402">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: 0D or 1D <code>int32</code> <code>Tensor</code>. Shape of the generated samples.</li>
<li><b><code>seed</code></b>: Python integer seed for RNG</li>
<li><b><code>name</code></b>: name to give to the op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-457">Returns:</h5>
<ul>
<li><b><code>samples</code></b>: a <code>Tensor</code> with prepended dimensions <code>sample_shape</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.uniform.sample_nn-seednone-namesample_n-condition_kwargs"><code id="Uniform.sample_n">tf.contrib.distributions.Uniform.sample_n(n, seed=None, name='sample_n', **condition_kwargs)</code></h4>
<p>Generate <code>n</code> samples.</p>
<h5 id="args-403">Args:</h5>
<ul>
<li><b><code>n</code></b>: <code>Scalar</code> <code>Tensor</code> of type <code>int32</code> or <code>int64</code>, the number of observations to sample.</li>
<li><b><code>seed</code></b>: Python integer seed for RNG</li>
<li><b><code>name</code></b>: name to give to the op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-458">Returns:</h5>
<ul>
<li><b><code>samples</code></b>: a <code>Tensor</code> with a prepended dimension (n,).</li>
</ul>
<h5 id="raises-145">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>n</code> is not an integer type.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.uniform.stdnamestd"><code id="Uniform.std">tf.contrib.distributions.Uniform.std(name='std')</code></h4>
<p>Standard deviation.</p>
<hr />
<h4 id="tf.contrib.distributions.uniform.survival_functionvalue-namesurvival_function-condition_kwargs"><code id="Uniform.survival_function">tf.contrib.distributions.Uniform.survival_function(value, name='survival_function', **condition_kwargs)</code></h4>
<p>Survival function.</p>
<p>Given random variable <code>X</code>, the survival function is defined:</p>
<pre><code>survival_function(x) = P[X &gt; x]
                     = 1 - P[X &lt;= x]
                     = 1 - cdf(x).</code></pre>
<h5 id="args-404">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-459">Returns:</h5>
<p>Tensor<code>of shape</code>sample_shape(x) + self.batch_shape<code>with values of type</code>self.dtype`.</p>
<hr />
<h4 id="tf.contrib.distributions.uniform.validate_args"><code id="Uniform.validate_args">tf.contrib.distributions.Uniform.validate_args</code></h4>
<p>Python boolean indicated possibly expensive checks are enabled.</p>
<hr />
<h4 id="tf.contrib.distributions.uniform.variancenamevariance"><code id="Uniform.variance">tf.contrib.distributions.Uniform.variance(name='variance')</code></h4>
<p>Variance.</p>
<h2 id="multivariate-distributions">Multivariate distributions</h2>
<h3 id="multivariate-normal">Multivariate normal</h3>
<hr />
<h3 id="class-tf.contrib.distributions.multivariatenormaldiag"><a name="//apple_ref/cpp/Class/MultivariateNormalDiag" class="dashAnchor"></a><code id="MultivariateNormalDiag">class tf.contrib.distributions.MultivariateNormalDiag</code></h3>
<p>The multivariate normal distribution on <code>R^k</code>.</p>
<p>This distribution is defined by a 1-D mean <code>mu</code> and a 1-D diagonal <code>diag_stdev</code>, representing the standard deviations. This distribution assumes the random variables, <code>(X_1,...,X_k)</code> are independent, thus no non-diagonal terms of the covariance matrix are needed.</p>
<p>This allows for <code>O(k)</code> pdf evaluation, sampling, and storage.</p>
<h4 id="mathematical-details-5">Mathematical details</h4>
<p>The PDF of this distribution is defined in terms of the diagonal covariance determined by <code>diag_stdev</code>: <code>C_{ii} = diag_stdev[i]**2</code>.</p>
<pre><code>f(x) = (2 pi)^(-k/2) |det(C)|^(-1/2) exp(-1/2 (x - mu)^T C^{-1} (x - mu))</code></pre>
<h4 id="examples-5">Examples</h4>
<p>A single multi-variate Gaussian distribution is defined by a vector of means of length <code>k</code>, and the square roots of the (independent) random variables.</p>
<p>Extra leading dimensions, if provided, allow for batches.</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="co"># Initialize a single 3-variate Gaussian with diagonal standard deviation.</span>
mu <span class="op">=</span> [<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>.]
diag_stdev <span class="op">=</span> [<span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">6</span>.]
dist <span class="op">=</span> tf.contrib.distributions.MultivariateNormalDiag(mu, diag_stdev)

<span class="co"># Evaluate this on an observation in R^3, returning a scalar.</span>
dist.pdf([<span class="op">-</span><span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>])

<span class="co"># Initialize a batch of two 3-variate Gaussians.</span>
mu <span class="op">=</span> [[<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>], [<span class="dv">11</span>, <span class="dv">22</span>, <span class="dv">33</span>]]  <span class="co"># shape 2 x 3</span>
diag_stdev <span class="op">=</span> ...  <span class="co"># shape 2 x 3, positive.</span>
dist <span class="op">=</span> tf.contrib.distributions.MultivariateNormalDiag(mu, diag_stdev)

<span class="co"># Evaluate this on a two observations, each in R^3, returning a length two</span>
<span class="co"># tensor.</span>
x <span class="op">=</span> [[<span class="op">-</span><span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>], [<span class="op">-</span><span class="dv">11</span>, <span class="dv">0</span>, <span class="dv">11</span>]]  <span class="co"># Shape 2 x 3.</span>
dist.pdf(x)</code></pre></div>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiag.__init__mu-diag_stdev-validate_argsfalse-allow_nan_statstrue-namemultivariatenormaldiag"><code id="MultivariateNormalDiag.__init__">tf.contrib.distributions.MultivariateNormalDiag.__init__(mu, diag_stdev, validate_args=False, allow_nan_stats=True, name='MultivariateNormalDiag')</code></h4>
<p>Multivariate Normal distributions on <code>R^k</code>.</p>
<p>User must provide means <code>mu</code> and standard deviations <code>diag_stdev</code>. Each batch member represents a random vector <code>(X_1,...,X_k)</code> of independent random normals. The mean of <code>X_i</code> is <code>mu[i]</code>, and the standard deviation is <code>diag_stdev[i]</code>.</p>
<h5 id="args-405">Args:</h5>
<ul>
<li><b><code>mu</code></b>: Rank <code>N + 1</code> floating point tensor with shape <code>[N1,...,Nb, k]</code>, <code>b &gt;= 0</code>.</li>
<li><b><code>diag_stdev</code></b>: Rank <code>N + 1</code> <code>Tensor</code> with same <code>dtype</code> and shape as <code>mu</code>, representing the standard deviations. Must be positive.</li>
<li><b><code>validate_args</code></b>: <code>Boolean</code>, default <code>False</code>. Whether to validate input with asserts. If <code>validate_args</code> is <code>False</code>, and the inputs are invalid, correct behavior is not guaranteed.</li>
<li><b><code>allow_nan_stats</code></b>: <code>Boolean</code>, default <code>True</code>. If <code>False</code>, raise an exception if a statistic (e.g. mean/mode/etc...) is undefined for any batch member If <code>True</code>, batch members with valid parameters leading to undefined statistics will return NaN for this statistic.</li>
<li><b><code>name</code></b>: The name to give Ops created by the initializer.</li>
</ul>
<h5 id="raises-146">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: If <code>mu</code> and <code>diag_stdev</code> are different dtypes.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiag.allow_nan_stats"><code id="MultivariateNormalDiag.allow_nan_stats">tf.contrib.distributions.MultivariateNormalDiag.allow_nan_stats</code></h4>
<p>Python boolean describing behavior when a stat is undefined.</p>
<p>Stats return +/- infinity when it makes sense. E.g., the variance of a Cauchy distribution is infinity. However, sometimes the statistic is undefined, e.g., if a distribution's pdf does not achieve a maximum within the support of the distribution, the mode is undefined. If the mean is undefined, then by definition the variance is undefined. E.g. the mean for Student's T for df = 1 is undefined (no clear way to say it is either + or - infinity), so the variance = E[(X - mean)^2] is also undefined.</p>
<h5 id="returns-460">Returns:</h5>
<ul>
<li><b><code>allow_nan_stats</code></b>: Python boolean.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiag.batch_shapenamebatch_shape"><code id="MultivariateNormalDiag.batch_shape">tf.contrib.distributions.MultivariateNormalDiag.batch_shape(name='batch_shape')</code></h4>
<p>Shape of a single sample from a single event index as a 1-D <code>Tensor</code>.</p>
<p>The product of the dimensions of the <code>batch_shape</code> is the number of independent distributions of this kind the instance represents.</p>
<h5 id="args-406">Args:</h5>
<ul>
<li><b><code>name</code></b>: name to give to the op</li>
</ul>
<h5 id="returns-461">Returns:</h5>
<ul>
<li><b><code>batch_shape</code></b>: <code>Tensor</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiag.cdfvalue-namecdf-condition_kwargs"><code id="MultivariateNormalDiag.cdf">tf.contrib.distributions.MultivariateNormalDiag.cdf(value, name='cdf', **condition_kwargs)</code></h4>
<p>Cumulative distribution function.</p>
<p>Given random variable <code>X</code>, the cumulative distribution function <code>cdf</code> is:</p>
<pre><code>cdf(x) := P[X &lt;= x]</code></pre>
<h5 id="args-407">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-462">Returns:</h5>
<ul>
<li><b><code>cdf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiag.copyoverride_parameters_kwargs"><code id="MultivariateNormalDiag.copy">tf.contrib.distributions.MultivariateNormalDiag.copy(**override_parameters_kwargs)</code></h4>
<p>Creates a deep copy of the distribution.</p>
<p>Note: the copy distribution may continue to depend on the original intialization arguments.</p>
<h5 id="args-408">Args:</h5>
<ul>
<li><b><code>**override_parameters_kwargs</code></b>: String/value dictionary of initialization arguments to override with new values.</li>
</ul>
<h5 id="returns-463">Returns:</h5>
<ul>
<li><b><code>distribution</code></b>: A new instance of <code>type(self)</code> intitialized from the union of self.parameters and override_parameters_kwargs, i.e., <code>dict(self.parameters, **override_parameters_kwargs)</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiag.dtype"><code id="MultivariateNormalDiag.dtype">tf.contrib.distributions.MultivariateNormalDiag.dtype</code></h4>
<p>The <code>DType</code> of <code>Tensor</code>s handled by this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiag.entropynameentropy"><code id="MultivariateNormalDiag.entropy">tf.contrib.distributions.MultivariateNormalDiag.entropy(name='entropy')</code></h4>
<p>Shannon entropy in nats.</p>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiag.event_shapenameevent_shape"><code id="MultivariateNormalDiag.event_shape">tf.contrib.distributions.MultivariateNormalDiag.event_shape(name='event_shape')</code></h4>
<p>Shape of a single sample from a single batch as a 1-D int32 <code>Tensor</code>.</p>
<h5 id="args-409">Args:</h5>
<ul>
<li><b><code>name</code></b>: name to give to the op</li>
</ul>
<h5 id="returns-464">Returns:</h5>
<ul>
<li><b><code>event_shape</code></b>: <code>Tensor</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiag.get_batch_shape"><code id="MultivariateNormalDiag.get_batch_shape">tf.contrib.distributions.MultivariateNormalDiag.get_batch_shape()</code></h4>
<p>Shape of a single sample from a single event index as a <code>TensorShape</code>.</p>
<p>Same meaning as <code>batch_shape</code>. May be only partially defined.</p>
<h5 id="returns-465">Returns:</h5>
<ul>
<li><b><code>batch_shape</code></b>: <code>TensorShape</code>, possibly unknown.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiag.get_event_shape"><code id="MultivariateNormalDiag.get_event_shape">tf.contrib.distributions.MultivariateNormalDiag.get_event_shape()</code></h4>
<p>Shape of a single sample from a single batch as a <code>TensorShape</code>.</p>
<p>Same meaning as <code>event_shape</code>. May be only partially defined.</p>
<h5 id="returns-466">Returns:</h5>
<ul>
<li><b><code>event_shape</code></b>: <code>TensorShape</code>, possibly unknown.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiag.is_continuous"><code id="MultivariateNormalDiag.is_continuous">tf.contrib.distributions.MultivariateNormalDiag.is_continuous</code></h4>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiag.is_reparameterized"><code id="MultivariateNormalDiag.is_reparameterized">tf.contrib.distributions.MultivariateNormalDiag.is_reparameterized</code></h4>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiag.log_cdfvalue-namelog_cdf-condition_kwargs"><code id="MultivariateNormalDiag.log_cdf">tf.contrib.distributions.MultivariateNormalDiag.log_cdf(value, name='log_cdf', **condition_kwargs)</code></h4>
<p>Log cumulative distribution function.</p>
<p>Given random variable <code>X</code>, the cumulative distribution function <code>cdf</code> is:</p>
<pre><code>log_cdf(x) := Log[ P[X &lt;= x] ]</code></pre>
<p>Often, a numerical approximation can be used for <code>log_cdf(x)</code> that yields a more accurate answer than simply taking the logarithm of the <code>cdf</code> when <code>x &lt;&lt; -1</code>.</p>
<h5 id="args-410">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-467">Returns:</h5>
<ul>
<li><b><code>logcdf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiag.log_pdfvalue-namelog_pdf-condition_kwargs"><code id="MultivariateNormalDiag.log_pdf">tf.contrib.distributions.MultivariateNormalDiag.log_pdf(value, name='log_pdf', **condition_kwargs)</code></h4>
<p>Log probability density function.</p>
<h5 id="args-411">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-468">Returns:</h5>
<ul>
<li><b><code>log_prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-147">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if not <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiag.log_pmfvalue-namelog_pmf-condition_kwargs"><code id="MultivariateNormalDiag.log_pmf">tf.contrib.distributions.MultivariateNormalDiag.log_pmf(value, name='log_pmf', **condition_kwargs)</code></h4>
<p>Log probability mass function.</p>
<h5 id="args-412">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-469">Returns:</h5>
<ul>
<li><b><code>log_pmf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-148">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiag.log_probvalue-namelog_prob-condition_kwargs"><code id="MultivariateNormalDiag.log_prob">tf.contrib.distributions.MultivariateNormalDiag.log_prob(value, name='log_prob', **condition_kwargs)</code></h4>
<p>Log probability density/mass function (depending on <code>is_continuous</code>).</p>
<p>Additional documentation from <code>_MultivariateNormalOperatorPD</code>:</p>
<p><code>x</code> is a batch vector with compatible shape if <code>x</code> is a <code>Tensor</code> whose shape can be broadcast up to either:</p>
<pre><code>self.batch_shape + self.event_shape</code></pre>
<p>or</p>
<pre><code>[M1,...,Mm] + self.batch_shape + self.event_shape</code></pre>
<h5 id="args-413">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-470">Returns:</h5>
<ul>
<li><b><code>log_prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiag.log_sigma_detnamelog_sigma_det"><code id="MultivariateNormalDiag.log_sigma_det">tf.contrib.distributions.MultivariateNormalDiag.log_sigma_det(name='log_sigma_det')</code></h4>
<p>Log of determinant of covariance matrix.</p>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiag.log_survival_functionvalue-namelog_survival_function-condition_kwargs"><code id="MultivariateNormalDiag.log_survival_function">tf.contrib.distributions.MultivariateNormalDiag.log_survival_function(value, name='log_survival_function', **condition_kwargs)</code></h4>
<p>Log survival function.</p>
<p>Given random variable <code>X</code>, the survival function is defined:</p>
<pre><code>log_survival_function(x) = Log[ P[X &gt; x] ]
                         = Log[ 1 - P[X &lt;= x] ]
                         = Log[ 1 - cdf(x) ]</code></pre>
<p>Typically, different numerical approximations can be used for the log survival function, which are more accurate than <code>1 - cdf(x)</code> when <code>x &gt;&gt; 1</code>.</p>
<h5 id="args-414">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-471">Returns:</h5>
<p><code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiag.meannamemean"><code id="MultivariateNormalDiag.mean">tf.contrib.distributions.MultivariateNormalDiag.mean(name='mean')</code></h4>
<p>Mean.</p>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiag.modenamemode"><code id="MultivariateNormalDiag.mode">tf.contrib.distributions.MultivariateNormalDiag.mode(name='mode')</code></h4>
<p>Mode.</p>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiag.mu"><code id="MultivariateNormalDiag.mu">tf.contrib.distributions.MultivariateNormalDiag.mu</code></h4>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiag.name"><code id="MultivariateNormalDiag.name">tf.contrib.distributions.MultivariateNormalDiag.name</code></h4>
<p>Name prepended to all ops created by this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiag.param_shapescls-sample_shape-namedistributionparamshapes"><code id="MultivariateNormalDiag.param_shapes">tf.contrib.distributions.MultivariateNormalDiag.param_shapes(cls, sample_shape, name='DistributionParamShapes')</code></h4>
<p>Shapes of parameters given the desired shape of a call to <code>sample()</code>.</p>
<p>Subclasses should override static method <code>_param_shapes</code>.</p>
<h5 id="args-415">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: <code>Tensor</code> or python list/tuple. Desired shape of a call to <code>sample()</code>.</li>
<li><b><code>name</code></b>: name to prepend ops with.</li>
</ul>
<h5 id="returns-472">Returns:</h5>
<p><code>dict</code> of parameter name to <code>Tensor</code> shapes.</p>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiag.param_static_shapescls-sample_shape"><code id="MultivariateNormalDiag.param_static_shapes">tf.contrib.distributions.MultivariateNormalDiag.param_static_shapes(cls, sample_shape)</code></h4>
<p>param_shapes with static (i.e. TensorShape) shapes.</p>
<h5 id="args-416">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: <code>TensorShape</code> or python list/tuple. Desired shape of a call to <code>sample()</code>.</li>
</ul>
<h5 id="returns-473">Returns:</h5>
<p><code>dict</code> of parameter name to <code>TensorShape</code>.</p>
<h5 id="raises-149">Raises:</h5>
<ul>
<li><b><code>ValueError</code></b>: if <code>sample_shape</code> is a <code>TensorShape</code> and is not fully defined.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiag.parameters"><code id="MultivariateNormalDiag.parameters">tf.contrib.distributions.MultivariateNormalDiag.parameters</code></h4>
<p>Dictionary of parameters used to instantiate this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiag.pdfvalue-namepdf-condition_kwargs"><code id="MultivariateNormalDiag.pdf">tf.contrib.distributions.MultivariateNormalDiag.pdf(value, name='pdf', **condition_kwargs)</code></h4>
<p>Probability density function.</p>
<h5 id="args-417">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-474">Returns:</h5>
<ul>
<li><b><code>prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-150">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if not <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiag.pmfvalue-namepmf-condition_kwargs"><code id="MultivariateNormalDiag.pmf">tf.contrib.distributions.MultivariateNormalDiag.pmf(value, name='pmf', **condition_kwargs)</code></h4>
<p>Probability mass function.</p>
<h5 id="args-418">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-475">Returns:</h5>
<ul>
<li><b><code>pmf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-151">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiag.probvalue-nameprob-condition_kwargs"><code id="MultivariateNormalDiag.prob">tf.contrib.distributions.MultivariateNormalDiag.prob(value, name='prob', **condition_kwargs)</code></h4>
<p>Probability density/mass function (depending on <code>is_continuous</code>).</p>
<p>Additional documentation from <code>_MultivariateNormalOperatorPD</code>:</p>
<p><code>x</code> is a batch vector with compatible shape if <code>x</code> is a <code>Tensor</code> whose shape can be broadcast up to either:</p>
<pre><code>self.batch_shape + self.event_shape</code></pre>
<p>or</p>
<pre><code>[M1,...,Mm] + self.batch_shape + self.event_shape</code></pre>
<h5 id="args-419">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-476">Returns:</h5>
<ul>
<li><b><code>prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiag.samplesample_shape-seednone-namesample-condition_kwargs"><code id="MultivariateNormalDiag.sample">tf.contrib.distributions.MultivariateNormalDiag.sample(sample_shape=(), seed=None, name='sample', **condition_kwargs)</code></h4>
<p>Generate samples of the specified shape.</p>
<p>Note that a call to <code>sample()</code> without arguments will generate a single sample.</p>
<h5 id="args-420">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: 0D or 1D <code>int32</code> <code>Tensor</code>. Shape of the generated samples.</li>
<li><b><code>seed</code></b>: Python integer seed for RNG</li>
<li><b><code>name</code></b>: name to give to the op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-477">Returns:</h5>
<ul>
<li><b><code>samples</code></b>: a <code>Tensor</code> with prepended dimensions <code>sample_shape</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiag.sample_nn-seednone-namesample_n-condition_kwargs"><code id="MultivariateNormalDiag.sample_n">tf.contrib.distributions.MultivariateNormalDiag.sample_n(n, seed=None, name='sample_n', **condition_kwargs)</code></h4>
<p>Generate <code>n</code> samples.</p>
<h5 id="args-421">Args:</h5>
<ul>
<li><b><code>n</code></b>: <code>Scalar</code> <code>Tensor</code> of type <code>int32</code> or <code>int64</code>, the number of observations to sample.</li>
<li><b><code>seed</code></b>: Python integer seed for RNG</li>
<li><b><code>name</code></b>: name to give to the op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-478">Returns:</h5>
<ul>
<li><b><code>samples</code></b>: a <code>Tensor</code> with a prepended dimension (n,).</li>
</ul>
<h5 id="raises-152">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>n</code> is not an integer type.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiag.sigma"><code id="MultivariateNormalDiag.sigma">tf.contrib.distributions.MultivariateNormalDiag.sigma</code></h4>
<p>Dense (batch) covariance matrix, if available.</p>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiag.sigma_detnamesigma_det"><code id="MultivariateNormalDiag.sigma_det">tf.contrib.distributions.MultivariateNormalDiag.sigma_det(name='sigma_det')</code></h4>
<p>Determinant of covariance matrix.</p>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiag.stdnamestd"><code id="MultivariateNormalDiag.std">tf.contrib.distributions.MultivariateNormalDiag.std(name='std')</code></h4>
<p>Standard deviation.</p>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiag.survival_functionvalue-namesurvival_function-condition_kwargs"><code id="MultivariateNormalDiag.survival_function">tf.contrib.distributions.MultivariateNormalDiag.survival_function(value, name='survival_function', **condition_kwargs)</code></h4>
<p>Survival function.</p>
<p>Given random variable <code>X</code>, the survival function is defined:</p>
<pre><code>survival_function(x) = P[X &gt; x]
                     = 1 - P[X &lt;= x]
                     = 1 - cdf(x).</code></pre>
<h5 id="args-422">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-479">Returns:</h5>
<p>Tensor<code>of shape</code>sample_shape(x) + self.batch_shape<code>with values of type</code>self.dtype`.</p>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiag.validate_args"><code id="MultivariateNormalDiag.validate_args">tf.contrib.distributions.MultivariateNormalDiag.validate_args</code></h4>
<p>Python boolean indicated possibly expensive checks are enabled.</p>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiag.variancenamevariance"><code id="MultivariateNormalDiag.variance">tf.contrib.distributions.MultivariateNormalDiag.variance(name='variance')</code></h4>
<p>Variance.</p>
<hr />
<h3 id="class-tf.contrib.distributions.multivariatenormalfull"><a name="//apple_ref/cpp/Class/MultivariateNormalFull" class="dashAnchor"></a><code id="MultivariateNormalFull">class tf.contrib.distributions.MultivariateNormalFull</code></h3>
<p>The multivariate normal distribution on <code>R^k</code>.</p>
<p>This distribution is defined by a 1-D mean <code>mu</code> and covariance matrix <code>sigma</code>. Evaluation of the pdf, determinant, and sampling are all <code>O(k^3)</code> operations.</p>
<h4 id="mathematical-details-6">Mathematical details</h4>
<p>With <code>C = sigma</code>, the PDF of this distribution is:</p>
<pre><code>f(x) = (2 pi)^(-k/2) |det(C)|^(-1/2) exp(-1/2 (x - mu)^T C^{-1} (x - mu))</code></pre>
<h4 id="examples-6">Examples</h4>
<p>A single multi-variate Gaussian distribution is defined by a vector of means of length <code>k</code>, and a covariance matrix of shape <code>k x k</code>.</p>
<p>Extra leading dimensions, if provided, allow for batches.</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="co"># Initialize a single 3-variate Gaussian with diagonal covariance.</span>
mu <span class="op">=</span> [<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>.]
sigma <span class="op">=</span> [[<span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>], [<span class="dv">0</span>, <span class="dv">3</span>, <span class="dv">0</span>], [<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">2</span>.]]
dist <span class="op">=</span> tf.contrib.distributions.MultivariateNormalFull(mu, chol)

<span class="co"># Evaluate this on an observation in R^3, returning a scalar.</span>
dist.pdf([<span class="op">-</span><span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>])

<span class="co"># Initialize a batch of two 3-variate Gaussians.</span>
mu <span class="op">=</span> [[<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>], [<span class="dv">11</span>, <span class="dv">22</span>, <span class="dv">33</span>.]]
sigma <span class="op">=</span> ...  <span class="co"># shape 2 x 3 x 3, positive definite.</span>
dist <span class="op">=</span> tf.contrib.distributions.MultivariateNormalFull(mu, sigma)

<span class="co"># Evaluate this on a two observations, each in R^3, returning a length two</span>
<span class="co"># tensor.</span>
x <span class="op">=</span> [[<span class="op">-</span><span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>], [<span class="op">-</span><span class="dv">11</span>, <span class="dv">0</span>, <span class="dv">11</span>.]]  <span class="co"># Shape 2 x 3.</span>
dist.pdf(x)</code></pre></div>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormalfull.__init__mu-sigma-validate_argsfalse-allow_nan_statstrue-namemultivariatenormalfull"><code id="MultivariateNormalFull.__init__">tf.contrib.distributions.MultivariateNormalFull.__init__(mu, sigma, validate_args=False, allow_nan_stats=True, name='MultivariateNormalFull')</code></h4>
<p>Multivariate Normal distributions on <code>R^k</code>.</p>
<p>User must provide means <code>mu</code> and <code>sigma</code>, the mean and covariance.</p>
<h5 id="args-423">Args:</h5>
<ul>
<li><b><code>mu</code></b>: <code>(N+1)-D</code> floating point tensor with shape <code>[N1,...,Nb, k]</code>, <code>b &gt;= 0</code>.</li>
<li><b><code>sigma</code></b>: <code>(N+2)-D</code> <code>Tensor</code> with same <code>dtype</code> as <code>mu</code> and shape <code>[N1,...,Nb, k, k]</code>. Each batch member must be positive definite.</li>
<li><b><code>validate_args</code></b>: <code>Boolean</code>, default <code>False</code>. Whether to validate input with asserts. If <code>validate_args</code> is <code>False</code>, and the inputs are invalid, correct behavior is not guaranteed.</li>
<li><b><code>allow_nan_stats</code></b>: <code>Boolean</code>, default <code>True</code>. If <code>False</code>, raise an exception if a statistic (e.g. mean/mode/etc...) is undefined for any batch member If <code>True</code>, batch members with valid parameters leading to undefined statistics will return NaN for this statistic.</li>
<li><b><code>name</code></b>: The name to give Ops created by the initializer.</li>
</ul>
<h5 id="raises-153">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: If <code>mu</code> and <code>sigma</code> are different dtypes.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormalfull.allow_nan_stats"><code id="MultivariateNormalFull.allow_nan_stats">tf.contrib.distributions.MultivariateNormalFull.allow_nan_stats</code></h4>
<p>Python boolean describing behavior when a stat is undefined.</p>
<p>Stats return +/- infinity when it makes sense. E.g., the variance of a Cauchy distribution is infinity. However, sometimes the statistic is undefined, e.g., if a distribution's pdf does not achieve a maximum within the support of the distribution, the mode is undefined. If the mean is undefined, then by definition the variance is undefined. E.g. the mean for Student's T for df = 1 is undefined (no clear way to say it is either + or - infinity), so the variance = E[(X - mean)^2] is also undefined.</p>
<h5 id="returns-480">Returns:</h5>
<ul>
<li><b><code>allow_nan_stats</code></b>: Python boolean.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormalfull.batch_shapenamebatch_shape"><code id="MultivariateNormalFull.batch_shape">tf.contrib.distributions.MultivariateNormalFull.batch_shape(name='batch_shape')</code></h4>
<p>Shape of a single sample from a single event index as a 1-D <code>Tensor</code>.</p>
<p>The product of the dimensions of the <code>batch_shape</code> is the number of independent distributions of this kind the instance represents.</p>
<h5 id="args-424">Args:</h5>
<ul>
<li><b><code>name</code></b>: name to give to the op</li>
</ul>
<h5 id="returns-481">Returns:</h5>
<ul>
<li><b><code>batch_shape</code></b>: <code>Tensor</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormalfull.cdfvalue-namecdf-condition_kwargs"><code id="MultivariateNormalFull.cdf">tf.contrib.distributions.MultivariateNormalFull.cdf(value, name='cdf', **condition_kwargs)</code></h4>
<p>Cumulative distribution function.</p>
<p>Given random variable <code>X</code>, the cumulative distribution function <code>cdf</code> is:</p>
<pre><code>cdf(x) := P[X &lt;= x]</code></pre>
<h5 id="args-425">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-482">Returns:</h5>
<ul>
<li><b><code>cdf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormalfull.copyoverride_parameters_kwargs"><code id="MultivariateNormalFull.copy">tf.contrib.distributions.MultivariateNormalFull.copy(**override_parameters_kwargs)</code></h4>
<p>Creates a deep copy of the distribution.</p>
<p>Note: the copy distribution may continue to depend on the original intialization arguments.</p>
<h5 id="args-426">Args:</h5>
<ul>
<li><b><code>**override_parameters_kwargs</code></b>: String/value dictionary of initialization arguments to override with new values.</li>
</ul>
<h5 id="returns-483">Returns:</h5>
<ul>
<li><b><code>distribution</code></b>: A new instance of <code>type(self)</code> intitialized from the union of self.parameters and override_parameters_kwargs, i.e., <code>dict(self.parameters, **override_parameters_kwargs)</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormalfull.dtype"><code id="MultivariateNormalFull.dtype">tf.contrib.distributions.MultivariateNormalFull.dtype</code></h4>
<p>The <code>DType</code> of <code>Tensor</code>s handled by this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormalfull.entropynameentropy"><code id="MultivariateNormalFull.entropy">tf.contrib.distributions.MultivariateNormalFull.entropy(name='entropy')</code></h4>
<p>Shannon entropy in nats.</p>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormalfull.event_shapenameevent_shape"><code id="MultivariateNormalFull.event_shape">tf.contrib.distributions.MultivariateNormalFull.event_shape(name='event_shape')</code></h4>
<p>Shape of a single sample from a single batch as a 1-D int32 <code>Tensor</code>.</p>
<h5 id="args-427">Args:</h5>
<ul>
<li><b><code>name</code></b>: name to give to the op</li>
</ul>
<h5 id="returns-484">Returns:</h5>
<ul>
<li><b><code>event_shape</code></b>: <code>Tensor</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormalfull.get_batch_shape"><code id="MultivariateNormalFull.get_batch_shape">tf.contrib.distributions.MultivariateNormalFull.get_batch_shape()</code></h4>
<p>Shape of a single sample from a single event index as a <code>TensorShape</code>.</p>
<p>Same meaning as <code>batch_shape</code>. May be only partially defined.</p>
<h5 id="returns-485">Returns:</h5>
<ul>
<li><b><code>batch_shape</code></b>: <code>TensorShape</code>, possibly unknown.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormalfull.get_event_shape"><code id="MultivariateNormalFull.get_event_shape">tf.contrib.distributions.MultivariateNormalFull.get_event_shape()</code></h4>
<p>Shape of a single sample from a single batch as a <code>TensorShape</code>.</p>
<p>Same meaning as <code>event_shape</code>. May be only partially defined.</p>
<h5 id="returns-486">Returns:</h5>
<ul>
<li><b><code>event_shape</code></b>: <code>TensorShape</code>, possibly unknown.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormalfull.is_continuous"><code id="MultivariateNormalFull.is_continuous">tf.contrib.distributions.MultivariateNormalFull.is_continuous</code></h4>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormalfull.is_reparameterized"><code id="MultivariateNormalFull.is_reparameterized">tf.contrib.distributions.MultivariateNormalFull.is_reparameterized</code></h4>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormalfull.log_cdfvalue-namelog_cdf-condition_kwargs"><code id="MultivariateNormalFull.log_cdf">tf.contrib.distributions.MultivariateNormalFull.log_cdf(value, name='log_cdf', **condition_kwargs)</code></h4>
<p>Log cumulative distribution function.</p>
<p>Given random variable <code>X</code>, the cumulative distribution function <code>cdf</code> is:</p>
<pre><code>log_cdf(x) := Log[ P[X &lt;= x] ]</code></pre>
<p>Often, a numerical approximation can be used for <code>log_cdf(x)</code> that yields a more accurate answer than simply taking the logarithm of the <code>cdf</code> when <code>x &lt;&lt; -1</code>.</p>
<h5 id="args-428">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-487">Returns:</h5>
<ul>
<li><b><code>logcdf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormalfull.log_pdfvalue-namelog_pdf-condition_kwargs"><code id="MultivariateNormalFull.log_pdf">tf.contrib.distributions.MultivariateNormalFull.log_pdf(value, name='log_pdf', **condition_kwargs)</code></h4>
<p>Log probability density function.</p>
<h5 id="args-429">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-488">Returns:</h5>
<ul>
<li><b><code>log_prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-154">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if not <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormalfull.log_pmfvalue-namelog_pmf-condition_kwargs"><code id="MultivariateNormalFull.log_pmf">tf.contrib.distributions.MultivariateNormalFull.log_pmf(value, name='log_pmf', **condition_kwargs)</code></h4>
<p>Log probability mass function.</p>
<h5 id="args-430">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-489">Returns:</h5>
<ul>
<li><b><code>log_pmf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-155">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormalfull.log_probvalue-namelog_prob-condition_kwargs"><code id="MultivariateNormalFull.log_prob">tf.contrib.distributions.MultivariateNormalFull.log_prob(value, name='log_prob', **condition_kwargs)</code></h4>
<p>Log probability density/mass function (depending on <code>is_continuous</code>).</p>
<p>Additional documentation from <code>_MultivariateNormalOperatorPD</code>:</p>
<p><code>x</code> is a batch vector with compatible shape if <code>x</code> is a <code>Tensor</code> whose shape can be broadcast up to either:</p>
<pre><code>self.batch_shape + self.event_shape</code></pre>
<p>or</p>
<pre><code>[M1,...,Mm] + self.batch_shape + self.event_shape</code></pre>
<h5 id="args-431">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-490">Returns:</h5>
<ul>
<li><b><code>log_prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormalfull.log_sigma_detnamelog_sigma_det"><code id="MultivariateNormalFull.log_sigma_det">tf.contrib.distributions.MultivariateNormalFull.log_sigma_det(name='log_sigma_det')</code></h4>
<p>Log of determinant of covariance matrix.</p>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormalfull.log_survival_functionvalue-namelog_survival_function-condition_kwargs"><code id="MultivariateNormalFull.log_survival_function">tf.contrib.distributions.MultivariateNormalFull.log_survival_function(value, name='log_survival_function', **condition_kwargs)</code></h4>
<p>Log survival function.</p>
<p>Given random variable <code>X</code>, the survival function is defined:</p>
<pre><code>log_survival_function(x) = Log[ P[X &gt; x] ]
                         = Log[ 1 - P[X &lt;= x] ]
                         = Log[ 1 - cdf(x) ]</code></pre>
<p>Typically, different numerical approximations can be used for the log survival function, which are more accurate than <code>1 - cdf(x)</code> when <code>x &gt;&gt; 1</code>.</p>
<h5 id="args-432">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-491">Returns:</h5>
<p><code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormalfull.meannamemean"><code id="MultivariateNormalFull.mean">tf.contrib.distributions.MultivariateNormalFull.mean(name='mean')</code></h4>
<p>Mean.</p>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormalfull.modenamemode"><code id="MultivariateNormalFull.mode">tf.contrib.distributions.MultivariateNormalFull.mode(name='mode')</code></h4>
<p>Mode.</p>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormalfull.mu"><code id="MultivariateNormalFull.mu">tf.contrib.distributions.MultivariateNormalFull.mu</code></h4>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormalfull.name"><code id="MultivariateNormalFull.name">tf.contrib.distributions.MultivariateNormalFull.name</code></h4>
<p>Name prepended to all ops created by this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormalfull.param_shapescls-sample_shape-namedistributionparamshapes"><code id="MultivariateNormalFull.param_shapes">tf.contrib.distributions.MultivariateNormalFull.param_shapes(cls, sample_shape, name='DistributionParamShapes')</code></h4>
<p>Shapes of parameters given the desired shape of a call to <code>sample()</code>.</p>
<p>Subclasses should override static method <code>_param_shapes</code>.</p>
<h5 id="args-433">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: <code>Tensor</code> or python list/tuple. Desired shape of a call to <code>sample()</code>.</li>
<li><b><code>name</code></b>: name to prepend ops with.</li>
</ul>
<h5 id="returns-492">Returns:</h5>
<p><code>dict</code> of parameter name to <code>Tensor</code> shapes.</p>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormalfull.param_static_shapescls-sample_shape"><code id="MultivariateNormalFull.param_static_shapes">tf.contrib.distributions.MultivariateNormalFull.param_static_shapes(cls, sample_shape)</code></h4>
<p>param_shapes with static (i.e. TensorShape) shapes.</p>
<h5 id="args-434">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: <code>TensorShape</code> or python list/tuple. Desired shape of a call to <code>sample()</code>.</li>
</ul>
<h5 id="returns-493">Returns:</h5>
<p><code>dict</code> of parameter name to <code>TensorShape</code>.</p>
<h5 id="raises-156">Raises:</h5>
<ul>
<li><b><code>ValueError</code></b>: if <code>sample_shape</code> is a <code>TensorShape</code> and is not fully defined.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormalfull.parameters"><code id="MultivariateNormalFull.parameters">tf.contrib.distributions.MultivariateNormalFull.parameters</code></h4>
<p>Dictionary of parameters used to instantiate this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormalfull.pdfvalue-namepdf-condition_kwargs"><code id="MultivariateNormalFull.pdf">tf.contrib.distributions.MultivariateNormalFull.pdf(value, name='pdf', **condition_kwargs)</code></h4>
<p>Probability density function.</p>
<h5 id="args-435">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-494">Returns:</h5>
<ul>
<li><b><code>prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-157">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if not <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormalfull.pmfvalue-namepmf-condition_kwargs"><code id="MultivariateNormalFull.pmf">tf.contrib.distributions.MultivariateNormalFull.pmf(value, name='pmf', **condition_kwargs)</code></h4>
<p>Probability mass function.</p>
<h5 id="args-436">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-495">Returns:</h5>
<ul>
<li><b><code>pmf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-158">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormalfull.probvalue-nameprob-condition_kwargs"><code id="MultivariateNormalFull.prob">tf.contrib.distributions.MultivariateNormalFull.prob(value, name='prob', **condition_kwargs)</code></h4>
<p>Probability density/mass function (depending on <code>is_continuous</code>).</p>
<p>Additional documentation from <code>_MultivariateNormalOperatorPD</code>:</p>
<p><code>x</code> is a batch vector with compatible shape if <code>x</code> is a <code>Tensor</code> whose shape can be broadcast up to either:</p>
<pre><code>self.batch_shape + self.event_shape</code></pre>
<p>or</p>
<pre><code>[M1,...,Mm] + self.batch_shape + self.event_shape</code></pre>
<h5 id="args-437">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-496">Returns:</h5>
<ul>
<li><b><code>prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormalfull.samplesample_shape-seednone-namesample-condition_kwargs"><code id="MultivariateNormalFull.sample">tf.contrib.distributions.MultivariateNormalFull.sample(sample_shape=(), seed=None, name='sample', **condition_kwargs)</code></h4>
<p>Generate samples of the specified shape.</p>
<p>Note that a call to <code>sample()</code> without arguments will generate a single sample.</p>
<h5 id="args-438">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: 0D or 1D <code>int32</code> <code>Tensor</code>. Shape of the generated samples.</li>
<li><b><code>seed</code></b>: Python integer seed for RNG</li>
<li><b><code>name</code></b>: name to give to the op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-497">Returns:</h5>
<ul>
<li><b><code>samples</code></b>: a <code>Tensor</code> with prepended dimensions <code>sample_shape</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormalfull.sample_nn-seednone-namesample_n-condition_kwargs"><code id="MultivariateNormalFull.sample_n">tf.contrib.distributions.MultivariateNormalFull.sample_n(n, seed=None, name='sample_n', **condition_kwargs)</code></h4>
<p>Generate <code>n</code> samples.</p>
<h5 id="args-439">Args:</h5>
<ul>
<li><b><code>n</code></b>: <code>Scalar</code> <code>Tensor</code> of type <code>int32</code> or <code>int64</code>, the number of observations to sample.</li>
<li><b><code>seed</code></b>: Python integer seed for RNG</li>
<li><b><code>name</code></b>: name to give to the op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-498">Returns:</h5>
<ul>
<li><b><code>samples</code></b>: a <code>Tensor</code> with a prepended dimension (n,).</li>
</ul>
<h5 id="raises-159">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>n</code> is not an integer type.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormalfull.sigma"><code id="MultivariateNormalFull.sigma">tf.contrib.distributions.MultivariateNormalFull.sigma</code></h4>
<p>Dense (batch) covariance matrix, if available.</p>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormalfull.sigma_detnamesigma_det"><code id="MultivariateNormalFull.sigma_det">tf.contrib.distributions.MultivariateNormalFull.sigma_det(name='sigma_det')</code></h4>
<p>Determinant of covariance matrix.</p>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormalfull.stdnamestd"><code id="MultivariateNormalFull.std">tf.contrib.distributions.MultivariateNormalFull.std(name='std')</code></h4>
<p>Standard deviation.</p>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormalfull.survival_functionvalue-namesurvival_function-condition_kwargs"><code id="MultivariateNormalFull.survival_function">tf.contrib.distributions.MultivariateNormalFull.survival_function(value, name='survival_function', **condition_kwargs)</code></h4>
<p>Survival function.</p>
<p>Given random variable <code>X</code>, the survival function is defined:</p>
<pre><code>survival_function(x) = P[X &gt; x]
                     = 1 - P[X &lt;= x]
                     = 1 - cdf(x).</code></pre>
<h5 id="args-440">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-499">Returns:</h5>
<p>Tensor<code>of shape</code>sample_shape(x) + self.batch_shape<code>with values of type</code>self.dtype`.</p>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormalfull.validate_args"><code id="MultivariateNormalFull.validate_args">tf.contrib.distributions.MultivariateNormalFull.validate_args</code></h4>
<p>Python boolean indicated possibly expensive checks are enabled.</p>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormalfull.variancenamevariance"><code id="MultivariateNormalFull.variance">tf.contrib.distributions.MultivariateNormalFull.variance(name='variance')</code></h4>
<p>Variance.</p>
<hr />
<h3 id="class-tf.contrib.distributions.multivariatenormalcholesky"><a name="//apple_ref/cpp/Class/MultivariateNormalCholesky" class="dashAnchor"></a><code id="MultivariateNormalCholesky">class tf.contrib.distributions.MultivariateNormalCholesky</code></h3>
<p>The multivariate normal distribution on <code>R^k</code>.</p>
<p>This distribution is defined by a 1-D mean <code>mu</code> and a Cholesky factor <code>chol</code>. Providing the Cholesky factor allows for <code>O(k^2)</code> pdf evaluation and sampling, and requires <code>O(k^2)</code> storage.</p>
<h4 id="mathematical-details-7">Mathematical details</h4>
<p>The Cholesky factor <code>chol</code> defines the covariance matrix: <code>C = chol chol^T</code>.</p>
<p>The PDF of this distribution is then:</p>
<pre><code>f(x) = (2 pi)^(-k/2) |det(C)|^(-1/2) exp(-1/2 (x - mu)^T C^{-1} (x - mu))</code></pre>
<h4 id="examples-7">Examples</h4>
<p>A single multi-variate Gaussian distribution is defined by a vector of means of length <code>k</code>, and a covariance matrix of shape <code>k x k</code>.</p>
<p>Extra leading dimensions, if provided, allow for batches.</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="co"># Initialize a single 3-variate Gaussian with diagonal covariance.</span>
<span class="co"># Note, this would be more efficient with MultivariateNormalDiag.</span>
mu <span class="op">=</span> [<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>.]
chol <span class="op">=</span> [[<span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>], [<span class="dv">0</span>, <span class="dv">3</span>, <span class="dv">0</span>], [<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">2</span>]]
dist <span class="op">=</span> tf.contrib.distributions.MultivariateNormalCholesky(mu, chol)

<span class="co"># Evaluate this on an observation in R^3, returning a scalar.</span>
dist.pdf([<span class="op">-</span><span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>])

<span class="co"># Initialize a batch of two 3-variate Gaussians.</span>
mu <span class="op">=</span> [[<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>], [<span class="dv">11</span>, <span class="dv">22</span>, <span class="dv">33</span>]]
chol <span class="op">=</span> ...  <span class="co"># shape 2 x 3 x 3, lower triangular, positive diagonal.</span>
dist <span class="op">=</span> tf.contrib.distributions.MultivariateNormalCholesky(mu, chol)

<span class="co"># Evaluate this on a two observations, each in R^3, returning a length two</span>
<span class="co"># tensor.</span>
x <span class="op">=</span> [[<span class="op">-</span><span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>], [<span class="op">-</span><span class="dv">11</span>, <span class="dv">0</span>, <span class="dv">11</span>]]  <span class="co"># Shape 2 x 3.</span>
dist.pdf(x)</code></pre></div>
<p>Trainable (batch) Cholesky matrices can be created with <code>tf.contrib.distributions.matrix_diag_transform()</code> - - -</p>
<h4 id="tf.contrib.distributions.multivariatenormalcholesky.__init__mu-chol-validate_argsfalse-allow_nan_statstrue-namemultivariatenormalcholesky"><code id="MultivariateNormalCholesky.__init__">tf.contrib.distributions.MultivariateNormalCholesky.__init__(mu, chol, validate_args=False, allow_nan_stats=True, name='MultivariateNormalCholesky')</code></h4>
<p>Multivariate Normal distributions on <code>R^k</code>.</p>
<p>User must provide means <code>mu</code> and <code>chol</code> which holds the (batch) Cholesky factors, such that the covariance of each batch member is <code>chol chol^T</code>.</p>
<h5 id="args-441">Args:</h5>
<ul>
<li><b><code>mu</code></b>: <code>(N+1)-D</code> floating point tensor with shape <code>[N1,...,Nb, k]</code>, <code>b &gt;= 0</code>.</li>
<li><b><code>chol</code></b>: <code>(N+2)-D</code> <code>Tensor</code> with same <code>dtype</code> as <code>mu</code> and shape <code>[N1,...,Nb, k, k]</code>. The upper triangular part is ignored (treated as though it is zero), and the diagonal must be positive.</li>
<li><b><code>validate_args</code></b>: <code>Boolean</code>, default <code>False</code>. Whether to validate input with asserts. If <code>validate_args</code> is <code>False</code>, and the inputs are invalid, correct behavior is not guaranteed.</li>
<li><b><code>allow_nan_stats</code></b>: <code>Boolean</code>, default <code>True</code>. If <code>False</code>, raise an exception if a statistic (e.g. mean/mode/etc...) is undefined for any batch member If <code>True</code>, batch members with valid parameters leading to undefined statistics will return NaN for this statistic.</li>
<li><b><code>name</code></b>: The name to give Ops created by the initializer.</li>
</ul>
<h5 id="raises-160">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: If <code>mu</code> and <code>chol</code> are different dtypes.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormalcholesky.allow_nan_stats"><code id="MultivariateNormalCholesky.allow_nan_stats">tf.contrib.distributions.MultivariateNormalCholesky.allow_nan_stats</code></h4>
<p>Python boolean describing behavior when a stat is undefined.</p>
<p>Stats return +/- infinity when it makes sense. E.g., the variance of a Cauchy distribution is infinity. However, sometimes the statistic is undefined, e.g., if a distribution's pdf does not achieve a maximum within the support of the distribution, the mode is undefined. If the mean is undefined, then by definition the variance is undefined. E.g. the mean for Student's T for df = 1 is undefined (no clear way to say it is either + or - infinity), so the variance = E[(X - mean)^2] is also undefined.</p>
<h5 id="returns-500">Returns:</h5>
<ul>
<li><b><code>allow_nan_stats</code></b>: Python boolean.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormalcholesky.batch_shapenamebatch_shape"><code id="MultivariateNormalCholesky.batch_shape">tf.contrib.distributions.MultivariateNormalCholesky.batch_shape(name='batch_shape')</code></h4>
<p>Shape of a single sample from a single event index as a 1-D <code>Tensor</code>.</p>
<p>The product of the dimensions of the <code>batch_shape</code> is the number of independent distributions of this kind the instance represents.</p>
<h5 id="args-442">Args:</h5>
<ul>
<li><b><code>name</code></b>: name to give to the op</li>
</ul>
<h5 id="returns-501">Returns:</h5>
<ul>
<li><b><code>batch_shape</code></b>: <code>Tensor</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormalcholesky.cdfvalue-namecdf-condition_kwargs"><code id="MultivariateNormalCholesky.cdf">tf.contrib.distributions.MultivariateNormalCholesky.cdf(value, name='cdf', **condition_kwargs)</code></h4>
<p>Cumulative distribution function.</p>
<p>Given random variable <code>X</code>, the cumulative distribution function <code>cdf</code> is:</p>
<pre><code>cdf(x) := P[X &lt;= x]</code></pre>
<h5 id="args-443">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-502">Returns:</h5>
<ul>
<li><b><code>cdf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormalcholesky.copyoverride_parameters_kwargs"><code id="MultivariateNormalCholesky.copy">tf.contrib.distributions.MultivariateNormalCholesky.copy(**override_parameters_kwargs)</code></h4>
<p>Creates a deep copy of the distribution.</p>
<p>Note: the copy distribution may continue to depend on the original intialization arguments.</p>
<h5 id="args-444">Args:</h5>
<ul>
<li><b><code>**override_parameters_kwargs</code></b>: String/value dictionary of initialization arguments to override with new values.</li>
</ul>
<h5 id="returns-503">Returns:</h5>
<ul>
<li><b><code>distribution</code></b>: A new instance of <code>type(self)</code> intitialized from the union of self.parameters and override_parameters_kwargs, i.e., <code>dict(self.parameters, **override_parameters_kwargs)</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormalcholesky.dtype"><code id="MultivariateNormalCholesky.dtype">tf.contrib.distributions.MultivariateNormalCholesky.dtype</code></h4>
<p>The <code>DType</code> of <code>Tensor</code>s handled by this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormalcholesky.entropynameentropy"><code id="MultivariateNormalCholesky.entropy">tf.contrib.distributions.MultivariateNormalCholesky.entropy(name='entropy')</code></h4>
<p>Shannon entropy in nats.</p>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormalcholesky.event_shapenameevent_shape"><code id="MultivariateNormalCholesky.event_shape">tf.contrib.distributions.MultivariateNormalCholesky.event_shape(name='event_shape')</code></h4>
<p>Shape of a single sample from a single batch as a 1-D int32 <code>Tensor</code>.</p>
<h5 id="args-445">Args:</h5>
<ul>
<li><b><code>name</code></b>: name to give to the op</li>
</ul>
<h5 id="returns-504">Returns:</h5>
<ul>
<li><b><code>event_shape</code></b>: <code>Tensor</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormalcholesky.get_batch_shape"><code id="MultivariateNormalCholesky.get_batch_shape">tf.contrib.distributions.MultivariateNormalCholesky.get_batch_shape()</code></h4>
<p>Shape of a single sample from a single event index as a <code>TensorShape</code>.</p>
<p>Same meaning as <code>batch_shape</code>. May be only partially defined.</p>
<h5 id="returns-505">Returns:</h5>
<ul>
<li><b><code>batch_shape</code></b>: <code>TensorShape</code>, possibly unknown.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormalcholesky.get_event_shape"><code id="MultivariateNormalCholesky.get_event_shape">tf.contrib.distributions.MultivariateNormalCholesky.get_event_shape()</code></h4>
<p>Shape of a single sample from a single batch as a <code>TensorShape</code>.</p>
<p>Same meaning as <code>event_shape</code>. May be only partially defined.</p>
<h5 id="returns-506">Returns:</h5>
<ul>
<li><b><code>event_shape</code></b>: <code>TensorShape</code>, possibly unknown.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormalcholesky.is_continuous"><code id="MultivariateNormalCholesky.is_continuous">tf.contrib.distributions.MultivariateNormalCholesky.is_continuous</code></h4>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormalcholesky.is_reparameterized"><code id="MultivariateNormalCholesky.is_reparameterized">tf.contrib.distributions.MultivariateNormalCholesky.is_reparameterized</code></h4>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormalcholesky.log_cdfvalue-namelog_cdf-condition_kwargs"><code id="MultivariateNormalCholesky.log_cdf">tf.contrib.distributions.MultivariateNormalCholesky.log_cdf(value, name='log_cdf', **condition_kwargs)</code></h4>
<p>Log cumulative distribution function.</p>
<p>Given random variable <code>X</code>, the cumulative distribution function <code>cdf</code> is:</p>
<pre><code>log_cdf(x) := Log[ P[X &lt;= x] ]</code></pre>
<p>Often, a numerical approximation can be used for <code>log_cdf(x)</code> that yields a more accurate answer than simply taking the logarithm of the <code>cdf</code> when <code>x &lt;&lt; -1</code>.</p>
<h5 id="args-446">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-507">Returns:</h5>
<ul>
<li><b><code>logcdf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormalcholesky.log_pdfvalue-namelog_pdf-condition_kwargs"><code id="MultivariateNormalCholesky.log_pdf">tf.contrib.distributions.MultivariateNormalCholesky.log_pdf(value, name='log_pdf', **condition_kwargs)</code></h4>
<p>Log probability density function.</p>
<h5 id="args-447">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-508">Returns:</h5>
<ul>
<li><b><code>log_prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-161">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if not <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormalcholesky.log_pmfvalue-namelog_pmf-condition_kwargs"><code id="MultivariateNormalCholesky.log_pmf">tf.contrib.distributions.MultivariateNormalCholesky.log_pmf(value, name='log_pmf', **condition_kwargs)</code></h4>
<p>Log probability mass function.</p>
<h5 id="args-448">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-509">Returns:</h5>
<ul>
<li><b><code>log_pmf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-162">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormalcholesky.log_probvalue-namelog_prob-condition_kwargs"><code id="MultivariateNormalCholesky.log_prob">tf.contrib.distributions.MultivariateNormalCholesky.log_prob(value, name='log_prob', **condition_kwargs)</code></h4>
<p>Log probability density/mass function (depending on <code>is_continuous</code>).</p>
<p>Additional documentation from <code>_MultivariateNormalOperatorPD</code>:</p>
<p><code>x</code> is a batch vector with compatible shape if <code>x</code> is a <code>Tensor</code> whose shape can be broadcast up to either:</p>
<pre><code>self.batch_shape + self.event_shape</code></pre>
<p>or</p>
<pre><code>[M1,...,Mm] + self.batch_shape + self.event_shape</code></pre>
<h5 id="args-449">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-510">Returns:</h5>
<ul>
<li><b><code>log_prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormalcholesky.log_sigma_detnamelog_sigma_det"><code id="MultivariateNormalCholesky.log_sigma_det">tf.contrib.distributions.MultivariateNormalCholesky.log_sigma_det(name='log_sigma_det')</code></h4>
<p>Log of determinant of covariance matrix.</p>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormalcholesky.log_survival_functionvalue-namelog_survival_function-condition_kwargs"><code id="MultivariateNormalCholesky.log_survival_function">tf.contrib.distributions.MultivariateNormalCholesky.log_survival_function(value, name='log_survival_function', **condition_kwargs)</code></h4>
<p>Log survival function.</p>
<p>Given random variable <code>X</code>, the survival function is defined:</p>
<pre><code>log_survival_function(x) = Log[ P[X &gt; x] ]
                         = Log[ 1 - P[X &lt;= x] ]
                         = Log[ 1 - cdf(x) ]</code></pre>
<p>Typically, different numerical approximations can be used for the log survival function, which are more accurate than <code>1 - cdf(x)</code> when <code>x &gt;&gt; 1</code>.</p>
<h5 id="args-450">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-511">Returns:</h5>
<p><code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormalcholesky.meannamemean"><code id="MultivariateNormalCholesky.mean">tf.contrib.distributions.MultivariateNormalCholesky.mean(name='mean')</code></h4>
<p>Mean.</p>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormalcholesky.modenamemode"><code id="MultivariateNormalCholesky.mode">tf.contrib.distributions.MultivariateNormalCholesky.mode(name='mode')</code></h4>
<p>Mode.</p>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormalcholesky.mu"><code id="MultivariateNormalCholesky.mu">tf.contrib.distributions.MultivariateNormalCholesky.mu</code></h4>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormalcholesky.name"><code id="MultivariateNormalCholesky.name">tf.contrib.distributions.MultivariateNormalCholesky.name</code></h4>
<p>Name prepended to all ops created by this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormalcholesky.param_shapescls-sample_shape-namedistributionparamshapes"><code id="MultivariateNormalCholesky.param_shapes">tf.contrib.distributions.MultivariateNormalCholesky.param_shapes(cls, sample_shape, name='DistributionParamShapes')</code></h4>
<p>Shapes of parameters given the desired shape of a call to <code>sample()</code>.</p>
<p>Subclasses should override static method <code>_param_shapes</code>.</p>
<h5 id="args-451">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: <code>Tensor</code> or python list/tuple. Desired shape of a call to <code>sample()</code>.</li>
<li><b><code>name</code></b>: name to prepend ops with.</li>
</ul>
<h5 id="returns-512">Returns:</h5>
<p><code>dict</code> of parameter name to <code>Tensor</code> shapes.</p>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormalcholesky.param_static_shapescls-sample_shape"><code id="MultivariateNormalCholesky.param_static_shapes">tf.contrib.distributions.MultivariateNormalCholesky.param_static_shapes(cls, sample_shape)</code></h4>
<p>param_shapes with static (i.e. TensorShape) shapes.</p>
<h5 id="args-452">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: <code>TensorShape</code> or python list/tuple. Desired shape of a call to <code>sample()</code>.</li>
</ul>
<h5 id="returns-513">Returns:</h5>
<p><code>dict</code> of parameter name to <code>TensorShape</code>.</p>
<h5 id="raises-163">Raises:</h5>
<ul>
<li><b><code>ValueError</code></b>: if <code>sample_shape</code> is a <code>TensorShape</code> and is not fully defined.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormalcholesky.parameters"><code id="MultivariateNormalCholesky.parameters">tf.contrib.distributions.MultivariateNormalCholesky.parameters</code></h4>
<p>Dictionary of parameters used to instantiate this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormalcholesky.pdfvalue-namepdf-condition_kwargs"><code id="MultivariateNormalCholesky.pdf">tf.contrib.distributions.MultivariateNormalCholesky.pdf(value, name='pdf', **condition_kwargs)</code></h4>
<p>Probability density function.</p>
<h5 id="args-453">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-514">Returns:</h5>
<ul>
<li><b><code>prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-164">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if not <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormalcholesky.pmfvalue-namepmf-condition_kwargs"><code id="MultivariateNormalCholesky.pmf">tf.contrib.distributions.MultivariateNormalCholesky.pmf(value, name='pmf', **condition_kwargs)</code></h4>
<p>Probability mass function.</p>
<h5 id="args-454">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-515">Returns:</h5>
<ul>
<li><b><code>pmf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-165">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormalcholesky.probvalue-nameprob-condition_kwargs"><code id="MultivariateNormalCholesky.prob">tf.contrib.distributions.MultivariateNormalCholesky.prob(value, name='prob', **condition_kwargs)</code></h4>
<p>Probability density/mass function (depending on <code>is_continuous</code>).</p>
<p>Additional documentation from <code>_MultivariateNormalOperatorPD</code>:</p>
<p><code>x</code> is a batch vector with compatible shape if <code>x</code> is a <code>Tensor</code> whose shape can be broadcast up to either:</p>
<pre><code>self.batch_shape + self.event_shape</code></pre>
<p>or</p>
<pre><code>[M1,...,Mm] + self.batch_shape + self.event_shape</code></pre>
<h5 id="args-455">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-516">Returns:</h5>
<ul>
<li><b><code>prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormalcholesky.samplesample_shape-seednone-namesample-condition_kwargs"><code id="MultivariateNormalCholesky.sample">tf.contrib.distributions.MultivariateNormalCholesky.sample(sample_shape=(), seed=None, name='sample', **condition_kwargs)</code></h4>
<p>Generate samples of the specified shape.</p>
<p>Note that a call to <code>sample()</code> without arguments will generate a single sample.</p>
<h5 id="args-456">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: 0D or 1D <code>int32</code> <code>Tensor</code>. Shape of the generated samples.</li>
<li><b><code>seed</code></b>: Python integer seed for RNG</li>
<li><b><code>name</code></b>: name to give to the op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-517">Returns:</h5>
<ul>
<li><b><code>samples</code></b>: a <code>Tensor</code> with prepended dimensions <code>sample_shape</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormalcholesky.sample_nn-seednone-namesample_n-condition_kwargs"><code id="MultivariateNormalCholesky.sample_n">tf.contrib.distributions.MultivariateNormalCholesky.sample_n(n, seed=None, name='sample_n', **condition_kwargs)</code></h4>
<p>Generate <code>n</code> samples.</p>
<h5 id="args-457">Args:</h5>
<ul>
<li><b><code>n</code></b>: <code>Scalar</code> <code>Tensor</code> of type <code>int32</code> or <code>int64</code>, the number of observations to sample.</li>
<li><b><code>seed</code></b>: Python integer seed for RNG</li>
<li><b><code>name</code></b>: name to give to the op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-518">Returns:</h5>
<ul>
<li><b><code>samples</code></b>: a <code>Tensor</code> with a prepended dimension (n,).</li>
</ul>
<h5 id="raises-166">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>n</code> is not an integer type.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormalcholesky.sigma"><code id="MultivariateNormalCholesky.sigma">tf.contrib.distributions.MultivariateNormalCholesky.sigma</code></h4>
<p>Dense (batch) covariance matrix, if available.</p>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormalcholesky.sigma_detnamesigma_det"><code id="MultivariateNormalCholesky.sigma_det">tf.contrib.distributions.MultivariateNormalCholesky.sigma_det(name='sigma_det')</code></h4>
<p>Determinant of covariance matrix.</p>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormalcholesky.stdnamestd"><code id="MultivariateNormalCholesky.std">tf.contrib.distributions.MultivariateNormalCholesky.std(name='std')</code></h4>
<p>Standard deviation.</p>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormalcholesky.survival_functionvalue-namesurvival_function-condition_kwargs"><code id="MultivariateNormalCholesky.survival_function">tf.contrib.distributions.MultivariateNormalCholesky.survival_function(value, name='survival_function', **condition_kwargs)</code></h4>
<p>Survival function.</p>
<p>Given random variable <code>X</code>, the survival function is defined:</p>
<pre><code>survival_function(x) = P[X &gt; x]
                     = 1 - P[X &lt;= x]
                     = 1 - cdf(x).</code></pre>
<h5 id="args-458">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-519">Returns:</h5>
<p>Tensor<code>of shape</code>sample_shape(x) + self.batch_shape<code>with values of type</code>self.dtype`.</p>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormalcholesky.validate_args"><code id="MultivariateNormalCholesky.validate_args">tf.contrib.distributions.MultivariateNormalCholesky.validate_args</code></h4>
<p>Python boolean indicated possibly expensive checks are enabled.</p>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormalcholesky.variancenamevariance"><code id="MultivariateNormalCholesky.variance">tf.contrib.distributions.MultivariateNormalCholesky.variance(name='variance')</code></h4>
<p>Variance.</p>
<hr />
<h3 id="class-tf.contrib.distributions.multivariatenormaldiagplusvdvt"><a name="//apple_ref/cpp/Class/MultivariateNormalDiagPlusVDVT" class="dashAnchor"></a><code id="MultivariateNormalDiagPlusVDVT">class tf.contrib.distributions.MultivariateNormalDiagPlusVDVT</code></h3>
<p>The multivariate normal distribution on <code>R^k</code>.</p>
<p>Every batch member of this distribution is defined by a mean and a lightweight covariance matrix <code>C</code>.</p>
<h4 id="mathematical-details-8">Mathematical details</h4>
<p>The PDF of this distribution in terms of the mean <code>mu</code> and covariance <code>C</code> is:</p>
<pre><code>f(x) = (2 pi)^(-k/2) |det(C)|^(-1/2) exp(-1/2 (x - mu)^T C^{-1} (x - mu))</code></pre>
<p>For every batch member, this distribution represents <code>k</code> random variables <code>(X_1,...,X_k)</code>, with mean <code>E[X_i] = mu[i]</code>, and covariance matrix <code>C_{ij} := E[(X_i - mu[i])(X_j - mu[j])]</code></p>
<p>The user initializes this class by providing the mean <code>mu</code>, and a lightweight definition of <code>C</code>:</p>
<pre><code>C = SS^T = SS = (M + V D V^T) (M + V D V^T)
M is diagonal (k x k)
V = is shape (k x r), typically r &lt;&lt; k
D = is diagonal (r x r), optional (defaults to identity).</code></pre>
<p>This allows for <code>O(kr + r^3)</code> pdf evaluation and determinant, and <code>O(kr)</code> sampling and storage (per batch member).</p>
<h4 id="examples-8">Examples</h4>
<p>A single multi-variate Gaussian distribution is defined by a vector of means of length <code>k</code>, and square root of the covariance <code>S = M + V D V^T</code>. Extra leading dimensions, if provided, allow for batches.</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="co"># Initialize a single 3-variate Gaussian with covariance square root</span>
<span class="co"># S = M + V D V^T, where V D V^T is a matrix-rank 2 update.</span>
mu <span class="op">=</span> [<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>.]
diag_large <span class="op">=</span> [<span class="fl">1.1</span>, <span class="fl">2.2</span>, <span class="fl">3.3</span>]
v <span class="op">=</span> ... <span class="co"># shape 3 x 2</span>
diag_small <span class="op">=</span> [<span class="dv">4</span>., <span class="dv">5</span>.]
dist <span class="op">=</span> tf.contrib.distributions.MultivariateNormalDiagPlusVDVT(
    mu, diag_large, v, diag_small<span class="op">=</span>diag_small)

<span class="co"># Evaluate this on an observation in R^3, returning a scalar.</span>
dist.pdf([<span class="op">-</span><span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>])

<span class="co"># Initialize a batch of two 3-variate Gaussians.  This time, don&#39;t provide</span>
<span class="co"># diag_small.  This means S = M + V V^T.</span>
mu <span class="op">=</span> [[<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>], [<span class="dv">11</span>, <span class="dv">22</span>, <span class="dv">33</span>]]  <span class="co"># shape 2 x 3</span>
diag_large <span class="op">=</span> ... <span class="co"># shape 2 x 3</span>
v <span class="op">=</span> ... <span class="co"># shape 2 x 3 x 1, a matrix-rank 1 update.</span>
dist <span class="op">=</span> tf.contrib.distributions.MultivariateNormalDiagPlusVDVT(
    mu, diag_large, v)

<span class="co"># Evaluate this on a two observations, each in R^3, returning a length two</span>
<span class="co"># tensor.</span>
x <span class="op">=</span> [[<span class="op">-</span><span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>], [<span class="op">-</span><span class="dv">11</span>, <span class="dv">0</span>, <span class="dv">11</span>]]  <span class="co"># Shape 2 x 3.</span>
dist.pdf(x)</code></pre></div>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiagplusvdvt.__init__mu-diag_large-v-diag_smallnone-validate_argsfalse-allow_nan_statstrue-namemultivariatenormaldiagplusvdvt"><code id="MultivariateNormalDiagPlusVDVT.__init__">tf.contrib.distributions.MultivariateNormalDiagPlusVDVT.__init__(mu, diag_large, v, diag_small=None, validate_args=False, allow_nan_stats=True, name='MultivariateNormalDiagPlusVDVT')</code></h4>
<p>Multivariate Normal distributions on <code>R^k</code>.</p>
<p>For every batch member, this distribution represents <code>k</code> random variables <code>(X_1,...,X_k)</code>, with mean <code>E[X_i] = mu[i]</code>, and covariance matrix <code>C_{ij} := E[(X_i - mu[i])(X_j - mu[j])]</code></p>
<p>The user initializes this class by providing the mean <code>mu</code>, and a lightweight definition of <code>C</code>:</p>
<pre><code>C = SS^T = SS = (M + V D V^T) (M + V D V^T)
M is diagonal (k x k)
V = is shape (k x r), typically r &lt;&lt; k
D = is diagonal (r x r), optional (defaults to identity).</code></pre>
<h5 id="args-459">Args:</h5>
<ul>
<li><b><code>mu</code></b>: Rank <code>n + 1</code> floating point tensor with shape <code>[N1,...,Nn, k]</code>, <code>n &gt;= 0</code>. The means.</li>
<li><b><code>diag_large</code></b>: Optional rank <code>n + 1</code> floating point tensor, shape <code>[N1,...,Nn, k]</code> <code>n &gt;= 0</code>. Defines the diagonal matrix <code>M</code>.</li>
<li><b><code>v</code></b>: Rank <code>n + 1</code> floating point tensor, shape <code>[N1,...,Nn, k, r]</code> <code>n &gt;= 0</code>. Defines the matrix <code>V</code>.</li>
<li><b><code>diag_small</code></b>: Rank <code>n + 1</code> floating point tensor, shape <code>[N1,...,Nn, k]</code> <code>n &gt;= 0</code>. Defines the diagonal matrix <code>D</code>. Default is <code>None</code>, which means <code>D</code> will be the identity matrix.</li>
<li><b><code>validate_args</code></b>: <code>Boolean</code>, default <code>False</code>. Whether to validate input with asserts. If <code>validate_args</code> is <code>False</code>, and the inputs are invalid, correct behavior is not guaranteed.</li>
<li><b><code>allow_nan_stats</code></b>: <code>Boolean</code>, default <code>True</code>. If <code>False</code>, raise an exception if a statistic (e.g. mean/mode/etc...) is undefined for any batch member If <code>True</code>, batch members with valid parameters leading to undefined statistics will return NaN for this statistic.</li>
<li><b><code>name</code></b>: The name to give Ops created by the initializer.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiagplusvdvt.allow_nan_stats"><code id="MultivariateNormalDiagPlusVDVT.allow_nan_stats">tf.contrib.distributions.MultivariateNormalDiagPlusVDVT.allow_nan_stats</code></h4>
<p>Python boolean describing behavior when a stat is undefined.</p>
<p>Stats return +/- infinity when it makes sense. E.g., the variance of a Cauchy distribution is infinity. However, sometimes the statistic is undefined, e.g., if a distribution's pdf does not achieve a maximum within the support of the distribution, the mode is undefined. If the mean is undefined, then by definition the variance is undefined. E.g. the mean for Student's T for df = 1 is undefined (no clear way to say it is either + or - infinity), so the variance = E[(X - mean)^2] is also undefined.</p>
<h5 id="returns-520">Returns:</h5>
<ul>
<li><b><code>allow_nan_stats</code></b>: Python boolean.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiagplusvdvt.batch_shapenamebatch_shape"><code id="MultivariateNormalDiagPlusVDVT.batch_shape">tf.contrib.distributions.MultivariateNormalDiagPlusVDVT.batch_shape(name='batch_shape')</code></h4>
<p>Shape of a single sample from a single event index as a 1-D <code>Tensor</code>.</p>
<p>The product of the dimensions of the <code>batch_shape</code> is the number of independent distributions of this kind the instance represents.</p>
<h5 id="args-460">Args:</h5>
<ul>
<li><b><code>name</code></b>: name to give to the op</li>
</ul>
<h5 id="returns-521">Returns:</h5>
<ul>
<li><b><code>batch_shape</code></b>: <code>Tensor</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiagplusvdvt.cdfvalue-namecdf-condition_kwargs"><code id="MultivariateNormalDiagPlusVDVT.cdf">tf.contrib.distributions.MultivariateNormalDiagPlusVDVT.cdf(value, name='cdf', **condition_kwargs)</code></h4>
<p>Cumulative distribution function.</p>
<p>Given random variable <code>X</code>, the cumulative distribution function <code>cdf</code> is:</p>
<pre><code>cdf(x) := P[X &lt;= x]</code></pre>
<h5 id="args-461">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-522">Returns:</h5>
<ul>
<li><b><code>cdf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiagplusvdvt.copyoverride_parameters_kwargs"><code id="MultivariateNormalDiagPlusVDVT.copy">tf.contrib.distributions.MultivariateNormalDiagPlusVDVT.copy(**override_parameters_kwargs)</code></h4>
<p>Creates a deep copy of the distribution.</p>
<p>Note: the copy distribution may continue to depend on the original intialization arguments.</p>
<h5 id="args-462">Args:</h5>
<ul>
<li><b><code>**override_parameters_kwargs</code></b>: String/value dictionary of initialization arguments to override with new values.</li>
</ul>
<h5 id="returns-523">Returns:</h5>
<ul>
<li><b><code>distribution</code></b>: A new instance of <code>type(self)</code> intitialized from the union of self.parameters and override_parameters_kwargs, i.e., <code>dict(self.parameters, **override_parameters_kwargs)</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiagplusvdvt.dtype"><code id="MultivariateNormalDiagPlusVDVT.dtype">tf.contrib.distributions.MultivariateNormalDiagPlusVDVT.dtype</code></h4>
<p>The <code>DType</code> of <code>Tensor</code>s handled by this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiagplusvdvt.entropynameentropy"><code id="MultivariateNormalDiagPlusVDVT.entropy">tf.contrib.distributions.MultivariateNormalDiagPlusVDVT.entropy(name='entropy')</code></h4>
<p>Shannon entropy in nats.</p>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiagplusvdvt.event_shapenameevent_shape"><code id="MultivariateNormalDiagPlusVDVT.event_shape">tf.contrib.distributions.MultivariateNormalDiagPlusVDVT.event_shape(name='event_shape')</code></h4>
<p>Shape of a single sample from a single batch as a 1-D int32 <code>Tensor</code>.</p>
<h5 id="args-463">Args:</h5>
<ul>
<li><b><code>name</code></b>: name to give to the op</li>
</ul>
<h5 id="returns-524">Returns:</h5>
<ul>
<li><b><code>event_shape</code></b>: <code>Tensor</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiagplusvdvt.get_batch_shape"><code id="MultivariateNormalDiagPlusVDVT.get_batch_shape">tf.contrib.distributions.MultivariateNormalDiagPlusVDVT.get_batch_shape()</code></h4>
<p>Shape of a single sample from a single event index as a <code>TensorShape</code>.</p>
<p>Same meaning as <code>batch_shape</code>. May be only partially defined.</p>
<h5 id="returns-525">Returns:</h5>
<ul>
<li><b><code>batch_shape</code></b>: <code>TensorShape</code>, possibly unknown.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiagplusvdvt.get_event_shape"><code id="MultivariateNormalDiagPlusVDVT.get_event_shape">tf.contrib.distributions.MultivariateNormalDiagPlusVDVT.get_event_shape()</code></h4>
<p>Shape of a single sample from a single batch as a <code>TensorShape</code>.</p>
<p>Same meaning as <code>event_shape</code>. May be only partially defined.</p>
<h5 id="returns-526">Returns:</h5>
<ul>
<li><b><code>event_shape</code></b>: <code>TensorShape</code>, possibly unknown.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiagplusvdvt.is_continuous"><code id="MultivariateNormalDiagPlusVDVT.is_continuous">tf.contrib.distributions.MultivariateNormalDiagPlusVDVT.is_continuous</code></h4>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiagplusvdvt.is_reparameterized"><code id="MultivariateNormalDiagPlusVDVT.is_reparameterized">tf.contrib.distributions.MultivariateNormalDiagPlusVDVT.is_reparameterized</code></h4>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiagplusvdvt.log_cdfvalue-namelog_cdf-condition_kwargs"><code id="MultivariateNormalDiagPlusVDVT.log_cdf">tf.contrib.distributions.MultivariateNormalDiagPlusVDVT.log_cdf(value, name='log_cdf', **condition_kwargs)</code></h4>
<p>Log cumulative distribution function.</p>
<p>Given random variable <code>X</code>, the cumulative distribution function <code>cdf</code> is:</p>
<pre><code>log_cdf(x) := Log[ P[X &lt;= x] ]</code></pre>
<p>Often, a numerical approximation can be used for <code>log_cdf(x)</code> that yields a more accurate answer than simply taking the logarithm of the <code>cdf</code> when <code>x &lt;&lt; -1</code>.</p>
<h5 id="args-464">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-527">Returns:</h5>
<ul>
<li><b><code>logcdf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiagplusvdvt.log_pdfvalue-namelog_pdf-condition_kwargs"><code id="MultivariateNormalDiagPlusVDVT.log_pdf">tf.contrib.distributions.MultivariateNormalDiagPlusVDVT.log_pdf(value, name='log_pdf', **condition_kwargs)</code></h4>
<p>Log probability density function.</p>
<h5 id="args-465">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-528">Returns:</h5>
<ul>
<li><b><code>log_prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-167">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if not <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiagplusvdvt.log_pmfvalue-namelog_pmf-condition_kwargs"><code id="MultivariateNormalDiagPlusVDVT.log_pmf">tf.contrib.distributions.MultivariateNormalDiagPlusVDVT.log_pmf(value, name='log_pmf', **condition_kwargs)</code></h4>
<p>Log probability mass function.</p>
<h5 id="args-466">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-529">Returns:</h5>
<ul>
<li><b><code>log_pmf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-168">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiagplusvdvt.log_probvalue-namelog_prob-condition_kwargs"><code id="MultivariateNormalDiagPlusVDVT.log_prob">tf.contrib.distributions.MultivariateNormalDiagPlusVDVT.log_prob(value, name='log_prob', **condition_kwargs)</code></h4>
<p>Log probability density/mass function (depending on <code>is_continuous</code>).</p>
<p>Additional documentation from <code>_MultivariateNormalOperatorPD</code>:</p>
<p><code>x</code> is a batch vector with compatible shape if <code>x</code> is a <code>Tensor</code> whose shape can be broadcast up to either:</p>
<pre><code>self.batch_shape + self.event_shape</code></pre>
<p>or</p>
<pre><code>[M1,...,Mm] + self.batch_shape + self.event_shape</code></pre>
<h5 id="args-467">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-530">Returns:</h5>
<ul>
<li><b><code>log_prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiagplusvdvt.log_sigma_detnamelog_sigma_det"><code id="MultivariateNormalDiagPlusVDVT.log_sigma_det">tf.contrib.distributions.MultivariateNormalDiagPlusVDVT.log_sigma_det(name='log_sigma_det')</code></h4>
<p>Log of determinant of covariance matrix.</p>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiagplusvdvt.log_survival_functionvalue-namelog_survival_function-condition_kwargs"><code id="MultivariateNormalDiagPlusVDVT.log_survival_function">tf.contrib.distributions.MultivariateNormalDiagPlusVDVT.log_survival_function(value, name='log_survival_function', **condition_kwargs)</code></h4>
<p>Log survival function.</p>
<p>Given random variable <code>X</code>, the survival function is defined:</p>
<pre><code>log_survival_function(x) = Log[ P[X &gt; x] ]
                         = Log[ 1 - P[X &lt;= x] ]
                         = Log[ 1 - cdf(x) ]</code></pre>
<p>Typically, different numerical approximations can be used for the log survival function, which are more accurate than <code>1 - cdf(x)</code> when <code>x &gt;&gt; 1</code>.</p>
<h5 id="args-468">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-531">Returns:</h5>
<p><code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiagplusvdvt.meannamemean"><code id="MultivariateNormalDiagPlusVDVT.mean">tf.contrib.distributions.MultivariateNormalDiagPlusVDVT.mean(name='mean')</code></h4>
<p>Mean.</p>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiagplusvdvt.modenamemode"><code id="MultivariateNormalDiagPlusVDVT.mode">tf.contrib.distributions.MultivariateNormalDiagPlusVDVT.mode(name='mode')</code></h4>
<p>Mode.</p>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiagplusvdvt.mu"><code id="MultivariateNormalDiagPlusVDVT.mu">tf.contrib.distributions.MultivariateNormalDiagPlusVDVT.mu</code></h4>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiagplusvdvt.name"><code id="MultivariateNormalDiagPlusVDVT.name">tf.contrib.distributions.MultivariateNormalDiagPlusVDVT.name</code></h4>
<p>Name prepended to all ops created by this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiagplusvdvt.param_shapescls-sample_shape-namedistributionparamshapes"><code id="MultivariateNormalDiagPlusVDVT.param_shapes">tf.contrib.distributions.MultivariateNormalDiagPlusVDVT.param_shapes(cls, sample_shape, name='DistributionParamShapes')</code></h4>
<p>Shapes of parameters given the desired shape of a call to <code>sample()</code>.</p>
<p>Subclasses should override static method <code>_param_shapes</code>.</p>
<h5 id="args-469">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: <code>Tensor</code> or python list/tuple. Desired shape of a call to <code>sample()</code>.</li>
<li><b><code>name</code></b>: name to prepend ops with.</li>
</ul>
<h5 id="returns-532">Returns:</h5>
<p><code>dict</code> of parameter name to <code>Tensor</code> shapes.</p>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiagplusvdvt.param_static_shapescls-sample_shape"><code id="MultivariateNormalDiagPlusVDVT.param_static_shapes">tf.contrib.distributions.MultivariateNormalDiagPlusVDVT.param_static_shapes(cls, sample_shape)</code></h4>
<p>param_shapes with static (i.e. TensorShape) shapes.</p>
<h5 id="args-470">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: <code>TensorShape</code> or python list/tuple. Desired shape of a call to <code>sample()</code>.</li>
</ul>
<h5 id="returns-533">Returns:</h5>
<p><code>dict</code> of parameter name to <code>TensorShape</code>.</p>
<h5 id="raises-169">Raises:</h5>
<ul>
<li><b><code>ValueError</code></b>: if <code>sample_shape</code> is a <code>TensorShape</code> and is not fully defined.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiagplusvdvt.parameters"><code id="MultivariateNormalDiagPlusVDVT.parameters">tf.contrib.distributions.MultivariateNormalDiagPlusVDVT.parameters</code></h4>
<p>Dictionary of parameters used to instantiate this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiagplusvdvt.pdfvalue-namepdf-condition_kwargs"><code id="MultivariateNormalDiagPlusVDVT.pdf">tf.contrib.distributions.MultivariateNormalDiagPlusVDVT.pdf(value, name='pdf', **condition_kwargs)</code></h4>
<p>Probability density function.</p>
<h5 id="args-471">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-534">Returns:</h5>
<ul>
<li><b><code>prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-170">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if not <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiagplusvdvt.pmfvalue-namepmf-condition_kwargs"><code id="MultivariateNormalDiagPlusVDVT.pmf">tf.contrib.distributions.MultivariateNormalDiagPlusVDVT.pmf(value, name='pmf', **condition_kwargs)</code></h4>
<p>Probability mass function.</p>
<h5 id="args-472">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-535">Returns:</h5>
<ul>
<li><b><code>pmf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-171">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiagplusvdvt.probvalue-nameprob-condition_kwargs"><code id="MultivariateNormalDiagPlusVDVT.prob">tf.contrib.distributions.MultivariateNormalDiagPlusVDVT.prob(value, name='prob', **condition_kwargs)</code></h4>
<p>Probability density/mass function (depending on <code>is_continuous</code>).</p>
<p>Additional documentation from <code>_MultivariateNormalOperatorPD</code>:</p>
<p><code>x</code> is a batch vector with compatible shape if <code>x</code> is a <code>Tensor</code> whose shape can be broadcast up to either:</p>
<pre><code>self.batch_shape + self.event_shape</code></pre>
<p>or</p>
<pre><code>[M1,...,Mm] + self.batch_shape + self.event_shape</code></pre>
<h5 id="args-473">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-536">Returns:</h5>
<ul>
<li><b><code>prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiagplusvdvt.samplesample_shape-seednone-namesample-condition_kwargs"><code id="MultivariateNormalDiagPlusVDVT.sample">tf.contrib.distributions.MultivariateNormalDiagPlusVDVT.sample(sample_shape=(), seed=None, name='sample', **condition_kwargs)</code></h4>
<p>Generate samples of the specified shape.</p>
<p>Note that a call to <code>sample()</code> without arguments will generate a single sample.</p>
<h5 id="args-474">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: 0D or 1D <code>int32</code> <code>Tensor</code>. Shape of the generated samples.</li>
<li><b><code>seed</code></b>: Python integer seed for RNG</li>
<li><b><code>name</code></b>: name to give to the op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-537">Returns:</h5>
<ul>
<li><b><code>samples</code></b>: a <code>Tensor</code> with prepended dimensions <code>sample_shape</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiagplusvdvt.sample_nn-seednone-namesample_n-condition_kwargs"><code id="MultivariateNormalDiagPlusVDVT.sample_n">tf.contrib.distributions.MultivariateNormalDiagPlusVDVT.sample_n(n, seed=None, name='sample_n', **condition_kwargs)</code></h4>
<p>Generate <code>n</code> samples.</p>
<h5 id="args-475">Args:</h5>
<ul>
<li><b><code>n</code></b>: <code>Scalar</code> <code>Tensor</code> of type <code>int32</code> or <code>int64</code>, the number of observations to sample.</li>
<li><b><code>seed</code></b>: Python integer seed for RNG</li>
<li><b><code>name</code></b>: name to give to the op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-538">Returns:</h5>
<ul>
<li><b><code>samples</code></b>: a <code>Tensor</code> with a prepended dimension (n,).</li>
</ul>
<h5 id="raises-172">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>n</code> is not an integer type.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiagplusvdvt.sigma"><code id="MultivariateNormalDiagPlusVDVT.sigma">tf.contrib.distributions.MultivariateNormalDiagPlusVDVT.sigma</code></h4>
<p>Dense (batch) covariance matrix, if available.</p>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiagplusvdvt.sigma_detnamesigma_det"><code id="MultivariateNormalDiagPlusVDVT.sigma_det">tf.contrib.distributions.MultivariateNormalDiagPlusVDVT.sigma_det(name='sigma_det')</code></h4>
<p>Determinant of covariance matrix.</p>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiagplusvdvt.stdnamestd"><code id="MultivariateNormalDiagPlusVDVT.std">tf.contrib.distributions.MultivariateNormalDiagPlusVDVT.std(name='std')</code></h4>
<p>Standard deviation.</p>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiagplusvdvt.survival_functionvalue-namesurvival_function-condition_kwargs"><code id="MultivariateNormalDiagPlusVDVT.survival_function">tf.contrib.distributions.MultivariateNormalDiagPlusVDVT.survival_function(value, name='survival_function', **condition_kwargs)</code></h4>
<p>Survival function.</p>
<p>Given random variable <code>X</code>, the survival function is defined:</p>
<pre><code>survival_function(x) = P[X &gt; x]
                     = 1 - P[X &lt;= x]
                     = 1 - cdf(x).</code></pre>
<h5 id="args-476">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-539">Returns:</h5>
<p>Tensor<code>of shape</code>sample_shape(x) + self.batch_shape<code>with values of type</code>self.dtype`.</p>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiagplusvdvt.validate_args"><code id="MultivariateNormalDiagPlusVDVT.validate_args">tf.contrib.distributions.MultivariateNormalDiagPlusVDVT.validate_args</code></h4>
<p>Python boolean indicated possibly expensive checks are enabled.</p>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiagplusvdvt.variancenamevariance"><code id="MultivariateNormalDiagPlusVDVT.variance">tf.contrib.distributions.MultivariateNormalDiagPlusVDVT.variance(name='variance')</code></h4>
<p>Variance.</p>
<hr />
<h3 id="class-tf.contrib.distributions.multivariatenormaldiagwithsoftplusstdev"><a name="//apple_ref/cpp/Class/MultivariateNormalDiagWithSoftplusStDev" class="dashAnchor"></a><code id="MultivariateNormalDiagWithSoftplusStDev">class tf.contrib.distributions.MultivariateNormalDiagWithSoftplusStDev</code></h3>
<p>MultivariateNormalDiag with <code>diag_stddev = softplus(diag_stddev)</code>. - - -</p>
<h4 id="tf.contrib.distributions.multivariatenormaldiagwithsoftplusstdev.__init__mu-diag_stdev-validate_argsfalse-allow_nan_statstrue-namemultivariatenormaldiagwithsoftplusstddev"><code id="MultivariateNormalDiagWithSoftplusStDev.__init__">tf.contrib.distributions.MultivariateNormalDiagWithSoftplusStDev.__init__(mu, diag_stdev, validate_args=False, allow_nan_stats=True, name='MultivariateNormalDiagWithSoftplusStdDev')</code></h4>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiagwithsoftplusstdev.allow_nan_stats"><code id="MultivariateNormalDiagWithSoftplusStDev.allow_nan_stats">tf.contrib.distributions.MultivariateNormalDiagWithSoftplusStDev.allow_nan_stats</code></h4>
<p>Python boolean describing behavior when a stat is undefined.</p>
<p>Stats return +/- infinity when it makes sense. E.g., the variance of a Cauchy distribution is infinity. However, sometimes the statistic is undefined, e.g., if a distribution's pdf does not achieve a maximum within the support of the distribution, the mode is undefined. If the mean is undefined, then by definition the variance is undefined. E.g. the mean for Student's T for df = 1 is undefined (no clear way to say it is either + or - infinity), so the variance = E[(X - mean)^2] is also undefined.</p>
<h5 id="returns-540">Returns:</h5>
<ul>
<li><b><code>allow_nan_stats</code></b>: Python boolean.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiagwithsoftplusstdev.batch_shapenamebatch_shape"><code id="MultivariateNormalDiagWithSoftplusStDev.batch_shape">tf.contrib.distributions.MultivariateNormalDiagWithSoftplusStDev.batch_shape(name='batch_shape')</code></h4>
<p>Shape of a single sample from a single event index as a 1-D <code>Tensor</code>.</p>
<p>The product of the dimensions of the <code>batch_shape</code> is the number of independent distributions of this kind the instance represents.</p>
<h5 id="args-477">Args:</h5>
<ul>
<li><b><code>name</code></b>: name to give to the op</li>
</ul>
<h5 id="returns-541">Returns:</h5>
<ul>
<li><b><code>batch_shape</code></b>: <code>Tensor</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiagwithsoftplusstdev.cdfvalue-namecdf-condition_kwargs"><code id="MultivariateNormalDiagWithSoftplusStDev.cdf">tf.contrib.distributions.MultivariateNormalDiagWithSoftplusStDev.cdf(value, name='cdf', **condition_kwargs)</code></h4>
<p>Cumulative distribution function.</p>
<p>Given random variable <code>X</code>, the cumulative distribution function <code>cdf</code> is:</p>
<pre><code>cdf(x) := P[X &lt;= x]</code></pre>
<h5 id="args-478">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-542">Returns:</h5>
<ul>
<li><b><code>cdf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiagwithsoftplusstdev.copyoverride_parameters_kwargs"><code id="MultivariateNormalDiagWithSoftplusStDev.copy">tf.contrib.distributions.MultivariateNormalDiagWithSoftplusStDev.copy(**override_parameters_kwargs)</code></h4>
<p>Creates a deep copy of the distribution.</p>
<p>Note: the copy distribution may continue to depend on the original intialization arguments.</p>
<h5 id="args-479">Args:</h5>
<ul>
<li><b><code>**override_parameters_kwargs</code></b>: String/value dictionary of initialization arguments to override with new values.</li>
</ul>
<h5 id="returns-543">Returns:</h5>
<ul>
<li><b><code>distribution</code></b>: A new instance of <code>type(self)</code> intitialized from the union of self.parameters and override_parameters_kwargs, i.e., <code>dict(self.parameters, **override_parameters_kwargs)</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiagwithsoftplusstdev.dtype"><code id="MultivariateNormalDiagWithSoftplusStDev.dtype">tf.contrib.distributions.MultivariateNormalDiagWithSoftplusStDev.dtype</code></h4>
<p>The <code>DType</code> of <code>Tensor</code>s handled by this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiagwithsoftplusstdev.entropynameentropy"><code id="MultivariateNormalDiagWithSoftplusStDev.entropy">tf.contrib.distributions.MultivariateNormalDiagWithSoftplusStDev.entropy(name='entropy')</code></h4>
<p>Shannon entropy in nats.</p>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiagwithsoftplusstdev.event_shapenameevent_shape"><code id="MultivariateNormalDiagWithSoftplusStDev.event_shape">tf.contrib.distributions.MultivariateNormalDiagWithSoftplusStDev.event_shape(name='event_shape')</code></h4>
<p>Shape of a single sample from a single batch as a 1-D int32 <code>Tensor</code>.</p>
<h5 id="args-480">Args:</h5>
<ul>
<li><b><code>name</code></b>: name to give to the op</li>
</ul>
<h5 id="returns-544">Returns:</h5>
<ul>
<li><b><code>event_shape</code></b>: <code>Tensor</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiagwithsoftplusstdev.get_batch_shape"><code id="MultivariateNormalDiagWithSoftplusStDev.get_batch_shape">tf.contrib.distributions.MultivariateNormalDiagWithSoftplusStDev.get_batch_shape()</code></h4>
<p>Shape of a single sample from a single event index as a <code>TensorShape</code>.</p>
<p>Same meaning as <code>batch_shape</code>. May be only partially defined.</p>
<h5 id="returns-545">Returns:</h5>
<ul>
<li><b><code>batch_shape</code></b>: <code>TensorShape</code>, possibly unknown.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiagwithsoftplusstdev.get_event_shape"><code id="MultivariateNormalDiagWithSoftplusStDev.get_event_shape">tf.contrib.distributions.MultivariateNormalDiagWithSoftplusStDev.get_event_shape()</code></h4>
<p>Shape of a single sample from a single batch as a <code>TensorShape</code>.</p>
<p>Same meaning as <code>event_shape</code>. May be only partially defined.</p>
<h5 id="returns-546">Returns:</h5>
<ul>
<li><b><code>event_shape</code></b>: <code>TensorShape</code>, possibly unknown.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiagwithsoftplusstdev.is_continuous"><code id="MultivariateNormalDiagWithSoftplusStDev.is_continuous">tf.contrib.distributions.MultivariateNormalDiagWithSoftplusStDev.is_continuous</code></h4>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiagwithsoftplusstdev.is_reparameterized"><code id="MultivariateNormalDiagWithSoftplusStDev.is_reparameterized">tf.contrib.distributions.MultivariateNormalDiagWithSoftplusStDev.is_reparameterized</code></h4>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiagwithsoftplusstdev.log_cdfvalue-namelog_cdf-condition_kwargs"><code id="MultivariateNormalDiagWithSoftplusStDev.log_cdf">tf.contrib.distributions.MultivariateNormalDiagWithSoftplusStDev.log_cdf(value, name='log_cdf', **condition_kwargs)</code></h4>
<p>Log cumulative distribution function.</p>
<p>Given random variable <code>X</code>, the cumulative distribution function <code>cdf</code> is:</p>
<pre><code>log_cdf(x) := Log[ P[X &lt;= x] ]</code></pre>
<p>Often, a numerical approximation can be used for <code>log_cdf(x)</code> that yields a more accurate answer than simply taking the logarithm of the <code>cdf</code> when <code>x &lt;&lt; -1</code>.</p>
<h5 id="args-481">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-547">Returns:</h5>
<ul>
<li><b><code>logcdf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiagwithsoftplusstdev.log_pdfvalue-namelog_pdf-condition_kwargs"><code id="MultivariateNormalDiagWithSoftplusStDev.log_pdf">tf.contrib.distributions.MultivariateNormalDiagWithSoftplusStDev.log_pdf(value, name='log_pdf', **condition_kwargs)</code></h4>
<p>Log probability density function.</p>
<h5 id="args-482">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-548">Returns:</h5>
<ul>
<li><b><code>log_prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-173">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if not <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiagwithsoftplusstdev.log_pmfvalue-namelog_pmf-condition_kwargs"><code id="MultivariateNormalDiagWithSoftplusStDev.log_pmf">tf.contrib.distributions.MultivariateNormalDiagWithSoftplusStDev.log_pmf(value, name='log_pmf', **condition_kwargs)</code></h4>
<p>Log probability mass function.</p>
<h5 id="args-483">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-549">Returns:</h5>
<ul>
<li><b><code>log_pmf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-174">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiagwithsoftplusstdev.log_probvalue-namelog_prob-condition_kwargs"><code id="MultivariateNormalDiagWithSoftplusStDev.log_prob">tf.contrib.distributions.MultivariateNormalDiagWithSoftplusStDev.log_prob(value, name='log_prob', **condition_kwargs)</code></h4>
<p>Log probability density/mass function (depending on <code>is_continuous</code>).</p>
<p>Additional documentation from <code>_MultivariateNormalOperatorPD</code>:</p>
<p><code>x</code> is a batch vector with compatible shape if <code>x</code> is a <code>Tensor</code> whose shape can be broadcast up to either:</p>
<pre><code>self.batch_shape + self.event_shape</code></pre>
<p>or</p>
<pre><code>[M1,...,Mm] + self.batch_shape + self.event_shape</code></pre>
<h5 id="args-484">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-550">Returns:</h5>
<ul>
<li><b><code>log_prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiagwithsoftplusstdev.log_sigma_detnamelog_sigma_det"><code id="MultivariateNormalDiagWithSoftplusStDev.log_sigma_det">tf.contrib.distributions.MultivariateNormalDiagWithSoftplusStDev.log_sigma_det(name='log_sigma_det')</code></h4>
<p>Log of determinant of covariance matrix.</p>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiagwithsoftplusstdev.log_survival_functionvalue-namelog_survival_function-condition_kwargs"><code id="MultivariateNormalDiagWithSoftplusStDev.log_survival_function">tf.contrib.distributions.MultivariateNormalDiagWithSoftplusStDev.log_survival_function(value, name='log_survival_function', **condition_kwargs)</code></h4>
<p>Log survival function.</p>
<p>Given random variable <code>X</code>, the survival function is defined:</p>
<pre><code>log_survival_function(x) = Log[ P[X &gt; x] ]
                         = Log[ 1 - P[X &lt;= x] ]
                         = Log[ 1 - cdf(x) ]</code></pre>
<p>Typically, different numerical approximations can be used for the log survival function, which are more accurate than <code>1 - cdf(x)</code> when <code>x &gt;&gt; 1</code>.</p>
<h5 id="args-485">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-551">Returns:</h5>
<p><code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiagwithsoftplusstdev.meannamemean"><code id="MultivariateNormalDiagWithSoftplusStDev.mean">tf.contrib.distributions.MultivariateNormalDiagWithSoftplusStDev.mean(name='mean')</code></h4>
<p>Mean.</p>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiagwithsoftplusstdev.modenamemode"><code id="MultivariateNormalDiagWithSoftplusStDev.mode">tf.contrib.distributions.MultivariateNormalDiagWithSoftplusStDev.mode(name='mode')</code></h4>
<p>Mode.</p>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiagwithsoftplusstdev.mu"><code id="MultivariateNormalDiagWithSoftplusStDev.mu">tf.contrib.distributions.MultivariateNormalDiagWithSoftplusStDev.mu</code></h4>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiagwithsoftplusstdev.name"><code id="MultivariateNormalDiagWithSoftplusStDev.name">tf.contrib.distributions.MultivariateNormalDiagWithSoftplusStDev.name</code></h4>
<p>Name prepended to all ops created by this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiagwithsoftplusstdev.param_shapescls-sample_shape-namedistributionparamshapes"><code id="MultivariateNormalDiagWithSoftplusStDev.param_shapes">tf.contrib.distributions.MultivariateNormalDiagWithSoftplusStDev.param_shapes(cls, sample_shape, name='DistributionParamShapes')</code></h4>
<p>Shapes of parameters given the desired shape of a call to <code>sample()</code>.</p>
<p>Subclasses should override static method <code>_param_shapes</code>.</p>
<h5 id="args-486">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: <code>Tensor</code> or python list/tuple. Desired shape of a call to <code>sample()</code>.</li>
<li><b><code>name</code></b>: name to prepend ops with.</li>
</ul>
<h5 id="returns-552">Returns:</h5>
<p><code>dict</code> of parameter name to <code>Tensor</code> shapes.</p>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiagwithsoftplusstdev.param_static_shapescls-sample_shape"><code id="MultivariateNormalDiagWithSoftplusStDev.param_static_shapes">tf.contrib.distributions.MultivariateNormalDiagWithSoftplusStDev.param_static_shapes(cls, sample_shape)</code></h4>
<p>param_shapes with static (i.e. TensorShape) shapes.</p>
<h5 id="args-487">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: <code>TensorShape</code> or python list/tuple. Desired shape of a call to <code>sample()</code>.</li>
</ul>
<h5 id="returns-553">Returns:</h5>
<p><code>dict</code> of parameter name to <code>TensorShape</code>.</p>
<h5 id="raises-175">Raises:</h5>
<ul>
<li><b><code>ValueError</code></b>: if <code>sample_shape</code> is a <code>TensorShape</code> and is not fully defined.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiagwithsoftplusstdev.parameters"><code id="MultivariateNormalDiagWithSoftplusStDev.parameters">tf.contrib.distributions.MultivariateNormalDiagWithSoftplusStDev.parameters</code></h4>
<p>Dictionary of parameters used to instantiate this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiagwithsoftplusstdev.pdfvalue-namepdf-condition_kwargs"><code id="MultivariateNormalDiagWithSoftplusStDev.pdf">tf.contrib.distributions.MultivariateNormalDiagWithSoftplusStDev.pdf(value, name='pdf', **condition_kwargs)</code></h4>
<p>Probability density function.</p>
<h5 id="args-488">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-554">Returns:</h5>
<ul>
<li><b><code>prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-176">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if not <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiagwithsoftplusstdev.pmfvalue-namepmf-condition_kwargs"><code id="MultivariateNormalDiagWithSoftplusStDev.pmf">tf.contrib.distributions.MultivariateNormalDiagWithSoftplusStDev.pmf(value, name='pmf', **condition_kwargs)</code></h4>
<p>Probability mass function.</p>
<h5 id="args-489">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-555">Returns:</h5>
<ul>
<li><b><code>pmf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-177">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiagwithsoftplusstdev.probvalue-nameprob-condition_kwargs"><code id="MultivariateNormalDiagWithSoftplusStDev.prob">tf.contrib.distributions.MultivariateNormalDiagWithSoftplusStDev.prob(value, name='prob', **condition_kwargs)</code></h4>
<p>Probability density/mass function (depending on <code>is_continuous</code>).</p>
<p>Additional documentation from <code>_MultivariateNormalOperatorPD</code>:</p>
<p><code>x</code> is a batch vector with compatible shape if <code>x</code> is a <code>Tensor</code> whose shape can be broadcast up to either:</p>
<pre><code>self.batch_shape + self.event_shape</code></pre>
<p>or</p>
<pre><code>[M1,...,Mm] + self.batch_shape + self.event_shape</code></pre>
<h5 id="args-490">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-556">Returns:</h5>
<ul>
<li><b><code>prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiagwithsoftplusstdev.samplesample_shape-seednone-namesample-condition_kwargs"><code id="MultivariateNormalDiagWithSoftplusStDev.sample">tf.contrib.distributions.MultivariateNormalDiagWithSoftplusStDev.sample(sample_shape=(), seed=None, name='sample', **condition_kwargs)</code></h4>
<p>Generate samples of the specified shape.</p>
<p>Note that a call to <code>sample()</code> without arguments will generate a single sample.</p>
<h5 id="args-491">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: 0D or 1D <code>int32</code> <code>Tensor</code>. Shape of the generated samples.</li>
<li><b><code>seed</code></b>: Python integer seed for RNG</li>
<li><b><code>name</code></b>: name to give to the op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-557">Returns:</h5>
<ul>
<li><b><code>samples</code></b>: a <code>Tensor</code> with prepended dimensions <code>sample_shape</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiagwithsoftplusstdev.sample_nn-seednone-namesample_n-condition_kwargs"><code id="MultivariateNormalDiagWithSoftplusStDev.sample_n">tf.contrib.distributions.MultivariateNormalDiagWithSoftplusStDev.sample_n(n, seed=None, name='sample_n', **condition_kwargs)</code></h4>
<p>Generate <code>n</code> samples.</p>
<h5 id="args-492">Args:</h5>
<ul>
<li><b><code>n</code></b>: <code>Scalar</code> <code>Tensor</code> of type <code>int32</code> or <code>int64</code>, the number of observations to sample.</li>
<li><b><code>seed</code></b>: Python integer seed for RNG</li>
<li><b><code>name</code></b>: name to give to the op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-558">Returns:</h5>
<ul>
<li><b><code>samples</code></b>: a <code>Tensor</code> with a prepended dimension (n,).</li>
</ul>
<h5 id="raises-178">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>n</code> is not an integer type.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiagwithsoftplusstdev.sigma"><code id="MultivariateNormalDiagWithSoftplusStDev.sigma">tf.contrib.distributions.MultivariateNormalDiagWithSoftplusStDev.sigma</code></h4>
<p>Dense (batch) covariance matrix, if available.</p>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiagwithsoftplusstdev.sigma_detnamesigma_det"><code id="MultivariateNormalDiagWithSoftplusStDev.sigma_det">tf.contrib.distributions.MultivariateNormalDiagWithSoftplusStDev.sigma_det(name='sigma_det')</code></h4>
<p>Determinant of covariance matrix.</p>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiagwithsoftplusstdev.stdnamestd"><code id="MultivariateNormalDiagWithSoftplusStDev.std">tf.contrib.distributions.MultivariateNormalDiagWithSoftplusStDev.std(name='std')</code></h4>
<p>Standard deviation.</p>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiagwithsoftplusstdev.survival_functionvalue-namesurvival_function-condition_kwargs"><code id="MultivariateNormalDiagWithSoftplusStDev.survival_function">tf.contrib.distributions.MultivariateNormalDiagWithSoftplusStDev.survival_function(value, name='survival_function', **condition_kwargs)</code></h4>
<p>Survival function.</p>
<p>Given random variable <code>X</code>, the survival function is defined:</p>
<pre><code>survival_function(x) = P[X &gt; x]
                     = 1 - P[X &lt;= x]
                     = 1 - cdf(x).</code></pre>
<h5 id="args-493">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-559">Returns:</h5>
<p>Tensor<code>of shape</code>sample_shape(x) + self.batch_shape<code>with values of type</code>self.dtype`.</p>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiagwithsoftplusstdev.validate_args"><code id="MultivariateNormalDiagWithSoftplusStDev.validate_args">tf.contrib.distributions.MultivariateNormalDiagWithSoftplusStDev.validate_args</code></h4>
<p>Python boolean indicated possibly expensive checks are enabled.</p>
<hr />
<h4 id="tf.contrib.distributions.multivariatenormaldiagwithsoftplusstdev.variancenamevariance"><code id="MultivariateNormalDiagWithSoftplusStDev.variance">tf.contrib.distributions.MultivariateNormalDiagWithSoftplusStDev.variance(name='variance')</code></h4>
<p>Variance.</p>
<h3 id="other-multivariate-distributions">Other multivariate distributions</h3>
<hr />
<h3 id="class-tf.contrib.distributions.dirichlet"><a name="//apple_ref/cpp/Class/Dirichlet" class="dashAnchor"></a><code id="Dirichlet">class tf.contrib.distributions.Dirichlet</code></h3>
<p>Dirichlet distribution.</p>
<p>This distribution is parameterized by a vector <code>alpha</code> of concentration parameters for <code>k</code> classes.</p>
<h4 id="mathematical-details-9">Mathematical details</h4>
<p>The Dirichlet is a distribution over the standard n-simplex, where the standard n-simplex is defined by: <code>{ (x_1, ..., x_n) in R^(n+1) | sum_j x_j = 1 and x_j &gt;= 0 for all j }</code>. The distribution has hyperparameters <code>alpha = (alpha_1,...,alpha_k)</code>, and probability mass function (prob):</p>
<p><code>prob(x) = 1 / Beta(alpha) * prod_j x_j^(alpha_j - 1)</code></p>
<p>where <code>Beta(x) = prod_j Gamma(x_j) / Gamma(sum_j x_j)</code> is the multivariate beta function.</p>
<p>This class provides methods to create indexed batches of Dirichlet distributions. If the provided <code>alpha</code> is rank 2 or higher, for every fixed set of leading dimensions, the last dimension represents one single Dirichlet distribution. When calling distribution functions (e.g. <code>dist.prob(x)</code>), <code>alpha</code> and <code>x</code> are broadcast to the same shape (if possible). In all cases, the last dimension of alpha/x represents single Dirichlet distributions.</p>
<h4 id="examples-9">Examples</h4>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">alpha <span class="op">=</span> [<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>]
dist <span class="op">=</span> Dirichlet(alpha)</code></pre></div>
<p>Creates a 3-class distribution, with the 3rd class is most likely to be drawn. The distribution functions can be evaluated on x.</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="co"># x same shape as alpha.</span>
x <span class="op">=</span> [.<span class="dv">2</span>, .<span class="dv">3</span>, .<span class="dv">5</span>]
dist.prob(x)  <span class="co"># Shape []</span>

<span class="co"># alpha will be broadcast to [[1, 2, 3], [1, 2, 3]] to match x.</span>
x <span class="op">=</span> [[.<span class="dv">1</span>, .<span class="dv">4</span>, .<span class="dv">5</span>], [.<span class="dv">2</span>, .<span class="dv">3</span>, .<span class="dv">5</span>]]
dist.prob(x)  <span class="co"># Shape [2]</span>

<span class="co"># alpha will be broadcast to shape [5, 7, 3] to match x.</span>
x <span class="op">=</span> [[...]]  <span class="co"># Shape [5, 7, 3]</span>
dist.prob(x)  <span class="co"># Shape [5, 7]</span></code></pre></div>
<p>Creates a 2-batch of 3-class distributions.</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">alpha <span class="op">=</span> [[<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>], [<span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">6</span>]]  <span class="co"># Shape [2, 3]</span>
dist <span class="op">=</span> Dirichlet(alpha)

<span class="co"># x will be broadcast to [[2, 1, 0], [2, 1, 0]] to match alpha.</span>
x <span class="op">=</span> [.<span class="dv">2</span>, .<span class="dv">3</span>, .<span class="dv">5</span>]
dist.prob(x)  <span class="co"># Shape [2]</span></code></pre></div>
<hr />
<h4 id="tf.contrib.distributions.dirichlet.__init__alpha-validate_argsfalse-allow_nan_statstrue-namedirichlet"><code id="Dirichlet.__init__">tf.contrib.distributions.Dirichlet.__init__(alpha, validate_args=False, allow_nan_stats=True, name='Dirichlet')</code></h4>
<p>Initialize a batch of Dirichlet distributions.</p>
<h5 id="args-494">Args:</h5>
<ul>
<li><b><code>alpha</code></b>: Positive floating point tensor with shape broadcastable to <code>[N1,..., Nm, k]</code> <code>m &gt;= 0</code>. Defines this as a batch of <code>N1 x ... x Nm</code> different <code>k</code> class Dirichlet distributions.</li>
<li><b><code>validate_args</code></b>: <code>Boolean</code>, default <code>False</code>. Whether to assert valid values for parameters <code>alpha</code> and <code>x</code> in <code>prob</code> and <code>log_prob</code>. If <code>False</code>, correct behavior is not guaranteed.</li>
<li><b><code>allow_nan_stats</code></b>: <code>Boolean</code>, default <code>True</code>. If <code>False</code>, raise an exception if a statistic (e.g. mean/mode/etc...) is undefined for any batch member. If <code>True</code>, batch members with valid parameters leading to undefined statistics will return NaN for this statistic.</li>
<li><p><b><code>name</code></b>: The name to prefix Ops created by this distribution class.</p></li>
<li><p><b><code>Examples</code></b>:</p></li>
</ul>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="co"># Define 1-batch of 2-class Dirichlet distributions,</span>
<span class="co"># also known as a Beta distribution.</span>
dist <span class="op">=</span> Dirichlet([<span class="fl">1.1</span>, <span class="fl">2.0</span>])

<span class="co"># Define a 2-batch of 3-class distributions.</span>
dist <span class="op">=</span> Dirichlet([[<span class="fl">1.0</span>, <span class="fl">2.0</span>, <span class="fl">3.0</span>], [<span class="fl">4.0</span>, <span class="fl">5.0</span>, <span class="fl">6.0</span>]])</code></pre></div>
<hr />
<h4 id="tf.contrib.distributions.dirichlet.allow_nan_stats"><code id="Dirichlet.allow_nan_stats">tf.contrib.distributions.Dirichlet.allow_nan_stats</code></h4>
<p>Python boolean describing behavior when a stat is undefined.</p>
<p>Stats return +/- infinity when it makes sense. E.g., the variance of a Cauchy distribution is infinity. However, sometimes the statistic is undefined, e.g., if a distribution's pdf does not achieve a maximum within the support of the distribution, the mode is undefined. If the mean is undefined, then by definition the variance is undefined. E.g. the mean for Student's T for df = 1 is undefined (no clear way to say it is either + or - infinity), so the variance = E[(X - mean)^2] is also undefined.</p>
<h5 id="returns-560">Returns:</h5>
<ul>
<li><b><code>allow_nan_stats</code></b>: Python boolean.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.dirichlet.alpha"><code id="Dirichlet.alpha">tf.contrib.distributions.Dirichlet.alpha</code></h4>
<p>Shape parameter.</p>
<hr />
<h4 id="tf.contrib.distributions.dirichlet.alpha_sum"><code id="Dirichlet.alpha_sum">tf.contrib.distributions.Dirichlet.alpha_sum</code></h4>
<p>Sum of shape parameter.</p>
<hr />
<h4 id="tf.contrib.distributions.dirichlet.batch_shapenamebatch_shape"><code id="Dirichlet.batch_shape">tf.contrib.distributions.Dirichlet.batch_shape(name='batch_shape')</code></h4>
<p>Shape of a single sample from a single event index as a 1-D <code>Tensor</code>.</p>
<p>The product of the dimensions of the <code>batch_shape</code> is the number of independent distributions of this kind the instance represents.</p>
<h5 id="args-495">Args:</h5>
<ul>
<li><b><code>name</code></b>: name to give to the op</li>
</ul>
<h5 id="returns-561">Returns:</h5>
<ul>
<li><b><code>batch_shape</code></b>: <code>Tensor</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.dirichlet.cdfvalue-namecdf-condition_kwargs"><code id="Dirichlet.cdf">tf.contrib.distributions.Dirichlet.cdf(value, name='cdf', **condition_kwargs)</code></h4>
<p>Cumulative distribution function.</p>
<p>Given random variable <code>X</code>, the cumulative distribution function <code>cdf</code> is:</p>
<pre><code>cdf(x) := P[X &lt;= x]</code></pre>
<h5 id="args-496">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-562">Returns:</h5>
<ul>
<li><b><code>cdf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.dirichlet.copyoverride_parameters_kwargs"><code id="Dirichlet.copy">tf.contrib.distributions.Dirichlet.copy(**override_parameters_kwargs)</code></h4>
<p>Creates a deep copy of the distribution.</p>
<p>Note: the copy distribution may continue to depend on the original intialization arguments.</p>
<h5 id="args-497">Args:</h5>
<ul>
<li><b><code>**override_parameters_kwargs</code></b>: String/value dictionary of initialization arguments to override with new values.</li>
</ul>
<h5 id="returns-563">Returns:</h5>
<ul>
<li><b><code>distribution</code></b>: A new instance of <code>type(self)</code> intitialized from the union of self.parameters and override_parameters_kwargs, i.e., <code>dict(self.parameters, **override_parameters_kwargs)</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.dirichlet.dtype"><code id="Dirichlet.dtype">tf.contrib.distributions.Dirichlet.dtype</code></h4>
<p>The <code>DType</code> of <code>Tensor</code>s handled by this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.dirichlet.entropynameentropy"><code id="Dirichlet.entropy">tf.contrib.distributions.Dirichlet.entropy(name='entropy')</code></h4>
<p>Shannon entropy in nats.</p>
<hr />
<h4 id="tf.contrib.distributions.dirichlet.event_shapenameevent_shape"><code id="Dirichlet.event_shape">tf.contrib.distributions.Dirichlet.event_shape(name='event_shape')</code></h4>
<p>Shape of a single sample from a single batch as a 1-D int32 <code>Tensor</code>.</p>
<h5 id="args-498">Args:</h5>
<ul>
<li><b><code>name</code></b>: name to give to the op</li>
</ul>
<h5 id="returns-564">Returns:</h5>
<ul>
<li><b><code>event_shape</code></b>: <code>Tensor</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.dirichlet.get_batch_shape"><code id="Dirichlet.get_batch_shape">tf.contrib.distributions.Dirichlet.get_batch_shape()</code></h4>
<p>Shape of a single sample from a single event index as a <code>TensorShape</code>.</p>
<p>Same meaning as <code>batch_shape</code>. May be only partially defined.</p>
<h5 id="returns-565">Returns:</h5>
<ul>
<li><b><code>batch_shape</code></b>: <code>TensorShape</code>, possibly unknown.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.dirichlet.get_event_shape"><code id="Dirichlet.get_event_shape">tf.contrib.distributions.Dirichlet.get_event_shape()</code></h4>
<p>Shape of a single sample from a single batch as a <code>TensorShape</code>.</p>
<p>Same meaning as <code>event_shape</code>. May be only partially defined.</p>
<h5 id="returns-566">Returns:</h5>
<ul>
<li><b><code>event_shape</code></b>: <code>TensorShape</code>, possibly unknown.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.dirichlet.is_continuous"><code id="Dirichlet.is_continuous">tf.contrib.distributions.Dirichlet.is_continuous</code></h4>
<hr />
<h4 id="tf.contrib.distributions.dirichlet.is_reparameterized"><code id="Dirichlet.is_reparameterized">tf.contrib.distributions.Dirichlet.is_reparameterized</code></h4>
<hr />
<h4 id="tf.contrib.distributions.dirichlet.log_cdfvalue-namelog_cdf-condition_kwargs"><code id="Dirichlet.log_cdf">tf.contrib.distributions.Dirichlet.log_cdf(value, name='log_cdf', **condition_kwargs)</code></h4>
<p>Log cumulative distribution function.</p>
<p>Given random variable <code>X</code>, the cumulative distribution function <code>cdf</code> is:</p>
<pre><code>log_cdf(x) := Log[ P[X &lt;= x] ]</code></pre>
<p>Often, a numerical approximation can be used for <code>log_cdf(x)</code> that yields a more accurate answer than simply taking the logarithm of the <code>cdf</code> when <code>x &lt;&lt; -1</code>.</p>
<h5 id="args-499">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-567">Returns:</h5>
<ul>
<li><b><code>logcdf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.dirichlet.log_pdfvalue-namelog_pdf-condition_kwargs"><code id="Dirichlet.log_pdf">tf.contrib.distributions.Dirichlet.log_pdf(value, name='log_pdf', **condition_kwargs)</code></h4>
<p>Log probability density function.</p>
<h5 id="args-500">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-568">Returns:</h5>
<ul>
<li><b><code>log_prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-179">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if not <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.dirichlet.log_pmfvalue-namelog_pmf-condition_kwargs"><code id="Dirichlet.log_pmf">tf.contrib.distributions.Dirichlet.log_pmf(value, name='log_pmf', **condition_kwargs)</code></h4>
<p>Log probability mass function.</p>
<h5 id="args-501">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-569">Returns:</h5>
<ul>
<li><b><code>log_pmf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-180">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.dirichlet.log_probvalue-namelog_prob-condition_kwargs"><code id="Dirichlet.log_prob">tf.contrib.distributions.Dirichlet.log_prob(value, name='log_prob', **condition_kwargs)</code></h4>
<p>Log probability density/mass function (depending on <code>is_continuous</code>).</p>
<p>Additional documentation from <code>Dirichlet</code>:</p>
<p>Note that the input must be a non-negative tensor with dtype <code>dtype</code> and whose shape can be broadcast with <code>self.alpha</code>. For fixed leading dimensions, the last dimension represents counts for the corresponding Dirichlet distribution in <code>self.alpha</code>. <code>x</code> is only legal if it sums up to one.</p>
<h5 id="args-502">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-570">Returns:</h5>
<ul>
<li><b><code>log_prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.dirichlet.log_survival_functionvalue-namelog_survival_function-condition_kwargs"><code id="Dirichlet.log_survival_function">tf.contrib.distributions.Dirichlet.log_survival_function(value, name='log_survival_function', **condition_kwargs)</code></h4>
<p>Log survival function.</p>
<p>Given random variable <code>X</code>, the survival function is defined:</p>
<pre><code>log_survival_function(x) = Log[ P[X &gt; x] ]
                         = Log[ 1 - P[X &lt;= x] ]
                         = Log[ 1 - cdf(x) ]</code></pre>
<p>Typically, different numerical approximations can be used for the log survival function, which are more accurate than <code>1 - cdf(x)</code> when <code>x &gt;&gt; 1</code>.</p>
<h5 id="args-503">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-571">Returns:</h5>
<p><code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.dirichlet.meannamemean"><code id="Dirichlet.mean">tf.contrib.distributions.Dirichlet.mean(name='mean')</code></h4>
<p>Mean.</p>
<hr />
<h4 id="tf.contrib.distributions.dirichlet.modenamemode"><code id="Dirichlet.mode">tf.contrib.distributions.Dirichlet.mode(name='mode')</code></h4>
<p>Mode.</p>
<p>Additional documentation from <code>Dirichlet</code>:</p>
<p>Note that the mode for the Dirichlet distribution is only defined when <code>alpha &gt; 1</code>. This returns the mode when <code>alpha &gt; 1</code>, and NaN otherwise. If <code>self.allow_nan_stats</code> is <code>False</code>, an exception will be raised rather than returning <code>NaN</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.dirichlet.name"><code id="Dirichlet.name">tf.contrib.distributions.Dirichlet.name</code></h4>
<p>Name prepended to all ops created by this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.dirichlet.param_shapescls-sample_shape-namedistributionparamshapes"><code id="Dirichlet.param_shapes">tf.contrib.distributions.Dirichlet.param_shapes(cls, sample_shape, name='DistributionParamShapes')</code></h4>
<p>Shapes of parameters given the desired shape of a call to <code>sample()</code>.</p>
<p>Subclasses should override static method <code>_param_shapes</code>.</p>
<h5 id="args-504">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: <code>Tensor</code> or python list/tuple. Desired shape of a call to <code>sample()</code>.</li>
<li><b><code>name</code></b>: name to prepend ops with.</li>
</ul>
<h5 id="returns-572">Returns:</h5>
<p><code>dict</code> of parameter name to <code>Tensor</code> shapes.</p>
<hr />
<h4 id="tf.contrib.distributions.dirichlet.param_static_shapescls-sample_shape"><code id="Dirichlet.param_static_shapes">tf.contrib.distributions.Dirichlet.param_static_shapes(cls, sample_shape)</code></h4>
<p>param_shapes with static (i.e. TensorShape) shapes.</p>
<h5 id="args-505">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: <code>TensorShape</code> or python list/tuple. Desired shape of a call to <code>sample()</code>.</li>
</ul>
<h5 id="returns-573">Returns:</h5>
<p><code>dict</code> of parameter name to <code>TensorShape</code>.</p>
<h5 id="raises-181">Raises:</h5>
<ul>
<li><b><code>ValueError</code></b>: if <code>sample_shape</code> is a <code>TensorShape</code> and is not fully defined.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.dirichlet.parameters"><code id="Dirichlet.parameters">tf.contrib.distributions.Dirichlet.parameters</code></h4>
<p>Dictionary of parameters used to instantiate this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.dirichlet.pdfvalue-namepdf-condition_kwargs"><code id="Dirichlet.pdf">tf.contrib.distributions.Dirichlet.pdf(value, name='pdf', **condition_kwargs)</code></h4>
<p>Probability density function.</p>
<h5 id="args-506">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-574">Returns:</h5>
<ul>
<li><b><code>prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-182">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if not <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.dirichlet.pmfvalue-namepmf-condition_kwargs"><code id="Dirichlet.pmf">tf.contrib.distributions.Dirichlet.pmf(value, name='pmf', **condition_kwargs)</code></h4>
<p>Probability mass function.</p>
<h5 id="args-507">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-575">Returns:</h5>
<ul>
<li><b><code>pmf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-183">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.dirichlet.probvalue-nameprob-condition_kwargs"><code id="Dirichlet.prob">tf.contrib.distributions.Dirichlet.prob(value, name='prob', **condition_kwargs)</code></h4>
<p>Probability density/mass function (depending on <code>is_continuous</code>).</p>
<p>Additional documentation from <code>Dirichlet</code>:</p>
<p>Note that the input must be a non-negative tensor with dtype <code>dtype</code> and whose shape can be broadcast with <code>self.alpha</code>. For fixed leading dimensions, the last dimension represents counts for the corresponding Dirichlet distribution in <code>self.alpha</code>. <code>x</code> is only legal if it sums up to one.</p>
<h5 id="args-508">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-576">Returns:</h5>
<ul>
<li><b><code>prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.dirichlet.samplesample_shape-seednone-namesample-condition_kwargs"><code id="Dirichlet.sample">tf.contrib.distributions.Dirichlet.sample(sample_shape=(), seed=None, name='sample', **condition_kwargs)</code></h4>
<p>Generate samples of the specified shape.</p>
<p>Note that a call to <code>sample()</code> without arguments will generate a single sample.</p>
<h5 id="args-509">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: 0D or 1D <code>int32</code> <code>Tensor</code>. Shape of the generated samples.</li>
<li><b><code>seed</code></b>: Python integer seed for RNG</li>
<li><b><code>name</code></b>: name to give to the op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-577">Returns:</h5>
<ul>
<li><b><code>samples</code></b>: a <code>Tensor</code> with prepended dimensions <code>sample_shape</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.dirichlet.sample_nn-seednone-namesample_n-condition_kwargs"><code id="Dirichlet.sample_n">tf.contrib.distributions.Dirichlet.sample_n(n, seed=None, name='sample_n', **condition_kwargs)</code></h4>
<p>Generate <code>n</code> samples.</p>
<h5 id="args-510">Args:</h5>
<ul>
<li><b><code>n</code></b>: <code>Scalar</code> <code>Tensor</code> of type <code>int32</code> or <code>int64</code>, the number of observations to sample.</li>
<li><b><code>seed</code></b>: Python integer seed for RNG</li>
<li><b><code>name</code></b>: name to give to the op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-578">Returns:</h5>
<ul>
<li><b><code>samples</code></b>: a <code>Tensor</code> with a prepended dimension (n,).</li>
</ul>
<h5 id="raises-184">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>n</code> is not an integer type.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.dirichlet.stdnamestd"><code id="Dirichlet.std">tf.contrib.distributions.Dirichlet.std(name='std')</code></h4>
<p>Standard deviation.</p>
<hr />
<h4 id="tf.contrib.distributions.dirichlet.survival_functionvalue-namesurvival_function-condition_kwargs"><code id="Dirichlet.survival_function">tf.contrib.distributions.Dirichlet.survival_function(value, name='survival_function', **condition_kwargs)</code></h4>
<p>Survival function.</p>
<p>Given random variable <code>X</code>, the survival function is defined:</p>
<pre><code>survival_function(x) = P[X &gt; x]
                     = 1 - P[X &lt;= x]
                     = 1 - cdf(x).</code></pre>
<h5 id="args-511">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-579">Returns:</h5>
<p>Tensor<code>of shape</code>sample_shape(x) + self.batch_shape<code>with values of type</code>self.dtype`.</p>
<hr />
<h4 id="tf.contrib.distributions.dirichlet.validate_args"><code id="Dirichlet.validate_args">tf.contrib.distributions.Dirichlet.validate_args</code></h4>
<p>Python boolean indicated possibly expensive checks are enabled.</p>
<hr />
<h4 id="tf.contrib.distributions.dirichlet.variancenamevariance"><code id="Dirichlet.variance">tf.contrib.distributions.Dirichlet.variance(name='variance')</code></h4>
<p>Variance.</p>
<hr />
<h3 id="class-tf.contrib.distributions.dirichletmultinomial"><a name="//apple_ref/cpp/Class/DirichletMultinomial" class="dashAnchor"></a><code id="DirichletMultinomial">class tf.contrib.distributions.DirichletMultinomial</code></h3>
<p>DirichletMultinomial mixture distribution.</p>
<p>This distribution is parameterized by a vector <code>alpha</code> of concentration parameters for <code>k</code> classes and <code>n</code>, the counts per each class..</p>
<h4 id="mathematical-details-10">Mathematical details</h4>
<p>The Dirichlet Multinomial is a distribution over k-class count data, meaning for each k-tuple of non-negative integer <code>counts = [c_1,...,c_k]</code>, we have a probability of these draws being made from the distribution. The distribution has hyperparameters <code>alpha = (alpha_1,...,alpha_k)</code>, and probability mass function (pmf):</p>
<p><code>pmf(counts) = N! / (n_1!...n_k!) * Beta(alpha + c) / Beta(alpha)</code></p>
<p>where above <code>N = sum_j n_j</code>, <code>N!</code> is <code>N</code> factorial, and <code>Beta(x) = prod_j Gamma(x_j) / Gamma(sum_j x_j)</code> is the multivariate beta function.</p>
<p>This is a mixture distribution in that <code>M</code> samples can be produced by: 1. Choose class probabilities <code>p = (p_1,...,p_k) ~ Dir(alpha)</code> 2. Draw integers <code>m = (n_1,...,n_k) ~ Multinomial(N, p)</code></p>
<p>This class provides methods to create indexed batches of Dirichlet Multinomial distributions. If the provided <code>alpha</code> is rank 2 or higher, for every fixed set of leading dimensions, the last dimension represents one single Dirichlet Multinomial distribution. When calling distribution functions (e.g. <code>dist.pmf(counts)</code>), <code>alpha</code> and <code>counts</code> are broadcast to the same shape (if possible). In all cases, the last dimension of alpha/counts represents single Dirichlet Multinomial distributions.</p>
<h4 id="examples-10">Examples</h4>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">alpha <span class="op">=</span> [<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>]
n <span class="op">=</span> <span class="dv">2</span>
dist <span class="op">=</span> DirichletMultinomial(n, alpha)</code></pre></div>
<p>Creates a 3-class distribution, with the 3rd class is most likely to be drawn. The distribution functions can be evaluated on counts.</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="co"># counts same shape as alpha.</span>
counts <span class="op">=</span> [<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">2</span>]
dist.pmf(counts)  <span class="co"># Shape []</span>

<span class="co"># alpha will be broadcast to [[1, 2, 3], [1, 2, 3]] to match counts.</span>
counts <span class="op">=</span> [[<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">0</span>], [<span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>]]
dist.pmf(counts)  <span class="co"># Shape [2]</span>

<span class="co"># alpha will be broadcast to shape [5, 7, 3] to match counts.</span>
counts <span class="op">=</span> [[...]]  <span class="co"># Shape [5, 7, 3]</span>
dist.pmf(counts)  <span class="co"># Shape [5, 7]</span></code></pre></div>
<p>Creates a 2-batch of 3-class distributions.</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">alpha <span class="op">=</span> [[<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>], [<span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">6</span>]]  <span class="co"># Shape [2, 3]</span>
n <span class="op">=</span> [<span class="dv">3</span>, <span class="dv">3</span>]
dist <span class="op">=</span> DirichletMultinomial(n, alpha)

<span class="co"># counts will be broadcast to [[2, 1, 0], [2, 1, 0]] to match alpha.</span>
counts <span class="op">=</span> [<span class="dv">2</span>, <span class="dv">1</span>, <span class="dv">0</span>]
dist.pmf(counts)  <span class="co"># Shape [2]</span></code></pre></div>
<hr />
<h4 id="tf.contrib.distributions.dirichletmultinomial.__init__n-alpha-validate_argsfalse-allow_nan_statstrue-namedirichletmultinomial"><code id="DirichletMultinomial.__init__">tf.contrib.distributions.DirichletMultinomial.__init__(n, alpha, validate_args=False, allow_nan_stats=True, name='DirichletMultinomial')</code></h4>
<p>Initialize a batch of DirichletMultinomial distributions.</p>
<h5 id="args-512">Args:</h5>
<ul>
<li><b><code>n</code></b>: Non-negative floating point tensor, whose dtype is the same as <code>alpha</code>. The shape is broadcastable to <code>[N1,..., Nm]</code> with <code>m &gt;= 0</code>. Defines this as a batch of <code>N1 x ... x Nm</code> different Dirichlet multinomial distributions. Its components should be equal to integer values.</li>
<li><b><code>alpha</code></b>: Positive floating point tensor, whose dtype is the same as <code>n</code> with shape broadcastable to <code>[N1,..., Nm, k]</code> <code>m &gt;= 0</code>. Defines this as a batch of <code>N1 x ... x Nm</code> different <code>k</code> class Dirichlet multinomial distributions.</li>
<li><b><code>validate_args</code></b>: <code>Boolean</code>, default <code>False</code>. Whether to assert valid values for parameters <code>alpha</code> and <code>n</code>, and <code>x</code> in <code>prob</code> and <code>log_prob</code>. If <code>False</code>, correct behavior is not guaranteed.</li>
<li><b><code>allow_nan_stats</code></b>: <code>Boolean</code>, default <code>True</code>. If <code>False</code>, raise an exception if a statistic (e.g. mean/mode/etc...) is undefined for any batch member. If <code>True</code>, batch members with valid parameters leading to undefined statistics will return NaN for this statistic.</li>
<li><p><b><code>name</code></b>: The name to prefix Ops created by this distribution class.</p></li>
<li><p><b><code>Examples</code></b>:</p></li>
</ul>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="co"># Define 1-batch of 2-class Dirichlet multinomial distribution,</span>
<span class="co"># also known as a beta-binomial.</span>
dist <span class="op">=</span> DirichletMultinomial(<span class="fl">2.0</span>, [<span class="fl">1.1</span>, <span class="fl">2.0</span>])

<span class="co"># Define a 2-batch of 3-class distributions.</span>
dist <span class="op">=</span> DirichletMultinomial([<span class="dv">3</span>., <span class="dv">4</span>], [[<span class="fl">1.0</span>, <span class="fl">2.0</span>, <span class="fl">3.0</span>], [<span class="fl">4.0</span>, <span class="fl">5.0</span>, <span class="fl">6.0</span>]])</code></pre></div>
<hr />
<h4 id="tf.contrib.distributions.dirichletmultinomial.allow_nan_stats"><code id="DirichletMultinomial.allow_nan_stats">tf.contrib.distributions.DirichletMultinomial.allow_nan_stats</code></h4>
<p>Python boolean describing behavior when a stat is undefined.</p>
<p>Stats return +/- infinity when it makes sense. E.g., the variance of a Cauchy distribution is infinity. However, sometimes the statistic is undefined, e.g., if a distribution's pdf does not achieve a maximum within the support of the distribution, the mode is undefined. If the mean is undefined, then by definition the variance is undefined. E.g. the mean for Student's T for df = 1 is undefined (no clear way to say it is either + or - infinity), so the variance = E[(X - mean)^2] is also undefined.</p>
<h5 id="returns-580">Returns:</h5>
<ul>
<li><b><code>allow_nan_stats</code></b>: Python boolean.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.dirichletmultinomial.alpha"><code id="DirichletMultinomial.alpha">tf.contrib.distributions.DirichletMultinomial.alpha</code></h4>
<p>Parameter defining this distribution.</p>
<hr />
<h4 id="tf.contrib.distributions.dirichletmultinomial.alpha_sum"><code id="DirichletMultinomial.alpha_sum">tf.contrib.distributions.DirichletMultinomial.alpha_sum</code></h4>
<p>Summation of alpha parameter.</p>
<hr />
<h4 id="tf.contrib.distributions.dirichletmultinomial.batch_shapenamebatch_shape"><code id="DirichletMultinomial.batch_shape">tf.contrib.distributions.DirichletMultinomial.batch_shape(name='batch_shape')</code></h4>
<p>Shape of a single sample from a single event index as a 1-D <code>Tensor</code>.</p>
<p>The product of the dimensions of the <code>batch_shape</code> is the number of independent distributions of this kind the instance represents.</p>
<h5 id="args-513">Args:</h5>
<ul>
<li><b><code>name</code></b>: name to give to the op</li>
</ul>
<h5 id="returns-581">Returns:</h5>
<ul>
<li><b><code>batch_shape</code></b>: <code>Tensor</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.dirichletmultinomial.cdfvalue-namecdf-condition_kwargs"><code id="DirichletMultinomial.cdf">tf.contrib.distributions.DirichletMultinomial.cdf(value, name='cdf', **condition_kwargs)</code></h4>
<p>Cumulative distribution function.</p>
<p>Given random variable <code>X</code>, the cumulative distribution function <code>cdf</code> is:</p>
<pre><code>cdf(x) := P[X &lt;= x]</code></pre>
<h5 id="args-514">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-582">Returns:</h5>
<ul>
<li><b><code>cdf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.dirichletmultinomial.copyoverride_parameters_kwargs"><code id="DirichletMultinomial.copy">tf.contrib.distributions.DirichletMultinomial.copy(**override_parameters_kwargs)</code></h4>
<p>Creates a deep copy of the distribution.</p>
<p>Note: the copy distribution may continue to depend on the original intialization arguments.</p>
<h5 id="args-515">Args:</h5>
<ul>
<li><b><code>**override_parameters_kwargs</code></b>: String/value dictionary of initialization arguments to override with new values.</li>
</ul>
<h5 id="returns-583">Returns:</h5>
<ul>
<li><b><code>distribution</code></b>: A new instance of <code>type(self)</code> intitialized from the union of self.parameters and override_parameters_kwargs, i.e., <code>dict(self.parameters, **override_parameters_kwargs)</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.dirichletmultinomial.dtype"><code id="DirichletMultinomial.dtype">tf.contrib.distributions.DirichletMultinomial.dtype</code></h4>
<p>The <code>DType</code> of <code>Tensor</code>s handled by this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.dirichletmultinomial.entropynameentropy"><code id="DirichletMultinomial.entropy">tf.contrib.distributions.DirichletMultinomial.entropy(name='entropy')</code></h4>
<p>Shannon entropy in nats.</p>
<hr />
<h4 id="tf.contrib.distributions.dirichletmultinomial.event_shapenameevent_shape"><code id="DirichletMultinomial.event_shape">tf.contrib.distributions.DirichletMultinomial.event_shape(name='event_shape')</code></h4>
<p>Shape of a single sample from a single batch as a 1-D int32 <code>Tensor</code>.</p>
<h5 id="args-516">Args:</h5>
<ul>
<li><b><code>name</code></b>: name to give to the op</li>
</ul>
<h5 id="returns-584">Returns:</h5>
<ul>
<li><b><code>event_shape</code></b>: <code>Tensor</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.dirichletmultinomial.get_batch_shape"><code id="DirichletMultinomial.get_batch_shape">tf.contrib.distributions.DirichletMultinomial.get_batch_shape()</code></h4>
<p>Shape of a single sample from a single event index as a <code>TensorShape</code>.</p>
<p>Same meaning as <code>batch_shape</code>. May be only partially defined.</p>
<h5 id="returns-585">Returns:</h5>
<ul>
<li><b><code>batch_shape</code></b>: <code>TensorShape</code>, possibly unknown.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.dirichletmultinomial.get_event_shape"><code id="DirichletMultinomial.get_event_shape">tf.contrib.distributions.DirichletMultinomial.get_event_shape()</code></h4>
<p>Shape of a single sample from a single batch as a <code>TensorShape</code>.</p>
<p>Same meaning as <code>event_shape</code>. May be only partially defined.</p>
<h5 id="returns-586">Returns:</h5>
<ul>
<li><b><code>event_shape</code></b>: <code>TensorShape</code>, possibly unknown.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.dirichletmultinomial.is_continuous"><code id="DirichletMultinomial.is_continuous">tf.contrib.distributions.DirichletMultinomial.is_continuous</code></h4>
<hr />
<h4 id="tf.contrib.distributions.dirichletmultinomial.is_reparameterized"><code id="DirichletMultinomial.is_reparameterized">tf.contrib.distributions.DirichletMultinomial.is_reparameterized</code></h4>
<hr />
<h4 id="tf.contrib.distributions.dirichletmultinomial.log_cdfvalue-namelog_cdf-condition_kwargs"><code id="DirichletMultinomial.log_cdf">tf.contrib.distributions.DirichletMultinomial.log_cdf(value, name='log_cdf', **condition_kwargs)</code></h4>
<p>Log cumulative distribution function.</p>
<p>Given random variable <code>X</code>, the cumulative distribution function <code>cdf</code> is:</p>
<pre><code>log_cdf(x) := Log[ P[X &lt;= x] ]</code></pre>
<p>Often, a numerical approximation can be used for <code>log_cdf(x)</code> that yields a more accurate answer than simply taking the logarithm of the <code>cdf</code> when <code>x &lt;&lt; -1</code>.</p>
<h5 id="args-517">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-587">Returns:</h5>
<ul>
<li><b><code>logcdf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.dirichletmultinomial.log_pdfvalue-namelog_pdf-condition_kwargs"><code id="DirichletMultinomial.log_pdf">tf.contrib.distributions.DirichletMultinomial.log_pdf(value, name='log_pdf', **condition_kwargs)</code></h4>
<p>Log probability density function.</p>
<h5 id="args-518">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-588">Returns:</h5>
<ul>
<li><b><code>log_prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-185">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if not <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.dirichletmultinomial.log_pmfvalue-namelog_pmf-condition_kwargs"><code id="DirichletMultinomial.log_pmf">tf.contrib.distributions.DirichletMultinomial.log_pmf(value, name='log_pmf', **condition_kwargs)</code></h4>
<p>Log probability mass function.</p>
<h5 id="args-519">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-589">Returns:</h5>
<ul>
<li><b><code>log_pmf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-186">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.dirichletmultinomial.log_probvalue-namelog_prob-condition_kwargs"><code id="DirichletMultinomial.log_prob">tf.contrib.distributions.DirichletMultinomial.log_prob(value, name='log_prob', **condition_kwargs)</code></h4>
<p>Log probability density/mass function (depending on <code>is_continuous</code>).</p>
<p>Additional documentation from <code>DirichletMultinomial</code>:</p>
<p>For each batch of counts <code>[n_1,...,n_k]</code>, <code>P[counts]</code> is the probability that after sampling <code>n</code> draws from this Dirichlet Multinomial distribution, the number of draws falling in class <code>j</code> is <code>n_j</code>. Note that different sequences of draws can result in the same counts, thus the probability includes a combinatorial coefficient.</p>
<p>Note that input, &quot;counts&quot;, must be a non-negative tensor with dtype <code>dtype</code> and whose shape can be broadcast with <code>self.alpha</code>. For fixed leading dimensions, the last dimension represents counts for the corresponding Dirichlet Multinomial distribution in <code>self.alpha</code>. <code>counts</code> is only legal if it sums up to <code>n</code> and its components are equal to integer values.</p>
<h5 id="args-520">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-590">Returns:</h5>
<ul>
<li><b><code>log_prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.dirichletmultinomial.log_survival_functionvalue-namelog_survival_function-condition_kwargs"><code id="DirichletMultinomial.log_survival_function">tf.contrib.distributions.DirichletMultinomial.log_survival_function(value, name='log_survival_function', **condition_kwargs)</code></h4>
<p>Log survival function.</p>
<p>Given random variable <code>X</code>, the survival function is defined:</p>
<pre><code>log_survival_function(x) = Log[ P[X &gt; x] ]
                         = Log[ 1 - P[X &lt;= x] ]
                         = Log[ 1 - cdf(x) ]</code></pre>
<p>Typically, different numerical approximations can be used for the log survival function, which are more accurate than <code>1 - cdf(x)</code> when <code>x &gt;&gt; 1</code>.</p>
<h5 id="args-521">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-591">Returns:</h5>
<p><code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.dirichletmultinomial.meannamemean"><code id="DirichletMultinomial.mean">tf.contrib.distributions.DirichletMultinomial.mean(name='mean')</code></h4>
<p>Mean.</p>
<hr />
<h4 id="tf.contrib.distributions.dirichletmultinomial.modenamemode"><code id="DirichletMultinomial.mode">tf.contrib.distributions.DirichletMultinomial.mode(name='mode')</code></h4>
<p>Mode.</p>
<hr />
<h4 id="tf.contrib.distributions.dirichletmultinomial.n"><code id="DirichletMultinomial.n">tf.contrib.distributions.DirichletMultinomial.n</code></h4>
<p>Parameter defining this distribution.</p>
<hr />
<h4 id="tf.contrib.distributions.dirichletmultinomial.name"><code id="DirichletMultinomial.name">tf.contrib.distributions.DirichletMultinomial.name</code></h4>
<p>Name prepended to all ops created by this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.dirichletmultinomial.param_shapescls-sample_shape-namedistributionparamshapes"><code id="DirichletMultinomial.param_shapes">tf.contrib.distributions.DirichletMultinomial.param_shapes(cls, sample_shape, name='DistributionParamShapes')</code></h4>
<p>Shapes of parameters given the desired shape of a call to <code>sample()</code>.</p>
<p>Subclasses should override static method <code>_param_shapes</code>.</p>
<h5 id="args-522">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: <code>Tensor</code> or python list/tuple. Desired shape of a call to <code>sample()</code>.</li>
<li><b><code>name</code></b>: name to prepend ops with.</li>
</ul>
<h5 id="returns-592">Returns:</h5>
<p><code>dict</code> of parameter name to <code>Tensor</code> shapes.</p>
<hr />
<h4 id="tf.contrib.distributions.dirichletmultinomial.param_static_shapescls-sample_shape"><code id="DirichletMultinomial.param_static_shapes">tf.contrib.distributions.DirichletMultinomial.param_static_shapes(cls, sample_shape)</code></h4>
<p>param_shapes with static (i.e. TensorShape) shapes.</p>
<h5 id="args-523">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: <code>TensorShape</code> or python list/tuple. Desired shape of a call to <code>sample()</code>.</li>
</ul>
<h5 id="returns-593">Returns:</h5>
<p><code>dict</code> of parameter name to <code>TensorShape</code>.</p>
<h5 id="raises-187">Raises:</h5>
<ul>
<li><b><code>ValueError</code></b>: if <code>sample_shape</code> is a <code>TensorShape</code> and is not fully defined.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.dirichletmultinomial.parameters"><code id="DirichletMultinomial.parameters">tf.contrib.distributions.DirichletMultinomial.parameters</code></h4>
<p>Dictionary of parameters used to instantiate this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.dirichletmultinomial.pdfvalue-namepdf-condition_kwargs"><code id="DirichletMultinomial.pdf">tf.contrib.distributions.DirichletMultinomial.pdf(value, name='pdf', **condition_kwargs)</code></h4>
<p>Probability density function.</p>
<h5 id="args-524">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-594">Returns:</h5>
<ul>
<li><b><code>prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-188">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if not <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.dirichletmultinomial.pmfvalue-namepmf-condition_kwargs"><code id="DirichletMultinomial.pmf">tf.contrib.distributions.DirichletMultinomial.pmf(value, name='pmf', **condition_kwargs)</code></h4>
<p>Probability mass function.</p>
<h5 id="args-525">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-595">Returns:</h5>
<ul>
<li><b><code>pmf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-189">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.dirichletmultinomial.probvalue-nameprob-condition_kwargs"><code id="DirichletMultinomial.prob">tf.contrib.distributions.DirichletMultinomial.prob(value, name='prob', **condition_kwargs)</code></h4>
<p>Probability density/mass function (depending on <code>is_continuous</code>).</p>
<p>Additional documentation from <code>DirichletMultinomial</code>:</p>
<p>For each batch of counts <code>[n_1,...,n_k]</code>, <code>P[counts]</code> is the probability that after sampling <code>n</code> draws from this Dirichlet Multinomial distribution, the number of draws falling in class <code>j</code> is <code>n_j</code>. Note that different sequences of draws can result in the same counts, thus the probability includes a combinatorial coefficient.</p>
<p>Note that input, &quot;counts&quot;, must be a non-negative tensor with dtype <code>dtype</code> and whose shape can be broadcast with <code>self.alpha</code>. For fixed leading dimensions, the last dimension represents counts for the corresponding Dirichlet Multinomial distribution in <code>self.alpha</code>. <code>counts</code> is only legal if it sums up to <code>n</code> and its components are equal to integer values.</p>
<h5 id="args-526">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-596">Returns:</h5>
<ul>
<li><b><code>prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.dirichletmultinomial.samplesample_shape-seednone-namesample-condition_kwargs"><code id="DirichletMultinomial.sample">tf.contrib.distributions.DirichletMultinomial.sample(sample_shape=(), seed=None, name='sample', **condition_kwargs)</code></h4>
<p>Generate samples of the specified shape.</p>
<p>Note that a call to <code>sample()</code> without arguments will generate a single sample.</p>
<h5 id="args-527">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: 0D or 1D <code>int32</code> <code>Tensor</code>. Shape of the generated samples.</li>
<li><b><code>seed</code></b>: Python integer seed for RNG</li>
<li><b><code>name</code></b>: name to give to the op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-597">Returns:</h5>
<ul>
<li><b><code>samples</code></b>: a <code>Tensor</code> with prepended dimensions <code>sample_shape</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.dirichletmultinomial.sample_nn-seednone-namesample_n-condition_kwargs"><code id="DirichletMultinomial.sample_n">tf.contrib.distributions.DirichletMultinomial.sample_n(n, seed=None, name='sample_n', **condition_kwargs)</code></h4>
<p>Generate <code>n</code> samples.</p>
<h5 id="args-528">Args:</h5>
<ul>
<li><b><code>n</code></b>: <code>Scalar</code> <code>Tensor</code> of type <code>int32</code> or <code>int64</code>, the number of observations to sample.</li>
<li><b><code>seed</code></b>: Python integer seed for RNG</li>
<li><b><code>name</code></b>: name to give to the op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-598">Returns:</h5>
<ul>
<li><b><code>samples</code></b>: a <code>Tensor</code> with a prepended dimension (n,).</li>
</ul>
<h5 id="raises-190">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>n</code> is not an integer type.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.dirichletmultinomial.stdnamestd"><code id="DirichletMultinomial.std">tf.contrib.distributions.DirichletMultinomial.std(name='std')</code></h4>
<p>Standard deviation.</p>
<hr />
<h4 id="tf.contrib.distributions.dirichletmultinomial.survival_functionvalue-namesurvival_function-condition_kwargs"><code id="DirichletMultinomial.survival_function">tf.contrib.distributions.DirichletMultinomial.survival_function(value, name='survival_function', **condition_kwargs)</code></h4>
<p>Survival function.</p>
<p>Given random variable <code>X</code>, the survival function is defined:</p>
<pre><code>survival_function(x) = P[X &gt; x]
                     = 1 - P[X &lt;= x]
                     = 1 - cdf(x).</code></pre>
<h5 id="args-529">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-599">Returns:</h5>
<p>Tensor<code>of shape</code>sample_shape(x) + self.batch_shape<code>with values of type</code>self.dtype`.</p>
<hr />
<h4 id="tf.contrib.distributions.dirichletmultinomial.validate_args"><code id="DirichletMultinomial.validate_args">tf.contrib.distributions.DirichletMultinomial.validate_args</code></h4>
<p>Python boolean indicated possibly expensive checks are enabled.</p>
<hr />
<h4 id="tf.contrib.distributions.dirichletmultinomial.variancenamevariance"><code id="DirichletMultinomial.variance">tf.contrib.distributions.DirichletMultinomial.variance(name='variance')</code></h4>
<p>Variance.</p>
<p>Additional documentation from <code>DirichletMultinomial</code>:</p>
<p>The variance for each batch member is defined as the following:</p>
<pre><code>Var(X_j) = n * alpha_j / alpha_0 * (1 - alpha_j / alpha_0) *
(n + alpha_0) / (1 + alpha_0)</code></pre>
<p>where <code>alpha_0 = sum_j alpha_j</code>.</p>
<p>The covariance between elements in a batch is defined as:</p>
<pre><code>Cov(X_i, X_j) = -n * alpha_i * alpha_j / alpha_0 ** 2 *
(n + alpha_0) / (1 + alpha_0)</code></pre>
<hr />
<h3 id="class-tf.contrib.distributions.multinomial"><a name="//apple_ref/cpp/Class/Multinomial" class="dashAnchor"></a><code id="Multinomial">class tf.contrib.distributions.Multinomial</code></h3>
<p>Multinomial distribution.</p>
<p>This distribution is parameterized by a vector <code>p</code> of probability parameters for <code>k</code> classes and <code>n</code>, the counts per each class..</p>
<h4 id="mathematical-details-11">Mathematical details</h4>
<p>The Multinomial is a distribution over k-class count data, meaning for each k-tuple of non-negative integer <code>counts = [n_1,...,n_k]</code>, we have a probability of these draws being made from the distribution. The distribution has hyperparameters <code>p = (p_1,...,p_k)</code>, and probability mass function (pmf):</p>
<p><code>pmf(counts) = n! / (n_1!...n_k!) * (p_1)^n_1*(p_2)^n_2*...(p_k)^n_k</code></p>
<p>where above <code>n = sum_j n_j</code>, <code>n!</code> is <code>n</code> factorial.</p>
<h4 id="examples-11">Examples</h4>
<p>Create a 3-class distribution, with the 3rd class is most likely to be drawn, using logits..</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">logits <span class="op">=</span> [<span class="op">-</span><span class="dv">50</span>., <span class="op">-</span><span class="dv">43</span>, <span class="dv">0</span>]
dist <span class="op">=</span> Multinomial(n<span class="op">=</span><span class="dv">4</span>., logits<span class="op">=</span>logits)</code></pre></div>
<p>Create a 3-class distribution, with the 3rd class is most likely to be drawn.</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">p <span class="op">=</span> [.<span class="dv">2</span>, .<span class="dv">3</span>, .<span class="dv">5</span>]
dist <span class="op">=</span> Multinomial(n<span class="op">=</span><span class="dv">4</span>., p<span class="op">=</span>p)</code></pre></div>
<p>The distribution functions can be evaluated on counts.</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="co"># counts same shape as p.</span>
counts <span class="op">=</span> [<span class="dv">1</span>., <span class="dv">0</span>, <span class="dv">3</span>]
dist.prob(counts)  <span class="co"># Shape []</span>

<span class="co"># p will be broadcast to [[.2, .3, .5], [.2, .3, .5]] to match counts.</span>
counts <span class="op">=</span> [[<span class="dv">1</span>., <span class="dv">2</span>, <span class="dv">1</span>], [<span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">0</span>]]
dist.prob(counts)  <span class="co"># Shape [2]</span>

<span class="co"># p will be broadcast to shape [5, 7, 3] to match counts.</span>
counts <span class="op">=</span> [[...]]  <span class="co"># Shape [5, 7, 3]</span>
dist.prob(counts)  <span class="co"># Shape [5, 7]</span></code></pre></div>
<p>Create a 2-batch of 3-class distributions.</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">p <span class="op">=</span> [[.<span class="dv">1</span>, .<span class="dv">2</span>, .<span class="dv">7</span>], [.<span class="dv">3</span>, .<span class="dv">3</span>, .<span class="dv">4</span>]]  <span class="co"># Shape [2, 3]</span>
dist <span class="op">=</span> Multinomial(n<span class="op">=</span>[<span class="dv">4</span>., <span class="dv">5</span>], p<span class="op">=</span>p)

counts <span class="op">=</span> [[<span class="dv">2</span>., <span class="dv">1</span>, <span class="dv">1</span>], [<span class="dv">3</span>, <span class="dv">1</span>, <span class="dv">1</span>]]
dist.prob(counts)  <span class="co"># Shape [2]</span></code></pre></div>
<hr />
<h4 id="tf.contrib.distributions.multinomial.__init__n-logitsnone-pnone-validate_argsfalse-allow_nan_statstrue-namemultinomial"><code id="Multinomial.__init__">tf.contrib.distributions.Multinomial.__init__(n, logits=None, p=None, validate_args=False, allow_nan_stats=True, name='Multinomial')</code></h4>
<p>Initialize a batch of Multinomial distributions.</p>
<h5 id="args-530">Args:</h5>
<ul>
<li><b><code>n</code></b>: Non-negative floating point tensor with shape broadcastable to <code>[N1,..., Nm]</code> with <code>m &gt;= 0</code>. Defines this as a batch of <code>N1 x ... x Nm</code> different Multinomial distributions. Its components should be equal to integer values.</li>
<li><b><code>logits</code></b>: Floating point tensor representing the log-odds of a positive event with shape broadcastable to <code>[N1,..., Nm, k], m &gt;= 0</code>, and the same dtype as <code>n</code>. Defines this as a batch of <code>N1 x ... x Nm</code> different <code>k</code> class Multinomial distributions. Only one of <code>logits</code> or <code>p</code> should be passed in.</li>
<li><b><code>p</code></b>: Positive floating point tensor with shape broadcastable to <code>[N1,..., Nm, k]</code> <code>m &gt;= 0</code> and same dtype as <code>n</code>. Defines this as a batch of <code>N1 x ... x Nm</code> different <code>k</code> class Multinomial distributions. <code>p</code>'s components in the last portion of its shape should sum up to 1. Only one of <code>logits</code> or <code>p</code> should be passed in.</li>
<li><b><code>validate_args</code></b>: <code>Boolean</code>, default <code>False</code>. Whether to assert valid values for parameters <code>n</code> and <code>p</code>, and <code>x</code> in <code>prob</code> and <code>log_prob</code>. If <code>False</code>, correct behavior is not guaranteed.</li>
<li><b><code>allow_nan_stats</code></b>: <code>Boolean</code>, default <code>True</code>. If <code>False</code>, raise an exception if a statistic (e.g. mean/mode/etc...) is undefined for any batch member. If <code>True</code>, batch members with valid parameters leading to undefined statistics will return NaN for this statistic.</li>
<li><p><b><code>name</code></b>: The name to prefix Ops created by this distribution class.</p></li>
<li><p><b><code>Examples</code></b>:</p></li>
</ul>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="co"># Define 1-batch of 2-class multinomial distribution,</span>
<span class="co"># also known as a Binomial distribution.</span>
dist <span class="op">=</span> Multinomial(n<span class="op">=</span><span class="dv">2</span>., p<span class="op">=</span>[.<span class="dv">1</span>, .<span class="dv">9</span>])

<span class="co"># Define a 2-batch of 3-class distributions.</span>
dist <span class="op">=</span> Multinomial(n<span class="op">=</span>[<span class="dv">4</span>., <span class="dv">5</span>], p<span class="op">=</span>[[.<span class="dv">1</span>, .<span class="dv">3</span>, .<span class="dv">6</span>], [.<span class="dv">4</span>, .<span class="dv">05</span>, .<span class="dv">55</span>]])</code></pre></div>
<hr />
<h4 id="tf.contrib.distributions.multinomial.allow_nan_stats"><code id="Multinomial.allow_nan_stats">tf.contrib.distributions.Multinomial.allow_nan_stats</code></h4>
<p>Python boolean describing behavior when a stat is undefined.</p>
<p>Stats return +/- infinity when it makes sense. E.g., the variance of a Cauchy distribution is infinity. However, sometimes the statistic is undefined, e.g., if a distribution's pdf does not achieve a maximum within the support of the distribution, the mode is undefined. If the mean is undefined, then by definition the variance is undefined. E.g. the mean for Student's T for df = 1 is undefined (no clear way to say it is either + or - infinity), so the variance = E[(X - mean)^2] is also undefined.</p>
<h5 id="returns-600">Returns:</h5>
<ul>
<li><b><code>allow_nan_stats</code></b>: Python boolean.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multinomial.batch_shapenamebatch_shape"><code id="Multinomial.batch_shape">tf.contrib.distributions.Multinomial.batch_shape(name='batch_shape')</code></h4>
<p>Shape of a single sample from a single event index as a 1-D <code>Tensor</code>.</p>
<p>The product of the dimensions of the <code>batch_shape</code> is the number of independent distributions of this kind the instance represents.</p>
<h5 id="args-531">Args:</h5>
<ul>
<li><b><code>name</code></b>: name to give to the op</li>
</ul>
<h5 id="returns-601">Returns:</h5>
<ul>
<li><b><code>batch_shape</code></b>: <code>Tensor</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multinomial.cdfvalue-namecdf-condition_kwargs"><code id="Multinomial.cdf">tf.contrib.distributions.Multinomial.cdf(value, name='cdf', **condition_kwargs)</code></h4>
<p>Cumulative distribution function.</p>
<p>Given random variable <code>X</code>, the cumulative distribution function <code>cdf</code> is:</p>
<pre><code>cdf(x) := P[X &lt;= x]</code></pre>
<h5 id="args-532">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-602">Returns:</h5>
<ul>
<li><b><code>cdf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multinomial.copyoverride_parameters_kwargs"><code id="Multinomial.copy">tf.contrib.distributions.Multinomial.copy(**override_parameters_kwargs)</code></h4>
<p>Creates a deep copy of the distribution.</p>
<p>Note: the copy distribution may continue to depend on the original intialization arguments.</p>
<h5 id="args-533">Args:</h5>
<ul>
<li><b><code>**override_parameters_kwargs</code></b>: String/value dictionary of initialization arguments to override with new values.</li>
</ul>
<h5 id="returns-603">Returns:</h5>
<ul>
<li><b><code>distribution</code></b>: A new instance of <code>type(self)</code> intitialized from the union of self.parameters and override_parameters_kwargs, i.e., <code>dict(self.parameters, **override_parameters_kwargs)</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multinomial.dtype"><code id="Multinomial.dtype">tf.contrib.distributions.Multinomial.dtype</code></h4>
<p>The <code>DType</code> of <code>Tensor</code>s handled by this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.multinomial.entropynameentropy"><code id="Multinomial.entropy">tf.contrib.distributions.Multinomial.entropy(name='entropy')</code></h4>
<p>Shannon entropy in nats.</p>
<hr />
<h4 id="tf.contrib.distributions.multinomial.event_shapenameevent_shape"><code id="Multinomial.event_shape">tf.contrib.distributions.Multinomial.event_shape(name='event_shape')</code></h4>
<p>Shape of a single sample from a single batch as a 1-D int32 <code>Tensor</code>.</p>
<h5 id="args-534">Args:</h5>
<ul>
<li><b><code>name</code></b>: name to give to the op</li>
</ul>
<h5 id="returns-604">Returns:</h5>
<ul>
<li><b><code>event_shape</code></b>: <code>Tensor</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multinomial.get_batch_shape"><code id="Multinomial.get_batch_shape">tf.contrib.distributions.Multinomial.get_batch_shape()</code></h4>
<p>Shape of a single sample from a single event index as a <code>TensorShape</code>.</p>
<p>Same meaning as <code>batch_shape</code>. May be only partially defined.</p>
<h5 id="returns-605">Returns:</h5>
<ul>
<li><b><code>batch_shape</code></b>: <code>TensorShape</code>, possibly unknown.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multinomial.get_event_shape"><code id="Multinomial.get_event_shape">tf.contrib.distributions.Multinomial.get_event_shape()</code></h4>
<p>Shape of a single sample from a single batch as a <code>TensorShape</code>.</p>
<p>Same meaning as <code>event_shape</code>. May be only partially defined.</p>
<h5 id="returns-606">Returns:</h5>
<ul>
<li><b><code>event_shape</code></b>: <code>TensorShape</code>, possibly unknown.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multinomial.is_continuous"><code id="Multinomial.is_continuous">tf.contrib.distributions.Multinomial.is_continuous</code></h4>
<hr />
<h4 id="tf.contrib.distributions.multinomial.is_reparameterized"><code id="Multinomial.is_reparameterized">tf.contrib.distributions.Multinomial.is_reparameterized</code></h4>
<hr />
<h4 id="tf.contrib.distributions.multinomial.log_cdfvalue-namelog_cdf-condition_kwargs"><code id="Multinomial.log_cdf">tf.contrib.distributions.Multinomial.log_cdf(value, name='log_cdf', **condition_kwargs)</code></h4>
<p>Log cumulative distribution function.</p>
<p>Given random variable <code>X</code>, the cumulative distribution function <code>cdf</code> is:</p>
<pre><code>log_cdf(x) := Log[ P[X &lt;= x] ]</code></pre>
<p>Often, a numerical approximation can be used for <code>log_cdf(x)</code> that yields a more accurate answer than simply taking the logarithm of the <code>cdf</code> when <code>x &lt;&lt; -1</code>.</p>
<h5 id="args-535">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-607">Returns:</h5>
<ul>
<li><b><code>logcdf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multinomial.log_pdfvalue-namelog_pdf-condition_kwargs"><code id="Multinomial.log_pdf">tf.contrib.distributions.Multinomial.log_pdf(value, name='log_pdf', **condition_kwargs)</code></h4>
<p>Log probability density function.</p>
<h5 id="args-536">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-608">Returns:</h5>
<ul>
<li><b><code>log_prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-191">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if not <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multinomial.log_pmfvalue-namelog_pmf-condition_kwargs"><code id="Multinomial.log_pmf">tf.contrib.distributions.Multinomial.log_pmf(value, name='log_pmf', **condition_kwargs)</code></h4>
<p>Log probability mass function.</p>
<h5 id="args-537">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-609">Returns:</h5>
<ul>
<li><b><code>log_pmf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-192">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multinomial.log_probvalue-namelog_prob-condition_kwargs"><code id="Multinomial.log_prob">tf.contrib.distributions.Multinomial.log_prob(value, name='log_prob', **condition_kwargs)</code></h4>
<p>Log probability density/mass function (depending on <code>is_continuous</code>).</p>
<p>Additional documentation from <code>Multinomial</code>:</p>
<p>For each batch of counts <code>[n_1,...,n_k]</code>, <code>P[counts]</code> is the probability that after sampling <code>n</code> draws from this Multinomial distribution, the number of draws falling in class <code>j</code> is <code>n_j</code>. Note that different sequences of draws can result in the same counts, thus the probability includes a combinatorial coefficient.</p>
<p>Note that input &quot;counts&quot; must be a non-negative tensor with dtype <code>dtype</code> and whose shape can be broadcast with <code>self.p</code> and <code>self.n</code>. For fixed leading dimensions, the last dimension represents counts for the corresponding Multinomial distribution in <code>self.p</code>. <code>counts</code> is only legal if it sums up to <code>n</code> and its components are equal to integer values.</p>
<h5 id="args-538">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-610">Returns:</h5>
<ul>
<li><b><code>log_prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multinomial.log_survival_functionvalue-namelog_survival_function-condition_kwargs"><code id="Multinomial.log_survival_function">tf.contrib.distributions.Multinomial.log_survival_function(value, name='log_survival_function', **condition_kwargs)</code></h4>
<p>Log survival function.</p>
<p>Given random variable <code>X</code>, the survival function is defined:</p>
<pre><code>log_survival_function(x) = Log[ P[X &gt; x] ]
                         = Log[ 1 - P[X &lt;= x] ]
                         = Log[ 1 - cdf(x) ]</code></pre>
<p>Typically, different numerical approximations can be used for the log survival function, which are more accurate than <code>1 - cdf(x)</code> when <code>x &gt;&gt; 1</code>.</p>
<h5 id="args-539">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-611">Returns:</h5>
<p><code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.multinomial.logits"><code id="Multinomial.logits">tf.contrib.distributions.Multinomial.logits</code></h4>
<p>Vector of coordinatewise logits.</p>
<hr />
<h4 id="tf.contrib.distributions.multinomial.meannamemean"><code id="Multinomial.mean">tf.contrib.distributions.Multinomial.mean(name='mean')</code></h4>
<p>Mean.</p>
<hr />
<h4 id="tf.contrib.distributions.multinomial.modenamemode"><code id="Multinomial.mode">tf.contrib.distributions.Multinomial.mode(name='mode')</code></h4>
<p>Mode.</p>
<hr />
<h4 id="tf.contrib.distributions.multinomial.n"><code id="Multinomial.n">tf.contrib.distributions.Multinomial.n</code></h4>
<p>Number of trials.</p>
<hr />
<h4 id="tf.contrib.distributions.multinomial.name"><code id="Multinomial.name">tf.contrib.distributions.Multinomial.name</code></h4>
<p>Name prepended to all ops created by this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.multinomial.p"><code id="Multinomial.p">tf.contrib.distributions.Multinomial.p</code></h4>
<p>Vector of probabilities summing to one.</p>
<p>Each element is the probability of drawing that coordinate.</p>
<hr />
<h4 id="tf.contrib.distributions.multinomial.param_shapescls-sample_shape-namedistributionparamshapes"><code id="Multinomial.param_shapes">tf.contrib.distributions.Multinomial.param_shapes(cls, sample_shape, name='DistributionParamShapes')</code></h4>
<p>Shapes of parameters given the desired shape of a call to <code>sample()</code>.</p>
<p>Subclasses should override static method <code>_param_shapes</code>.</p>
<h5 id="args-540">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: <code>Tensor</code> or python list/tuple. Desired shape of a call to <code>sample()</code>.</li>
<li><b><code>name</code></b>: name to prepend ops with.</li>
</ul>
<h5 id="returns-612">Returns:</h5>
<p><code>dict</code> of parameter name to <code>Tensor</code> shapes.</p>
<hr />
<h4 id="tf.contrib.distributions.multinomial.param_static_shapescls-sample_shape"><code id="Multinomial.param_static_shapes">tf.contrib.distributions.Multinomial.param_static_shapes(cls, sample_shape)</code></h4>
<p>param_shapes with static (i.e. TensorShape) shapes.</p>
<h5 id="args-541">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: <code>TensorShape</code> or python list/tuple. Desired shape of a call to <code>sample()</code>.</li>
</ul>
<h5 id="returns-613">Returns:</h5>
<p><code>dict</code> of parameter name to <code>TensorShape</code>.</p>
<h5 id="raises-193">Raises:</h5>
<ul>
<li><b><code>ValueError</code></b>: if <code>sample_shape</code> is a <code>TensorShape</code> and is not fully defined.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multinomial.parameters"><code id="Multinomial.parameters">tf.contrib.distributions.Multinomial.parameters</code></h4>
<p>Dictionary of parameters used to instantiate this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.multinomial.pdfvalue-namepdf-condition_kwargs"><code id="Multinomial.pdf">tf.contrib.distributions.Multinomial.pdf(value, name='pdf', **condition_kwargs)</code></h4>
<p>Probability density function.</p>
<h5 id="args-542">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-614">Returns:</h5>
<ul>
<li><b><code>prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-194">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if not <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multinomial.pmfvalue-namepmf-condition_kwargs"><code id="Multinomial.pmf">tf.contrib.distributions.Multinomial.pmf(value, name='pmf', **condition_kwargs)</code></h4>
<p>Probability mass function.</p>
<h5 id="args-543">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-615">Returns:</h5>
<ul>
<li><b><code>pmf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-195">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multinomial.probvalue-nameprob-condition_kwargs"><code id="Multinomial.prob">tf.contrib.distributions.Multinomial.prob(value, name='prob', **condition_kwargs)</code></h4>
<p>Probability density/mass function (depending on <code>is_continuous</code>).</p>
<p>Additional documentation from <code>Multinomial</code>:</p>
<p>For each batch of counts <code>[n_1,...,n_k]</code>, <code>P[counts]</code> is the probability that after sampling <code>n</code> draws from this Multinomial distribution, the number of draws falling in class <code>j</code> is <code>n_j</code>. Note that different sequences of draws can result in the same counts, thus the probability includes a combinatorial coefficient.</p>
<p>Note that input &quot;counts&quot; must be a non-negative tensor with dtype <code>dtype</code> and whose shape can be broadcast with <code>self.p</code> and <code>self.n</code>. For fixed leading dimensions, the last dimension represents counts for the corresponding Multinomial distribution in <code>self.p</code>. <code>counts</code> is only legal if it sums up to <code>n</code> and its components are equal to integer values.</p>
<h5 id="args-544">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-616">Returns:</h5>
<ul>
<li><b><code>prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multinomial.samplesample_shape-seednone-namesample-condition_kwargs"><code id="Multinomial.sample">tf.contrib.distributions.Multinomial.sample(sample_shape=(), seed=None, name='sample', **condition_kwargs)</code></h4>
<p>Generate samples of the specified shape.</p>
<p>Note that a call to <code>sample()</code> without arguments will generate a single sample.</p>
<h5 id="args-545">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: 0D or 1D <code>int32</code> <code>Tensor</code>. Shape of the generated samples.</li>
<li><b><code>seed</code></b>: Python integer seed for RNG</li>
<li><b><code>name</code></b>: name to give to the op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-617">Returns:</h5>
<ul>
<li><b><code>samples</code></b>: a <code>Tensor</code> with prepended dimensions <code>sample_shape</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multinomial.sample_nn-seednone-namesample_n-condition_kwargs"><code id="Multinomial.sample_n">tf.contrib.distributions.Multinomial.sample_n(n, seed=None, name='sample_n', **condition_kwargs)</code></h4>
<p>Generate <code>n</code> samples.</p>
<h5 id="args-546">Args:</h5>
<ul>
<li><b><code>n</code></b>: <code>Scalar</code> <code>Tensor</code> of type <code>int32</code> or <code>int64</code>, the number of observations to sample.</li>
<li><b><code>seed</code></b>: Python integer seed for RNG</li>
<li><b><code>name</code></b>: name to give to the op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-618">Returns:</h5>
<ul>
<li><b><code>samples</code></b>: a <code>Tensor</code> with a prepended dimension (n,).</li>
</ul>
<h5 id="raises-196">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>n</code> is not an integer type.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.multinomial.stdnamestd"><code id="Multinomial.std">tf.contrib.distributions.Multinomial.std(name='std')</code></h4>
<p>Standard deviation.</p>
<hr />
<h4 id="tf.contrib.distributions.multinomial.survival_functionvalue-namesurvival_function-condition_kwargs"><code id="Multinomial.survival_function">tf.contrib.distributions.Multinomial.survival_function(value, name='survival_function', **condition_kwargs)</code></h4>
<p>Survival function.</p>
<p>Given random variable <code>X</code>, the survival function is defined:</p>
<pre><code>survival_function(x) = P[X &gt; x]
                     = 1 - P[X &lt;= x]
                     = 1 - cdf(x).</code></pre>
<h5 id="args-547">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-619">Returns:</h5>
<p>Tensor<code>of shape</code>sample_shape(x) + self.batch_shape<code>with values of type</code>self.dtype`.</p>
<hr />
<h4 id="tf.contrib.distributions.multinomial.validate_args"><code id="Multinomial.validate_args">tf.contrib.distributions.Multinomial.validate_args</code></h4>
<p>Python boolean indicated possibly expensive checks are enabled.</p>
<hr />
<h4 id="tf.contrib.distributions.multinomial.variancenamevariance"><code id="Multinomial.variance">tf.contrib.distributions.Multinomial.variance(name='variance')</code></h4>
<p>Variance.</p>
<hr />
<h3 id="class-tf.contrib.distributions.wishartcholesky"><a name="//apple_ref/cpp/Class/WishartCholesky" class="dashAnchor"></a><code id="WishartCholesky">class tf.contrib.distributions.WishartCholesky</code></h3>
<p>The matrix Wishart distribution on positive definite matrices.</p>
<p>This distribution is defined by a scalar degrees of freedom <code>df</code> and a lower, triangular Cholesky factor which characterizes the scale matrix.</p>
<p>Using WishartCholesky is a constant-time improvement over WishartFull. It saves an O(nbk^3) operation, i.e., a matrix-product operation for sampling and a Cholesky factorization in log_prob. For most use-cases it often saves another O(nbk^3) operation since most uses of Wishart will also use the Cholesky factorization.</p>
<h4 id="mathematical-details.">Mathematical details.</h4>
<p>The PDF of this distribution is,</p>
<pre><code>f(X) = det(X)^(0.5 (df-k-1)) exp(-0.5 tr[inv(scale) X]) / B(scale, df)</code></pre>
<p>where <code>df &gt;= k</code> denotes the degrees of freedom, <code>scale</code> is a symmetric, pd, <code>k x k</code> matrix, and the normalizing constant <code>B(scale, df)</code> is given by:</p>
<pre><code>B(scale, df) = 2^(0.5 df k) |det(scale)|^(0.5 df) Gamma_k(0.5 df)</code></pre>
<p>where <code>Gamma_k</code> is the multivariate Gamma function.</p>
<h4 id="examples-12">Examples</h4>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="co"># Initialize a single 3x3 Wishart with Cholesky factored scale matrix and 5</span>
<span class="co"># degrees-of-freedom.(*)</span>
df <span class="op">=</span> <span class="dv">5</span>
chol_scale <span class="op">=</span> tf.cholesky(...)  <span class="co"># Shape is [3, 3].</span>
dist <span class="op">=</span> tf.contrib.distributions.WishartCholesky(df<span class="op">=</span>df, scale<span class="op">=</span>chol_scale)

<span class="co"># Evaluate this on an observation in R^3, returning a scalar.</span>
x <span class="op">=</span> ... <span class="co"># A 3x3 positive definite matrix.</span>
dist.pdf(x)  <span class="co"># Shape is [], a scalar.</span>

<span class="co"># Evaluate this on a two observations, each in R^{3x3}, returning a length two</span>
<span class="co"># Tensor.</span>
x <span class="op">=</span> [x0, x1]  <span class="co"># Shape is [2, 3, 3].</span>
dist.pdf(x)  <span class="co"># Shape is [2].</span>

<span class="co"># Initialize two 3x3 Wisharts with Cholesky factored scale matrices.</span>
df <span class="op">=</span> [<span class="dv">5</span>, <span class="dv">4</span>]
chol_scale <span class="op">=</span> tf.cholesky(...)  <span class="co"># Shape is [2, 3, 3].</span>
dist <span class="op">=</span> tf.contrib.distributions.WishartCholesky(df<span class="op">=</span>df, scale<span class="op">=</span>chol_scale)

<span class="co"># Evaluate this on four observations.</span>
x <span class="op">=</span> [[x0, x1], [x2, x3]]  <span class="co"># Shape is [2, 2, 3, 3].</span>
dist.pdf(x)  <span class="co"># Shape is [2, 2].</span>

<span class="co"># (*) - To efficiently create a trainable covariance matrix, see the example</span>
<span class="co">#   in tf.contrib.distributions.matrix_diag_transform.</span></code></pre></div>
<hr />
<h4 id="tf.contrib.distributions.wishartcholesky.__init__df-scale-cholesky_input_output_matricesfalse-validate_argsfalse-allow_nan_statstrue-namewishartcholesky"><code id="WishartCholesky.__init__">tf.contrib.distributions.WishartCholesky.__init__(df, scale, cholesky_input_output_matrices=False, validate_args=False, allow_nan_stats=True, name='WishartCholesky')</code></h4>
<p>Construct Wishart distributions.</p>
<h5 id="args-548">Args:</h5>
<ul>
<li><b><code>df</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>. Degrees of freedom, must be greater than or equal to dimension of the scale matrix.</li>
<li><b><code>scale</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>. The Cholesky factorization of the symmetric positive definite scale matrix of the distribution.</li>
<li><b><code>cholesky_input_output_matrices</code></b>: <code>Boolean</code>. Any function which whose input or output is a matrix assumes the input is Cholesky and returns a Cholesky factored matrix. Example<code>log_pdf</code> input takes a Cholesky and <code>sample_n</code> returns a Cholesky when <code>cholesky_input_output_matrices=True</code>.</li>
<li><b><code>validate_args</code></b>: <code>Boolean</code>, default <code>False</code>. Whether to validate input with asserts. If <code>validate_args</code> is <code>False</code>, and the inputs are invalid, correct behavior is not guaranteed.</li>
<li><b><code>allow_nan_stats</code></b>: <code>Boolean</code>, default <code>True</code>. If <code>False</code>, raise an exception if a statistic (e.g., mean, mode) is undefined for any batch member. If True, batch members with valid parameters leading to undefined statistics will return <code>NaN</code> for this statistic.</li>
<li><b><code>name</code></b>: The name scope to give class member ops.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.wishartcholesky.allow_nan_stats"><code id="WishartCholesky.allow_nan_stats">tf.contrib.distributions.WishartCholesky.allow_nan_stats</code></h4>
<p>Python boolean describing behavior when a stat is undefined.</p>
<p>Stats return +/- infinity when it makes sense. E.g., the variance of a Cauchy distribution is infinity. However, sometimes the statistic is undefined, e.g., if a distribution's pdf does not achieve a maximum within the support of the distribution, the mode is undefined. If the mean is undefined, then by definition the variance is undefined. E.g. the mean for Student's T for df = 1 is undefined (no clear way to say it is either + or - infinity), so the variance = E[(X - mean)^2] is also undefined.</p>
<h5 id="returns-620">Returns:</h5>
<ul>
<li><b><code>allow_nan_stats</code></b>: Python boolean.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.wishartcholesky.batch_shapenamebatch_shape"><code id="WishartCholesky.batch_shape">tf.contrib.distributions.WishartCholesky.batch_shape(name='batch_shape')</code></h4>
<p>Shape of a single sample from a single event index as a 1-D <code>Tensor</code>.</p>
<p>The product of the dimensions of the <code>batch_shape</code> is the number of independent distributions of this kind the instance represents.</p>
<h5 id="args-549">Args:</h5>
<ul>
<li><b><code>name</code></b>: name to give to the op</li>
</ul>
<h5 id="returns-621">Returns:</h5>
<ul>
<li><b><code>batch_shape</code></b>: <code>Tensor</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.wishartcholesky.cdfvalue-namecdf-condition_kwargs"><code id="WishartCholesky.cdf">tf.contrib.distributions.WishartCholesky.cdf(value, name='cdf', **condition_kwargs)</code></h4>
<p>Cumulative distribution function.</p>
<p>Given random variable <code>X</code>, the cumulative distribution function <code>cdf</code> is:</p>
<pre><code>cdf(x) := P[X &lt;= x]</code></pre>
<h5 id="args-550">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-622">Returns:</h5>
<ul>
<li><b><code>cdf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.wishartcholesky.cholesky_input_output_matrices"><code id="WishartCholesky.cholesky_input_output_matrices">tf.contrib.distributions.WishartCholesky.cholesky_input_output_matrices</code></h4>
<p>Boolean indicating if <code>Tensor</code> input/outputs are Cholesky factorized.</p>
<hr />
<h4 id="tf.contrib.distributions.wishartcholesky.copyoverride_parameters_kwargs"><code id="WishartCholesky.copy">tf.contrib.distributions.WishartCholesky.copy(**override_parameters_kwargs)</code></h4>
<p>Creates a deep copy of the distribution.</p>
<p>Note: the copy distribution may continue to depend on the original intialization arguments.</p>
<h5 id="args-551">Args:</h5>
<ul>
<li><b><code>**override_parameters_kwargs</code></b>: String/value dictionary of initialization arguments to override with new values.</li>
</ul>
<h5 id="returns-623">Returns:</h5>
<ul>
<li><b><code>distribution</code></b>: A new instance of <code>type(self)</code> intitialized from the union of self.parameters and override_parameters_kwargs, i.e., <code>dict(self.parameters, **override_parameters_kwargs)</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.wishartcholesky.df"><code id="WishartCholesky.df">tf.contrib.distributions.WishartCholesky.df</code></h4>
<p>Wishart distribution degree(s) of freedom.</p>
<hr />
<h4 id="tf.contrib.distributions.wishartcholesky.dimension"><code id="WishartCholesky.dimension">tf.contrib.distributions.WishartCholesky.dimension</code></h4>
<p>Dimension of underlying vector space. The <code>p</code> in <code>R^(p*p)</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.wishartcholesky.dtype"><code id="WishartCholesky.dtype">tf.contrib.distributions.WishartCholesky.dtype</code></h4>
<p>The <code>DType</code> of <code>Tensor</code>s handled by this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.wishartcholesky.entropynameentropy"><code id="WishartCholesky.entropy">tf.contrib.distributions.WishartCholesky.entropy(name='entropy')</code></h4>
<p>Shannon entropy in nats.</p>
<hr />
<h4 id="tf.contrib.distributions.wishartcholesky.event_shapenameevent_shape"><code id="WishartCholesky.event_shape">tf.contrib.distributions.WishartCholesky.event_shape(name='event_shape')</code></h4>
<p>Shape of a single sample from a single batch as a 1-D int32 <code>Tensor</code>.</p>
<h5 id="args-552">Args:</h5>
<ul>
<li><b><code>name</code></b>: name to give to the op</li>
</ul>
<h5 id="returns-624">Returns:</h5>
<ul>
<li><b><code>event_shape</code></b>: <code>Tensor</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.wishartcholesky.get_batch_shape"><code id="WishartCholesky.get_batch_shape">tf.contrib.distributions.WishartCholesky.get_batch_shape()</code></h4>
<p>Shape of a single sample from a single event index as a <code>TensorShape</code>.</p>
<p>Same meaning as <code>batch_shape</code>. May be only partially defined.</p>
<h5 id="returns-625">Returns:</h5>
<ul>
<li><b><code>batch_shape</code></b>: <code>TensorShape</code>, possibly unknown.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.wishartcholesky.get_event_shape"><code id="WishartCholesky.get_event_shape">tf.contrib.distributions.WishartCholesky.get_event_shape()</code></h4>
<p>Shape of a single sample from a single batch as a <code>TensorShape</code>.</p>
<p>Same meaning as <code>event_shape</code>. May be only partially defined.</p>
<h5 id="returns-626">Returns:</h5>
<ul>
<li><b><code>event_shape</code></b>: <code>TensorShape</code>, possibly unknown.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.wishartcholesky.is_continuous"><code id="WishartCholesky.is_continuous">tf.contrib.distributions.WishartCholesky.is_continuous</code></h4>
<hr />
<h4 id="tf.contrib.distributions.wishartcholesky.is_reparameterized"><code id="WishartCholesky.is_reparameterized">tf.contrib.distributions.WishartCholesky.is_reparameterized</code></h4>
<hr />
<h4 id="tf.contrib.distributions.wishartcholesky.log_cdfvalue-namelog_cdf-condition_kwargs"><code id="WishartCholesky.log_cdf">tf.contrib.distributions.WishartCholesky.log_cdf(value, name='log_cdf', **condition_kwargs)</code></h4>
<p>Log cumulative distribution function.</p>
<p>Given random variable <code>X</code>, the cumulative distribution function <code>cdf</code> is:</p>
<pre><code>log_cdf(x) := Log[ P[X &lt;= x] ]</code></pre>
<p>Often, a numerical approximation can be used for <code>log_cdf(x)</code> that yields a more accurate answer than simply taking the logarithm of the <code>cdf</code> when <code>x &lt;&lt; -1</code>.</p>
<h5 id="args-553">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-627">Returns:</h5>
<ul>
<li><b><code>logcdf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.wishartcholesky.log_normalizing_constantnamelog_normalizing_constant"><code id="WishartCholesky.log_normalizing_constant">tf.contrib.distributions.WishartCholesky.log_normalizing_constant(name='log_normalizing_constant')</code></h4>
<p>Computes the log normalizing constant, log(Z).</p>
<hr />
<h4 id="tf.contrib.distributions.wishartcholesky.log_pdfvalue-namelog_pdf-condition_kwargs"><code id="WishartCholesky.log_pdf">tf.contrib.distributions.WishartCholesky.log_pdf(value, name='log_pdf', **condition_kwargs)</code></h4>
<p>Log probability density function.</p>
<h5 id="args-554">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-628">Returns:</h5>
<ul>
<li><b><code>log_prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-197">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if not <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.wishartcholesky.log_pmfvalue-namelog_pmf-condition_kwargs"><code id="WishartCholesky.log_pmf">tf.contrib.distributions.WishartCholesky.log_pmf(value, name='log_pmf', **condition_kwargs)</code></h4>
<p>Log probability mass function.</p>
<h5 id="args-555">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-629">Returns:</h5>
<ul>
<li><b><code>log_pmf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-198">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.wishartcholesky.log_probvalue-namelog_prob-condition_kwargs"><code id="WishartCholesky.log_prob">tf.contrib.distributions.WishartCholesky.log_prob(value, name='log_prob', **condition_kwargs)</code></h4>
<p>Log probability density/mass function (depending on <code>is_continuous</code>).</p>
<h5 id="args-556">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-630">Returns:</h5>
<ul>
<li><b><code>log_prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.wishartcholesky.log_survival_functionvalue-namelog_survival_function-condition_kwargs"><code id="WishartCholesky.log_survival_function">tf.contrib.distributions.WishartCholesky.log_survival_function(value, name='log_survival_function', **condition_kwargs)</code></h4>
<p>Log survival function.</p>
<p>Given random variable <code>X</code>, the survival function is defined:</p>
<pre><code>log_survival_function(x) = Log[ P[X &gt; x] ]
                         = Log[ 1 - P[X &lt;= x] ]
                         = Log[ 1 - cdf(x) ]</code></pre>
<p>Typically, different numerical approximations can be used for the log survival function, which are more accurate than <code>1 - cdf(x)</code> when <code>x &gt;&gt; 1</code>.</p>
<h5 id="args-557">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-631">Returns:</h5>
<p><code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.wishartcholesky.meannamemean"><code id="WishartCholesky.mean">tf.contrib.distributions.WishartCholesky.mean(name='mean')</code></h4>
<p>Mean.</p>
<hr />
<h4 id="tf.contrib.distributions.wishartcholesky.mean_log_detnamemean_log_det"><code id="WishartCholesky.mean_log_det">tf.contrib.distributions.WishartCholesky.mean_log_det(name='mean_log_det')</code></h4>
<p>Computes E[log(det(X))] under this Wishart distribution.</p>
<hr />
<h4 id="tf.contrib.distributions.wishartcholesky.modenamemode"><code id="WishartCholesky.mode">tf.contrib.distributions.WishartCholesky.mode(name='mode')</code></h4>
<p>Mode.</p>
<hr />
<h4 id="tf.contrib.distributions.wishartcholesky.name"><code id="WishartCholesky.name">tf.contrib.distributions.WishartCholesky.name</code></h4>
<p>Name prepended to all ops created by this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.wishartcholesky.param_shapescls-sample_shape-namedistributionparamshapes"><code id="WishartCholesky.param_shapes">tf.contrib.distributions.WishartCholesky.param_shapes(cls, sample_shape, name='DistributionParamShapes')</code></h4>
<p>Shapes of parameters given the desired shape of a call to <code>sample()</code>.</p>
<p>Subclasses should override static method <code>_param_shapes</code>.</p>
<h5 id="args-558">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: <code>Tensor</code> or python list/tuple. Desired shape of a call to <code>sample()</code>.</li>
<li><b><code>name</code></b>: name to prepend ops with.</li>
</ul>
<h5 id="returns-632">Returns:</h5>
<p><code>dict</code> of parameter name to <code>Tensor</code> shapes.</p>
<hr />
<h4 id="tf.contrib.distributions.wishartcholesky.param_static_shapescls-sample_shape"><code id="WishartCholesky.param_static_shapes">tf.contrib.distributions.WishartCholesky.param_static_shapes(cls, sample_shape)</code></h4>
<p>param_shapes with static (i.e. TensorShape) shapes.</p>
<h5 id="args-559">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: <code>TensorShape</code> or python list/tuple. Desired shape of a call to <code>sample()</code>.</li>
</ul>
<h5 id="returns-633">Returns:</h5>
<p><code>dict</code> of parameter name to <code>TensorShape</code>.</p>
<h5 id="raises-199">Raises:</h5>
<ul>
<li><b><code>ValueError</code></b>: if <code>sample_shape</code> is a <code>TensorShape</code> and is not fully defined.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.wishartcholesky.parameters"><code id="WishartCholesky.parameters">tf.contrib.distributions.WishartCholesky.parameters</code></h4>
<p>Dictionary of parameters used to instantiate this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.wishartcholesky.pdfvalue-namepdf-condition_kwargs"><code id="WishartCholesky.pdf">tf.contrib.distributions.WishartCholesky.pdf(value, name='pdf', **condition_kwargs)</code></h4>
<p>Probability density function.</p>
<h5 id="args-560">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-634">Returns:</h5>
<ul>
<li><b><code>prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-200">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if not <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.wishartcholesky.pmfvalue-namepmf-condition_kwargs"><code id="WishartCholesky.pmf">tf.contrib.distributions.WishartCholesky.pmf(value, name='pmf', **condition_kwargs)</code></h4>
<p>Probability mass function.</p>
<h5 id="args-561">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-635">Returns:</h5>
<ul>
<li><b><code>pmf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-201">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.wishartcholesky.probvalue-nameprob-condition_kwargs"><code id="WishartCholesky.prob">tf.contrib.distributions.WishartCholesky.prob(value, name='prob', **condition_kwargs)</code></h4>
<p>Probability density/mass function (depending on <code>is_continuous</code>).</p>
<h5 id="args-562">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-636">Returns:</h5>
<ul>
<li><b><code>prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.wishartcholesky.samplesample_shape-seednone-namesample-condition_kwargs"><code id="WishartCholesky.sample">tf.contrib.distributions.WishartCholesky.sample(sample_shape=(), seed=None, name='sample', **condition_kwargs)</code></h4>
<p>Generate samples of the specified shape.</p>
<p>Note that a call to <code>sample()</code> without arguments will generate a single sample.</p>
<h5 id="args-563">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: 0D or 1D <code>int32</code> <code>Tensor</code>. Shape of the generated samples.</li>
<li><b><code>seed</code></b>: Python integer seed for RNG</li>
<li><b><code>name</code></b>: name to give to the op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-637">Returns:</h5>
<ul>
<li><b><code>samples</code></b>: a <code>Tensor</code> with prepended dimensions <code>sample_shape</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.wishartcholesky.sample_nn-seednone-namesample_n-condition_kwargs"><code id="WishartCholesky.sample_n">tf.contrib.distributions.WishartCholesky.sample_n(n, seed=None, name='sample_n', **condition_kwargs)</code></h4>
<p>Generate <code>n</code> samples.</p>
<h5 id="args-564">Args:</h5>
<ul>
<li><b><code>n</code></b>: <code>Scalar</code> <code>Tensor</code> of type <code>int32</code> or <code>int64</code>, the number of observations to sample.</li>
<li><b><code>seed</code></b>: Python integer seed for RNG</li>
<li><b><code>name</code></b>: name to give to the op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-638">Returns:</h5>
<ul>
<li><b><code>samples</code></b>: a <code>Tensor</code> with a prepended dimension (n,).</li>
</ul>
<h5 id="raises-202">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>n</code> is not an integer type.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.wishartcholesky.scale"><code id="WishartCholesky.scale">tf.contrib.distributions.WishartCholesky.scale()</code></h4>
<p>Wishart distribution scale matrix.</p>
<hr />
<h4 id="tf.contrib.distributions.wishartcholesky.scale_operator_pd"><code id="WishartCholesky.scale_operator_pd">tf.contrib.distributions.WishartCholesky.scale_operator_pd</code></h4>
<p>Wishart distribution scale matrix as an OperatorPD.</p>
<hr />
<h4 id="tf.contrib.distributions.wishartcholesky.stdnamestd"><code id="WishartCholesky.std">tf.contrib.distributions.WishartCholesky.std(name='std')</code></h4>
<p>Standard deviation.</p>
<hr />
<h4 id="tf.contrib.distributions.wishartcholesky.survival_functionvalue-namesurvival_function-condition_kwargs"><code id="WishartCholesky.survival_function">tf.contrib.distributions.WishartCholesky.survival_function(value, name='survival_function', **condition_kwargs)</code></h4>
<p>Survival function.</p>
<p>Given random variable <code>X</code>, the survival function is defined:</p>
<pre><code>survival_function(x) = P[X &gt; x]
                     = 1 - P[X &lt;= x]
                     = 1 - cdf(x).</code></pre>
<h5 id="args-565">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-639">Returns:</h5>
<p>Tensor<code>of shape</code>sample_shape(x) + self.batch_shape<code>with values of type</code>self.dtype`.</p>
<hr />
<h4 id="tf.contrib.distributions.wishartcholesky.validate_args"><code id="WishartCholesky.validate_args">tf.contrib.distributions.WishartCholesky.validate_args</code></h4>
<p>Python boolean indicated possibly expensive checks are enabled.</p>
<hr />
<h4 id="tf.contrib.distributions.wishartcholesky.variancenamevariance"><code id="WishartCholesky.variance">tf.contrib.distributions.WishartCholesky.variance(name='variance')</code></h4>
<p>Variance.</p>
<hr />
<h3 id="class-tf.contrib.distributions.wishartfull"><a name="//apple_ref/cpp/Class/WishartFull" class="dashAnchor"></a><code id="WishartFull">class tf.contrib.distributions.WishartFull</code></h3>
<p>The matrix Wishart distribution on positive definite matrices.</p>
<p>This distribution is defined by a scalar degrees of freedom <code>df</code> and a symmetric, positive definite scale matrix.</p>
<p>Evaluation of the pdf, determinant, and sampling are all <code>O(k^3)</code> operations where <code>(k, k)</code> is the event space shape.</p>
<h4 id="mathematical-details.-1">Mathematical details.</h4>
<p>The PDF of this distribution is,</p>
<pre><code>f(X) = det(X)^(0.5 (df-k-1)) exp(-0.5 tr[inv(scale) X]) / B(scale, df)</code></pre>
<p>where <code>df &gt;= k</code> denotes the degrees of freedom, <code>scale</code> is a symmetric, pd, <code>k x k</code> matrix, and the normalizing constant <code>B(scale, df)</code> is given by:</p>
<pre><code>B(scale, df) = 2^(0.5 df k) |det(scale)|^(0.5 df) Gamma_k(0.5 df)</code></pre>
<p>where <code>Gamma_k</code> is the multivariate Gamma function.</p>
<h4 id="examples-13">Examples</h4>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="co"># Initialize a single 3x3 Wishart with Full factored scale matrix and 5</span>
<span class="co"># degrees-of-freedom.(*)</span>
df <span class="op">=</span> <span class="dv">5</span>
scale <span class="op">=</span> ...  <span class="co"># Shape is [3, 3]; positive definite.</span>
dist <span class="op">=</span> tf.contrib.distributions.WishartFull(df<span class="op">=</span>df, scale<span class="op">=</span>scale)

<span class="co"># Evaluate this on an observation in R^3, returning a scalar.</span>
x <span class="op">=</span> ... <span class="co"># A 3x3 positive definite matrix.</span>
dist.pdf(x)  <span class="co"># Shape is [], a scalar.</span>

<span class="co"># Evaluate this on a two observations, each in R^{3x3}, returning a length two</span>
<span class="co"># Tensor.</span>
x <span class="op">=</span> [x0, x1]  <span class="co"># Shape is [2, 3, 3].</span>
dist.pdf(x)  <span class="co"># Shape is [2].</span>

<span class="co"># Initialize two 3x3 Wisharts with Full factored scale matrices.</span>
df <span class="op">=</span> [<span class="dv">5</span>, <span class="dv">4</span>]
scale <span class="op">=</span> ...  <span class="co"># Shape is [2, 3, 3].</span>
dist <span class="op">=</span> tf.contrib.distributions.WishartFull(df<span class="op">=</span>df, scale<span class="op">=</span>scale)

<span class="co"># Evaluate this on four observations.</span>
x <span class="op">=</span> [[x0, x1], [x2, x3]]  <span class="co"># Shape is [2, 2, 3, 3]; xi is positive definite.</span>
dist.pdf(x)  <span class="co"># Shape is [2, 2].</span>

<span class="co"># (*) - To efficiently create a trainable covariance matrix, see the example</span>
<span class="co">#   in tf.contrib.distributions.matrix_diag_transform.</span></code></pre></div>
<hr />
<h4 id="tf.contrib.distributions.wishartfull.__init__df-scale-cholesky_input_output_matricesfalse-validate_argsfalse-allow_nan_statstrue-namewishartfull"><code id="WishartFull.__init__">tf.contrib.distributions.WishartFull.__init__(df, scale, cholesky_input_output_matrices=False, validate_args=False, allow_nan_stats=True, name='WishartFull')</code></h4>
<p>Construct Wishart distributions.</p>
<h5 id="args-566">Args:</h5>
<ul>
<li><b><code>df</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>. Degrees of freedom, must be greater than or equal to dimension of the scale matrix.</li>
<li><b><code>scale</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>. The symmetric positive definite scale matrix of the distribution.</li>
<li><b><code>cholesky_input_output_matrices</code></b>: <code>Boolean</code>. Any function which whose input or output is a matrix assumes the input is Cholesky and returns a Cholesky factored matrix. Example<code>log_pdf</code> input takes a Cholesky and <code>sample_n</code> returns a Cholesky when <code>cholesky_input_output_matrices=True</code>.</li>
<li><b><code>validate_args</code></b>: <code>Boolean</code>, default <code>False</code>. Whether to validate input with asserts. If <code>validate_args</code> is <code>False</code>, and the inputs are invalid, correct behavior is not guaranteed.</li>
<li><b><code>allow_nan_stats</code></b>: <code>Boolean</code>, default <code>True</code>. If <code>False</code>, raise an exception if a statistic (e.g., mean, mode) is undefined for any batch member. If True, batch members with valid parameters leading to undefined statistics will return <code>NaN</code> for this statistic.</li>
<li><b><code>name</code></b>: The name scope to give class member ops.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.wishartfull.allow_nan_stats"><code id="WishartFull.allow_nan_stats">tf.contrib.distributions.WishartFull.allow_nan_stats</code></h4>
<p>Python boolean describing behavior when a stat is undefined.</p>
<p>Stats return +/- infinity when it makes sense. E.g., the variance of a Cauchy distribution is infinity. However, sometimes the statistic is undefined, e.g., if a distribution's pdf does not achieve a maximum within the support of the distribution, the mode is undefined. If the mean is undefined, then by definition the variance is undefined. E.g. the mean for Student's T for df = 1 is undefined (no clear way to say it is either + or - infinity), so the variance = E[(X - mean)^2] is also undefined.</p>
<h5 id="returns-640">Returns:</h5>
<ul>
<li><b><code>allow_nan_stats</code></b>: Python boolean.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.wishartfull.batch_shapenamebatch_shape"><code id="WishartFull.batch_shape">tf.contrib.distributions.WishartFull.batch_shape(name='batch_shape')</code></h4>
<p>Shape of a single sample from a single event index as a 1-D <code>Tensor</code>.</p>
<p>The product of the dimensions of the <code>batch_shape</code> is the number of independent distributions of this kind the instance represents.</p>
<h5 id="args-567">Args:</h5>
<ul>
<li><b><code>name</code></b>: name to give to the op</li>
</ul>
<h5 id="returns-641">Returns:</h5>
<ul>
<li><b><code>batch_shape</code></b>: <code>Tensor</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.wishartfull.cdfvalue-namecdf-condition_kwargs"><code id="WishartFull.cdf">tf.contrib.distributions.WishartFull.cdf(value, name='cdf', **condition_kwargs)</code></h4>
<p>Cumulative distribution function.</p>
<p>Given random variable <code>X</code>, the cumulative distribution function <code>cdf</code> is:</p>
<pre><code>cdf(x) := P[X &lt;= x]</code></pre>
<h5 id="args-568">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-642">Returns:</h5>
<ul>
<li><b><code>cdf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.wishartfull.cholesky_input_output_matrices"><code id="WishartFull.cholesky_input_output_matrices">tf.contrib.distributions.WishartFull.cholesky_input_output_matrices</code></h4>
<p>Boolean indicating if <code>Tensor</code> input/outputs are Cholesky factorized.</p>
<hr />
<h4 id="tf.contrib.distributions.wishartfull.copyoverride_parameters_kwargs"><code id="WishartFull.copy">tf.contrib.distributions.WishartFull.copy(**override_parameters_kwargs)</code></h4>
<p>Creates a deep copy of the distribution.</p>
<p>Note: the copy distribution may continue to depend on the original intialization arguments.</p>
<h5 id="args-569">Args:</h5>
<ul>
<li><b><code>**override_parameters_kwargs</code></b>: String/value dictionary of initialization arguments to override with new values.</li>
</ul>
<h5 id="returns-643">Returns:</h5>
<ul>
<li><b><code>distribution</code></b>: A new instance of <code>type(self)</code> intitialized from the union of self.parameters and override_parameters_kwargs, i.e., <code>dict(self.parameters, **override_parameters_kwargs)</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.wishartfull.df"><code id="WishartFull.df">tf.contrib.distributions.WishartFull.df</code></h4>
<p>Wishart distribution degree(s) of freedom.</p>
<hr />
<h4 id="tf.contrib.distributions.wishartfull.dimension"><code id="WishartFull.dimension">tf.contrib.distributions.WishartFull.dimension</code></h4>
<p>Dimension of underlying vector space. The <code>p</code> in <code>R^(p*p)</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.wishartfull.dtype"><code id="WishartFull.dtype">tf.contrib.distributions.WishartFull.dtype</code></h4>
<p>The <code>DType</code> of <code>Tensor</code>s handled by this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.wishartfull.entropynameentropy"><code id="WishartFull.entropy">tf.contrib.distributions.WishartFull.entropy(name='entropy')</code></h4>
<p>Shannon entropy in nats.</p>
<hr />
<h4 id="tf.contrib.distributions.wishartfull.event_shapenameevent_shape"><code id="WishartFull.event_shape">tf.contrib.distributions.WishartFull.event_shape(name='event_shape')</code></h4>
<p>Shape of a single sample from a single batch as a 1-D int32 <code>Tensor</code>.</p>
<h5 id="args-570">Args:</h5>
<ul>
<li><b><code>name</code></b>: name to give to the op</li>
</ul>
<h5 id="returns-644">Returns:</h5>
<ul>
<li><b><code>event_shape</code></b>: <code>Tensor</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.wishartfull.get_batch_shape"><code id="WishartFull.get_batch_shape">tf.contrib.distributions.WishartFull.get_batch_shape()</code></h4>
<p>Shape of a single sample from a single event index as a <code>TensorShape</code>.</p>
<p>Same meaning as <code>batch_shape</code>. May be only partially defined.</p>
<h5 id="returns-645">Returns:</h5>
<ul>
<li><b><code>batch_shape</code></b>: <code>TensorShape</code>, possibly unknown.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.wishartfull.get_event_shape"><code id="WishartFull.get_event_shape">tf.contrib.distributions.WishartFull.get_event_shape()</code></h4>
<p>Shape of a single sample from a single batch as a <code>TensorShape</code>.</p>
<p>Same meaning as <code>event_shape</code>. May be only partially defined.</p>
<h5 id="returns-646">Returns:</h5>
<ul>
<li><b><code>event_shape</code></b>: <code>TensorShape</code>, possibly unknown.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.wishartfull.is_continuous"><code id="WishartFull.is_continuous">tf.contrib.distributions.WishartFull.is_continuous</code></h4>
<hr />
<h4 id="tf.contrib.distributions.wishartfull.is_reparameterized"><code id="WishartFull.is_reparameterized">tf.contrib.distributions.WishartFull.is_reparameterized</code></h4>
<hr />
<h4 id="tf.contrib.distributions.wishartfull.log_cdfvalue-namelog_cdf-condition_kwargs"><code id="WishartFull.log_cdf">tf.contrib.distributions.WishartFull.log_cdf(value, name='log_cdf', **condition_kwargs)</code></h4>
<p>Log cumulative distribution function.</p>
<p>Given random variable <code>X</code>, the cumulative distribution function <code>cdf</code> is:</p>
<pre><code>log_cdf(x) := Log[ P[X &lt;= x] ]</code></pre>
<p>Often, a numerical approximation can be used for <code>log_cdf(x)</code> that yields a more accurate answer than simply taking the logarithm of the <code>cdf</code> when <code>x &lt;&lt; -1</code>.</p>
<h5 id="args-571">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-647">Returns:</h5>
<ul>
<li><b><code>logcdf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.wishartfull.log_normalizing_constantnamelog_normalizing_constant"><code id="WishartFull.log_normalizing_constant">tf.contrib.distributions.WishartFull.log_normalizing_constant(name='log_normalizing_constant')</code></h4>
<p>Computes the log normalizing constant, log(Z).</p>
<hr />
<h4 id="tf.contrib.distributions.wishartfull.log_pdfvalue-namelog_pdf-condition_kwargs"><code id="WishartFull.log_pdf">tf.contrib.distributions.WishartFull.log_pdf(value, name='log_pdf', **condition_kwargs)</code></h4>
<p>Log probability density function.</p>
<h5 id="args-572">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-648">Returns:</h5>
<ul>
<li><b><code>log_prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-203">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if not <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.wishartfull.log_pmfvalue-namelog_pmf-condition_kwargs"><code id="WishartFull.log_pmf">tf.contrib.distributions.WishartFull.log_pmf(value, name='log_pmf', **condition_kwargs)</code></h4>
<p>Log probability mass function.</p>
<h5 id="args-573">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-649">Returns:</h5>
<ul>
<li><b><code>log_pmf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-204">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.wishartfull.log_probvalue-namelog_prob-condition_kwargs"><code id="WishartFull.log_prob">tf.contrib.distributions.WishartFull.log_prob(value, name='log_prob', **condition_kwargs)</code></h4>
<p>Log probability density/mass function (depending on <code>is_continuous</code>).</p>
<h5 id="args-574">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-650">Returns:</h5>
<ul>
<li><b><code>log_prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.wishartfull.log_survival_functionvalue-namelog_survival_function-condition_kwargs"><code id="WishartFull.log_survival_function">tf.contrib.distributions.WishartFull.log_survival_function(value, name='log_survival_function', **condition_kwargs)</code></h4>
<p>Log survival function.</p>
<p>Given random variable <code>X</code>, the survival function is defined:</p>
<pre><code>log_survival_function(x) = Log[ P[X &gt; x] ]
                         = Log[ 1 - P[X &lt;= x] ]
                         = Log[ 1 - cdf(x) ]</code></pre>
<p>Typically, different numerical approximations can be used for the log survival function, which are more accurate than <code>1 - cdf(x)</code> when <code>x &gt;&gt; 1</code>.</p>
<h5 id="args-575">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-651">Returns:</h5>
<p><code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.wishartfull.meannamemean"><code id="WishartFull.mean">tf.contrib.distributions.WishartFull.mean(name='mean')</code></h4>
<p>Mean.</p>
<hr />
<h4 id="tf.contrib.distributions.wishartfull.mean_log_detnamemean_log_det"><code id="WishartFull.mean_log_det">tf.contrib.distributions.WishartFull.mean_log_det(name='mean_log_det')</code></h4>
<p>Computes E[log(det(X))] under this Wishart distribution.</p>
<hr />
<h4 id="tf.contrib.distributions.wishartfull.modenamemode"><code id="WishartFull.mode">tf.contrib.distributions.WishartFull.mode(name='mode')</code></h4>
<p>Mode.</p>
<hr />
<h4 id="tf.contrib.distributions.wishartfull.name"><code id="WishartFull.name">tf.contrib.distributions.WishartFull.name</code></h4>
<p>Name prepended to all ops created by this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.wishartfull.param_shapescls-sample_shape-namedistributionparamshapes"><code id="WishartFull.param_shapes">tf.contrib.distributions.WishartFull.param_shapes(cls, sample_shape, name='DistributionParamShapes')</code></h4>
<p>Shapes of parameters given the desired shape of a call to <code>sample()</code>.</p>
<p>Subclasses should override static method <code>_param_shapes</code>.</p>
<h5 id="args-576">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: <code>Tensor</code> or python list/tuple. Desired shape of a call to <code>sample()</code>.</li>
<li><b><code>name</code></b>: name to prepend ops with.</li>
</ul>
<h5 id="returns-652">Returns:</h5>
<p><code>dict</code> of parameter name to <code>Tensor</code> shapes.</p>
<hr />
<h4 id="tf.contrib.distributions.wishartfull.param_static_shapescls-sample_shape"><code id="WishartFull.param_static_shapes">tf.contrib.distributions.WishartFull.param_static_shapes(cls, sample_shape)</code></h4>
<p>param_shapes with static (i.e. TensorShape) shapes.</p>
<h5 id="args-577">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: <code>TensorShape</code> or python list/tuple. Desired shape of a call to <code>sample()</code>.</li>
</ul>
<h5 id="returns-653">Returns:</h5>
<p><code>dict</code> of parameter name to <code>TensorShape</code>.</p>
<h5 id="raises-205">Raises:</h5>
<ul>
<li><b><code>ValueError</code></b>: if <code>sample_shape</code> is a <code>TensorShape</code> and is not fully defined.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.wishartfull.parameters"><code id="WishartFull.parameters">tf.contrib.distributions.WishartFull.parameters</code></h4>
<p>Dictionary of parameters used to instantiate this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.wishartfull.pdfvalue-namepdf-condition_kwargs"><code id="WishartFull.pdf">tf.contrib.distributions.WishartFull.pdf(value, name='pdf', **condition_kwargs)</code></h4>
<p>Probability density function.</p>
<h5 id="args-578">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-654">Returns:</h5>
<ul>
<li><b><code>prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-206">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if not <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.wishartfull.pmfvalue-namepmf-condition_kwargs"><code id="WishartFull.pmf">tf.contrib.distributions.WishartFull.pmf(value, name='pmf', **condition_kwargs)</code></h4>
<p>Probability mass function.</p>
<h5 id="args-579">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-655">Returns:</h5>
<ul>
<li><b><code>pmf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-207">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.wishartfull.probvalue-nameprob-condition_kwargs"><code id="WishartFull.prob">tf.contrib.distributions.WishartFull.prob(value, name='prob', **condition_kwargs)</code></h4>
<p>Probability density/mass function (depending on <code>is_continuous</code>).</p>
<h5 id="args-580">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-656">Returns:</h5>
<ul>
<li><b><code>prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.wishartfull.samplesample_shape-seednone-namesample-condition_kwargs"><code id="WishartFull.sample">tf.contrib.distributions.WishartFull.sample(sample_shape=(), seed=None, name='sample', **condition_kwargs)</code></h4>
<p>Generate samples of the specified shape.</p>
<p>Note that a call to <code>sample()</code> without arguments will generate a single sample.</p>
<h5 id="args-581">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: 0D or 1D <code>int32</code> <code>Tensor</code>. Shape of the generated samples.</li>
<li><b><code>seed</code></b>: Python integer seed for RNG</li>
<li><b><code>name</code></b>: name to give to the op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-657">Returns:</h5>
<ul>
<li><b><code>samples</code></b>: a <code>Tensor</code> with prepended dimensions <code>sample_shape</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.wishartfull.sample_nn-seednone-namesample_n-condition_kwargs"><code id="WishartFull.sample_n">tf.contrib.distributions.WishartFull.sample_n(n, seed=None, name='sample_n', **condition_kwargs)</code></h4>
<p>Generate <code>n</code> samples.</p>
<h5 id="args-582">Args:</h5>
<ul>
<li><b><code>n</code></b>: <code>Scalar</code> <code>Tensor</code> of type <code>int32</code> or <code>int64</code>, the number of observations to sample.</li>
<li><b><code>seed</code></b>: Python integer seed for RNG</li>
<li><b><code>name</code></b>: name to give to the op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-658">Returns:</h5>
<ul>
<li><b><code>samples</code></b>: a <code>Tensor</code> with a prepended dimension (n,).</li>
</ul>
<h5 id="raises-208">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>n</code> is not an integer type.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.wishartfull.scale"><code id="WishartFull.scale">tf.contrib.distributions.WishartFull.scale()</code></h4>
<p>Wishart distribution scale matrix.</p>
<hr />
<h4 id="tf.contrib.distributions.wishartfull.scale_operator_pd"><code id="WishartFull.scale_operator_pd">tf.contrib.distributions.WishartFull.scale_operator_pd</code></h4>
<p>Wishart distribution scale matrix as an OperatorPD.</p>
<hr />
<h4 id="tf.contrib.distributions.wishartfull.stdnamestd"><code id="WishartFull.std">tf.contrib.distributions.WishartFull.std(name='std')</code></h4>
<p>Standard deviation.</p>
<hr />
<h4 id="tf.contrib.distributions.wishartfull.survival_functionvalue-namesurvival_function-condition_kwargs"><code id="WishartFull.survival_function">tf.contrib.distributions.WishartFull.survival_function(value, name='survival_function', **condition_kwargs)</code></h4>
<p>Survival function.</p>
<p>Given random variable <code>X</code>, the survival function is defined:</p>
<pre><code>survival_function(x) = P[X &gt; x]
                     = 1 - P[X &lt;= x]
                     = 1 - cdf(x).</code></pre>
<h5 id="args-583">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-659">Returns:</h5>
<p>Tensor<code>of shape</code>sample_shape(x) + self.batch_shape<code>with values of type</code>self.dtype`.</p>
<hr />
<h4 id="tf.contrib.distributions.wishartfull.validate_args"><code id="WishartFull.validate_args">tf.contrib.distributions.WishartFull.validate_args</code></h4>
<p>Python boolean indicated possibly expensive checks are enabled.</p>
<hr />
<h4 id="tf.contrib.distributions.wishartfull.variancenamevariance"><code id="WishartFull.variance">tf.contrib.distributions.WishartFull.variance(name='variance')</code></h4>
<p>Variance.</p>
<h3 id="multivariate-utilities">Multivariate Utilities</h3>
<hr />
<h3 id="tf.contrib.distributions.matrix_diag_transformmatrix-transformnone-namenone"><a name="//apple_ref/cpp/Function/matrix_diag_transform" class="dashAnchor"></a><code id="matrix_diag_transform">tf.contrib.distributions.matrix_diag_transform(matrix, transform=None, name=None)</code></h3>
<p>Transform diagonal of [batch-]matrix, leave rest of matrix unchanged.</p>
<p>Create a trainable covariance defined by a Cholesky factor:</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="co"># Transform network layer into 2 x 2 array.</span>
matrix_values <span class="op">=</span> tf.contrib.layers.fully_connected(activations, <span class="dv">4</span>)
matrix <span class="op">=</span> tf.reshape(matrix_values, (batch_size, <span class="dv">2</span>, <span class="dv">2</span>))

<span class="co"># Make the diagonal positive.  If the upper triangle was zero, this would be a</span>
<span class="co"># valid Cholesky factor.</span>
chol <span class="op">=</span> matrix_diag_transform(matrix, transform<span class="op">=</span>tf.nn.softplus)

<span class="co"># OperatorPDCholesky ignores the upper triangle.</span>
operator <span class="op">=</span> OperatorPDCholesky(chol)</code></pre></div>
<p>Example of heteroskedastic 2-D linear regression.</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="co"># Get a trainable Cholesky factor.</span>
matrix_values <span class="op">=</span> tf.contrib.layers.fully_connected(activations, <span class="dv">4</span>)
matrix <span class="op">=</span> tf.reshape(matrix_values, (batch_size, <span class="dv">2</span>, <span class="dv">2</span>))
chol <span class="op">=</span> matrix_diag_transform(matrix, transform<span class="op">=</span>tf.nn.softplus)

<span class="co"># Get a trainable mean.</span>
mu <span class="op">=</span> tf.contrib.layers.fully_connected(activations, <span class="dv">2</span>)

<span class="co"># This is a fully trainable multivariate normal!</span>
dist <span class="op">=</span> tf.contrib.distributions.MVNCholesky(mu, chol)

<span class="co"># Standard log loss.  Minimizing this will &quot;train&quot; mu and chol, and then dist</span>
<span class="co"># will be a distribution predicting labels as multivariate Gaussians.</span>
loss <span class="op">=</span> <span class="op">-</span><span class="dv">1</span> <span class="op">*</span> tf.reduce_mean(dist.log_pdf(labels))</code></pre></div>
<h5 id="args-584">Args:</h5>
<ul>
<li><b><code>matrix</code></b>: Rank <code>R</code> <code>Tensor</code>, <code>R &gt;= 2</code>, where the last two dimensions are equal.</li>
<li><b><code>transform</code></b>: Element-wise function mapping <code>Tensors</code> to <code>Tensors</code>. To be applied to the diagonal of <code>matrix</code>. If <code>None</code>, <code>matrix</code> is returned unchanged. Defaults to <code>None</code>.</li>
<li><b><code>name</code></b>: A name to give created ops. Defaults to &quot;matrix_diag_transform&quot;.</li>
</ul>
<h5 id="returns-660">Returns:</h5>
<p>A <code>Tensor</code> with same shape and <code>dtype</code> as <code>matrix</code>.</p>
<h2 id="transformed-distributions">Transformed distributions</h2>
<hr />
<h3 id="class-tf.contrib.distributions.transformeddistribution"><a name="//apple_ref/cpp/Class/TransformedDistribution" class="dashAnchor"></a><code id="TransformedDistribution">class tf.contrib.distributions.TransformedDistribution</code></h3>
<p>A Transformed Distribution.</p>
<p>A <code>TransformedDistribution</code> models <code>p(y)</code> given a base distribution <code>p(x)</code>, and a deterministic, invertible, differentiable transform, <code>Y = g(X)</code>. The transform is typically an instance of the <code>Bijector</code> class and the base distribution is typically an instance of the <code>Distribution</code> class.</p>
<p>A <code>Bijector</code> is expected to implement the following functions: - <code>forward</code>, - <code>inverse</code>, - <code>inverse_log_det_jacobian</code>. The semantics of these functions are outlined in the <code>Bijector</code> documentation.</p>
<p>Shapes, type, and reparameterization are taken from the base distribution.</p>
<p>Write <code>P(Y=y)</code> for cumulative density function of random variable (rv) <code>Y</code> and <code>p</code> for its derivative wrt to <code>Y</code>. Assume that <code>Y=g(X)</code> where <code>g</code> is continuous and <code>X=g^{-1}(Y)</code>. Write <code>J</code> for the Jacobian (of some function).</p>
<p>A <code>TransformedDistribution</code> alters the input/outputs of a <code>Distribution</code> associated with rv <code>X</code> in the following ways:</p>
<ul>
<li><p><code>sample</code>:</p>
<p>Mathematically:</p>
<pre class="none"><code>Y = g(X)</code></pre>
<p>Programmatically:</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="cf">return</span> bijector.forward(distribution.sample(...))</code></pre></div></li>
<li><p><code>log_prob</code>:</p>
<p>Mathematically:</p>
<pre class="none"><code>(log o p o g^{-1})(y) + (log o det o J o g^{-1})(y)</code></pre>
<p>Programmatically:</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="cf">return</span> (bijector.inverse_log_det_jacobian(x) <span class="op">+</span>
        distribution.log_prob(bijector.inverse(x))</code></pre></div></li>
<li><p><code>log_cdf</code>:</p>
<p>Mathematically:</p>
<pre class="none"><code>(log o P o g^{-1})(y)</code></pre>
<p>Programmatically:</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="cf">return</span> distribution.log_prob(bijector.inverse(x))</code></pre></div></li>
<li><p>and similarly for: <code>cdf</code>, <code>prob</code>, <code>log_survival_function</code>, <code>survival_function</code>.</p></li>
</ul>
<p>A simple example constructing a Log-Normal distribution from a Normal distribution:</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">ds <span class="op">=</span> tf.contrib.distributions
log_normal <span class="op">=</span> ds.TransformedDistribution(
  distribution<span class="op">=</span>ds.Normal(mu<span class="op">=</span>mu, sigma<span class="op">=</span>sigma),
  bijector<span class="op">=</span>ds.bijector.Exp(),
  name<span class="op">=</span><span class="st">&quot;LogNormalTransformedDistribution&quot;</span>)</code></pre></div>
<p>A <code>LogNormal</code> made from callables:</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">ds <span class="op">=</span> tf.contrib.distributions
log_normal <span class="op">=</span> ds.TransformedDistribution(
  distribution<span class="op">=</span>ds.Normal(mu<span class="op">=</span>mu, sigma<span class="op">=</span>sigma),
  bijector<span class="op">=</span>ds.bijector.Inline(
    forward_fn<span class="op">=</span>tf.exp,
    inverse_fn<span class="op">=</span>tf.log,
    inverse_log_det_jacobian_fn<span class="op">=</span>(
      <span class="kw">lambda</span> y: <span class="op">-</span>tf.reduce_sum(tf.log(x), reduction_indices<span class="op">=-</span><span class="dv">1</span>)),
  name<span class="op">=</span><span class="st">&quot;LogNormalTransformedDistribution&quot;</span>)</code></pre></div>
<p>Another example constructing a Normal from a StandardNormal:</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">ds <span class="op">=</span> tf.contrib.distributions
normal <span class="op">=</span> ds.TransformedDistribution(
  distribution<span class="op">=</span>ds.Normal(mu<span class="op">=</span><span class="dv">0</span>, sigma<span class="op">=</span><span class="dv">1</span>),
  bijector<span class="op">=</span>ds.bijector.ScaleAndShift(loc<span class="op">=</span>mu, scale<span class="op">=</span>sigma, event_ndims<span class="op">=</span><span class="dv">0</span>),
  name<span class="op">=</span><span class="st">&quot;NormalTransformedDistribution&quot;</span>)</code></pre></div>
<hr />
<h4 id="tf.contrib.distributions.transformeddistribution.__init__distribution-bijector-validate_argsfalse-namenone"><code id="TransformedDistribution.__init__">tf.contrib.distributions.TransformedDistribution.__init__(distribution, bijector, validate_args=False, name=None)</code></h4>
<p>Construct a Transformed Distribution.</p>
<h5 id="args-585">Args:</h5>
<ul>
<li><b><code>distribution</code></b>: The base distribution class to transform. Typically an instance of <code>Distribution</code>.</li>
<li><b><code>bijector</code></b>: The object responsible for calculating the transformation. Typically an instance of <code>Bijector</code>.</li>
<li><b><code>validate_args</code></b>: Python boolean. Whether to validate input with asserts. If <code>validate_args</code> is <code>False</code>, and the inputs are invalid, correct behavior is not guaranteed.</li>
<li><b><code>name</code></b>: The name for the distribution. Default: <code>bijector.name + distribution.name</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.transformeddistribution.allow_nan_stats"><code id="TransformedDistribution.allow_nan_stats">tf.contrib.distributions.TransformedDistribution.allow_nan_stats</code></h4>
<p>Python boolean describing behavior when a stat is undefined.</p>
<p>Stats return +/- infinity when it makes sense. E.g., the variance of a Cauchy distribution is infinity. However, sometimes the statistic is undefined, e.g., if a distribution's pdf does not achieve a maximum within the support of the distribution, the mode is undefined. If the mean is undefined, then by definition the variance is undefined. E.g. the mean for Student's T for df = 1 is undefined (no clear way to say it is either + or - infinity), so the variance = E[(X - mean)^2] is also undefined.</p>
<h5 id="returns-661">Returns:</h5>
<ul>
<li><b><code>allow_nan_stats</code></b>: Python boolean.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.transformeddistribution.batch_shapenamebatch_shape"><code id="TransformedDistribution.batch_shape">tf.contrib.distributions.TransformedDistribution.batch_shape(name='batch_shape')</code></h4>
<p>Shape of a single sample from a single event index as a 1-D <code>Tensor</code>.</p>
<p>The product of the dimensions of the <code>batch_shape</code> is the number of independent distributions of this kind the instance represents.</p>
<h5 id="args-586">Args:</h5>
<ul>
<li><b><code>name</code></b>: name to give to the op</li>
</ul>
<h5 id="returns-662">Returns:</h5>
<ul>
<li><b><code>batch_shape</code></b>: <code>Tensor</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.transformeddistribution.bijector"><code id="TransformedDistribution.bijector">tf.contrib.distributions.TransformedDistribution.bijector</code></h4>
<p>Function transforming x =&gt; y.</p>
<hr />
<h4 id="tf.contrib.distributions.transformeddistribution.cdfvalue-namecdf-condition_kwargs"><code id="TransformedDistribution.cdf">tf.contrib.distributions.TransformedDistribution.cdf(value, name='cdf', **condition_kwargs)</code></h4>
<p>Cumulative distribution function.</p>
<p>Given random variable <code>X</code>, the cumulative distribution function <code>cdf</code> is:</p>
<pre><code>cdf(x) := P[X &lt;= x]</code></pre>
<p>Additional documentation from <code>TransformedDistribution</code>:</p>
<h5 id="condition_kwargs"><b><code>condition_kwargs</code></b>:</h5>
<ul>
<li><b><code>bijector_kwargs</code></b>: Python dictionary of arg names/values forwarded to the bijector.</li>
<li><b><code>distribution_kwargs</code></b>: Python dictionary of arg names/values forwarded to the distribution.</li>
</ul>
<h5 id="args-587">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-663">Returns:</h5>
<ul>
<li><b><code>cdf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.transformeddistribution.copyoverride_parameters_kwargs"><code id="TransformedDistribution.copy">tf.contrib.distributions.TransformedDistribution.copy(**override_parameters_kwargs)</code></h4>
<p>Creates a deep copy of the distribution.</p>
<p>Note: the copy distribution may continue to depend on the original intialization arguments.</p>
<h5 id="args-588">Args:</h5>
<ul>
<li><b><code>**override_parameters_kwargs</code></b>: String/value dictionary of initialization arguments to override with new values.</li>
</ul>
<h5 id="returns-664">Returns:</h5>
<ul>
<li><b><code>distribution</code></b>: A new instance of <code>type(self)</code> intitialized from the union of self.parameters and override_parameters_kwargs, i.e., <code>dict(self.parameters, **override_parameters_kwargs)</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.transformeddistribution.distribution"><code id="TransformedDistribution.distribution">tf.contrib.distributions.TransformedDistribution.distribution</code></h4>
<p>Base distribution, p(x).</p>
<hr />
<h4 id="tf.contrib.distributions.transformeddistribution.dtype"><code id="TransformedDistribution.dtype">tf.contrib.distributions.TransformedDistribution.dtype</code></h4>
<p>The <code>DType</code> of <code>Tensor</code>s handled by this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.transformeddistribution.entropynameentropy"><code id="TransformedDistribution.entropy">tf.contrib.distributions.TransformedDistribution.entropy(name='entropy')</code></h4>
<p>Shannon entropy in nats.</p>
<hr />
<h4 id="tf.contrib.distributions.transformeddistribution.event_shapenameevent_shape"><code id="TransformedDistribution.event_shape">tf.contrib.distributions.TransformedDistribution.event_shape(name='event_shape')</code></h4>
<p>Shape of a single sample from a single batch as a 1-D int32 <code>Tensor</code>.</p>
<h5 id="args-589">Args:</h5>
<ul>
<li><b><code>name</code></b>: name to give to the op</li>
</ul>
<h5 id="returns-665">Returns:</h5>
<ul>
<li><b><code>event_shape</code></b>: <code>Tensor</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.transformeddistribution.get_batch_shape"><code id="TransformedDistribution.get_batch_shape">tf.contrib.distributions.TransformedDistribution.get_batch_shape()</code></h4>
<p>Shape of a single sample from a single event index as a <code>TensorShape</code>.</p>
<p>Same meaning as <code>batch_shape</code>. May be only partially defined.</p>
<h5 id="returns-666">Returns:</h5>
<ul>
<li><b><code>batch_shape</code></b>: <code>TensorShape</code>, possibly unknown.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.transformeddistribution.get_event_shape"><code id="TransformedDistribution.get_event_shape">tf.contrib.distributions.TransformedDistribution.get_event_shape()</code></h4>
<p>Shape of a single sample from a single batch as a <code>TensorShape</code>.</p>
<p>Same meaning as <code>event_shape</code>. May be only partially defined.</p>
<h5 id="returns-667">Returns:</h5>
<ul>
<li><b><code>event_shape</code></b>: <code>TensorShape</code>, possibly unknown.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.transformeddistribution.is_continuous"><code id="TransformedDistribution.is_continuous">tf.contrib.distributions.TransformedDistribution.is_continuous</code></h4>
<hr />
<h4 id="tf.contrib.distributions.transformeddistribution.is_reparameterized"><code id="TransformedDistribution.is_reparameterized">tf.contrib.distributions.TransformedDistribution.is_reparameterized</code></h4>
<hr />
<h4 id="tf.contrib.distributions.transformeddistribution.log_cdfvalue-namelog_cdf-condition_kwargs"><code id="TransformedDistribution.log_cdf">tf.contrib.distributions.TransformedDistribution.log_cdf(value, name='log_cdf', **condition_kwargs)</code></h4>
<p>Log cumulative distribution function.</p>
<p>Given random variable <code>X</code>, the cumulative distribution function <code>cdf</code> is:</p>
<pre><code>log_cdf(x) := Log[ P[X &lt;= x] ]</code></pre>
<p>Often, a numerical approximation can be used for <code>log_cdf(x)</code> that yields a more accurate answer than simply taking the logarithm of the <code>cdf</code> when <code>x &lt;&lt; -1</code>.</p>
<p>Additional documentation from <code>TransformedDistribution</code>:</p>
<h5 id="condition_kwargs-1"><b><code>condition_kwargs</code></b>:</h5>
<ul>
<li><b><code>bijector_kwargs</code></b>: Python dictionary of arg names/values forwarded to the bijector.</li>
<li><b><code>distribution_kwargs</code></b>: Python dictionary of arg names/values forwarded to the distribution.</li>
</ul>
<h5 id="args-590">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-668">Returns:</h5>
<ul>
<li><b><code>logcdf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.transformeddistribution.log_pdfvalue-namelog_pdf-condition_kwargs"><code id="TransformedDistribution.log_pdf">tf.contrib.distributions.TransformedDistribution.log_pdf(value, name='log_pdf', **condition_kwargs)</code></h4>
<p>Log probability density function.</p>
<h5 id="args-591">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-669">Returns:</h5>
<ul>
<li><b><code>log_prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-209">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if not <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.transformeddistribution.log_pmfvalue-namelog_pmf-condition_kwargs"><code id="TransformedDistribution.log_pmf">tf.contrib.distributions.TransformedDistribution.log_pmf(value, name='log_pmf', **condition_kwargs)</code></h4>
<p>Log probability mass function.</p>
<h5 id="args-592">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-670">Returns:</h5>
<ul>
<li><b><code>log_pmf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-210">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.transformeddistribution.log_probvalue-namelog_prob-condition_kwargs"><code id="TransformedDistribution.log_prob">tf.contrib.distributions.TransformedDistribution.log_prob(value, name='log_prob', **condition_kwargs)</code></h4>
<p>Log probability density/mass function (depending on <code>is_continuous</code>).</p>
<p>Additional documentation from <code>TransformedDistribution</code>:</p>
<p>Implements <code>(log o p o g^{-1})(y) + (log o det o J o g^{-1})(y)</code>, where <code>g^{-1}</code> is the inverse of <code>transform</code>.</p>
<pre><code>  Also raises a `ValueError` if `inverse` was not provided to the
  distribution and `y` was not returned from `sample`.</code></pre>
<h5 id="condition_kwargs-2"><b><code>condition_kwargs</code></b>:</h5>
<ul>
<li><b><code>bijector_kwargs</code></b>: Python dictionary of arg names/values forwarded to the bijector.</li>
<li><b><code>distribution_kwargs</code></b>: Python dictionary of arg names/values forwarded to the distribution.</li>
</ul>
<h5 id="args-593">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-671">Returns:</h5>
<ul>
<li><b><code>log_prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.transformeddistribution.log_survival_functionvalue-namelog_survival_function-condition_kwargs"><code id="TransformedDistribution.log_survival_function">tf.contrib.distributions.TransformedDistribution.log_survival_function(value, name='log_survival_function', **condition_kwargs)</code></h4>
<p>Log survival function.</p>
<p>Given random variable <code>X</code>, the survival function is defined:</p>
<pre><code>log_survival_function(x) = Log[ P[X &gt; x] ]
                         = Log[ 1 - P[X &lt;= x] ]
                         = Log[ 1 - cdf(x) ]</code></pre>
<p>Typically, different numerical approximations can be used for the log survival function, which are more accurate than <code>1 - cdf(x)</code> when <code>x &gt;&gt; 1</code>.</p>
<p>Additional documentation from <code>TransformedDistribution</code>:</p>
<h5 id="condition_kwargs-3"><b><code>condition_kwargs</code></b>:</h5>
<ul>
<li><b><code>bijector_kwargs</code></b>: Python dictionary of arg names/values forwarded to the bijector.</li>
<li><b><code>distribution_kwargs</code></b>: Python dictionary of arg names/values forwarded to the distribution.</li>
</ul>
<h5 id="args-594">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-672">Returns:</h5>
<p><code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.transformeddistribution.meannamemean"><code id="TransformedDistribution.mean">tf.contrib.distributions.TransformedDistribution.mean(name='mean')</code></h4>
<p>Mean.</p>
<hr />
<h4 id="tf.contrib.distributions.transformeddistribution.modenamemode"><code id="TransformedDistribution.mode">tf.contrib.distributions.TransformedDistribution.mode(name='mode')</code></h4>
<p>Mode.</p>
<hr />
<h4 id="tf.contrib.distributions.transformeddistribution.name"><code id="TransformedDistribution.name">tf.contrib.distributions.TransformedDistribution.name</code></h4>
<p>Name prepended to all ops created by this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.transformeddistribution.param_shapescls-sample_shape-namedistributionparamshapes"><code id="TransformedDistribution.param_shapes">tf.contrib.distributions.TransformedDistribution.param_shapes(cls, sample_shape, name='DistributionParamShapes')</code></h4>
<p>Shapes of parameters given the desired shape of a call to <code>sample()</code>.</p>
<p>Subclasses should override static method <code>_param_shapes</code>.</p>
<h5 id="args-595">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: <code>Tensor</code> or python list/tuple. Desired shape of a call to <code>sample()</code>.</li>
<li><b><code>name</code></b>: name to prepend ops with.</li>
</ul>
<h5 id="returns-673">Returns:</h5>
<p><code>dict</code> of parameter name to <code>Tensor</code> shapes.</p>
<hr />
<h4 id="tf.contrib.distributions.transformeddistribution.param_static_shapescls-sample_shape"><code id="TransformedDistribution.param_static_shapes">tf.contrib.distributions.TransformedDistribution.param_static_shapes(cls, sample_shape)</code></h4>
<p>param_shapes with static (i.e. TensorShape) shapes.</p>
<h5 id="args-596">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: <code>TensorShape</code> or python list/tuple. Desired shape of a call to <code>sample()</code>.</li>
</ul>
<h5 id="returns-674">Returns:</h5>
<p><code>dict</code> of parameter name to <code>TensorShape</code>.</p>
<h5 id="raises-211">Raises:</h5>
<ul>
<li><b><code>ValueError</code></b>: if <code>sample_shape</code> is a <code>TensorShape</code> and is not fully defined.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.transformeddistribution.parameters"><code id="TransformedDistribution.parameters">tf.contrib.distributions.TransformedDistribution.parameters</code></h4>
<p>Dictionary of parameters used to instantiate this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.transformeddistribution.pdfvalue-namepdf-condition_kwargs"><code id="TransformedDistribution.pdf">tf.contrib.distributions.TransformedDistribution.pdf(value, name='pdf', **condition_kwargs)</code></h4>
<p>Probability density function.</p>
<h5 id="args-597">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-675">Returns:</h5>
<ul>
<li><b><code>prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-212">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if not <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.transformeddistribution.pmfvalue-namepmf-condition_kwargs"><code id="TransformedDistribution.pmf">tf.contrib.distributions.TransformedDistribution.pmf(value, name='pmf', **condition_kwargs)</code></h4>
<p>Probability mass function.</p>
<h5 id="args-598">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-676">Returns:</h5>
<ul>
<li><b><code>pmf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-213">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.transformeddistribution.probvalue-nameprob-condition_kwargs"><code id="TransformedDistribution.prob">tf.contrib.distributions.TransformedDistribution.prob(value, name='prob', **condition_kwargs)</code></h4>
<p>Probability density/mass function (depending on <code>is_continuous</code>).</p>
<p>Additional documentation from <code>TransformedDistribution</code>:</p>
<p>Implements <code>p(g^{-1}(y)) det|J(g^{-1}(y))|</code>, where <code>g^{-1}</code> is the inverse of <code>transform</code>.</p>
<pre><code>  Also raises a `ValueError` if `inverse` was not provided to the
  distribution and `y` was not returned from `sample`.</code></pre>
<h5 id="condition_kwargs-4"><b><code>condition_kwargs</code></b>:</h5>
<ul>
<li><b><code>bijector_kwargs</code></b>: Python dictionary of arg names/values forwarded to the bijector.</li>
<li><b><code>distribution_kwargs</code></b>: Python dictionary of arg names/values forwarded to the distribution.</li>
</ul>
<h5 id="args-599">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-677">Returns:</h5>
<ul>
<li><b><code>prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.transformeddistribution.samplesample_shape-seednone-namesample-condition_kwargs"><code id="TransformedDistribution.sample">tf.contrib.distributions.TransformedDistribution.sample(sample_shape=(), seed=None, name='sample', **condition_kwargs)</code></h4>
<p>Generate samples of the specified shape.</p>
<p>Note that a call to <code>sample()</code> without arguments will generate a single sample.</p>
<h5 id="args-600">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: 0D or 1D <code>int32</code> <code>Tensor</code>. Shape of the generated samples.</li>
<li><b><code>seed</code></b>: Python integer seed for RNG</li>
<li><b><code>name</code></b>: name to give to the op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-678">Returns:</h5>
<ul>
<li><b><code>samples</code></b>: a <code>Tensor</code> with prepended dimensions <code>sample_shape</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.transformeddistribution.sample_nn-seednone-namesample_n-condition_kwargs"><code id="TransformedDistribution.sample_n">tf.contrib.distributions.TransformedDistribution.sample_n(n, seed=None, name='sample_n', **condition_kwargs)</code></h4>
<p>Generate <code>n</code> samples.</p>
<p>Additional documentation from <code>TransformedDistribution</code>:</p>
<p>Samples from the base distribution and then passes through the bijector's forward transform.</p>
<h5 id="condition_kwargs-5"><b><code>condition_kwargs</code></b>:</h5>
<ul>
<li><b><code>bijector_kwargs</code></b>: Python dictionary of arg names/values forwarded to the bijector.</li>
<li><b><code>distribution_kwargs</code></b>: Python dictionary of arg names/values forwarded to the distribution.</li>
</ul>
<h5 id="args-601">Args:</h5>
<ul>
<li><b><code>n</code></b>: <code>Scalar</code> <code>Tensor</code> of type <code>int32</code> or <code>int64</code>, the number of observations to sample.</li>
<li><b><code>seed</code></b>: Python integer seed for RNG</li>
<li><b><code>name</code></b>: name to give to the op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-679">Returns:</h5>
<ul>
<li><b><code>samples</code></b>: a <code>Tensor</code> with a prepended dimension (n,).</li>
</ul>
<h5 id="raises-214">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>n</code> is not an integer type.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.transformeddistribution.stdnamestd"><code id="TransformedDistribution.std">tf.contrib.distributions.TransformedDistribution.std(name='std')</code></h4>
<p>Standard deviation.</p>
<hr />
<h4 id="tf.contrib.distributions.transformeddistribution.survival_functionvalue-namesurvival_function-condition_kwargs"><code id="TransformedDistribution.survival_function">tf.contrib.distributions.TransformedDistribution.survival_function(value, name='survival_function', **condition_kwargs)</code></h4>
<p>Survival function.</p>
<p>Given random variable <code>X</code>, the survival function is defined:</p>
<pre><code>survival_function(x) = P[X &gt; x]
                     = 1 - P[X &lt;= x]
                     = 1 - cdf(x).</code></pre>
<p>Additional documentation from <code>TransformedDistribution</code>:</p>
<h5 id="condition_kwargs-6"><b><code>condition_kwargs</code></b>:</h5>
<ul>
<li><b><code>bijector_kwargs</code></b>: Python dictionary of arg names/values forwarded to the bijector.</li>
<li><b><code>distribution_kwargs</code></b>: Python dictionary of arg names/values forwarded to the distribution.</li>
</ul>
<h5 id="args-602">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-680">Returns:</h5>
<p>Tensor<code>of shape</code>sample_shape(x) + self.batch_shape<code>with values of type</code>self.dtype`.</p>
<hr />
<h4 id="tf.contrib.distributions.transformeddistribution.validate_args"><code id="TransformedDistribution.validate_args">tf.contrib.distributions.TransformedDistribution.validate_args</code></h4>
<p>Python boolean indicated possibly expensive checks are enabled.</p>
<hr />
<h4 id="tf.contrib.distributions.transformeddistribution.variancenamevariance"><code id="TransformedDistribution.variance">tf.contrib.distributions.TransformedDistribution.variance(name='variance')</code></h4>
<p>Variance.</p>
<hr />
<h3 id="class-tf.contrib.distributions.quantizeddistribution"><a name="//apple_ref/cpp/Class/QuantizedDistribution" class="dashAnchor"></a><code id="QuantizedDistribution">class tf.contrib.distributions.QuantizedDistribution</code></h3>
<p>Distribution representing the quantization <code>Y = ceiling(X)</code>.</p>
<h4 id="definition-in-terms-of-sampling.">Definition in terms of sampling.</h4>
<pre><code>1. Draw X
2. Set Y &lt;-- ceiling(X)
3. If Y &lt; lower_cutoff, reset Y &lt;-- lower_cutoff
4. If Y &gt; upper_cutoff, reset Y &lt;-- upper_cutoff
5. Return Y</code></pre>
<h4 id="definition-in-terms-of-the-probability-mass-function.">Definition in terms of the probability mass function.</h4>
<p>Given scalar random variable <code>X</code>, we define a discrete random variable <code>Y</code> supported on the integers as follows:</p>
<pre><code>P[Y = j] := P[X &lt;= lower_cutoff],  if j == lower_cutoff,
         := P[X &gt; upper_cutoff - 1],  j == upper_cutoff,
         := 0, if j &lt; lower_cutoff or j &gt; upper_cutoff,
         := P[j - 1 &lt; X &lt;= j],  all other j.</code></pre>
<p>Conceptually, without cutoffs, the quantization process partitions the real line <code>R</code> into half open intervals, and identifies an integer <code>j</code> with the right endpoints:</p>
<pre><code>R = ... (-2, -1](-1, 0](0, 1](1, 2](2, 3](3, 4] ...
j = ...      -1      0     1     2     3     4  ...</code></pre>
<p><code>P[Y = j]</code> is the mass of <code>X</code> within the <code>jth</code> interval. If <code>lower_cutoff = 0</code>, and <code>upper_cutoff = 2</code>, then the intervals are redrawn and <code>j</code> is re-assigned:</p>
<pre><code>R = (-infty, 0](0, 1](1, infty)
j =          0     1     2</code></pre>
<p><code>P[Y = j]</code> is still the mass of <code>X</code> within the <code>jth</code> interval.</p>
<h4 id="caveats">Caveats</h4>
<p>Since evaluation of each <code>P[Y = j]</code> involves a cdf evaluation (rather than a closed form function such as for a Poisson), computations such as mean and entropy are better done with samples or approximations, and are not implemented by this class. - - -</p>
<h4 id="tf.contrib.distributions.quantizeddistribution.__init__distribution-lower_cutoffnone-upper_cutoffnone-validate_argsfalse-namequantizeddistribution"><code id="QuantizedDistribution.__init__">tf.contrib.distributions.QuantizedDistribution.__init__(distribution, lower_cutoff=None, upper_cutoff=None, validate_args=False, name='QuantizedDistribution')</code></h4>
<p>Construct a Quantized Distribution representing <code>Y = ceiling(X)</code>.</p>
<p>Some properties are inherited from the distribution defining <code>X</code>. Example: <code>allow_nan_stats</code> is determined for this <code>QuantizedDistribution</code> by reading the <code>distribution</code>.</p>
<h5 id="args-603">Args:</h5>
<ul>
<li><b><code>distribution</code></b>: The base distribution class to transform. Typically an instance of <code>Distribution</code>.</li>
<li><b><code>lower_cutoff</code></b>: <code>Tensor</code> with same <code>dtype</code> as this distribution and shape able to be added to samples. Should be a whole number. Default <code>None</code>. If provided, base distribution's pdf/pmf should be defined at <code>lower_cutoff</code>.</li>
<li><b><code>upper_cutoff</code></b>: <code>Tensor</code> with same <code>dtype</code> as this distribution and shape able to be added to samples. Should be a whole number. Default <code>None</code>. If provided, base distribution's pdf/pmf should be defined at <code>upper_cutoff - 1</code>. <code>upper_cutoff</code> must be strictly greater than <code>lower_cutoff</code>.</li>
<li><b><code>validate_args</code></b>: Python boolean. Whether to validate input with asserts. If <code>validate_args</code> is <code>False</code>, and the inputs are invalid, correct behavior is not guaranteed.</li>
<li><b><code>name</code></b>: The name for the distribution.</li>
</ul>
<h5 id="raises-215">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: If <code>dist_cls</code> is not a subclass of <code>Distribution</code> or continuous.</li>
<li><b><code>NotImplementedError</code></b>: If the base distribution does not implement <code>cdf</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.quantizeddistribution.allow_nan_stats"><code id="QuantizedDistribution.allow_nan_stats">tf.contrib.distributions.QuantizedDistribution.allow_nan_stats</code></h4>
<p>Python boolean describing behavior when a stat is undefined.</p>
<p>Stats return +/- infinity when it makes sense. E.g., the variance of a Cauchy distribution is infinity. However, sometimes the statistic is undefined, e.g., if a distribution's pdf does not achieve a maximum within the support of the distribution, the mode is undefined. If the mean is undefined, then by definition the variance is undefined. E.g. the mean for Student's T for df = 1 is undefined (no clear way to say it is either + or - infinity), so the variance = E[(X - mean)^2] is also undefined.</p>
<h5 id="returns-681">Returns:</h5>
<ul>
<li><b><code>allow_nan_stats</code></b>: Python boolean.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.quantizeddistribution.batch_shapenamebatch_shape"><code id="QuantizedDistribution.batch_shape">tf.contrib.distributions.QuantizedDistribution.batch_shape(name='batch_shape')</code></h4>
<p>Shape of a single sample from a single event index as a 1-D <code>Tensor</code>.</p>
<p>The product of the dimensions of the <code>batch_shape</code> is the number of independent distributions of this kind the instance represents.</p>
<h5 id="args-604">Args:</h5>
<ul>
<li><b><code>name</code></b>: name to give to the op</li>
</ul>
<h5 id="returns-682">Returns:</h5>
<ul>
<li><b><code>batch_shape</code></b>: <code>Tensor</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.quantizeddistribution.cdfvalue-namecdf-condition_kwargs"><code id="QuantizedDistribution.cdf">tf.contrib.distributions.QuantizedDistribution.cdf(value, name='cdf', **condition_kwargs)</code></h4>
<p>Cumulative distribution function.</p>
<p>Given random variable <code>X</code>, the cumulative distribution function <code>cdf</code> is:</p>
<pre><code>cdf(x) := P[X &lt;= x]</code></pre>
<p>Additional documentation from <code>QuantizedDistribution</code>:</p>
<p>For whole numbers <code>y</code>,</p>
<pre><code>cdf(y) := P[Y &lt;= y]
        = 1, if y &gt;= upper_cutoff,
        = 0, if y &lt; lower_cutoff,
        = P[X &lt;= y], otherwise.</code></pre>
<p>Since <code>Y</code> only has mass at whole numbers, <code>P[Y &lt;= y] = P[Y &lt;= floor(y)]</code>. This dictates that fractional <code>y</code> are first floored to a whole number, and then above definition applies.</p>
<p>The base distribution's <code>cdf</code> method must be defined on <code>y - 1</code>.</p>
<h5 id="args-605">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-683">Returns:</h5>
<ul>
<li><b><code>cdf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.quantizeddistribution.copyoverride_parameters_kwargs"><code id="QuantizedDistribution.copy">tf.contrib.distributions.QuantizedDistribution.copy(**override_parameters_kwargs)</code></h4>
<p>Creates a deep copy of the distribution.</p>
<p>Note: the copy distribution may continue to depend on the original intialization arguments.</p>
<h5 id="args-606">Args:</h5>
<ul>
<li><b><code>**override_parameters_kwargs</code></b>: String/value dictionary of initialization arguments to override with new values.</li>
</ul>
<h5 id="returns-684">Returns:</h5>
<ul>
<li><b><code>distribution</code></b>: A new instance of <code>type(self)</code> intitialized from the union of self.parameters and override_parameters_kwargs, i.e., <code>dict(self.parameters, **override_parameters_kwargs)</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.quantizeddistribution.distribution"><code id="QuantizedDistribution.distribution">tf.contrib.distributions.QuantizedDistribution.distribution</code></h4>
<p>Base distribution, p(x).</p>
<hr />
<h4 id="tf.contrib.distributions.quantizeddistribution.dtype"><code id="QuantizedDistribution.dtype">tf.contrib.distributions.QuantizedDistribution.dtype</code></h4>
<p>The <code>DType</code> of <code>Tensor</code>s handled by this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.quantizeddistribution.entropynameentropy"><code id="QuantizedDistribution.entropy">tf.contrib.distributions.QuantizedDistribution.entropy(name='entropy')</code></h4>
<p>Shannon entropy in nats.</p>
<hr />
<h4 id="tf.contrib.distributions.quantizeddistribution.event_shapenameevent_shape"><code id="QuantizedDistribution.event_shape">tf.contrib.distributions.QuantizedDistribution.event_shape(name='event_shape')</code></h4>
<p>Shape of a single sample from a single batch as a 1-D int32 <code>Tensor</code>.</p>
<h5 id="args-607">Args:</h5>
<ul>
<li><b><code>name</code></b>: name to give to the op</li>
</ul>
<h5 id="returns-685">Returns:</h5>
<ul>
<li><b><code>event_shape</code></b>: <code>Tensor</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.quantizeddistribution.get_batch_shape"><code id="QuantizedDistribution.get_batch_shape">tf.contrib.distributions.QuantizedDistribution.get_batch_shape()</code></h4>
<p>Shape of a single sample from a single event index as a <code>TensorShape</code>.</p>
<p>Same meaning as <code>batch_shape</code>. May be only partially defined.</p>
<h5 id="returns-686">Returns:</h5>
<ul>
<li><b><code>batch_shape</code></b>: <code>TensorShape</code>, possibly unknown.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.quantizeddistribution.get_event_shape"><code id="QuantizedDistribution.get_event_shape">tf.contrib.distributions.QuantizedDistribution.get_event_shape()</code></h4>
<p>Shape of a single sample from a single batch as a <code>TensorShape</code>.</p>
<p>Same meaning as <code>event_shape</code>. May be only partially defined.</p>
<h5 id="returns-687">Returns:</h5>
<ul>
<li><b><code>event_shape</code></b>: <code>TensorShape</code>, possibly unknown.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.quantizeddistribution.is_continuous"><code id="QuantizedDistribution.is_continuous">tf.contrib.distributions.QuantizedDistribution.is_continuous</code></h4>
<hr />
<h4 id="tf.contrib.distributions.quantizeddistribution.is_reparameterized"><code id="QuantizedDistribution.is_reparameterized">tf.contrib.distributions.QuantizedDistribution.is_reparameterized</code></h4>
<hr />
<h4 id="tf.contrib.distributions.quantizeddistribution.log_cdfvalue-namelog_cdf-condition_kwargs"><code id="QuantizedDistribution.log_cdf">tf.contrib.distributions.QuantizedDistribution.log_cdf(value, name='log_cdf', **condition_kwargs)</code></h4>
<p>Log cumulative distribution function.</p>
<p>Given random variable <code>X</code>, the cumulative distribution function <code>cdf</code> is:</p>
<pre><code>log_cdf(x) := Log[ P[X &lt;= x] ]</code></pre>
<p>Often, a numerical approximation can be used for <code>log_cdf(x)</code> that yields a more accurate answer than simply taking the logarithm of the <code>cdf</code> when <code>x &lt;&lt; -1</code>.</p>
<p>Additional documentation from <code>QuantizedDistribution</code>:</p>
<p>For whole numbers <code>y</code>,</p>
<pre><code>cdf(y) := P[Y &lt;= y]
        = 1, if y &gt;= upper_cutoff,
        = 0, if y &lt; lower_cutoff,
        = P[X &lt;= y], otherwise.</code></pre>
<p>Since <code>Y</code> only has mass at whole numbers, <code>P[Y &lt;= y] = P[Y &lt;= floor(y)]</code>. This dictates that fractional <code>y</code> are first floored to a whole number, and then above definition applies.</p>
<p>The base distribution's <code>log_cdf</code> method must be defined on <code>y - 1</code>.</p>
<h5 id="args-608">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-688">Returns:</h5>
<ul>
<li><b><code>logcdf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.quantizeddistribution.log_pdfvalue-namelog_pdf-condition_kwargs"><code id="QuantizedDistribution.log_pdf">tf.contrib.distributions.QuantizedDistribution.log_pdf(value, name='log_pdf', **condition_kwargs)</code></h4>
<p>Log probability density function.</p>
<h5 id="args-609">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-689">Returns:</h5>
<ul>
<li><b><code>log_prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-216">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if not <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.quantizeddistribution.log_pmfvalue-namelog_pmf-condition_kwargs"><code id="QuantizedDistribution.log_pmf">tf.contrib.distributions.QuantizedDistribution.log_pmf(value, name='log_pmf', **condition_kwargs)</code></h4>
<p>Log probability mass function.</p>
<h5 id="args-610">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-690">Returns:</h5>
<ul>
<li><b><code>log_pmf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-217">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.quantizeddistribution.log_probvalue-namelog_prob-condition_kwargs"><code id="QuantizedDistribution.log_prob">tf.contrib.distributions.QuantizedDistribution.log_prob(value, name='log_prob', **condition_kwargs)</code></h4>
<p>Log probability density/mass function (depending on <code>is_continuous</code>).</p>
<p>Additional documentation from <code>QuantizedDistribution</code>:</p>
<p>For whole numbers <code>y</code>,</p>
<pre><code>P[Y = y] := P[X &lt;= lower_cutoff],  if y == lower_cutoff,
         := P[X &gt; upper_cutoff - 1],  y == upper_cutoff,
         := 0, if j &lt; lower_cutoff or y &gt; upper_cutoff,
         := P[y - 1 &lt; X &lt;= y],  all other y.</code></pre>
<p>The base distribution's <code>log_cdf</code> method must be defined on <code>y - 1</code>. If the base distribution has a <code>log_survival_function</code> method results will be more accurate for large values of <code>y</code>, and in this case the <code>log_survival_function</code> must also be defined on <code>y - 1</code>.</p>
<h5 id="args-611">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-691">Returns:</h5>
<ul>
<li><b><code>log_prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.quantizeddistribution.log_survival_functionvalue-namelog_survival_function-condition_kwargs"><code id="QuantizedDistribution.log_survival_function">tf.contrib.distributions.QuantizedDistribution.log_survival_function(value, name='log_survival_function', **condition_kwargs)</code></h4>
<p>Log survival function.</p>
<p>Given random variable <code>X</code>, the survival function is defined:</p>
<pre><code>log_survival_function(x) = Log[ P[X &gt; x] ]
                         = Log[ 1 - P[X &lt;= x] ]
                         = Log[ 1 - cdf(x) ]</code></pre>
<p>Typically, different numerical approximations can be used for the log survival function, which are more accurate than <code>1 - cdf(x)</code> when <code>x &gt;&gt; 1</code>.</p>
<p>Additional documentation from <code>QuantizedDistribution</code>:</p>
<p>For whole numbers <code>y</code>,</p>
<pre><code>survival_function(y) := P[Y &gt; y]
                      = 0, if y &gt;= upper_cutoff,
                      = 1, if y &lt; lower_cutoff,
                      = P[X &lt;= y], otherwise.</code></pre>
<p>Since <code>Y</code> only has mass at whole numbers, <code>P[Y &lt;= y] = P[Y &lt;= floor(y)]</code>. This dictates that fractional <code>y</code> are first floored to a whole number, and then above definition applies.</p>
<p>The base distribution's <code>log_cdf</code> method must be defined on <code>y - 1</code>.</p>
<h5 id="args-612">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-692">Returns:</h5>
<p><code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.quantizeddistribution.meannamemean"><code id="QuantizedDistribution.mean">tf.contrib.distributions.QuantizedDistribution.mean(name='mean')</code></h4>
<p>Mean.</p>
<hr />
<h4 id="tf.contrib.distributions.quantizeddistribution.modenamemode"><code id="QuantizedDistribution.mode">tf.contrib.distributions.QuantizedDistribution.mode(name='mode')</code></h4>
<p>Mode.</p>
<hr />
<h4 id="tf.contrib.distributions.quantizeddistribution.name"><code id="QuantizedDistribution.name">tf.contrib.distributions.QuantizedDistribution.name</code></h4>
<p>Name prepended to all ops created by this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.quantizeddistribution.param_shapescls-sample_shape-namedistributionparamshapes"><code id="QuantizedDistribution.param_shapes">tf.contrib.distributions.QuantizedDistribution.param_shapes(cls, sample_shape, name='DistributionParamShapes')</code></h4>
<p>Shapes of parameters given the desired shape of a call to <code>sample()</code>.</p>
<p>Subclasses should override static method <code>_param_shapes</code>.</p>
<h5 id="args-613">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: <code>Tensor</code> or python list/tuple. Desired shape of a call to <code>sample()</code>.</li>
<li><b><code>name</code></b>: name to prepend ops with.</li>
</ul>
<h5 id="returns-693">Returns:</h5>
<p><code>dict</code> of parameter name to <code>Tensor</code> shapes.</p>
<hr />
<h4 id="tf.contrib.distributions.quantizeddistribution.param_static_shapescls-sample_shape"><code id="QuantizedDistribution.param_static_shapes">tf.contrib.distributions.QuantizedDistribution.param_static_shapes(cls, sample_shape)</code></h4>
<p>param_shapes with static (i.e. TensorShape) shapes.</p>
<h5 id="args-614">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: <code>TensorShape</code> or python list/tuple. Desired shape of a call to <code>sample()</code>.</li>
</ul>
<h5 id="returns-694">Returns:</h5>
<p><code>dict</code> of parameter name to <code>TensorShape</code>.</p>
<h5 id="raises-218">Raises:</h5>
<ul>
<li><b><code>ValueError</code></b>: if <code>sample_shape</code> is a <code>TensorShape</code> and is not fully defined.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.quantizeddistribution.parameters"><code id="QuantizedDistribution.parameters">tf.contrib.distributions.QuantizedDistribution.parameters</code></h4>
<p>Dictionary of parameters used to instantiate this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.quantizeddistribution.pdfvalue-namepdf-condition_kwargs"><code id="QuantizedDistribution.pdf">tf.contrib.distributions.QuantizedDistribution.pdf(value, name='pdf', **condition_kwargs)</code></h4>
<p>Probability density function.</p>
<h5 id="args-615">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-695">Returns:</h5>
<ul>
<li><b><code>prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-219">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if not <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.quantizeddistribution.pmfvalue-namepmf-condition_kwargs"><code id="QuantizedDistribution.pmf">tf.contrib.distributions.QuantizedDistribution.pmf(value, name='pmf', **condition_kwargs)</code></h4>
<p>Probability mass function.</p>
<h5 id="args-616">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-696">Returns:</h5>
<ul>
<li><b><code>pmf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-220">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.quantizeddistribution.probvalue-nameprob-condition_kwargs"><code id="QuantizedDistribution.prob">tf.contrib.distributions.QuantizedDistribution.prob(value, name='prob', **condition_kwargs)</code></h4>
<p>Probability density/mass function (depending on <code>is_continuous</code>).</p>
<p>Additional documentation from <code>QuantizedDistribution</code>:</p>
<p>For whole numbers <code>y</code>,</p>
<pre><code>P[Y = y] := P[X &lt;= lower_cutoff],  if y == lower_cutoff,
         := P[X &gt; upper_cutoff - 1],  y == upper_cutoff,
         := 0, if j &lt; lower_cutoff or y &gt; upper_cutoff,
         := P[y - 1 &lt; X &lt;= y],  all other y.</code></pre>
<p>The base distribution's <code>cdf</code> method must be defined on <code>y - 1</code>. If the base distribution has a <code>survival_function</code> method, results will be more accurate for large values of <code>y</code>, and in this case the <code>survival_function</code> must also be defined on <code>y - 1</code>.</p>
<h5 id="args-617">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-697">Returns:</h5>
<ul>
<li><b><code>prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.quantizeddistribution.samplesample_shape-seednone-namesample-condition_kwargs"><code id="QuantizedDistribution.sample">tf.contrib.distributions.QuantizedDistribution.sample(sample_shape=(), seed=None, name='sample', **condition_kwargs)</code></h4>
<p>Generate samples of the specified shape.</p>
<p>Note that a call to <code>sample()</code> without arguments will generate a single sample.</p>
<h5 id="args-618">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: 0D or 1D <code>int32</code> <code>Tensor</code>. Shape of the generated samples.</li>
<li><b><code>seed</code></b>: Python integer seed for RNG</li>
<li><b><code>name</code></b>: name to give to the op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-698">Returns:</h5>
<ul>
<li><b><code>samples</code></b>: a <code>Tensor</code> with prepended dimensions <code>sample_shape</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.quantizeddistribution.sample_nn-seednone-namesample_n-condition_kwargs"><code id="QuantizedDistribution.sample_n">tf.contrib.distributions.QuantizedDistribution.sample_n(n, seed=None, name='sample_n', **condition_kwargs)</code></h4>
<p>Generate <code>n</code> samples.</p>
<h5 id="args-619">Args:</h5>
<ul>
<li><b><code>n</code></b>: <code>Scalar</code> <code>Tensor</code> of type <code>int32</code> or <code>int64</code>, the number of observations to sample.</li>
<li><b><code>seed</code></b>: Python integer seed for RNG</li>
<li><b><code>name</code></b>: name to give to the op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-699">Returns:</h5>
<ul>
<li><b><code>samples</code></b>: a <code>Tensor</code> with a prepended dimension (n,).</li>
</ul>
<h5 id="raises-221">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>n</code> is not an integer type.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.quantizeddistribution.stdnamestd"><code id="QuantizedDistribution.std">tf.contrib.distributions.QuantizedDistribution.std(name='std')</code></h4>
<p>Standard deviation.</p>
<hr />
<h4 id="tf.contrib.distributions.quantizeddistribution.survival_functionvalue-namesurvival_function-condition_kwargs"><code id="QuantizedDistribution.survival_function">tf.contrib.distributions.QuantizedDistribution.survival_function(value, name='survival_function', **condition_kwargs)</code></h4>
<p>Survival function.</p>
<p>Given random variable <code>X</code>, the survival function is defined:</p>
<pre><code>survival_function(x) = P[X &gt; x]
                     = 1 - P[X &lt;= x]
                     = 1 - cdf(x).</code></pre>
<p>Additional documentation from <code>QuantizedDistribution</code>:</p>
<p>For whole numbers <code>y</code>,</p>
<pre><code>survival_function(y) := P[Y &gt; y]
                      = 0, if y &gt;= upper_cutoff,
                      = 1, if y &lt; lower_cutoff,
                      = P[X &lt;= y], otherwise.</code></pre>
<p>Since <code>Y</code> only has mass at whole numbers, <code>P[Y &lt;= y] = P[Y &lt;= floor(y)]</code>. This dictates that fractional <code>y</code> are first floored to a whole number, and then above definition applies.</p>
<p>The base distribution's <code>cdf</code> method must be defined on <code>y - 1</code>.</p>
<h5 id="args-620">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-700">Returns:</h5>
<p>Tensor<code>of shape</code>sample_shape(x) + self.batch_shape<code>with values of type</code>self.dtype`.</p>
<hr />
<h4 id="tf.contrib.distributions.quantizeddistribution.validate_args"><code id="QuantizedDistribution.validate_args">tf.contrib.distributions.QuantizedDistribution.validate_args</code></h4>
<p>Python boolean indicated possibly expensive checks are enabled.</p>
<hr />
<h4 id="tf.contrib.distributions.quantizeddistribution.variancenamevariance"><code id="QuantizedDistribution.variance">tf.contrib.distributions.QuantizedDistribution.variance(name='variance')</code></h4>
<p>Variance.</p>
<h2 id="mixture-models">Mixture Models</h2>
<hr />
<h3 id="class-tf.contrib.distributions.mixture"><a name="//apple_ref/cpp/Class/Mixture" class="dashAnchor"></a><code id="Mixture">class tf.contrib.distributions.Mixture</code></h3>
<p>Mixture distribution.</p>
<p>The <code>Mixture</code> object implements batched mixture distributions. The mixture model is defined by a <code>Categorical</code> distribution (the mixture) and a python list of <code>Distribution</code> objects.</p>
<p>Methods supported include <code>log_prob</code>, <code>prob</code>, <code>mean</code>, <code>sample</code>, and <code>entropy_lower_bound</code>. - - -</p>
<h4 id="tf.contrib.distributions.mixture.__init__cat-components-validate_argsfalse-allow_nan_statstrue-namemixture"><code id="Mixture.__init__">tf.contrib.distributions.Mixture.__init__(cat, components, validate_args=False, allow_nan_stats=True, name='Mixture')</code></h4>
<p>Initialize a Mixture distribution.</p>
<p>A <code>Mixture</code> is defined by a <code>Categorical</code> (<code>cat</code>, representing the mixture probabilities) and a list of <code>Distribution</code> objects all having matching dtype, batch shape, event shape, and continuity properties (the components).</p>
<p>The <code>num_classes</code> of <code>cat</code> must be possible to infer at graph construction time and match <code>len(components)</code>.</p>
<h5 id="args-621">Args:</h5>
<ul>
<li><b><code>cat</code></b>: A <code>Categorical</code> distribution instance, representing the probabilities of <code>distributions</code>.</li>
<li><b><code>components</code></b>: A list or tuple of <code>Distribution</code> instances. Each instance must have the same type, be defined on the same domain, and have matching <code>event_shape</code> and <code>batch_shape</code>.</li>
<li><b><code>validate_args</code></b>: <code>Boolean</code>, default <code>False</code>. If <code>True</code>, raise a runtime error if batch or event ranks are inconsistent between cat and any of the distributions. This is only checked if the ranks cannot be determined statically at graph construction time.</li>
<li><b><code>allow_nan_stats</code></b>: Boolean, default <code>True</code>. If <code>False</code>, raise an exception if a statistic (e.g. mean/mode/etc...) is undefined for any batch member. If <code>True</code>, batch members with valid parameters leading to undefined statistics will return NaN for this statistic.</li>
<li><b><code>name</code></b>: A name for this distribution (optional).</li>
</ul>
<h5 id="raises-222">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: If cat is not a <code>Categorical</code>, or <code>components</code> is not a list or tuple, or the elements of <code>components</code> are not instances of <code>Distribution</code>, or do not have matching <code>dtype</code>.</li>
<li><b><code>ValueError</code></b>: If <code>components</code> is an empty list or tuple, or its elements do not have a statically known event rank. If <code>cat.num_classes</code> cannot be inferred at graph creation time, or the constant value of <code>cat.num_classes</code> is not equal to <code>len(components)</code>, or all <code>components</code> and <code>cat</code> do not have matching static batch shapes, or all components do not have matching static event shapes.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.mixture.allow_nan_stats"><code id="Mixture.allow_nan_stats">tf.contrib.distributions.Mixture.allow_nan_stats</code></h4>
<p>Python boolean describing behavior when a stat is undefined.</p>
<p>Stats return +/- infinity when it makes sense. E.g., the variance of a Cauchy distribution is infinity. However, sometimes the statistic is undefined, e.g., if a distribution's pdf does not achieve a maximum within the support of the distribution, the mode is undefined. If the mean is undefined, then by definition the variance is undefined. E.g. the mean for Student's T for df = 1 is undefined (no clear way to say it is either + or - infinity), so the variance = E[(X - mean)^2] is also undefined.</p>
<h5 id="returns-701">Returns:</h5>
<ul>
<li><b><code>allow_nan_stats</code></b>: Python boolean.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.mixture.batch_shapenamebatch_shape"><code id="Mixture.batch_shape">tf.contrib.distributions.Mixture.batch_shape(name='batch_shape')</code></h4>
<p>Shape of a single sample from a single event index as a 1-D <code>Tensor</code>.</p>
<p>The product of the dimensions of the <code>batch_shape</code> is the number of independent distributions of this kind the instance represents.</p>
<h5 id="args-622">Args:</h5>
<ul>
<li><b><code>name</code></b>: name to give to the op</li>
</ul>
<h5 id="returns-702">Returns:</h5>
<ul>
<li><b><code>batch_shape</code></b>: <code>Tensor</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.mixture.cat"><code id="Mixture.cat">tf.contrib.distributions.Mixture.cat</code></h4>
<hr />
<h4 id="tf.contrib.distributions.mixture.cdfvalue-namecdf-condition_kwargs"><code id="Mixture.cdf">tf.contrib.distributions.Mixture.cdf(value, name='cdf', **condition_kwargs)</code></h4>
<p>Cumulative distribution function.</p>
<p>Given random variable <code>X</code>, the cumulative distribution function <code>cdf</code> is:</p>
<pre><code>cdf(x) := P[X &lt;= x]</code></pre>
<h5 id="args-623">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-703">Returns:</h5>
<ul>
<li><b><code>cdf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.mixture.components"><code id="Mixture.components">tf.contrib.distributions.Mixture.components</code></h4>
<hr />
<h4 id="tf.contrib.distributions.mixture.copyoverride_parameters_kwargs"><code id="Mixture.copy">tf.contrib.distributions.Mixture.copy(**override_parameters_kwargs)</code></h4>
<p>Creates a deep copy of the distribution.</p>
<p>Note: the copy distribution may continue to depend on the original intialization arguments.</p>
<h5 id="args-624">Args:</h5>
<ul>
<li><b><code>**override_parameters_kwargs</code></b>: String/value dictionary of initialization arguments to override with new values.</li>
</ul>
<h5 id="returns-704">Returns:</h5>
<ul>
<li><b><code>distribution</code></b>: A new instance of <code>type(self)</code> intitialized from the union of self.parameters and override_parameters_kwargs, i.e., <code>dict(self.parameters, **override_parameters_kwargs)</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.mixture.dtype"><code id="Mixture.dtype">tf.contrib.distributions.Mixture.dtype</code></h4>
<p>The <code>DType</code> of <code>Tensor</code>s handled by this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.mixture.entropynameentropy"><code id="Mixture.entropy">tf.contrib.distributions.Mixture.entropy(name='entropy')</code></h4>
<p>Shannon entropy in nats.</p>
<hr />
<h4 id="tf.contrib.distributions.mixture.entropy_lower_boundnameentropy_lower_bound"><code id="Mixture.entropy_lower_bound">tf.contrib.distributions.Mixture.entropy_lower_bound(name='entropy_lower_bound')</code></h4>
<p>A lower bound on the entropy of this mixture model.</p>
<p>The bound below is not always very tight, and its usefulness depends on the mixture probabilities and the components in use.</p>
<p>A lower bound is useful for ELBO when the <code>Mixture</code> is the variational distribution:</p>
<p>\( p(x) &gt;= ELBO = q(z) p(x, z) dz + H[q] \)</p>
<p>where \( p \) is the prior distribution, \( q \) is the variational, and \( H[q] \) is the entropy of \( q \). If there is a lower bound \( G[q] \) such that \( H[q] G[q] \) then it can be used in place of \( H[q] \).</p>
<p>For a mixture of distributions \( q(Z) = _i c_i q_i(Z) \) with \( _i c_i = 1 \), by the concavity of \( f(x) = -x x \), a simple lower bound is:</p>
\(

<p>\)</p>
<p>This is the term we calculate below for \( G[q] \).</p>
<h5 id="args-625">Args:</h5>
<ul>
<li><b><code>name</code></b>: A name for this operation (optional).</li>
</ul>
<h5 id="returns-705">Returns:</h5>
<p>A lower bound on the Mixture's entropy.</p>
<hr />
<h4 id="tf.contrib.distributions.mixture.event_shapenameevent_shape"><code id="Mixture.event_shape">tf.contrib.distributions.Mixture.event_shape(name='event_shape')</code></h4>
<p>Shape of a single sample from a single batch as a 1-D int32 <code>Tensor</code>.</p>
<h5 id="args-626">Args:</h5>
<ul>
<li><b><code>name</code></b>: name to give to the op</li>
</ul>
<h5 id="returns-706">Returns:</h5>
<ul>
<li><b><code>event_shape</code></b>: <code>Tensor</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.mixture.get_batch_shape"><code id="Mixture.get_batch_shape">tf.contrib.distributions.Mixture.get_batch_shape()</code></h4>
<p>Shape of a single sample from a single event index as a <code>TensorShape</code>.</p>
<p>Same meaning as <code>batch_shape</code>. May be only partially defined.</p>
<h5 id="returns-707">Returns:</h5>
<ul>
<li><b><code>batch_shape</code></b>: <code>TensorShape</code>, possibly unknown.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.mixture.get_event_shape"><code id="Mixture.get_event_shape">tf.contrib.distributions.Mixture.get_event_shape()</code></h4>
<p>Shape of a single sample from a single batch as a <code>TensorShape</code>.</p>
<p>Same meaning as <code>event_shape</code>. May be only partially defined.</p>
<h5 id="returns-708">Returns:</h5>
<ul>
<li><b><code>event_shape</code></b>: <code>TensorShape</code>, possibly unknown.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.mixture.is_continuous"><code id="Mixture.is_continuous">tf.contrib.distributions.Mixture.is_continuous</code></h4>
<hr />
<h4 id="tf.contrib.distributions.mixture.is_reparameterized"><code id="Mixture.is_reparameterized">tf.contrib.distributions.Mixture.is_reparameterized</code></h4>
<hr />
<h4 id="tf.contrib.distributions.mixture.log_cdfvalue-namelog_cdf-condition_kwargs"><code id="Mixture.log_cdf">tf.contrib.distributions.Mixture.log_cdf(value, name='log_cdf', **condition_kwargs)</code></h4>
<p>Log cumulative distribution function.</p>
<p>Given random variable <code>X</code>, the cumulative distribution function <code>cdf</code> is:</p>
<pre><code>log_cdf(x) := Log[ P[X &lt;= x] ]</code></pre>
<p>Often, a numerical approximation can be used for <code>log_cdf(x)</code> that yields a more accurate answer than simply taking the logarithm of the <code>cdf</code> when <code>x &lt;&lt; -1</code>.</p>
<h5 id="args-627">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-709">Returns:</h5>
<ul>
<li><b><code>logcdf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.mixture.log_pdfvalue-namelog_pdf-condition_kwargs"><code id="Mixture.log_pdf">tf.contrib.distributions.Mixture.log_pdf(value, name='log_pdf', **condition_kwargs)</code></h4>
<p>Log probability density function.</p>
<h5 id="args-628">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-710">Returns:</h5>
<ul>
<li><b><code>log_prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-223">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if not <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.mixture.log_pmfvalue-namelog_pmf-condition_kwargs"><code id="Mixture.log_pmf">tf.contrib.distributions.Mixture.log_pmf(value, name='log_pmf', **condition_kwargs)</code></h4>
<p>Log probability mass function.</p>
<h5 id="args-629">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-711">Returns:</h5>
<ul>
<li><b><code>log_pmf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-224">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.mixture.log_probvalue-namelog_prob-condition_kwargs"><code id="Mixture.log_prob">tf.contrib.distributions.Mixture.log_prob(value, name='log_prob', **condition_kwargs)</code></h4>
<p>Log probability density/mass function (depending on <code>is_continuous</code>).</p>
<h5 id="args-630">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-712">Returns:</h5>
<ul>
<li><b><code>log_prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.mixture.log_survival_functionvalue-namelog_survival_function-condition_kwargs"><code id="Mixture.log_survival_function">tf.contrib.distributions.Mixture.log_survival_function(value, name='log_survival_function', **condition_kwargs)</code></h4>
<p>Log survival function.</p>
<p>Given random variable <code>X</code>, the survival function is defined:</p>
<pre><code>log_survival_function(x) = Log[ P[X &gt; x] ]
                         = Log[ 1 - P[X &lt;= x] ]
                         = Log[ 1 - cdf(x) ]</code></pre>
<p>Typically, different numerical approximations can be used for the log survival function, which are more accurate than <code>1 - cdf(x)</code> when <code>x &gt;&gt; 1</code>.</p>
<h5 id="args-631">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-713">Returns:</h5>
<p><code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.mixture.meannamemean"><code id="Mixture.mean">tf.contrib.distributions.Mixture.mean(name='mean')</code></h4>
<p>Mean.</p>
<hr />
<h4 id="tf.contrib.distributions.mixture.modenamemode"><code id="Mixture.mode">tf.contrib.distributions.Mixture.mode(name='mode')</code></h4>
<p>Mode.</p>
<hr />
<h4 id="tf.contrib.distributions.mixture.name"><code id="Mixture.name">tf.contrib.distributions.Mixture.name</code></h4>
<p>Name prepended to all ops created by this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.mixture.num_components"><code id="Mixture.num_components">tf.contrib.distributions.Mixture.num_components</code></h4>
<hr />
<h4 id="tf.contrib.distributions.mixture.param_shapescls-sample_shape-namedistributionparamshapes"><code id="Mixture.param_shapes">tf.contrib.distributions.Mixture.param_shapes(cls, sample_shape, name='DistributionParamShapes')</code></h4>
<p>Shapes of parameters given the desired shape of a call to <code>sample()</code>.</p>
<p>Subclasses should override static method <code>_param_shapes</code>.</p>
<h5 id="args-632">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: <code>Tensor</code> or python list/tuple. Desired shape of a call to <code>sample()</code>.</li>
<li><b><code>name</code></b>: name to prepend ops with.</li>
</ul>
<h5 id="returns-714">Returns:</h5>
<p><code>dict</code> of parameter name to <code>Tensor</code> shapes.</p>
<hr />
<h4 id="tf.contrib.distributions.mixture.param_static_shapescls-sample_shape"><code id="Mixture.param_static_shapes">tf.contrib.distributions.Mixture.param_static_shapes(cls, sample_shape)</code></h4>
<p>param_shapes with static (i.e. TensorShape) shapes.</p>
<h5 id="args-633">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: <code>TensorShape</code> or python list/tuple. Desired shape of a call to <code>sample()</code>.</li>
</ul>
<h5 id="returns-715">Returns:</h5>
<p><code>dict</code> of parameter name to <code>TensorShape</code>.</p>
<h5 id="raises-225">Raises:</h5>
<ul>
<li><b><code>ValueError</code></b>: if <code>sample_shape</code> is a <code>TensorShape</code> and is not fully defined.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.mixture.parameters"><code id="Mixture.parameters">tf.contrib.distributions.Mixture.parameters</code></h4>
<p>Dictionary of parameters used to instantiate this <code>Distribution</code>.</p>
<hr />
<h4 id="tf.contrib.distributions.mixture.pdfvalue-namepdf-condition_kwargs"><code id="Mixture.pdf">tf.contrib.distributions.Mixture.pdf(value, name='pdf', **condition_kwargs)</code></h4>
<p>Probability density function.</p>
<h5 id="args-634">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-716">Returns:</h5>
<ul>
<li><b><code>prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-226">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if not <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.mixture.pmfvalue-namepmf-condition_kwargs"><code id="Mixture.pmf">tf.contrib.distributions.Mixture.pmf(value, name='pmf', **condition_kwargs)</code></h4>
<p>Probability mass function.</p>
<h5 id="args-635">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-717">Returns:</h5>
<ul>
<li><b><code>pmf</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<h5 id="raises-227">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>is_continuous</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.mixture.probvalue-nameprob-condition_kwargs"><code id="Mixture.prob">tf.contrib.distributions.Mixture.prob(value, name='prob', **condition_kwargs)</code></h4>
<p>Probability density/mass function (depending on <code>is_continuous</code>).</p>
<h5 id="args-636">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-718">Returns:</h5>
<ul>
<li><b><code>prob</code></b>: a <code>Tensor</code> of shape <code>sample_shape(x) + self.batch_shape</code> with values of type <code>self.dtype</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.mixture.samplesample_shape-seednone-namesample-condition_kwargs"><code id="Mixture.sample">tf.contrib.distributions.Mixture.sample(sample_shape=(), seed=None, name='sample', **condition_kwargs)</code></h4>
<p>Generate samples of the specified shape.</p>
<p>Note that a call to <code>sample()</code> without arguments will generate a single sample.</p>
<h5 id="args-637">Args:</h5>
<ul>
<li><b><code>sample_shape</code></b>: 0D or 1D <code>int32</code> <code>Tensor</code>. Shape of the generated samples.</li>
<li><b><code>seed</code></b>: Python integer seed for RNG</li>
<li><b><code>name</code></b>: name to give to the op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-719">Returns:</h5>
<ul>
<li><b><code>samples</code></b>: a <code>Tensor</code> with prepended dimensions <code>sample_shape</code>.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.mixture.sample_nn-seednone-namesample_n-condition_kwargs"><code id="Mixture.sample_n">tf.contrib.distributions.Mixture.sample_n(n, seed=None, name='sample_n', **condition_kwargs)</code></h4>
<p>Generate <code>n</code> samples.</p>
<h5 id="args-638">Args:</h5>
<ul>
<li><b><code>n</code></b>: <code>Scalar</code> <code>Tensor</code> of type <code>int32</code> or <code>int64</code>, the number of observations to sample.</li>
<li><b><code>seed</code></b>: Python integer seed for RNG</li>
<li><b><code>name</code></b>: name to give to the op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-720">Returns:</h5>
<ul>
<li><b><code>samples</code></b>: a <code>Tensor</code> with a prepended dimension (n,).</li>
</ul>
<h5 id="raises-228">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if <code>n</code> is not an integer type.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.mixture.stdnamestd"><code id="Mixture.std">tf.contrib.distributions.Mixture.std(name='std')</code></h4>
<p>Standard deviation.</p>
<hr />
<h4 id="tf.contrib.distributions.mixture.survival_functionvalue-namesurvival_function-condition_kwargs"><code id="Mixture.survival_function">tf.contrib.distributions.Mixture.survival_function(value, name='survival_function', **condition_kwargs)</code></h4>
<p>Survival function.</p>
<p>Given random variable <code>X</code>, the survival function is defined:</p>
<pre><code>survival_function(x) = P[X &gt; x]
                     = 1 - P[X &lt;= x]
                     = 1 - cdf(x).</code></pre>
<h5 id="args-639">Args:</h5>
<ul>
<li><b><code>value</code></b>: <code>float</code> or <code>double</code> <code>Tensor</code>.</li>
<li><b><code>name</code></b>: The name to give this op.</li>
<li><b><code>**condition_kwargs</code></b>: Named arguments forwarded to subclass implementation.</li>
</ul>
<h5 id="returns-721">Returns:</h5>
<p>Tensor<code>of shape</code>sample_shape(x) + self.batch_shape<code>with values of type</code>self.dtype`.</p>
<hr />
<h4 id="tf.contrib.distributions.mixture.validate_args"><code id="Mixture.validate_args">tf.contrib.distributions.Mixture.validate_args</code></h4>
<p>Python boolean indicated possibly expensive checks are enabled.</p>
<hr />
<h4 id="tf.contrib.distributions.mixture.variancenamevariance"><code id="Mixture.variance">tf.contrib.distributions.Mixture.variance(name='variance')</code></h4>
<p>Variance.</p>
<h2 id="posterior-inference-with-conjugate-priors.">Posterior inference with conjugate priors.</h2>
<p>Functions that transform conjugate prior/likelihood pairs to distributions representing the posterior or posterior predictive.</p>
<h2 id="normal-likelihood-with-conjugate-prior.">Normal likelihood with conjugate prior.</h2>
<hr />
<h3 id="tf.contrib.distributions.normal_conjugates_known_sigma_posteriorprior-sigma-s-n"><a name="//apple_ref/cpp/Function/normal_conjugates_known_sigma_posterior" class="dashAnchor"></a><code id="normal_conjugates_known_sigma_posterior">tf.contrib.distributions.normal_conjugates_known_sigma_posterior(prior, sigma, s, n)</code></h3>
<p>Posterior Normal distribution with conjugate prior on the mean.</p>
<p>This model assumes that <code>n</code> observations (with sum <code>s</code>) come from a Normal with unknown mean <code>mu</code> (described by the Normal <code>prior</code>) and known variance <code>sigma^2</code>. The &quot;known sigma posterior&quot; is the distribution of the unknown <code>mu</code>.</p>
<p>Accepts a prior Normal distribution object, having parameters <code>mu0</code> and <code>sigma0</code>, as well as known <code>sigma</code> values of the predictive distribution(s) (also assumed Normal), and statistical estimates <code>s</code> (the sum(s) of the observations) and <code>n</code> (the number(s) of observations).</p>
<p>Returns a posterior (also Normal) distribution object, with parameters <code>(mu', sigma'^2)</code>, where:</p>
<pre><code>mu ~ N(mu&#39;, sigma&#39;^2)
sigma&#39;^2 = 1/(1/sigma0^2 + n/sigma^2),
mu&#39; = (mu0/sigma0^2 + s/sigma^2) * sigma&#39;^2.</code></pre>
<p>Distribution parameters from <code>prior</code>, as well as <code>sigma</code>, <code>s</code>, and <code>n</code>. will broadcast in the case of multidimensional sets of parameters.</p>
<h5 id="args-640">Args:</h5>
<ul>
<li><b><code>prior</code></b>: <code>Normal</code> object of type <code>dtype</code>: the prior distribution having parameters <code>(mu0, sigma0)</code>.</li>
<li><b><code>sigma</code></b>: tensor of type <code>dtype</code>, taking values <code>sigma &gt; 0</code>. The known stddev parameter(s).</li>
<li><b><code>s</code></b>: Tensor of type <code>dtype</code>. The sum(s) of observations.</li>
<li><b><code>n</code></b>: Tensor of type <code>int</code>. The number(s) of observations.</li>
</ul>
<h5 id="returns-722">Returns:</h5>
<p>A new Normal posterior distribution object for the unknown observation mean <code>mu</code>.</p>
<h5 id="raises-229">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if dtype of <code>s</code> does not match <code>dtype</code>, or <code>prior</code> is not a Normal object.</li>
</ul>
<hr />
<h3 id="tf.contrib.distributions.normal_conjugates_known_sigma_predictiveprior-sigma-s-n"><a name="//apple_ref/cpp/Function/normal_conjugates_known_sigma_predictive" class="dashAnchor"></a><code id="normal_conjugates_known_sigma_predictive">tf.contrib.distributions.normal_conjugates_known_sigma_predictive(prior, sigma, s, n)</code></h3>
<p>Posterior predictive Normal distribution w. conjugate prior on the mean.</p>
<p>This model assumes that <code>n</code> observations (with sum <code>s</code>) come from a Normal with unknown mean <code>mu</code> (described by the Normal <code>prior</code>) and known variance <code>sigma^2</code>. The &quot;known sigma predictive&quot; is the distribution of new observations, conditioned on the existing observations and our prior.</p>
<p>Accepts a prior Normal distribution object, having parameters <code>mu0</code> and <code>sigma0</code>, as well as known <code>sigma</code> values of the predictive distribution(s) (also assumed Normal), and statistical estimates <code>s</code> (the sum(s) of the observations) and <code>n</code> (the number(s) of observations).</p>
<p>Calculates the Normal distribution(s) <code>p(x | sigma^2)</code>:</p>
<pre><code>  p(x | sigma^2) = int N(x | mu, sigma^2) N(mu | prior.mu, prior.sigma^2) dmu
                 = N(x | prior.mu, 1/(sigma^2 + prior.sigma^2))</code></pre>
<p>Returns the predictive posterior distribution object, with parameters <code>(mu', sigma'^2)</code>, where:</p>
<pre><code>sigma_n^2 = 1/(1/sigma0^2 + n/sigma^2),
mu&#39; = (mu0/sigma0^2 + s/sigma^2) * sigma_n^2.
sigma&#39;^2 = sigma_n^2 + sigma^2,</code></pre>
<p>Distribution parameters from <code>prior</code>, as well as <code>sigma</code>, <code>s</code>, and <code>n</code>. will broadcast in the case of multidimensional sets of parameters.</p>
<h5 id="args-641">Args:</h5>
<ul>
<li><b><code>prior</code></b>: <code>Normal</code> object of type <code>dtype</code>: the prior distribution having parameters <code>(mu0, sigma0)</code>.</li>
<li><b><code>sigma</code></b>: tensor of type <code>dtype</code>, taking values <code>sigma &gt; 0</code>. The known stddev parameter(s).</li>
<li><b><code>s</code></b>: Tensor of type <code>dtype</code>. The sum(s) of observations.</li>
<li><b><code>n</code></b>: Tensor of type <code>int</code>. The number(s) of observations.</li>
</ul>
<h5 id="returns-723">Returns:</h5>
<p>A new Normal predictive distribution object.</p>
<h5 id="raises-230">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if dtype of <code>s</code> does not match <code>dtype</code>, or <code>prior</code> is not a Normal object.</li>
</ul>
<h2 id="kullback-leibler-divergence">Kullback-Leibler Divergence</h2>
<hr />
<h3 id="tf.contrib.distributions.kldist_a-dist_b-allow_nanfalse-namenone"><a name="//apple_ref/cpp/Function/kl" class="dashAnchor"></a><code id="kl">tf.contrib.distributions.kl(dist_a, dist_b, allow_nan=False, name=None)</code></h3>
<p>Get the KL-divergence KL(dist_a || dist_b).</p>
<p>If there is no KL method registered specifically for <code>type(dist_a)</code> and <code>type(dist_b)</code>, then the class hierarchies of these types are searched.</p>
<p>If one KL method is registered between any pairs of classes in these two parent hierarchies, it is used.</p>
<p>If more than one such registered method exists, the method whose registered classes have the shortest sum MRO paths to the input types is used.</p>
<p>If more than one such shortest path exists, the first method identified in the search is used (favoring a shorter MRO distance to <code>type(dist_a)</code>).</p>
<h5 id="args-642">Args:</h5>
<ul>
<li><b><code>dist_a</code></b>: The first distribution.</li>
<li><b><code>dist_b</code></b>: The second distribution.</li>
<li><b><code>allow_nan</code></b>: If <code>False</code> (default), a runtime error is raised if the KL returns NaN values for any batch entry of the given distributions. If <code>True</code>, the KL may return a NaN for the given entry.</li>
<li><b><code>name</code></b>: (optional) Name scope to use for created operations.</li>
</ul>
<h5 id="returns-724">Returns:</h5>
<p>A Tensor with the batchwise KL-divergence between dist_a and dist_b.</p>
<h5 id="raises-231">Raises:</h5>
<ul>
<li><b><code>NotImplementedError</code></b>: If no KL method is defined for distribution types of dist_a and dist_b.</li>
</ul>
<hr />
<h3 id="class-tf.contrib.distributions.registerkl"><a name="//apple_ref/cpp/Class/RegisterKL" class="dashAnchor"></a><code id="RegisterKL">class tf.contrib.distributions.RegisterKL</code></h3>
<p>Decorator to register a KL divergence implementation function.</p>
<p>Usage:</p>
<p><span class="citation">@distributions.RegisterKL</span>(distributions.Normal, distributions.Normal) def _kl_normal_mvn(norm_a, norm_b): # Return KL(norm_a || norm_b) - - -</p>
<h4 id="tf.contrib.distributions.registerkl.__call__kl_fn"><code id="RegisterKL.__call__">tf.contrib.distributions.RegisterKL.__call__(kl_fn)</code></h4>
<p>Perform the KL registration.</p>
<h5 id="args-643">Args:</h5>
<ul>
<li><b><code>kl_fn</code></b>: The function to use for the KL divergence.</li>
</ul>
<h5 id="returns-725">Returns:</h5>
<p>kl_fn</p>
<h5 id="raises-232">Raises:</h5>
<ul>
<li><b><code>TypeError</code></b>: if kl_fn is not a callable.</li>
<li><b><code>ValueError</code></b>: if a KL divergence function has already been registered for the given argument classes.</li>
</ul>
<hr />
<h4 id="tf.contrib.distributions.registerkl.__init__dist_cls_a-dist_cls_b"><code id="RegisterKL.__init__">tf.contrib.distributions.RegisterKL.__init__(dist_cls_a, dist_cls_b)</code></h4>
<p>Initialize the KL registrar.</p>
<h5 id="args-644">Args:</h5>
<ul>
<li><b><code>dist_cls_a</code></b>: the class of the first argument of the KL divergence.</li>
<li><b><code>dist_cls_b</code></b>: the class of the second argument of the KL divergence.</li>
</ul>

<div itemscope="" itemtype="http://developers.google.com/ReferenceObject">
<p><meta itemprop="name" content="tfdbg.DebugDumpDir" /> <meta itemprop="property" content="core_metadata"/> <meta itemprop="property" content="dumped_tensor_data"/> <meta itemprop="property" content="python_graph"/> <meta itemprop="property" content="run_feed_keys_info"/> <meta itemprop="property" content="run_fetches_info"/> <meta itemprop="property" content="size"/> <meta itemprop="property" content="t0"/> <meta itemprop="property" content="__init__"/> <meta itemprop="property" content="debug_watch_keys"/> <meta itemprop="property" content="devices"/> <meta itemprop="property" content="find"/> <meta itemprop="property" content="get_dump_sizes_bytes"/> <meta itemprop="property" content="get_rel_timestamps"/> <meta itemprop="property" content="get_tensor_file_paths"/> <meta itemprop="property" content="get_tensors"/> <meta itemprop="property" content="loaded_partition_graphs"/> <meta itemprop="property" content="node_attributes"/> <meta itemprop="property" content="node_device"/> <meta itemprop="property" content="node_exists"/> <meta itemprop="property" content="node_inputs"/> <meta itemprop="property" content="node_op_type"/> <meta itemprop="property" content="node_recipients"/> <meta itemprop="property" content="node_traceback"/> <meta itemprop="property" content="nodes"/> <meta itemprop="property" content="partition_graphs"/> <meta itemprop="property" content="set_python_graph"/> <meta itemprop="property" content="transitive_inputs"/> <meta itemprop="property" content="watch_key_to_data"/></p>
</div>
<a name="//apple_ref/cpp/Class/tfdbg.DebugDumpDir" class="dashAnchor"></a><h1 id="tfdbg.debugdumpdir">tfdbg.DebugDumpDir</h1>
<h3 id="class-tfdbg.debugdumpdir"><code>class tfdbg.DebugDumpDir</code></h3>
<p>Defined in <a href="https://www.tensorflow.org/code/tensorflow/python/debug/lib/debug_data.py"><code>tensorflow/python/debug/lib/debug_data.py</code></a>.</p>
<p>See the guide: <a href="../../../api_guides/python/tfdbg.md#Classes_for_debug_dump_data_and_directories">TensorFlow Debugger &gt; Classes for debug-dump data and directories</a></p>
<p>Data set from a debug-dump directory on filesystem.</p>
<p>An instance of <code>DebugDumpDir</code> contains all <code>DebugTensorDatum</code> instances in a tfdbg dump root directory.</p>
<h2 id="properties">Properties</h2>
<h3 id="core_metadata">
<code>core_metadata</code>
</h3>
<p>Metadata about the <code>Session.run()</code> call from the core runtime.</p>
<p>Of the three counters available in the return value, <code>global_step</code> is supplied by the caller of the debugged <code>Session.run()</code>, while <code>session_run_count</code> and <code>executor_step_count</code> are determined by the state of the core runtime, automatically. For the same fetch list, feed keys and debug tensor watch options, the same executor will be used and <code>executor_step_count</code> should increase by one at a time. However, runs with different fetch lists, feed keys and debug_tensor watch options that all share the same <code>Session</code> object can lead to gaps in <code>session_run_count</code>.</p>
<h4 id="returns">Returns:</h4>
<p>If core metadata are loaded, a <code>namedtuple</code> with the fields: <code>global_step</code>: A global step count supplied by the caller of <code>Session.run()</code>. It is optional to the caller. If the caller did not supply this parameter, its value will be -1. <code>session_run_count</code>: A counter for Run() calls to the underlying TensorFlow <code>Session</code> object. <code>executor_step_count</code>: A counter for invocations of a given runtime executor. The same executor is re-used for the same fetched tensors, target nodes, input feed keys and debug tensor watch options. <code>input_names</code>: Names of the input (feed) Tensors. <code>output_names</code>: Names of the output (fetched) Tensors. <code>target_nodes</code>: Names of the target nodes. If the core metadata have not been loaded, <code>None</code>.</p>
<h3 id="dumped_tensor_data">
<code>dumped_tensor_data</code>
</h3>
<h3 id="python_graph">
<code>python_graph</code>
</h3>
<p>Get the Python graph.</p>
<h4 id="returns-1">Returns:</h4>
<p>If the Python graph has been set, returns a <code>tf.Graph</code> object. Otherwise, returns None.</p>
<h3 id="run_feed_keys_info">
<code>run_feed_keys_info</code>
</h3>
<p>Get a str representation of the feed_dict used in the Session.run() call.</p>
<h4 id="returns-2">Returns:</h4>
<p>If the information is available, a <code>str</code> obtained from <code>repr(feed_dict)</code>. If the information is not available, <code>None</code>.</p>
<h3 id="run_fetches_info">
<code>run_fetches_info</code>
</h3>
<p>Get a str representation of the fetches used in the Session.run() call.</p>
<h4 id="returns-3">Returns:</h4>
<p>If the information is available, a <code>str</code> obtained from <code>repr(fetches)</code>. If the information is not available, <code>None</code>.</p>
<h3 id="size">
<code>size</code>
</h3>
<p>Total number of dumped tensors in the dump root directory.</p>
<h4 id="returns-4">Returns:</h4>
<p>(<code>int</code>) total number of dumped tensors in the dump root directory.</p>
<h3 id="t0">
<code>t0</code>
</h3>
<p>Absolute timestamp of the first dumped tensor.</p>
<h4 id="returns-5">Returns:</h4>
<p>(<code>int</code>) absolute timestamp of the first dumped tensor, in microseconds.</p>
<h2 id="methods">Methods</h2>
<h3 id="__init__">
<code><strong>init</strong></code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="fu">__init__</span>(
    dump_root,
    partition_graphs<span class="op">=</span><span class="va">None</span>,
    validate<span class="op">=</span><span class="va">True</span>
)</code></pre></div>
<p><code>DebugDumpDir</code> constructor.</p>
<h4 id="args">Args:</h4>
<ul>
<li><b><code>dump_root</code></b>: (<code>str</code>) path to the dump root directory.</li>
<li><b><code>partition_graphs</code></b>: A repeated field of GraphDefs representing the partition graphs executed by the TensorFlow runtime.</li>
<li><b><code>validate</code></b>: (<code>bool</code>) whether the dump files are to be validated against the partition graphs.</li>
</ul>
<h4 id="raises">Raises:</h4>
<ul>
<li><b><code>IOError</code></b>: If dump_root does not exist as a directory.</li>
</ul>
<h3 id="debug_watch_keys">
<code>debug_watch_keys</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">debug_watch_keys(node_name)</code></pre></div>
<p>Get all tensor watch keys of given node according to partition graphs.</p>
<h4 id="args-1">Args:</h4>
<ul>
<li><b><code>node_name</code></b>: (<code>str</code>) name of the node.</li>
</ul>
<h4 id="returns-6">Returns:</h4>
<p>(<code>list</code> of <code>str</code>) all debug tensor watch keys. Returns an empty list if the node name does not correspond to any debug watch keys.</p>
<h4 id="raises-1">Raises:</h4>
<p><code>LookupError</code>: If debug watch information has not been loaded from partition graphs yet.</p>
<h3 id="devices">
<code>devices</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">devices()</code></pre></div>
<p>Get the list of devices.</p>
<h4 id="returns-7">Returns:</h4>
<p>(<code>list</code> of <code>str</code>) names of the devices.</p>
<h4 id="raises-2">Raises:</h4>
<ul>
<li><b><code>LookupError</code></b>: If node inputs and control inputs have not been loaded from partition graphs yet.</li>
</ul>
<h3 id="find">
<code>find</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">find(
    predicate,
    first_n<span class="op">=</span><span class="dv">0</span>
)</code></pre></div>
<p>Find dumped tensor data by a certain predicate.</p>
<h4 id="args-2">Args:</h4>
<ul>
<li><p><b><code>predicate</code></b>: A callable that takes two input arguments:</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="kw">def</span> predicate(debug_tensor_datum, tensor):
  <span class="co"># returns a bool</span></code></pre></div>
where <code>debug_tensor_datum</code> is an instance of <code>DebugTensorDatum</code>, which carries the metadata, such as the <code>Tensor</code>'s node name, output slot timestamp, debug op name, etc.; and <code>tensor</code> is the dumped tensor value as a <code>numpy.ndarray</code>.</li>
<li><p><b><code>first_n</code></b>: (<code>int</code>) return only the first n <code>DebugTensotDatum</code> instances (in time order) for which the predicate returns True. To return all the <code>DebugTensotDatum</code> instances, let first_n be &lt;= 0.</p></li>
</ul>
<h4 id="returns-8">Returns:</h4>
<p>A list of all <code>DebugTensorDatum</code> objects in this <code>DebugDumpDir</code> object for which predicate returns True, sorted in ascending order of the timestamp.</p>
<h3 id="get_dump_sizes_bytes">
<code>get_dump_sizes_bytes</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">get_dump_sizes_bytes(
    node_name,
    output_slot,
    debug_op
)</code></pre></div>
<p>Get the sizes of the dump files for a debug-dumped tensor.</p>
<p>Unit of the file size: byte.</p>
<h4 id="args-3">Args:</h4>
<ul>
<li><b><code>node_name</code></b>: (<code>str</code>) name of the node that the tensor is produced by.</li>
<li><b><code>output_slot</code></b>: (<code>int</code>) output slot index of tensor.</li>
<li><b><code>debug_op</code></b>: (<code>str</code>) name of the debug op.</li>
</ul>
<h4 id="returns-9">Returns:</h4>
<p>(<code>list</code> of <code>int</code>): list of dump file sizes in bytes.</p>
<h4 id="raises-3">Raises:</h4>
<ul>
<li><b><code>ValueError</code></b>: If the tensor watch key does not exist in the debug dump data.</li>
</ul>
<h3 id="get_rel_timestamps">
<code>get_rel_timestamps</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">get_rel_timestamps(
    node_name,
    output_slot,
    debug_op
)</code></pre></div>
<p>Get the relative timestamp from for a debug-dumped tensor.</p>
<p>Relative timestamp means (absolute timestamp - <code>t0</code>), where <code>t0</code> is the absolute timestamp of the first dumped tensor in the dump root. The tensor may be dumped multiple times in the dump root directory, so a list of relative timestamps (<code>numpy.ndarray</code>) is returned.</p>
<h4 id="args-4">Args:</h4>
<ul>
<li><b><code>node_name</code></b>: (<code>str</code>) name of the node that the tensor is produced by.</li>
<li><b><code>output_slot</code></b>: (<code>int</code>) output slot index of tensor.</li>
<li><b><code>debug_op</code></b>: (<code>str</code>) name of the debug op.</li>
</ul>
<h4 id="returns-10">Returns:</h4>
<p>(<code>list</code> of <code>int</code>) list of relative timestamps.</p>
<h4 id="raises-4">Raises:</h4>
<ul>
<li><b><code>ValueError</code></b>: If the tensor watch key does not exist in the debug dump data.</li>
</ul>
<h3 id="get_tensor_file_paths">
<code>get_tensor_file_paths</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">get_tensor_file_paths(
    node_name,
    output_slot,
    debug_op
)</code></pre></div>
<p>Get the file paths from a debug-dumped tensor.</p>
<h4 id="args-5">Args:</h4>
<ul>
<li><b><code>node_name</code></b>: (<code>str</code>) name of the node that the tensor is produced by.</li>
<li><b><code>output_slot</code></b>: (<code>int</code>) output slot index of tensor.</li>
<li><b><code>debug_op</code></b>: (<code>str</code>) name of the debug op.</li>
</ul>
<h4 id="returns-11">Returns:</h4>
<p>List of file path(s) loaded. This is a list because each debugged tensor may be dumped multiple times.</p>
<h4 id="raises-5">Raises:</h4>
<ul>
<li><b><code>ValueError</code></b>: If the tensor does not exist in the debug-dump data.</li>
</ul>
<h3 id="get_tensors">
<code>get_tensors</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">get_tensors(
    node_name,
    output_slot,
    debug_op
)</code></pre></div>
<p>Get the tensor value from for a debug-dumped tensor.</p>
<p>The tensor may be dumped multiple times in the dump root directory, so a list of tensors (<code>numpy.ndarray</code>) is returned.</p>
<h4 id="args-6">Args:</h4>
<ul>
<li><b><code>node_name</code></b>: (<code>str</code>) name of the node that the tensor is produced by.</li>
<li><b><code>output_slot</code></b>: (<code>int</code>) output slot index of tensor.</li>
<li><b><code>debug_op</code></b>: (<code>str</code>) name of the debug op.</li>
</ul>
<h4 id="returns-12">Returns:</h4>
<p>List of tensors (<code>numpy.ndarray</code>) loaded from the debug-dump file(s).</p>
<h4 id="raises-6">Raises:</h4>
<ul>
<li><b><code>ValueError</code></b>: If the tensor does not exist in the debug-dump data.</li>
</ul>
<h3 id="loaded_partition_graphs">
<code>loaded_partition_graphs</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">loaded_partition_graphs()</code></pre></div>
<p>Test whether partition graphs have been loaded.</p>
<h3 id="node_attributes">
<code>node_attributes</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">node_attributes(node_name)</code></pre></div>
<p>Get the attributes of a node.</p>
<h4 id="args-7">Args:</h4>
<ul>
<li><b><code>node_name</code></b>: Name of the node in question.</li>
</ul>
<h4 id="returns-13">Returns:</h4>
<p>Attributes of the node.</p>
<h4 id="raises-7">Raises:</h4>
<ul>
<li><b><code>LookupError</code></b>: If no partition graphs have been loaded.</li>
<li><b><code>ValueError</code></b>: If no node named node_name exists.</li>
</ul>
<h3 id="node_device">
<code>node_device</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">node_device(node_name)</code></pre></div>
<p>Get the device of a node.</p>
<h4 id="args-8">Args:</h4>
<ul>
<li><b><code>node_name</code></b>: (<code>str</code>) name of the node.</li>
</ul>
<h4 id="returns-14">Returns:</h4>
<p>(<code>str</code>) name of the device on which the node is placed.</p>
<h4 id="raises-8">Raises:</h4>
<ul>
<li><b><code>LookupError</code></b>: If node inputs and control inputs have not been loaded from partition graphs yet.</li>
<li><b><code>ValueError</code></b>: If the node does not exist in partition graphs.</li>
</ul>
<h3 id="node_exists">
<code>node_exists</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">node_exists(node_name)</code></pre></div>
<p>Test if a node exists in the partition graphs.</p>
<h4 id="args-9">Args:</h4>
<ul>
<li><b><code>node_name</code></b>: (<code>str</code>) name of the node to be checked.</li>
</ul>
<h4 id="returns-15">Returns:</h4>
<p>A boolean indicating whether the node exists.</p>
<h4 id="raises-9">Raises:</h4>
<ul>
<li><b><code>LookupError</code></b>: If no partition graphs have been loaded yet.</li>
</ul>
<h3 id="node_inputs">
<code>node_inputs</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">node_inputs(
    node_name,
    is_control<span class="op">=</span><span class="va">False</span>
)</code></pre></div>
<p>Get the inputs of given node according to partition graphs.</p>
<h4 id="args-10">Args:</h4>
<ul>
<li><b><code>node_name</code></b>: Name of the node.</li>
<li><b><code>is_control</code></b>: (<code>bool</code>) Whether control inputs, rather than non-control inputs, are to be returned.</li>
</ul>
<h4 id="returns-16">Returns:</h4>
<p>(<code>list</code> of <code>str</code>) inputs to the node, as a list of node names.</p>
<h4 id="raises-10">Raises:</h4>
<ul>
<li><b><code>LookupError</code></b>: If node inputs and control inputs have not been loaded from partition graphs yet.</li>
<li><b><code>ValueError</code></b>: If the node does not exist in partition graphs.</li>
</ul>
<h3 id="node_op_type">
<code>node_op_type</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">node_op_type(node_name)</code></pre></div>
<p>Get the op type of given node.</p>
<h4 id="args-11">Args:</h4>
<ul>
<li><b><code>node_name</code></b>: (<code>str</code>) name of the node.</li>
</ul>
<h4 id="returns-17">Returns:</h4>
<p>(<code>str</code>) op type of the node.</p>
<h4 id="raises-11">Raises:</h4>
<ul>
<li><b><code>LookupError</code></b>: If node op types have not been loaded from partition graphs yet.</li>
<li><b><code>ValueError</code></b>: If the node does not exist in partition graphs.</li>
</ul>
<h3 id="node_recipients">
<code>node_recipients</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">node_recipients(
    node_name,
    is_control<span class="op">=</span><span class="va">False</span>
)</code></pre></div>
<p>Get recipient of the given node's output according to partition graphs.</p>
<h4 id="args-12">Args:</h4>
<ul>
<li><b><code>node_name</code></b>: (<code>str</code>) name of the node.</li>
<li><b><code>is_control</code></b>: (<code>bool</code>) whether control outputs, rather than non-control outputs, are to be returned.</li>
</ul>
<h4 id="returns-18">Returns:</h4>
<p>(<code>list</code> of <code>str</code>) all inputs to the node, as a list of node names.</p>
<h4 id="raises-12">Raises:</h4>
<ul>
<li><b><code>LookupError</code></b>: If node inputs and control inputs have not been loaded from partition graphs yet.</li>
<li><b><code>ValueError</code></b>: If the node does not exist in partition graphs.</li>
</ul>
<h3 id="node_traceback">
<code>node_traceback</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">node_traceback(element_name)</code></pre></div>
<p>Try to retrieve the Python traceback of node's construction.</p>
<h4 id="args-13">Args:</h4>
<ul>
<li><b><code>element_name</code></b>: (<code>str</code>) Name of a graph element (node or tensor).</li>
</ul>
<h4 id="returns-19">Returns:</h4>
<p>(list) The traceback list object as returned by the <code>extract_trace</code> method of Python's traceback module.</p>
<h4 id="raises-13">Raises:</h4>
<ul>
<li><b><code>LookupError</code></b>: If Python graph is not available for traceback lookup.</li>
<li><b><code>KeyError</code></b>: If the node cannot be found in the Python graph loaded.</li>
</ul>
<h3 id="nodes">
<code>nodes</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">nodes()</code></pre></div>
<p>Get a list of all nodes from the partition graphs.</p>
<h4 id="returns-20">Returns:</h4>
<p>All nodes' names, as a list of str.</p>
<h4 id="raises-14">Raises:</h4>
<ul>
<li><b><code>LookupError</code></b>: If no partition graphs have been loaded.</li>
</ul>
<h3 id="partition_graphs">
<code>partition_graphs</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">partition_graphs()</code></pre></div>
<p>Get the partition graphs.</p>
<h4 id="returns-21">Returns:</h4>
<p>Partition graphs as repeated fields of GraphDef.</p>
<h4 id="raises-15">Raises:</h4>
<ul>
<li><b><code>LookupError</code></b>: If no partition graphs have been loaded.</li>
</ul>
<h3 id="set_python_graph">
<code>set_python_graph</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">set_python_graph(python_graph)</code></pre></div>
<p>Provide Python <code>Graph</code> object to the wrapper.</p>
<p>Unlike the partition graphs, which are protobuf <code>GraphDef</code> objects, <code>Graph</code> is a Python object and carries additional information such as the traceback of the construction of the nodes in the graph.</p>
<h4 id="args-14">Args:</h4>
<ul>
<li><b><code>python_graph</code></b>: (ops.Graph) The Python Graph object.</li>
</ul>
<h3 id="transitive_inputs">
<code>transitive_inputs</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">transitive_inputs(
    node_name,
    include_control<span class="op">=</span><span class="va">True</span>
)</code></pre></div>
<p>Get the transitive inputs of given node according to partition graphs.</p>
<h4 id="args-15">Args:</h4>
<ul>
<li><b><code>node_name</code></b>: Name of the node</li>
<li><b><code>include_control</code></b>: Include control inputs (True by default).</li>
</ul>
<h4 id="returns-22">Returns:</h4>
<p>(<code>list</code> of <code>str</code>) all transitive inputs to the node, as a list of node names.</p>
<h4 id="raises-16">Raises:</h4>
<ul>
<li><b><code>LookupError</code></b>: If node inputs and control inputs have not been loaded from partition graphs yet.</li>
<li><b><code>ValueError</code></b>: If the node does not exist in partition graphs.</li>
</ul>
<h3 id="watch_key_to_data">
<code>watch_key_to_data</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">watch_key_to_data(debug_watch_key)</code></pre></div>
<p>Get all <code>DebugTensorDatum</code> instances corresponding to a debug watch key.</p>
<h4 id="args-16">Args:</h4>
<ul>
<li><b><code>debug_watch_key</code></b>: (<code>str</code>) debug watch key.</li>
</ul>
<h4 id="returns-23">Returns:</h4>
<p>A list of <code>DebugTensorDatum</code> instances that correspond to the debug watch key. If the watch key does not exist, returns an empty list.</p>
<h4 id="raises-17">Raises:</h4>
<ul>
<li><b><code>ValueError</code></b>: If the debug watch key does not exist.</li>
</ul>

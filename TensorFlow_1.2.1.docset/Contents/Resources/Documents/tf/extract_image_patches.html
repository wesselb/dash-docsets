<div itemscope="" itemtype="http://developers.google.com/ReferenceObject">
<p><meta itemprop="name" content="tf.extract_image_patches" /></p>
</div>
<a name="//apple_ref/cpp/Function/tf.extract_image_patches" class="dashAnchor"></a><h1 id="tf.extract_image_patches">tf.extract_image_patches</h1>
<h3 id="tf.extract_image_patches-1"><code>tf.extract_image_patches</code></h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">extract_image_patches(
    images,
    ksizes,
    strides,
    rates,
    padding,
    name<span class="op">=</span><span class="va">None</span>
)</code></pre></div>
<p>Defined in <code>tensorflow/python/ops/gen_array_ops.py</code>.</p>
<p>See the guide: <a href="../../../api_guides/python/array_ops.md#Slicing_and_Joining">Tensor Transformations &gt; Slicing and Joining</a></p>
<p>Extract <code>patches</code> from <code>images</code> and put them in the &quot;depth&quot; output dimension.</p>
<h4 id="args">Args:</h4>
<ul>
<li><b><code>images</code></b>: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>, <code>int32</code>, <code>int64</code>, <code>uint8</code>, <code>int16</code>, <code>int8</code>, <code>uint16</code>, <code>half</code>. 4-D Tensor with shape <code>[batch, in_rows, in_cols, depth]</code>.</li>
<li><b><code>ksizes</code></b>: A list of <code>ints</code> that has length <code>&gt;= 4</code>. The size of the sliding window for each dimension of <code>images</code>.</li>
<li><b><code>strides</code></b>: A list of <code>ints</code> that has length <code>&gt;= 4</code>. 1-D of length 4. How far the centers of two consecutive patches are in the images. Must be: <code>[1, stride_rows, stride_cols, 1]</code>.</li>
<li><b><code>rates</code></b>: A list of <code>ints</code> that has length <code>&gt;= 4</code>. 1-D of length 4. Must be: <code>[1, rate_rows, rate_cols, 1]</code>. This is the input stride, specifying how far two consecutive patch samples are in the input. Equivalent to extracting patches with <code>patch_sizes_eff = patch_sizes + (patch_sizes - 1) * (rates - 1)</code>, followed by subsampling them spatially by a factor of <code>rates</code>.</li>
<li><p><b><code>padding</code></b>: A <code>string</code> from: <code>&quot;SAME&quot;, &quot;VALID&quot;</code>. The type of padding algorithm to use.</p>
<p>We specify the size-related attributes as:</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">      ksizes <span class="op">=</span> [<span class="dv">1</span>, ksize_rows, ksize_cols, <span class="dv">1</span>]
      strides <span class="op">=</span> [<span class="dv">1</span>, strides_rows, strides_cols, <span class="dv">1</span>]
      rates <span class="op">=</span> [<span class="dv">1</span>, rates_rows, rates_cols, <span class="dv">1</span>]</code></pre></div></li>
<li><p><b><code>name</code></b>: A name for the operation (optional).</p></li>
</ul>
<h4 id="returns">Returns:</h4>
<p>A <code>Tensor</code>. Has the same type as <code>images</code>. 4-D Tensor with shape <code>[batch, out_rows, out_cols, ksize_rows *   ksize_cols * depth]</code> containing image patches with size <code>ksize_rows x ksize_cols x depth</code> vectorized in the &quot;depth&quot; dimension.</p>

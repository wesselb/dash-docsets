<div itemscope="" itemtype="http://developers.google.com/ReferenceObject">
<p><meta itemprop="name" content="tf.nn.conv2d" /></p>
</div>
<a name="//apple_ref/cpp/Function/tf.nn.conv2d" class="dashAnchor"></a><h1 id="tf.nn.conv2d">tf.nn.conv2d</h1>
<h3 id="tf.nn.conv2d-1"><code>tf.nn.conv2d</code></h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">conv2d(
    <span class="bu">input</span>,
    <span class="bu">filter</span>,
    strides,
    padding,
    use_cudnn_on_gpu<span class="op">=</span><span class="va">None</span>,
    data_format<span class="op">=</span><span class="va">None</span>,
    name<span class="op">=</span><span class="va">None</span>
)</code></pre></div>
<p>Defined in <code>tensorflow/python/ops/gen_nn_ops.py</code>.</p>
<p>See the guide: <a href="../../../../api_guides/python/nn.md#Convolution">Neural Network &gt; Convolution</a></p>
<p>Computes a 2-D convolution given 4-D <code>input</code> and <code>filter</code> tensors.</p>
<p>Given an input tensor of shape <code>[batch, in_height, in_width, in_channels]</code> and a filter / kernel tensor of shape <code>[filter_height, filter_width, in_channels, out_channels]</code>, this op performs the following:</p>
<ol style="list-style-type: decimal">
<li>Flattens the filter to a 2-D matrix with shape <code>[filter_height * filter_width * in_channels, output_channels]</code>.</li>
<li>Extracts image patches from the input tensor to form a <em>virtual</em> tensor of shape <code>[batch, out_height, out_width,    filter_height * filter_width * in_channels]</code>.</li>
<li>For each patch, right-multiplies the filter matrix and the image patch vector.</li>
</ol>
<p>In detail, with the default NHWC format,</p>
<pre><code>output[b, i, j, k] =
    sum_{di, dj, q} input[b, strides[1] * i + di, strides[2] * j + dj, q] *
                    filter[di, dj, q, k]</code></pre>
<p>Must have <code>strides[0] = strides[3] = 1</code>. For the most common case of the same horizontal and vertices strides, <code>strides = [1, stride, stride, 1]</code>.</p>
<h4 id="args">Args:</h4>
<ul>
<li><b><code>input</code></b>: A <code>Tensor</code>. Must be one of the following types: <code>half</code>, <code>float32</code>. A 4-D tensor. The dimension order is interpreted according to the value of <code>data_format</code>, see below for details.</li>
<li><b><code>filter</code></b>: A <code>Tensor</code>. Must have the same type as <code>input</code>. A 4-D tensor of shape <code>[filter_height, filter_width, in_channels, out_channels]</code></li>
<li><b><code>strides</code></b>: A list of <code>ints</code>. 1-D tensor of length 4. The stride of the sliding window for each dimension of <code>input</code>. The dimension order is determined by the value of <code>data_format</code>, see below for details.</li>
<li><b><code>padding</code></b>: A <code>string</code> from: <code>&quot;SAME&quot;, &quot;VALID&quot;</code>. The type of padding algorithm to use.</li>
<li><b><code>use_cudnn_on_gpu</code></b>: An optional <code>bool</code>. Defaults to <code>True</code>.</li>
<li><b><code>data_format</code></b>: An optional <code>string</code> from: <code>&quot;NHWC&quot;, &quot;NCHW&quot;</code>. Defaults to <code>&quot;NHWC&quot;</code>. Specify the data format of the input and output data. With the default format &quot;NHWC&quot;, the data is stored in the order of: [batch, height, width, channels]. Alternatively, the format could be &quot;NCHW&quot;, the data storage order of: [batch, channels, height, width].</li>
<li><b><code>name</code></b>: A name for the operation (optional).</li>
</ul>
<h4 id="returns">Returns:</h4>
<p>A <code>Tensor</code>. Has the same type as <code>input</code>. A 4-D tensor. The dimension order is determined by the value of <code>data_format</code>, see below for details.</p>

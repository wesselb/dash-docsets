<div itemscope="" itemtype="http://developers.google.com/ReferenceObject">
<p><meta itemprop="name" content="tf.nn.log_poisson_loss" /></p>
</div>
<a name="//apple_ref/cpp/Function/tf.nn.log_poisson_loss" class="dashAnchor"></a><h1 id="tf.nn.log_poisson_loss">tf.nn.log_poisson_loss</h1>
<h3 id="tf.nn.log_poisson_loss-1"><code>tf.nn.log_poisson_loss</code></h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">log_poisson_loss(
    targets,
    log_input,
    compute_full_loss<span class="op">=</span><span class="va">False</span>,
    name<span class="op">=</span><span class="va">None</span>
)</code></pre></div>
<p>Defined in <a href="https://www.tensorflow.org/code/tensorflow/python/ops/nn_impl.py"><code>tensorflow/python/ops/nn_impl.py</code></a>.</p>
<p>See the guide: <a href="../../../../api_guides/python/nn.md#Losses">Neural Network &gt; Losses</a></p>
<p>Computes log Poisson loss given <code>log_input</code>.</p>
<p>Gives the log-likelihood loss between the prediction and the target under the assumption that the target has a Poisson distribution. Caveat: By default, this is not the exact loss, but the loss minus a constant term [log(z!)]. That has no effect for optimization, but does not play well with relative loss comparisons. To compute an approximation of the log factorial term, specify compute_full_loss=True to enable Stirling's Approximation.</p>
<p>For brevity, let <code>c = log(x) = log_input</code>, <code>z = targets</code>. The log Poisson loss is</p>
<pre><code>  -log(exp(-x) * (x^z) / z!)
= -log(exp(-x) * (x^z)) + log(z!)
~ -log(exp(-x)) - log(x^z) [+ z * log(z) - z + 0.5 * log(2 * pi * z)]
    [ Note the second term is the Stirling&#39;s Approximation for log(z!).
      It is invariant to x and does not affect optimization, though
      important for correct relative loss comparisons. It is only
      computed when compute_full_loss == True. ]
= x - z * log(x) [+ z * log(z) - z + 0.5 * log(2 * pi * z)]
= exp(c) - z * c [+ z * log(z) - z + 0.5 * log(2 * pi * z)]</code></pre>
<h4 id="args">Args:</h4>
<ul>
<li><b><code>targets</code></b>: A <code>Tensor</code> of the same type and shape as <code>log_input</code>.</li>
<li><b><code>log_input</code></b>: A <code>Tensor</code> of type <code>float32</code> or <code>float64</code>.</li>
<li><b><code>compute_full_loss</code></b>: whether to compute the full loss. If false, a constant term is dropped in favor of more efficient optimization.</li>
<li><b><code>name</code></b>: A name for the operation (optional).</li>
</ul>
<h4 id="returns">Returns:</h4>
<p>A <code>Tensor</code> of the same shape as <code>log_input</code> with the componentwise logistic losses.</p>
<h4 id="raises">Raises:</h4>
<ul>
<li><b><code>ValueError</code></b>: If <code>log_input</code> and <code>targets</code> do not have the same shape.</li>
</ul>

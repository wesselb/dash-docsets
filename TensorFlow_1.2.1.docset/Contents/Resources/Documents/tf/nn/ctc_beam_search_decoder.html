<div itemscope="" itemtype="http://developers.google.com/ReferenceObject">
<p><meta itemprop="name" content="tf.nn.ctc_beam_search_decoder" /></p>
</div>
<a name="//apple_ref/cpp/Function/tf.nn.ctc_beam_search_decoder" class="dashAnchor"></a><h1 id="tf.nn.ctc_beam_search_decoder">tf.nn.ctc_beam_search_decoder</h1>
<h3 id="tf.nn.ctc_beam_search_decoder-1"><code>tf.nn.ctc_beam_search_decoder</code></h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">ctc_beam_search_decoder(
    inputs,
    sequence_length,
    beam_width<span class="op">=</span><span class="dv">100</span>,
    top_paths<span class="op">=</span><span class="dv">1</span>,
    merge_repeated<span class="op">=</span><span class="va">True</span>
)</code></pre></div>
<p>Defined in <a href="https://www.tensorflow.org/code/tensorflow/python/ops/ctc_ops.py"><code>tensorflow/python/ops/ctc_ops.py</code></a>.</p>
<p>See the guide: <a href="../../../../api_guides/python/nn.md#Connectionist_Temporal_Classification_CTC_">Neural Network &gt; Connectionist Temporal Classification (CTC)</a></p>
<p>Performs beam search decoding on the logits given in input.</p>
<p><strong>Note</strong> The <code>ctc_greedy_decoder</code> is a special case of the <code>ctc_beam_search_decoder</code> with <code>top_paths=1</code> and <code>beam_width=1</code> (but that decoder is faster for this special case).</p>
<p>If <code>merge_repeated</code> is <code>True</code>, merge repeated classes in the output beams. This means that if consecutive entries in a beam are the same, only the first of these is emitted. That is, when the top path is <code>A B B B B</code>, the return value is:</p>
<ul>
<li><code>A B</code> if <code>merge_repeated = True</code>.</li>
<li><code>A B B B B</code> if <code>merge_repeated = False</code>.</li>
</ul>
<h4 id="args">Args:</h4>
<ul>
<li><b><code>inputs</code></b>: 3-D <code>float</code> <code>Tensor</code>, size <code>[max_time x batch_size x num_classes]</code>. The logits.</li>
<li><b><code>sequence_length</code></b>: 1-D <code>int32</code> vector containing sequence lengths, having size <code>[batch_size]</code>.</li>
<li><b><code>beam_width</code></b>: An int scalar &gt;= 0 (beam search beam width).</li>
<li><b><code>top_paths</code></b>: An int scalar &gt;= 0, &lt;= beam_width (controls output size).</li>
<li><b><code>merge_repeated</code></b>: Boolean. Default: True.</li>
</ul>
<h4 id="returns">Returns:</h4>
<p>A tuple <code>(decoded, log_probabilities)</code> where * <b><code>decoded</code></b>: A list of length top_paths, where <code>decoded[j]</code> is a <code>SparseTensor</code> containing the decoded outputs: <code>decoded[j].indices</code>: Indices matrix <code>(total_decoded_outputs[j] x 2)</code> The rows store: [batch, time]. <code>decoded[j].values</code>: Values vector, size <code>(total_decoded_outputs[j])</code>. The vector stores the decoded classes for beam j. <code>decoded[j].shape</code>: Shape vector, size <code>(2)</code>. The shape values are: <code>[batch_size, max_decoded_length[j]]</code>. * <b><code>log_probability</code></b>: A <code>float</code> matrix <code>(batch_size x top_paths)</code> containing sequence log-probabilities.</p>

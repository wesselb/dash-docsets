<div itemscope="" itemtype="http://developers.google.com/ReferenceObject">
<p><meta itemprop="name" content="tf.nn.with_space_to_batch" /></p>
</div>
<a name="//apple_ref/cpp/Function/tf.nn.with_space_to_batch" class="dashAnchor"></a><h1 id="tf.nn.with_space_to_batch">tf.nn.with_space_to_batch</h1>
<h3 id="tf.nn.with_space_to_batch-1"><code>tf.nn.with_space_to_batch</code></h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">with_space_to_batch(
    <span class="bu">input</span>,
    dilation_rate,
    padding,
    op,
    filter_shape<span class="op">=</span><span class="va">None</span>,
    spatial_dims<span class="op">=</span><span class="va">None</span>,
    data_format<span class="op">=</span><span class="va">None</span>
)</code></pre></div>
<p>Defined in <a href="https://www.tensorflow.org/code/tensorflow/python/ops/nn_ops.py"><code>tensorflow/python/ops/nn_ops.py</code></a>.</p>
<p>See the guide: <a href="../../../../api_guides/python/nn.md#Morphological_filtering">Neural Network &gt; Morphological filtering</a></p>
<p>Performs <code>op</code> on the space-to-batch representation of <code>input</code>.</p>
<p>This has the effect of transforming sliding window operations into the corresponding &quot;atrous&quot; operation in which the input is sampled at the specified <code>dilation_rate</code>.</p>
<p>In the special case that <code>dilation_rate</code> is uniformly 1, this simply returns:</p>
<p>op(input, num_spatial_dims, padding)</p>
<p>Otherwise, it returns:</p>
<p>batch_to_space_nd( op(space_to_batch_nd(input, adjusted_dilation_rate, adjusted_paddings), num_spatial_dims, &quot;VALID&quot;) adjusted_dilation_rate, adjusted_crops),</p>
<p>where:</p>
<p>adjusted_dilation_rate is an int64 tensor of shape [max(spatial_dims)], adjusted_{paddings,crops} are int64 tensors of shape [max(spatial_dims), 2]</p>
<p>defined as follows:</p>
<p>We first define two int64 tensors <code>paddings</code> and <code>crops</code> of shape <code>[num_spatial_dims, 2]</code> based on the value of <code>padding</code> and the spatial dimensions of the <code>input</code>:</p>
<p>If <code>padding = &quot;VALID&quot;</code>, then:</p>
<p>paddings, crops = required_space_to_batch_paddings( input_shape[spatial_dims], dilation_rate)</p>
<p>If <code>padding = &quot;SAME&quot;</code>, then:</p>
<p>dilated_filter_shape = filter_shape + (filter_shape - 1) * (dilation_rate - 1)</p>
<p>paddings, crops = required_space_to_batch_paddings( input_shape[spatial_dims], dilation_rate, [(dilated_filter_shape - 1) // 2, dilated_filter_shape - 1 - (dilated_filter_shape - 1) // 2])</p>
<p>Because <code>space_to_batch_nd</code> and <code>batch_to_space_nd</code> assume that the spatial dimensions are contiguous starting at the second dimension, but the specified <code>spatial_dims</code> may not be, we must adjust <code>dilation_rate</code>, <code>paddings</code> and <code>crops</code> in order to be usable with these operations. For a given dimension, if the block size is 1, and both the starting and ending padding and crop amounts are 0, then space_to_batch_nd effectively leaves that dimension alone, which is what is needed for dimensions not part of <code>spatial_dims</code>. Furthermore, <code>space_to_batch_nd</code> and <code>batch_to_space_nd</code> handle this case efficiently for any number of leading and trailing dimensions.</p>
<p>For 0 &lt;= i &lt; len(spatial_dims), we assign:</p>
<p>adjusted_dilation_rate[spatial_dims[i] - 1] = dilation_rate[i] adjusted_paddings[spatial_dims[i] - 1, :] = paddings[i, :] adjusted_crops[spatial_dims[i] - 1, :] = crops[i, :]</p>
<p>All unassigned values of <code>adjusted_dilation_rate</code> default to 1, while all unassigned values of <code>adjusted_paddings</code> and <code>adjusted_crops</code> default to 0.</p>
<p>Note in the case that <code>dilation_rate</code> is not uniformly 1, specifying &quot;VALID&quot; padding is equivalent to specifying <code>padding = &quot;SAME&quot;</code> with a filter_shape of <code>[1]*N</code>.</p>
<p>Advanced usage. Note the following optimization: A sequence of <code>with_space_to_batch</code> operations with identical (not uniformly 1) <code>dilation_rate</code> parameters and &quot;VALID&quot; padding</p>
<p>net = with_space_to_batch(net, dilation_rate, &quot;VALID&quot;, op_1) ... net = with_space_to_batch(net, dilation_rate, &quot;VALID&quot;, op_k)</p>
<p>can be combined into a single <code>with_space_to_batch</code> operation as follows:</p>
<p>def combined_op(converted_input, num_spatial_dims, _): result = op_1(converted_input, num_spatial_dims, &quot;VALID&quot;) ... result = op_k(result, num_spatial_dims, &quot;VALID&quot;)</p>
<p>net = with_space_to_batch(net, dilation_rate, &quot;VALID&quot;, combined_op)</p>
<p>This eliminates the overhead of <code>k-1</code> calls to <code>space_to_batch_nd</code> and <code>batch_to_space_nd</code>.</p>
<p>Similarly, a sequence of <code>with_space_to_batch</code> operations with identical (not uniformly 1) <code>dilation_rate</code> parameters, &quot;SAME&quot; padding, and odd filter dimensions</p>
<p>net = with_space_to_batch(net, dilation_rate, &quot;SAME&quot;, op_1, filter_shape_1) ... net = with_space_to_batch(net, dilation_rate, &quot;SAME&quot;, op_k, filter_shape_k)</p>
<p>can be combined into a single <code>with_space_to_batch</code> operation as follows:</p>
<p>def combined_op(converted_input, num_spatial_dims, _): result = op_1(converted_input, num_spatial_dims, &quot;SAME&quot;) ... result = op_k(result, num_spatial_dims, &quot;SAME&quot;)</p>
<p>net = with_space_to_batch(net, dilation_rate, &quot;VALID&quot;, combined_op)</p>
<h4 id="args">Args:</h4>
<ul>
<li><b><code>input</code></b>: Tensor of rank &gt; max(spatial_dims).</li>
<li><b><code>dilation_rate</code></b>: int32 Tensor of <em>known</em> shape [num_spatial_dims].</li>
<li><b><code>padding</code></b>: str constant equal to &quot;VALID&quot; or &quot;SAME&quot;</li>
<li><b><code>op</code></b>: Function that maps (input, num_spatial_dims, padding) -&gt; output</li>
<li><b><code>filter_shape</code></b>: If padding = &quot;SAME&quot;, specifies the shape of the convolution kernel/pooling window as an integer Tensor of shape [&gt;=num_spatial_dims]. If padding = &quot;VALID&quot;, filter_shape is ignored and need not be specified.</li>
<li><b><code>spatial_dims</code></b>: Monotonically increasing sequence of <code>num_spatial_dims</code> integers (which are &gt;= 1) specifying the spatial dimensions of <code>input</code> and output. Defaults to: <code>range(1, num_spatial_dims+1)</code>.</li>
<li><b><code>data_format</code></b>: A string or None. Specifies whether the channel dimension of the <code>input</code> and output is the last dimension (default, or if <code>data_format</code> does not start with &quot;NC&quot;), or the second dimension (if <code>data_format</code> starts with &quot;NC&quot;). For N=1, the valid values are &quot;NWC&quot; (default) and &quot;NCW&quot;. For N=2, the valid values are &quot;NHWC&quot; (default) and &quot;NCHW&quot;. For N=3, the valid values are &quot;NDHWC&quot; (default) and &quot;NCDHW&quot;.</li>
</ul>
<h4 id="returns">Returns:</h4>
<p>The output Tensor as described above, dimensions will vary based on the op provided.</p>
<h4 id="raises">Raises:</h4>
<ul>
<li><b><code>ValueError</code></b>: if <code>padding</code> is invalid or the arguments are incompatible.</li>
<li><b><code>ValueError</code></b>: if <code>spatial_dims</code> are invalid.</li>
</ul>

<div itemscope="" itemtype="http://developers.google.com/ReferenceObject">
<p><meta itemprop="name" content="tf.nn" /></p>
</div>
<a name="//apple_ref/cpp/Function/tf.nn" class="dashAnchor"></a><h1 id="module-tf.nn">Module: tf.nn</h1>
<h3 id="module-tf.nn-1">Module <code>tf.nn</code></h3>
<p>Defined in <a href="https://www.tensorflow.org/code/tensorflow/python/ops/nn.py"><code>tensorflow/python/ops/nn.py</code></a>.</p>
<p>Neural network support.</p>
<p>See the <a href="../../../api_guides/python/nn.html">Neural Network</a> guide.</p>
<h2 id="modules">Modules</h2>
<p><a href="../tf/nn/rnn_cell.html"><code>rnn_cell</code></a> module: Module for constructing RNN Cells.</p>
<h2 id="functions">Functions</h2>
<p><a href="../tf/nn/all_candidate_sampler.html"><code>all_candidate_sampler(...)</code></a>: Generate the set of all classes.</p>
<p><a href="../tf/nn/atrous_conv2d.html"><code>atrous_conv2d(...)</code></a>: Atrous convolution (a.k.a. convolution with holes or dilated convolution).</p>
<p><a href="../tf/nn/atrous_conv2d_transpose.html"><code>atrous_conv2d_transpose(...)</code></a>: The transpose of <code>atrous_conv2d</code>.</p>
<p><a href="../tf/nn/avg_pool.html"><code>avg_pool(...)</code></a>: Performs the average pooling on the input.</p>
<p><a href="../tf/nn/avg_pool3d.html"><code>avg_pool3d(...)</code></a>: Performs 3D average pooling on the input.</p>
<p><a href="../tf/nn/batch_norm_with_global_normalization.html"><code>batch_norm_with_global_normalization(...)</code></a>: Batch normalization.</p>
<p><a href="../tf/nn/batch_normalization.html"><code>batch_normalization(...)</code></a>: Batch normalization.</p>
<p><a href="../tf/nn/bias_add.html"><code>bias_add(...)</code></a>: Adds <code>bias</code> to <code>value</code>.</p>
<p><a href="../tf/nn/bidirectional_dynamic_rnn.html"><code>bidirectional_dynamic_rnn(...)</code></a>: Creates a dynamic version of bidirectional recurrent neural network.</p>
<p><a href="../tf/nn/compute_accidental_hits.html"><code>compute_accidental_hits(...)</code></a>: Compute the position ids in <code>sampled_candidates</code> matching <code>true_classes</code>.</p>
<p><a href="../tf/nn/conv1d.html"><code>conv1d(...)</code></a>: Computes a 1-D convolution given 3-D input and filter tensors.</p>
<p><a href="../tf/nn/conv2d.html"><code>conv2d(...)</code></a>: Computes a 2-D convolution given 4-D <code>input</code> and <code>filter</code> tensors.</p>
<p><a href="../tf/nn/conv2d_backprop_filter.html"><code>conv2d_backprop_filter(...)</code></a>: Computes the gradients of convolution with respect to the filter.</p>
<p><a href="../tf/nn/conv2d_backprop_input.html"><code>conv2d_backprop_input(...)</code></a>: Computes the gradients of convolution with respect to the input.</p>
<p><a href="../tf/nn/conv2d_transpose.html"><code>conv2d_transpose(...)</code></a>: The transpose of <code>conv2d</code>.</p>
<p><a href="../tf/nn/conv3d.html"><code>conv3d(...)</code></a>: Computes a 3-D convolution given 5-D <code>input</code> and <code>filter</code> tensors.</p>
<p><a href="../tf/nn/conv3d_backprop_filter_v2.html"><code>conv3d_backprop_filter_v2(...)</code></a>: Computes the gradients of 3-D convolution with respect to the filter.</p>
<p><a href="../tf/nn/conv3d_transpose.html"><code>conv3d_transpose(...)</code></a>: The transpose of <code>conv3d</code>.</p>
<p><a href="../tf/nn/convolution.html"><code>convolution(...)</code></a>: Computes sums of N-D convolutions (actually cross-correlation).</p>
<p><a href="../tf/nn/crelu.html"><code>crelu(...)</code></a>: Computes Concatenated ReLU.</p>
<p><a href="../tf/nn/ctc_beam_search_decoder.html"><code>ctc_beam_search_decoder(...)</code></a>: Performs beam search decoding on the logits given in input.</p>
<p><a href="../tf/nn/ctc_greedy_decoder.html"><code>ctc_greedy_decoder(...)</code></a>: Performs greedy decoding on the logits given in input (best path).</p>
<p><a href="../tf/nn/ctc_loss.html"><code>ctc_loss(...)</code></a>: Computes the CTC (Connectionist Temporal Classification) Loss.</p>
<p><a href="../tf/nn/depthwise_conv2d.html"><code>depthwise_conv2d(...)</code></a>: Depthwise 2-D convolution.</p>
<p><a href="../tf/nn/depthwise_conv2d_native.html"><code>depthwise_conv2d_native(...)</code></a>: Computes a 2-D depthwise convolution given 4-D <code>input</code> and <code>filter</code> tensors.</p>
<p><a href="../tf/nn/depthwise_conv2d_native_backprop_filter.html"><code>depthwise_conv2d_native_backprop_filter(...)</code></a>: Computes the gradients of depthwise convolution with respect to the filter.</p>
<p><a href="../tf/nn/depthwise_conv2d_native_backprop_input.html"><code>depthwise_conv2d_native_backprop_input(...)</code></a>: Computes the gradients of depthwise convolution with respect to the input.</p>
<p><a href="../tf/nn/dilation2d.html"><code>dilation2d(...)</code></a>: Computes the grayscale dilation of 4-D <code>input</code> and 3-D <code>filter</code> tensors.</p>
<p><a href="../tf/nn/dropout.html"><code>dropout(...)</code></a>: Computes dropout.</p>
<p><a href="../tf/nn/dynamic_rnn.html"><code>dynamic_rnn(...)</code></a>: Creates a recurrent neural network specified by RNNCell <code>cell</code>.</p>
<p><a href="../tf/nn/elu.html"><code>elu(...)</code></a>: Computes exponential linear: <code>exp(features) - 1</code> if &lt; 0, <code>features</code> otherwise.</p>
<p><a href="../tf/nn/embedding_lookup.html"><code>embedding_lookup(...)</code></a>: Looks up <code>ids</code> in a list of embedding tensors.</p>
<p><a href="../tf/nn/embedding_lookup_sparse.html"><code>embedding_lookup_sparse(...)</code></a>: Computes embeddings for the given ids and weights.</p>
<p><a href="../tf/nn/erosion2d.html"><code>erosion2d(...)</code></a>: Computes the grayscale erosion of 4-D <code>value</code> and 3-D <code>kernel</code> tensors.</p>
<p><a href="../tf/nn/fixed_unigram_candidate_sampler.html"><code>fixed_unigram_candidate_sampler(...)</code></a>: Samples a set of classes using the provided (fixed) base distribution.</p>
<p><a href="../tf/nn/fractional_avg_pool.html"><code>fractional_avg_pool(...)</code></a>: Performs fractional average pooling on the input.</p>
<p><a href="../tf/nn/fractional_max_pool.html"><code>fractional_max_pool(...)</code></a>: Performs fractional max pooling on the input.</p>
<p><a href="../tf/nn/fused_batch_norm.html"><code>fused_batch_norm(...)</code></a>: Batch normalization.</p>
<p><a href="../tf/nn/in_top_k.html"><code>in_top_k(...)</code></a>: Says whether the targets are in the top <code>K</code> predictions.</p>
<p><a href="../tf/nn/l2_loss.html"><code>l2_loss(...)</code></a>: L2 Loss.</p>
<p><a href="../tf/nn/l2_normalize.html"><code>l2_normalize(...)</code></a>: Normalizes along dimension <code>dim</code> using an L2 norm.</p>
<p><a href="../tf/nn/learned_unigram_candidate_sampler.html"><code>learned_unigram_candidate_sampler(...)</code></a>: Samples a set of classes from a distribution learned during training.</p>
<p><a href="../tf/nn/local_response_normalization.html"><code>local_response_normalization(...)</code></a>: Local Response Normalization.</p>
<p><a href="../tf/nn/log_poisson_loss.html"><code>log_poisson_loss(...)</code></a>: Computes log Poisson loss given <code>log_input</code>.</p>
<p><a href="../tf/nn/log_softmax.html"><code>log_softmax(...)</code></a>: Computes log softmax activations.</p>
<p><a href="../tf/nn/log_uniform_candidate_sampler.html"><code>log_uniform_candidate_sampler(...)</code></a>: Samples a set of classes using a log-uniform (Zipfian) base distribution.</p>
<p><a href="../tf/nn/local_response_normalization.html"><code>lrn(...)</code></a>: Local Response Normalization.</p>
<p><a href="../tf/nn/max_pool.html"><code>max_pool(...)</code></a>: Performs the max pooling on the input.</p>
<p><a href="../tf/nn/max_pool3d.html"><code>max_pool3d(...)</code></a>: Performs 3D max pooling on the input.</p>
<p><a href="../tf/nn/max_pool_with_argmax.html"><code>max_pool_with_argmax(...)</code></a>: Performs max pooling on the input and outputs both max values and indices.</p>
<p><a href="../tf/nn/moments.html"><code>moments(...)</code></a>: Calculate the mean and variance of <code>x</code>.</p>
<p><a href="../tf/nn/nce_loss.html"><code>nce_loss(...)</code></a>: Computes and returns the noise-contrastive estimation training loss.</p>
<p><a href="../tf/nn/normalize_moments.html"><code>normalize_moments(...)</code></a>: Calculate the mean and variance of based on the sufficient statistics.</p>
<p><a href="../tf/nn/pool.html"><code>pool(...)</code></a>: Performs an N-D pooling operation.</p>
<p><a href="../tf/nn/quantized_avg_pool.html"><code>quantized_avg_pool(...)</code></a>: Produces the average pool of the input tensor for quantized types.</p>
<p><a href="../tf/nn/quantized_conv2d.html"><code>quantized_conv2d(...)</code></a>: Computes a 2D convolution given quantized 4D input and filter tensors.</p>
<p><a href="../tf/nn/quantized_max_pool.html"><code>quantized_max_pool(...)</code></a>: Produces the max pool of the input tensor for quantized types.</p>
<p><a href="../tf/nn/quantized_relu_x.html"><code>quantized_relu_x(...)</code></a>: Computes Quantized Rectified Linear X: <code>min(max(features, 0), max_value)</code></p>
<p><a href="../tf/nn/raw_rnn.html"><code>raw_rnn(...)</code></a>: Creates an <code>RNN</code> specified by RNNCell <code>cell</code> and loop function <code>loop_fn</code>.</p>
<p><a href="../tf/nn/relu.html"><code>relu(...)</code></a>: Computes rectified linear: <code>max(features, 0)</code>.</p>
<p><a href="../tf/nn/relu6.html"><code>relu6(...)</code></a>: Computes Rectified Linear 6: <code>min(max(features, 0), 6)</code>.</p>
<p><a href="../tf/nn/relu_layer.html"><code>relu_layer(...)</code></a>: Computes Relu(x * weight + biases).</p>
<p><a href="../tf/nn/sampled_softmax_loss.html"><code>sampled_softmax_loss(...)</code></a>: Computes and returns the sampled softmax training loss.</p>
<p><a href="../tf/nn/separable_conv2d.html"><code>separable_conv2d(...)</code></a>: 2-D convolution with separable filters.</p>
<p><a href="../tf/sigmoid.html"><code>sigmoid(...)</code></a>: Computes sigmoid of <code>x</code> element-wise.</p>
<p><a href="../tf/nn/sigmoid_cross_entropy_with_logits.html"><code>sigmoid_cross_entropy_with_logits(...)</code></a>: Computes sigmoid cross entropy given <code>logits</code>.</p>
<p><a href="../tf/nn/softmax.html"><code>softmax(...)</code></a>: Computes softmax activations.</p>
<p><a href="../tf/nn/softmax_cross_entropy_with_logits.html"><code>softmax_cross_entropy_with_logits(...)</code></a>: Computes softmax cross entropy between <code>logits</code> and <code>labels</code>.</p>
<p><a href="../tf/nn/softplus.html"><code>softplus(...)</code></a>: Computes softplus: <code>log(exp(features) + 1)</code>.</p>
<p><a href="../tf/nn/softsign.html"><code>softsign(...)</code></a>: Computes softsign: <code>features / (abs(features) + 1)</code>.</p>
<p><a href="../tf/nn/sparse_softmax_cross_entropy_with_logits.html"><code>sparse_softmax_cross_entropy_with_logits(...)</code></a>: Computes sparse softmax cross entropy between <code>logits</code> and <code>labels</code>.</p>
<p><a href="../tf/nn/static_bidirectional_rnn.html"><code>static_bidirectional_rnn(...)</code></a>: Creates a bidirectional recurrent neural network.</p>
<p><a href="../tf/nn/static_rnn.html"><code>static_rnn(...)</code></a>: Creates a recurrent neural network specified by RNNCell <code>cell</code>.</p>
<p><a href="../tf/nn/static_state_saving_rnn.html"><code>static_state_saving_rnn(...)</code></a>: RNN that accepts a state saver for time-truncated RNN calculation.</p>
<p><a href="../tf/nn/sufficient_statistics.html"><code>sufficient_statistics(...)</code></a>: Calculate the sufficient statistics for the mean and variance of <code>x</code>.</p>
<p><a href="../tf/tanh.html"><code>tanh(...)</code></a>: Computes hyperbolic tangent of <code>x</code> element-wise.</p>
<p><a href="../tf/nn/top_k.html"><code>top_k(...)</code></a>: Finds values and indices of the <code>k</code> largest entries for the last dimension.</p>
<p><a href="../tf/nn/uniform_candidate_sampler.html"><code>uniform_candidate_sampler(...)</code></a>: Samples a set of classes using a uniform base distribution.</p>
<p><a href="../tf/nn/weighted_cross_entropy_with_logits.html"><code>weighted_cross_entropy_with_logits(...)</code></a>: Computes a weighted cross entropy.</p>
<p><a href="../tf/nn/weighted_moments.html"><code>weighted_moments(...)</code></a>: Returns the frequency-weighted mean and variance of <code>x</code>.</p>
<p><a href="../tf/nn/with_space_to_batch.html"><code>with_space_to_batch(...)</code></a>: Performs <code>op</code> on the space-to-batch representation of <code>input</code>.</p>
<p><a href="../tf/nn/xw_plus_b.html"><code>xw_plus_b(...)</code></a>: Computes matmul(x, weights) + biases.</p>
<p><a href="../tf/nn/zero_fraction.html"><code>zero_fraction(...)</code></a>: Returns the fraction of zeros in <code>value</code>.</p>

<div itemscope="" itemtype="http://developers.google.com/ReferenceObject">
<p><meta itemprop="name" content="tf.contrib.learn.Experiment" /> <meta itemprop="property" content="estimator"/> <meta itemprop="property" content="eval_metrics"/> <meta itemprop="property" content="eval_steps"/> <meta itemprop="property" content="train_steps"/> <meta itemprop="property" content="__init__"/> <meta itemprop="property" content="continuous_eval"/> <meta itemprop="property" content="continuous_eval_on_train_data"/> <meta itemprop="property" content="continuous_train_and_eval"/> <meta itemprop="property" content="evaluate"/> <meta itemprop="property" content="extend_train_hooks"/> <meta itemprop="property" content="local_run"/> <meta itemprop="property" content="reset_export_strategies"/> <meta itemprop="property" content="run_std_server"/> <meta itemprop="property" content="test"/> <meta itemprop="property" content="train"/> <meta itemprop="property" content="train_and_evaluate"/></p>
</div>
<a name="//apple_ref/cpp/Class/tf.contrib.learn.Experiment" class="dashAnchor"></a><h1 id="tf.contrib.learn.experiment">tf.contrib.learn.Experiment</h1>
<h3 id="class-tf.contrib.learn.experiment"><code>class tf.contrib.learn.Experiment</code></h3>
<p>Defined in <a href="https://www.tensorflow.org/code/tensorflow/contrib/learn/python/learn/experiment.py"><code>tensorflow/contrib/learn/python/learn/experiment.py</code></a>.</p>
<p>See the guide: <a href="../../../../../api_guides/python/contrib.learn.md#Distributed_training_utilities">Learn (contrib) &gt; Distributed training utilities</a></p>
<p>Experiment is a class containing all information needed to train a model.</p>
<p>After an experiment is created (by passing an Estimator and inputs for training and evaluation), an Experiment instance knows how to invoke training and eval loops in a sensible fashion for distributed training.</p>
<h2 id="properties">Properties</h2>
<h3 id="estimator">
<code>estimator</code>
</h3>
<h3 id="eval_metrics">
<code>eval_metrics</code>
</h3>
<h3 id="eval_steps">
<code>eval_steps</code>
</h3>
<h3 id="train_steps">
<code>train_steps</code>
</h3>
<h2 id="methods">Methods</h2>
<h3 id="__init__">
<code><strong>init</strong></code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="fu">__init__</span>(
    estimator,
    train_input_fn,
    eval_input_fn,
    eval_metrics<span class="op">=</span><span class="va">None</span>,
    train_steps<span class="op">=</span><span class="va">None</span>,
    eval_steps<span class="op">=</span><span class="dv">100</span>,
    train_monitors<span class="op">=</span><span class="va">None</span>,
    eval_hooks<span class="op">=</span><span class="va">None</span>,
    local_eval_frequency<span class="op">=</span><span class="va">None</span>,
    eval_delay_secs<span class="op">=</span><span class="dv">120</span>,
    continuous_eval_throttle_secs<span class="op">=</span><span class="dv">60</span>,
    min_eval_frequency<span class="op">=</span><span class="va">None</span>,
    delay_workers_by_global_step<span class="op">=</span><span class="va">False</span>,
    export_strategies<span class="op">=</span><span class="va">None</span>,
    train_steps_per_iteration<span class="op">=</span><span class="va">None</span>
)</code></pre></div>
<p>Constructor for <code>Experiment</code>. (deprecated arguments)</p>
<p>SOME ARGUMENTS ARE DEPRECATED. They will be removed after 2016-10-23. Instructions for updating: local_eval_frequency is deprecated as local_run will be renamed to train_and_evaluate. Use min_eval_frequency and call train_and_evaluate instead. Note, however, that the default for min_eval_frequency is 1, meaning models will be evaluated every time a new checkpoint is available. In contrast, the default for local_eval_frequency is None, resulting in evaluation occurring only after training has completed. min_eval_frequency is ignored when calling the deprecated local_run.</p>
<p>Creates an Experiment instance. None of the functions passed to this constructor are executed at construction time. They are stored and used when a method is executed which requires it.</p>
<h4 id="args">Args:</h4>
<ul>
<li><b><code>estimator</code></b>: Object implementing Estimator interface, which could be a combination of ${tf.contrib.learn.Trainable} and ${tf.contrib.learn.Evaluable} (deprecated), or ${tf.estimator.`Estimator}.</li>
<li><b><code>train_input_fn</code></b>: function, returns features and labels for training.</li>
<li><b><code>eval_input_fn</code></b>: function, returns features and labels for evaluation. If <code>eval_steps</code> is <code>None</code>, this should be configured only to produce for a finite number of batches (generally, 1 epoch over the evaluation data).</li>
<li><b><code>eval_metrics</code></b>: <code>dict</code> of string, metric function. If <code>None</code>, default set is used. This should be <code>None</code> if the <code>estimator</code> is ${tf.estimator.Estimator}. If metrics are provided they will be <em>appended</em> to the default set.</li>
<li><b><code>train_steps</code></b>: Perform this many steps of training. <code>None</code>, the default, means train forever.</li>
<li><b><code>eval_steps</code></b>: <code>evaluate</code> runs until input is exhausted (or another exception is raised), or for <code>eval_steps</code> steps, if specified.</li>
<li><b><code>train_monitors</code></b>: A list of monitors to pass to the <code>Estimator</code>'s <code>fit</code> function.</li>
<li><b><code>eval_hooks</code></b>: A list of <code>SessionRunHook</code> hooks to pass to the <code>Estimator</code>'s <code>evaluate</code> function.</li>
<li><b><code>local_eval_frequency</code></b>: (applies only to local_run) Frequency of running eval in steps. If <code>None</code>, runs evaluation only at the end of training.</li>
<li><b><code>eval_delay_secs</code></b>: Start evaluating after waiting for this many seconds.</li>
<li><b><code>continuous_eval_throttle_secs</code></b>: Do not re-evaluate unless the last evaluation was started at least this many seconds ago for continuous_eval().</li>
<li><b><code>min_eval_frequency</code></b>: (applies only to train_and_evaluate). the minimum number of steps between evaluations. Of course, evaluation does not occur if no new snapshot is available, hence, this is the minimum. If 0, the evaluation will only happen after training. If None, defaults to 1, unless model_dir is on GCS, in which case the default is 1000.</li>
<li><b><code>delay_workers_by_global_step</code></b>: if <code>True</code> delays training workers based on global step instead of time.</li>
<li><b><code>export_strategies</code></b>: Iterable of <code>ExportStrategy</code>s, or a single one, or <code>None</code>.</li>
<li><b><code>train_steps_per_iteration</code></b>: (applies only to continuous_train_and_eval). Perform this many (integer) number of train steps for each training-evaluation iteration. With a small value, the model will be evaluated more frequently with more checkpoints saved. If <code>None</code>, will use a default value (which is smaller than <code>train_steps</code> if provided).</li>
</ul>
<h4 id="raises">Raises:</h4>
<ul>
<li><b><code>ValueError</code></b>: if <code>estimator</code> does not implement Estimator interface, or if export_strategies has the wrong type.</li>
</ul>
<h3 id="continuous_eval">
<code>continuous_eval</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">continuous_eval(
    delay_secs<span class="op">=</span><span class="va">None</span>,
    throttle_delay_secs<span class="op">=</span><span class="va">None</span>,
    evaluate_checkpoint_only_once<span class="op">=</span><span class="va">True</span>,
    continuous_eval_predicate_fn<span class="op">=</span><span class="va">None</span>
)</code></pre></div>
<h3 id="continuous_eval_on_train_data">
<code>continuous_eval_on_train_data</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">continuous_eval_on_train_data(
    delay_secs<span class="op">=</span><span class="va">None</span>,
    throttle_delay_secs<span class="op">=</span><span class="va">None</span>,
    continuous_eval_predicate_fn<span class="op">=</span><span class="va">None</span>
)</code></pre></div>
<h3 id="continuous_train_and_eval">
<code>continuous_train_and_eval</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">continuous_train_and_eval(
    <span class="op">*</span>args,
    <span class="op">**</span>kwargs
)</code></pre></div>
<p>Interleaves training and evaluation. (experimental)</p>
<p>THIS FUNCTION IS EXPERIMENTAL. It may change or be removed at any time, and without warning.</p>
<p>The frequency of evaluation is controlled by the <code>train_steps_per_iteration</code> (via constructor). The model will be first trained for <code>train_steps_per_iteration</code>, and then be evaluated in turns.</p>
<p>This method is intended for single machine usage.</p>
<p>This differs from <code>train_and_evaluate</code> as follows: 1. The procedure will have train and evaluation in turns. The model will be trained for a number of steps (usuallly smaller than <code>train_steps</code> if provided) and then be evaluated. <code>train_and_evaluate</code> will train the model for <code>train_steps</code> (no small training iteraions).</p>
<ol start="2" style="list-style-type: decimal">
<li>Due to the different approach this schedule takes, it leads to two differences in resource control. First, the resources (e.g., memory) used by training will be released before evaluation (<code>train_and_evaluate</code> takes double resources). Second, more checkpoints will be saved as a checkpoint is generated at the end of each small trainning iteration.</li>
</ol>
<h4 id="args-1">Args:</h4>
<ul>
<li><b><code>continuous_eval_predicate_fn</code></b>: A predicate function determining whether to continue after each iteration. <code>predicate_fn</code> takes the evaluation results as its arguments. At the beginning of evaluation, the passed eval results will be None so it's expected that the predicate function handles that gracefully. When <code>predicate_fn</code> is not specified, this will run in an infinite loop or exit when global_step reaches <code>train_steps</code>.</li>
</ul>
<h4 id="returns">Returns:</h4>
<p>A tuple of the result of the <code>evaluate</code> call to the <code>Estimator</code> and the export results using the specified <code>ExportStrategy</code>.</p>
<h4 id="raises-1">Raises:</h4>
<ul>
<li><b><code>ValueError</code></b>: if <code>continuous_eval_predicate_fn</code> is neither None nor callable.</li>
</ul>
<h3 id="evaluate">
<code>evaluate</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">evaluate(delay_secs<span class="op">=</span><span class="va">None</span>)</code></pre></div>
<p>Evaluate on the evaluation data.</p>
<p>Runs evaluation on the evaluation data and returns the result. Runs for <code>self._eval_steps</code> steps, or if it's <code>None</code>, then run until input is exhausted or another exception is raised. Start the evaluation after <code>delay_secs</code> seconds, or if it's <code>None</code>, defaults to using <code>self._eval_delay_secs</code> seconds.</p>
<h4 id="args-2">Args:</h4>
<ul>
<li><b><code>delay_secs</code></b>: Start evaluating after this many seconds. If <code>None</code>, defaults to using <code>self._eval_delays_secs</code>.</li>
</ul>
<h4 id="returns-1">Returns:</h4>
<p>The result of the <code>evaluate</code> call to the <code>Estimator</code>.</p>
<h3 id="extend_train_hooks">
<code>extend_train_hooks</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">extend_train_hooks(additional_hooks)</code></pre></div>
<p>Extends the hooks for training.</p>
<h3 id="local_run">
<code>local_run</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">local_run()</code></pre></div>
<p>DEPRECATED FUNCTION</p>
<p>THIS FUNCTION IS DEPRECATED. It will be removed after 2016-10-23. Instructions for updating: local_run will be renamed to train_and_evaluate and the new default behavior will be to run evaluation every time there is a new checkpoint.</p>
<h3 id="reset_export_strategies">
<code>reset_export_strategies</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">reset_export_strategies(new_export_strategies<span class="op">=</span><span class="va">None</span>)</code></pre></div>
<p>Resets the export strategies with the <code>new_export_strategies</code>.</p>
<h4 id="args-3">Args:</h4>
<ul>
<li><b><code>new_export_strategies</code></b>: A new list of <code>ExportStrategy</code>s, or a single one, or None.</li>
</ul>
<h4 id="returns-2">Returns:</h4>
<p>The old export strategies.</p>
<h3 id="run_std_server">
<code>run_std_server</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">run_std_server()</code></pre></div>
<p>Starts a TensorFlow server and joins the serving thread.</p>
<p>Typically used for parameter servers.</p>
<h4 id="raises-2">Raises:</h4>
<ul>
<li><b><code>ValueError</code></b>: if not enough information is available in the estimator's config to create a server.</li>
</ul>
<h3 id="test">
<code>test</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">test()</code></pre></div>
<p>Tests training, evaluating and exporting the estimator for a single step.</p>
<h4 id="returns-3">Returns:</h4>
<p>The result of the <code>evaluate</code> call to the <code>Estimator</code>.</p>
<h3 id="train">
<code>train</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">train(delay_secs<span class="op">=</span><span class="va">None</span>)</code></pre></div>
<p>Fit the estimator using the training data.</p>
<p>Train the estimator for <code>self._train_steps</code> steps, after waiting for <code>delay_secs</code> seconds. If <code>self._train_steps</code> is <code>None</code>, train forever.</p>
<h4 id="args-4">Args:</h4>
<ul>
<li><b><code>delay_secs</code></b>: Start training after this many seconds.</li>
</ul>
<h4 id="returns-4">Returns:</h4>
<p>The trained estimator.</p>
<h3 id="train_and_evaluate">
<code>train_and_evaluate</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">train_and_evaluate()</code></pre></div>
<p>Interleaves training and evaluation.</p>
<p>The frequency of evaluation is controlled by the contructor arg <code>min_eval_frequency</code>. When this parameter is 0, evaluation happens only after training has completed. Note that evaluation cannot happen more frequently than checkpoints are taken. If no new snapshots are available when evaluation is supposed to occur, then evaluation doesn't happen for another <code>min_eval_frequency</code> steps (assuming a checkpoint is available at that point). Thus, settings <code>min_eval_frequency</code> to 1 means that the model will be evaluated everytime there is a new checkpoint.</p>
<p>This is particular useful for a &quot;Master&quot; task in the cloud, whose responsibility it is to take checkpoints, evaluate those checkpoints, and write out summaries. Participating in training as the supervisor allows such a task to accomplish the first and last items, while performing evaluation allows for the second.</p>
<h4 id="returns-5">Returns:</h4>
<p>The result of the <code>evaluate</code> call to the <code>Estimator</code> as well as the export results using the specified <code>ExportStrategy</code>.</p>

<div itemscope="" itemtype="http://developers.google.com/ReferenceObject">
<p><meta itemprop="name" content="tf.contrib.linear_optimizer.SDCAOptimizer" /> <meta itemprop="property" content="example_id_column"/> <meta itemprop="property" content="num_loss_partitions"/> <meta itemprop="property" content="num_table_shards"/> <meta itemprop="property" content="symmetric_l1_regularization"/> <meta itemprop="property" content="symmetric_l2_regularization"/> <meta itemprop="property" content="__init__"/> <meta itemprop="property" content="get_name"/> <meta itemprop="property" content="get_train_step"/></p>
</div>
<a name="//apple_ref/cpp/Class/tf.contrib.linear_optimizer.SDCAOptimizer" class="dashAnchor"></a><h1 id="tf.contrib.linear_optimizer.sdcaoptimizer">tf.contrib.linear_optimizer.SDCAOptimizer</h1>
<h3 id="class-tf.contrib.linear_optimizer.sdcaoptimizer"><code>class tf.contrib.linear_optimizer.SDCAOptimizer</code></h3>
<p>Defined in <a href="https://www.tensorflow.org/code/tensorflow/contrib/linear_optimizer/python/sdca_optimizer.py"><code>tensorflow/contrib/linear_optimizer/python/sdca_optimizer.py</code></a>.</p>
<p>Wrapper class for SDCA optimizer.</p>
<p>The wrapper is currently meant for use as an optimizer within a tf.learn Estimator.</p>
<p>Example usage:</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">  real_feature_column <span class="op">=</span> real_valued_column(...)
  sparse_feature_column <span class="op">=</span> sparse_column_with_hash_bucket(...)
  sdca_optimizer <span class="op">=</span> linear.SDCAOptimizer(example_id_column<span class="op">=</span><span class="st">&#39;example_id&#39;</span>,
                                        num_loss_partitions<span class="op">=</span><span class="dv">1</span>,
                                        num_table_shards<span class="op">=</span><span class="dv">1</span>,
                                        symmetric_l2_regularization<span class="op">=</span><span class="fl">2.0</span>)
  classifier <span class="op">=</span> tf.contrib.learn.LinearClassifier(
      feature_columns<span class="op">=</span>[real_feature_column, sparse_feature_column],
      weight_column_name<span class="op">=</span>...,
      optimizer<span class="op">=</span>sdca_optimizer)
  classifier.fit(input_fn_train, steps<span class="op">=</span><span class="dv">50</span>)
  classifier.evaluate(input_fn<span class="op">=</span>input_fn_eval)</code></pre></div>
<p>Here the expectation is that the <code>input_fn_*</code> functions passed to train and evaluate return a pair (dict, label_tensor) where dict has <code>example_id_column</code> as <code>key</code> whose value is a <code>Tensor</code> of shape [batch_size] and dtype string. num_loss_partitions defines the number of partitions of the global loss function and should be set to <code>(#concurrent train ops/per worker) x (#workers)</code>. Convergence of (global) loss is guaranteed if <code>num_loss_partitions</code> is larger or equal to the above product. Larger values for <code>num_loss_partitions</code> lead to slower convergence. The recommended value for <code>num_loss_partitions</code> in <code>tf.learn</code> (where currently there is one process per worker) is the number of workers running the train steps. It defaults to 1 (single machine). <code>num_table_shards</code> defines the number of shards for the internal state table, typically set to match the number of parameter servers for large data sets.</p>
<h2 id="properties">Properties</h2>
<h3 id="example_id_column">
<code>example_id_column</code>
</h3>
<h3 id="num_loss_partitions">
<code>num_loss_partitions</code>
</h3>
<h3 id="num_table_shards">
<code>num_table_shards</code>
</h3>
<h3 id="symmetric_l1_regularization">
<code>symmetric_l1_regularization</code>
</h3>
<h3 id="symmetric_l2_regularization">
<code>symmetric_l2_regularization</code>
</h3>
<h2 id="methods">Methods</h2>
<h3 id="__init__">
<code><strong>init</strong></code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="fu">__init__</span>(
    example_id_column,
    num_loss_partitions<span class="op">=</span><span class="dv">1</span>,
    num_table_shards<span class="op">=</span><span class="va">None</span>,
    symmetric_l1_regularization<span class="op">=</span><span class="fl">0.0</span>,
    symmetric_l2_regularization<span class="op">=</span><span class="fl">1.0</span>
)</code></pre></div>
<h3 id="get_name">
<code>get_name</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">get_name()</code></pre></div>
<h3 id="get_train_step">
<code>get_train_step</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">get_train_step(
    columns_to_variables,
    weight_column_name,
    loss_type,
    features,
    targets,
    global_step
)</code></pre></div>
<p>Returns the training operation of an SdcaModel optimizer.</p>

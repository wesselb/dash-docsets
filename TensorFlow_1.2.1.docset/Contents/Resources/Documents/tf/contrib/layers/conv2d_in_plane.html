<div itemscope="" itemtype="http://developers.google.com/ReferenceObject">
<p><meta itemprop="name" content="tf.contrib.layers.conv2d_in_plane" /></p>
</div>
<a name="//apple_ref/cpp/Function/tf.contrib.layers.conv2d_in_plane" class="dashAnchor"></a><h1 id="tf.contrib.layers.conv2d_in_plane">tf.contrib.layers.conv2d_in_plane</h1>
<h3 id="tf.contrib.layers.conv2d_in_plane-1"><code>tf.contrib.layers.conv2d_in_plane</code></h3>
<a name="//apple_ref/cpp/Function/tf.contrib.layers.convolution2d_in_plane" class="dashAnchor"></a><h3 id="tf.contrib.layers.convolution2d_in_plane"><code>tf.contrib.layers.convolution2d_in_plane</code></h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">conv2d_in_plane(
    inputs,
    kernel_size,
    stride<span class="op">=</span><span class="dv">1</span>,
    padding<span class="op">=</span><span class="st">&#39;SAME&#39;</span>,
    activation_fn<span class="op">=</span>tf.nn.relu,
    normalizer_fn<span class="op">=</span><span class="va">None</span>,
    normalizer_params<span class="op">=</span><span class="va">None</span>,
    weights_initializer<span class="op">=</span>initializers.xavier_initializer(),
    weights_regularizer<span class="op">=</span><span class="va">None</span>,
    biases_initializer<span class="op">=</span>tf.zeros_initializer(),
    biases_regularizer<span class="op">=</span><span class="va">None</span>,
    reuse<span class="op">=</span><span class="va">None</span>,
    variables_collections<span class="op">=</span><span class="va">None</span>,
    outputs_collections<span class="op">=</span><span class="va">None</span>,
    trainable<span class="op">=</span><span class="va">True</span>,
    scope<span class="op">=</span><span class="va">None</span>
)</code></pre></div>
<p>Defined in <a href="https://www.tensorflow.org/code/tensorflow/contrib/layers/python/layers/layers.py"><code>tensorflow/contrib/layers/python/layers/layers.py</code></a>.</p>
<p>See the guide: <a href="../../../../../api_guides/python/contrib.layers.md#Higher_level_ops_for_building_neural_network_layers">Layers (contrib) &gt; Higher level ops for building neural network layers</a></p>
<p>Performs the same in-plane convolution to each channel independently.</p>
<p>This is useful for performing various simple channel-independent convolution operations such as image gradients:</p>
<p>image = tf.constant(..., shape=(16, 240, 320, 3)) vert_gradients = layers.conv2d_in_plane(image, kernel=[1, -1], kernel_size=[2, 1]) horz_gradients = layers.conv2d_in_plane(image, kernel=[1, -1], kernel_size=[1, 2])</p>
<h4 id="args">Args:</h4>
<ul>
<li><b><code>inputs</code></b>: A 4-D tensor with dimensions [batch_size, height, width, channels].</li>
<li><b><code>kernel_size</code></b>: A list of length 2 holding the [kernel_height, kernel_width] of of the pooling. Can be an int if both values are the same.</li>
<li><b><code>stride</code></b>: A list of length 2 <code>[stride_height, stride_width]</code>. Can be an int if both strides are the same. Note that presently both strides must have the same value.</li>
<li><b><code>padding</code></b>: The padding type to use, either 'SAME' or 'VALID'.</li>
<li><b><code>activation_fn</code></b>: Activation function. The default value is a ReLU function. Explicitly set it to None to skip it and maintain a linear activation.</li>
<li><b><code>normalizer_fn</code></b>: Normalization function to use instead of <code>biases</code>. If <code>normalizer_fn</code> is provided then <code>biases_initializer</code> and <code>biases_regularizer</code> are ignored and <code>biases</code> are not created nor added. default set to None for no normalizer function</li>
<li><b><code>normalizer_params</code></b>: Normalization function parameters.</li>
<li><b><code>weights_initializer</code></b>: An initializer for the weights.</li>
<li><b><code>weights_regularizer</code></b>: Optional regularizer for the weights.</li>
<li><b><code>biases_initializer</code></b>: An initializer for the biases. If None skip biases.</li>
<li><b><code>biases_regularizer</code></b>: Optional regularizer for the biases.</li>
<li><b><code>reuse</code></b>: Whether or not the layer and its variables should be reused. To be able to reuse the layer scope must be given.</li>
<li><b><code>variables_collections</code></b>: Optional list of collections for all the variables or a dictionary containing a different list of collection per variable.</li>
<li><b><code>outputs_collections</code></b>: Collection to add the outputs.</li>
<li><b><code>trainable</code></b>: If <code>True</code> also add variables to the graph collection <code>GraphKeys.TRAINABLE_VARIABLES</code> (see tf.Variable).</li>
<li><b><code>scope</code></b>: Optional scope for <code>variable_scope</code>.</li>
</ul>
<h4 id="returns">Returns:</h4>
<p>A <code>Tensor</code> representing the output of the operation.</p>

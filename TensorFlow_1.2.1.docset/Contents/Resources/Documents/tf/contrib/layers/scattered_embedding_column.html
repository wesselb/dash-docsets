<div itemscope="" itemtype="http://developers.google.com/ReferenceObject">
<p><meta itemprop="name" content="tf.contrib.layers.scattered_embedding_column" /></p>
</div>
<a name="//apple_ref/cpp/Function/tf.contrib.layers.scattered_embedding_column" class="dashAnchor"></a><h1 id="tf.contrib.layers.scattered_embedding_column">tf.contrib.layers.scattered_embedding_column</h1>
<h3 id="tf.contrib.layers.scattered_embedding_column-1"><code>tf.contrib.layers.scattered_embedding_column</code></h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">scattered_embedding_column(
    column_name,
    size,
    dimension,
    hash_key,
    combiner<span class="op">=</span><span class="st">&#39;mean&#39;</span>,
    initializer<span class="op">=</span><span class="va">None</span>
)</code></pre></div>
<p>Defined in <a href="https://www.tensorflow.org/code/tensorflow/contrib/layers/python/layers/feature_column.py"><code>tensorflow/contrib/layers/python/layers/feature_column.py</code></a>.</p>
<p>See the guide: <a href="../../../../../api_guides/python/contrib.layers.md#Feature_columns">Layers (contrib) &gt; Feature columns</a></p>
<p>Creates an embedding column of a sparse feature using parameter hashing.</p>
<p>This is a useful shorthand when you have a sparse feature you want to use an embedding for, but also want to hash the embedding's values in each dimension to a variable based on a different hash.</p>
<p>Specifically, the i-th embedding component of a value v is found by retrieving an embedding weight whose index is a fingerprint of the pair (v,i).</p>
<p>An embedding column with sparse_column_with_hash_bucket such as</p>
<pre><code>embedding_column(
  sparse_column_with_hash_bucket(column_name, bucket_size),
  dimension)</code></pre>
<p>could be replaced by</p>
<pre><code>scattered_embedding_column(
  column_name,
  size=bucket_size * dimension,
  dimension=dimension,
  hash_key=tf.contrib.layers.SPARSE_FEATURE_CROSS_DEFAULT_HASH_KEY)</code></pre>
<p>for the same number of embedding parameters. This should hopefully reduce the impact of collisions, but adds the cost of slowing down training.</p>
<h4 id="args">Args:</h4>
<ul>
<li><b><code>column_name</code></b>: A string defining sparse column name.</li>
<li><b><code>size</code></b>: An integer specifying the number of parameters in the embedding layer.</li>
<li><b><code>dimension</code></b>: An integer specifying dimension of the embedding.</li>
<li><b><code>hash_key</code></b>: Specify the hash_key that will be used by the <code>FingerprintCat64</code> function to combine the crosses fingerprints on SparseFeatureCrossOp.</li>
<li><b><code>combiner</code></b>: A string specifying how to reduce if there are multiple entries in a single row. Currently &quot;mean&quot;, &quot;sqrtn&quot; and &quot;sum&quot; are supported, with &quot;mean&quot; the default. &quot;sqrtn&quot; often achieves good accuracy, in particular with bag-of-words columns. Each of this can be thought as example level normalizations on the column:
<ul>
<li>&quot;sum&quot;: do not normalize features in the column</li>
<li>&quot;mean&quot;: do l1 normalization on features in the column</li>
<li>&quot;sqrtn&quot;: do l2 normalization on features in the column For more information: <code>tf.embedding_lookup_sparse</code>.</li>
</ul></li>
<li><b><code>initializer</code></b>: A variable initializer function to be used in embedding variable initialization. If not specified, defaults to <code>tf.truncated_normal_initializer</code> with mean 0 and standard deviation 0.1.</li>
</ul>
<h4 id="returns">Returns:</h4>
<p>A _ScatteredEmbeddingColumn.</p>
<h4 id="raises">Raises:</h4>
<ul>
<li><b><code>ValueError</code></b>: if dimension or size is not a positive integer; or if combiner is not supported.</li>
</ul>

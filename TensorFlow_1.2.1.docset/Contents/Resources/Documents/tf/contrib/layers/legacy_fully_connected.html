<div itemscope="" itemtype="http://developers.google.com/ReferenceObject">
<p><meta itemprop="name" content="tf.contrib.layers.legacy_fully_connected" /></p>
</div>
<a name="//apple_ref/cpp/Function/tf.contrib.layers.legacy_fully_connected" class="dashAnchor"></a><h1 id="tf.contrib.layers.legacy_fully_connected">tf.contrib.layers.legacy_fully_connected</h1>
<h3 id="tf.contrib.layers.legacy_fully_connected-1"><code>tf.contrib.layers.legacy_fully_connected</code></h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">legacy_fully_connected(
    x,
    num_output_units,
    activation_fn<span class="op">=</span><span class="va">None</span>,
    weight_init<span class="op">=</span>initializers.xavier_initializer(),
    bias_init<span class="op">=</span>tf.zeros_initializer(),
    name<span class="op">=</span><span class="va">None</span>,
    weight_collections<span class="op">=</span>(ops.GraphKeys.WEIGHTS,),
    bias_collections<span class="op">=</span>(ops.GraphKeys.BIASES,),
    output_collections<span class="op">=</span>(ops.GraphKeys.ACTIVATIONS,),
    trainable<span class="op">=</span><span class="va">True</span>,
    weight_regularizer<span class="op">=</span><span class="va">None</span>,
    bias_regularizer<span class="op">=</span><span class="va">None</span>
)</code></pre></div>
<p>Defined in <a href="https://www.tensorflow.org/code/tensorflow/contrib/layers/python/layers/layers.py"><code>tensorflow/contrib/layers/python/layers/layers.py</code></a>.</p>
<p>Adds the parameters for a fully connected layer and returns the output.</p>
<p>A fully connected layer is generally defined as a matrix multiply: <code>y = f(w * x + b)</code> where <code>f</code> is given by <code>activation_fn</code>. If <code>activation_fn</code> is <code>None</code>, the result of <code>y = w * x + b</code> is returned.</p>
<p>If <code>x</code> has shape [\(\text{dim}_0, \text{dim}_1, ..., \text{dim}_n\)] with more than 2 dimensions (\(n &gt; 1\)), then we repeat the matrix multiply along the first dimensions. The result r is a tensor of shape [\(\text{dim}<em>0, ..., \text{dim}</em>{n-1},\) <code>num_output_units</code>], where \( r_{i_0, ..., i_{n-1}, k} = \sum_{0 \leq j &lt; \text{dim}<em>n} x</em>{i_0, ... i_{n-1}, j} w_{j, k}\). This is accomplished by reshaping <code>x</code> to 2-D [\(\text{dim}<em>0 \cdot ... \cdot \text{dim}</em>{n-1}, \text{dim}_n\)] before the matrix multiply and afterwards reshaping it to [\(\text{dim}<em>0, ..., \text{dim}</em>{n-1},\) <code>num_output_units</code>].</p>
<p>This op creates <code>w</code> and optionally <code>b</code>. Bias (<code>b</code>) can be disabled by setting <code>bias_init</code> to <code>None</code>.</p>
<p>The variable creation is compatible with <code>tf.variable_scope</code> and so can be reused with <code>tf.variable_scope</code> or <code>tf.make_template</code>.</p>
<p>Most of the details of variable creation can be controlled by specifying the initializers (<code>weight_init</code> and <code>bias_init</code>) and in which collections to place the created variables (<code>weight_collections</code> and <code>bias_collections</code>; note that the variables are always added to the <code>VARIABLES</code> collection). The output of the layer can be placed in custom collections using <code>output_collections</code>. The collections arguments default to <code>WEIGHTS</code>, <code>BIASES</code> and <code>ACTIVATIONS</code>, respectively.</p>
<p>A per layer regularization can be specified by setting <code>weight_regularizer</code> and <code>bias_regularizer</code>, which are applied to the weights and biases respectively, and whose output is added to the <code>REGULARIZATION_LOSSES</code> collection.</p>
<h4 id="args">Args:</h4>
<ul>
<li><b><code>x</code></b>: The input <code>Tensor</code>.</li>
<li><b><code>num_output_units</code></b>: The size of the output.</li>
<li><b><code>activation_fn</code></b>: Activation function, default set to None to skip it and maintain a linear activation.</li>
<li><b><code>weight_init</code></b>: An optional weight initialization, defaults to <code>xavier_initializer</code>.</li>
<li><b><code>bias_init</code></b>: An initializer for the bias, defaults to 0. Set to <code>None</code> in order to disable bias.</li>
<li><b><code>name</code></b>: The name for this operation is used to name operations and to find variables. If specified it must be unique for this scope, otherwise a unique name starting with &quot;fully_connected&quot; will be created. See <code>tf.variable_scope</code> for details.</li>
<li><b><code>weight_collections</code></b>: List of graph collections to which weights are added.</li>
<li><b><code>bias_collections</code></b>: List of graph collections to which biases are added.</li>
<li><b><code>output_collections</code></b>: List of graph collections to which outputs are added.</li>
<li><b><code>trainable</code></b>: If <code>True</code> also add variables to the graph collection <code>GraphKeys.TRAINABLE_VARIABLES</code> (see tf.Variable).</li>
<li><b><code>weight_regularizer</code></b>: A regularizer like the result of <code>l1_regularizer</code> or <code>l2_regularizer</code>. Used for weights.</li>
<li><b><code>bias_regularizer</code></b>: A regularizer like the result of <code>l1_regularizer</code> or <code>l2_regularizer</code>. Used for biases.</li>
</ul>
<h4 id="returns">Returns:</h4>
<p>The output of the fully connected layer.</p>
<h4 id="raises">Raises:</h4>
<ul>
<li><b><code>ValueError</code></b>: If x has rank less than 2 or if its last dimension is not set.</li>
</ul>

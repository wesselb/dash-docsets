<div itemscope="" itemtype="http://developers.google.com/ReferenceObject">
<p><meta itemprop="name" content="tf.contrib.layers.conv2d" /></p>
</div>
<a name="//apple_ref/cpp/Function/tf.contrib.layers.conv2d" class="dashAnchor"></a><h1 id="tf.contrib.layers.conv2d">tf.contrib.layers.conv2d</h1>
<h3 id="tf.contrib.layers.conv2d-1"><code>tf.contrib.layers.conv2d</code></h3>
<a name="//apple_ref/cpp/Function/tf.contrib.layers.convolution2d" class="dashAnchor"></a><h3 id="tf.contrib.layers.convolution2d"><code>tf.contrib.layers.convolution2d</code></h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">conv2d(
    inputs,
    num_outputs,
    kernel_size,
    stride<span class="op">=</span><span class="dv">1</span>,
    padding<span class="op">=</span><span class="st">&#39;SAME&#39;</span>,
    data_format<span class="op">=</span><span class="va">None</span>,
    rate<span class="op">=</span><span class="dv">1</span>,
    activation_fn<span class="op">=</span>tf.nn.relu,
    normalizer_fn<span class="op">=</span><span class="va">None</span>,
    normalizer_params<span class="op">=</span><span class="va">None</span>,
    weights_initializer<span class="op">=</span>initializers.xavier_initializer(),
    weights_regularizer<span class="op">=</span><span class="va">None</span>,
    biases_initializer<span class="op">=</span>tf.zeros_initializer(),
    biases_regularizer<span class="op">=</span><span class="va">None</span>,
    reuse<span class="op">=</span><span class="va">None</span>,
    variables_collections<span class="op">=</span><span class="va">None</span>,
    outputs_collections<span class="op">=</span><span class="va">None</span>,
    trainable<span class="op">=</span><span class="va">True</span>,
    scope<span class="op">=</span><span class="va">None</span>
)</code></pre></div>
<p>Defined in <a href="https://www.tensorflow.org/code/tensorflow/contrib/layers/python/layers/layers.py"><code>tensorflow/contrib/layers/python/layers/layers.py</code></a>.</p>
<p>See the guide: <a href="../../../../../api_guides/python/contrib.layers.md#Higher_level_ops_for_building_neural_network_layers">Layers (contrib) &gt; Higher level ops for building neural network layers</a></p>
<p>Adds an N-D convolution followed by an optional batch_norm layer.</p>
<p>It is required that 1 &lt;= N &lt;= 3.</p>
<p><code>convolution</code> creates a variable called <code>weights</code>, representing the convolutional kernel, that is convolved (actually cross-correlated) with the <code>inputs</code> to produce a <code>Tensor</code> of activations. If a <code>normalizer_fn</code> is provided (such as <code>batch_norm</code>), it is then applied. Otherwise, if <code>normalizer_fn</code> is None and a <code>biases_initializer</code> is provided then a <code>biases</code> variable would be created and added the activations. Finally, if <code>activation_fn</code> is not <code>None</code>, it is applied to the activations as well.</p>
<p>Performs atrous convolution with input stride/dilation rate equal to <code>rate</code> if a value &gt; 1 for any dimension of <code>rate</code> is specified. In this case <code>stride</code> values != 1 are not supported.</p>
<h4 id="args">Args:</h4>
<ul>
<li><b><code>inputs</code></b>: A Tensor of rank N+2 of shape <code>[batch_size] + input_spatial_shape + [in_channels]</code> if data_format does not start with &quot;NC&quot; (default), or <code>[batch_size, in_channels] + input_spatial_shape</code> if data_format starts with &quot;NC&quot;.</li>
<li><b><code>num_outputs</code></b>: Integer, the number of output filters.</li>
<li><b><code>kernel_size</code></b>: A sequence of N positive integers specifying the spatial dimensions of of the filters. Can be a single integer to specify the same value for all spatial dimensions.</li>
<li><b><code>stride</code></b>: A sequence of N positive integers specifying the stride at which to compute output. Can be a single integer to specify the same value for all spatial dimensions. Specifying any <code>stride</code> value != 1 is incompatible with specifying any <code>rate</code> value != 1.</li>
<li><b><code>padding</code></b>: One of <code>&quot;VALID&quot;</code> or <code>&quot;SAME&quot;</code>.</li>
<li><b><code>data_format</code></b>: A string or None. Specifies whether the channel dimension of the <code>input</code> and output is the last dimension (default, or if <code>data_format</code> does not start with &quot;NC&quot;), or the second dimension (if <code>data_format</code> starts with &quot;NC&quot;). For N=1, the valid values are &quot;NWC&quot; (default) and &quot;NCW&quot;. For N=2, the valid values are &quot;NHWC&quot; (default) and &quot;NCHW&quot;. For N=3, the valid values are &quot;NDHWC&quot; (default) and &quot;NCDHW&quot;.</li>
<li><b><code>rate</code></b>: A sequence of N positive integers specifying the dilation rate to use for atrous convolution. Can be a single integer to specify the same value for all spatial dimensions. Specifying any <code>rate</code> value != 1 is incompatible with specifying any <code>stride</code> value != 1.</li>
<li><b><code>activation_fn</code></b>: Activation function. The default value is a ReLU function. Explicitly set it to None to skip it and maintain a linear activation.</li>
<li><b><code>normalizer_fn</code></b>: Normalization function to use instead of <code>biases</code>. If <code>normalizer_fn</code> is provided then <code>biases_initializer</code> and <code>biases_regularizer</code> are ignored and <code>biases</code> are not created nor added. default set to None for no normalizer function</li>
<li><b><code>normalizer_params</code></b>: Normalization function parameters.</li>
<li><b><code>weights_initializer</code></b>: An initializer for the weights.</li>
<li><b><code>weights_regularizer</code></b>: Optional regularizer for the weights.</li>
<li><b><code>biases_initializer</code></b>: An initializer for the biases. If None skip biases.</li>
<li><b><code>biases_regularizer</code></b>: Optional regularizer for the biases.</li>
<li><b><code>reuse</code></b>: Whether or not the layer and its variables should be reused. To be able to reuse the layer scope must be given.</li>
<li><b><code>variables_collections</code></b>: Optional list of collections for all the variables or a dictionary containing a different list of collection per variable.</li>
<li><b><code>outputs_collections</code></b>: Collection to add the outputs.</li>
<li><b><code>trainable</code></b>: If <code>True</code> also add variables to the graph collection <code>GraphKeys.TRAINABLE_VARIABLES</code> (see tf.Variable).</li>
<li><b><code>scope</code></b>: Optional scope for <code>variable_scope</code>.</li>
</ul>
<h4 id="returns">Returns:</h4>
<p>A tensor representing the output of the operation.</p>
<h4 id="raises">Raises:</h4>
<ul>
<li><b><code>ValueError</code></b>: If <code>data_format</code> is invalid.</li>
<li><b><code>ValueError</code></b>: Both 'rate' and <code>stride</code> are not uniformly 1.</li>
</ul>

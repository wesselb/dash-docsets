<div itemscope="" itemtype="http://developers.google.com/ReferenceObject">
<p><meta itemprop="name" content="tf.contrib.layers.conv2d_transpose" /></p>
</div>
<a name="//apple_ref/cpp/Function/tf.contrib.layers.conv2d_transpose" class="dashAnchor"></a><h1 id="tf.contrib.layers.conv2d_transpose">tf.contrib.layers.conv2d_transpose</h1>
<h3 id="tf.contrib.layers.conv2d_transpose-1"><code>tf.contrib.layers.conv2d_transpose</code></h3>
<a name="//apple_ref/cpp/Function/tf.contrib.layers.convolution2d_transpose" class="dashAnchor"></a><h3 id="tf.contrib.layers.convolution2d_transpose"><code>tf.contrib.layers.convolution2d_transpose</code></h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">conv2d_transpose(
    inputs,
    num_outputs,
    kernel_size,
    stride<span class="op">=</span><span class="dv">1</span>,
    padding<span class="op">=</span><span class="st">&#39;SAME&#39;</span>,
    data_format<span class="op">=</span>DATA_FORMAT_NHWC,
    activation_fn<span class="op">=</span>tf.nn.relu,
    normalizer_fn<span class="op">=</span><span class="va">None</span>,
    normalizer_params<span class="op">=</span><span class="va">None</span>,
    weights_initializer<span class="op">=</span>initializers.xavier_initializer(),
    weights_regularizer<span class="op">=</span><span class="va">None</span>,
    biases_initializer<span class="op">=</span>tf.zeros_initializer(),
    biases_regularizer<span class="op">=</span><span class="va">None</span>,
    reuse<span class="op">=</span><span class="va">None</span>,
    variables_collections<span class="op">=</span><span class="va">None</span>,
    outputs_collections<span class="op">=</span><span class="va">None</span>,
    trainable<span class="op">=</span><span class="va">True</span>,
    scope<span class="op">=</span><span class="va">None</span>
)</code></pre></div>
<p>Defined in <a href="https://www.tensorflow.org/code/tensorflow/contrib/layers/python/layers/layers.py"><code>tensorflow/contrib/layers/python/layers/layers.py</code></a>.</p>
<p>See the guide: <a href="../../../../../api_guides/python/contrib.layers.md#Higher_level_ops_for_building_neural_network_layers">Layers (contrib) &gt; Higher level ops for building neural network layers</a></p>
<p>Adds a convolution2d_transpose with an optional batch normalization layer.</p>
<p>The function creates a variable called <code>weights</code>, representing the kernel, that is convolved with the input. If <code>normalizer_fn</code> is <code>None</code>, a second variable called 'biases' is added to the result of the operation.</p>
<h4 id="args">Args:</h4>
<ul>
<li><b><code>inputs</code></b>: A 4-D <code>Tensor</code> of type <code>float</code> and shape <code>[batch, height, width, in_channels]</code> for <code>NHWC</code> data format or <code>[batch, in_channels, height, width]</code> for <code>NCHW</code> data format.</li>
<li><b><code>num_outputs</code></b>: Integer, the number of output filters.</li>
<li><b><code>kernel_size</code></b>: A list of length 2 holding the [kernel_height, kernel_width] of of the filters. Can be an int if both values are the same.</li>
<li><b><code>stride</code></b>: A list of length 2: [stride_height, stride_width]. Can be an int if both strides are the same. Note that presently both strides must have the same value.</li>
<li><b><code>padding</code></b>: One of 'VALID' or 'SAME'.</li>
<li><b><code>data_format</code></b>: A string. <code>NHWC</code> (default) and <code>NCHW</code> are supported.</li>
<li><b><code>activation_fn</code></b>: Activation function. The default value is a ReLU function. Explicitly set it to None to skip it and maintain a linear activation.</li>
<li><b><code>normalizer_fn</code></b>: Normalization function to use instead of <code>biases</code>. If <code>normalizer_fn</code> is provided then <code>biases_initializer</code> and <code>biases_regularizer</code> are ignored and <code>biases</code> are not created nor added. default set to None for no normalizer function</li>
<li><b><code>normalizer_params</code></b>: Normalization function parameters.</li>
<li><b><code>weights_initializer</code></b>: An initializer for the weights.</li>
<li><b><code>weights_regularizer</code></b>: Optional regularizer for the weights.</li>
<li><b><code>biases_initializer</code></b>: An initializer for the biases. If None skip biases.</li>
<li><b><code>biases_regularizer</code></b>: Optional regularizer for the biases.</li>
<li><b><code>reuse</code></b>: Whether or not the layer and its variables should be reused. To be able to reuse the layer scope must be given.</li>
<li><b><code>variables_collections</code></b>: Optional list of collections for all the variables or a dictionary containing a different list of collection per variable.</li>
<li><b><code>outputs_collections</code></b>: Collection to add the outputs.</li>
<li><b><code>trainable</code></b>: Whether or not the variables should be trainable or not.</li>
<li><b><code>scope</code></b>: Optional scope for variable_scope.</li>
</ul>
<h4 id="returns">Returns:</h4>
<p>A tensor representing the output of the operation.</p>
<h4 id="raises">Raises:</h4>
<ul>
<li><b><code>ValueError</code></b>: If 'kernel_size' is not a list of length 2.</li>
<li><b><code>ValueError</code></b>: If <code>data_format</code> is neither <code>NHWC</code> nor <code>NCHW</code>.</li>
<li><b><code>ValueError</code></b>: If <code>C</code> dimension of <code>inputs</code> is None.</li>
</ul>

<div itemscope="" itemtype="http://developers.google.com/ReferenceObject">
<p><meta itemprop="name" content="tf.contrib.bayesflow.stochastic_tensor.StochasticTensor" /> <meta itemprop="property" content="distribution"/> <meta itemprop="property" content="dtype"/> <meta itemprop="property" content="graph"/> <meta itemprop="property" content="name"/> <meta itemprop="property" content="value_type"/> <meta itemprop="property" content="__init__"/> <meta itemprop="property" content="entropy"/> <meta itemprop="property" content="loss"/> <meta itemprop="property" content="mean"/> <meta itemprop="property" content="value"/></p>
</div>
<a name="//apple_ref/cpp/Class/tf.contrib.bayesflow.stochastic_tensor.StochasticTensor" class="dashAnchor"></a><h1 id="tf.contrib.bayesflow.stochastic_tensor.stochastictensor">tf.contrib.bayesflow.stochastic_tensor.StochasticTensor</h1>
<h3 id="class-tf.contrib.bayesflow.stochastic_tensor.stochastictensor"><code>class tf.contrib.bayesflow.stochastic_tensor.StochasticTensor</code></h3>
<p>Defined in <a href="https://www.tensorflow.org/code/tensorflow/contrib/bayesflow/python/ops/stochastic_tensor_impl.py"><code>tensorflow/contrib/bayesflow/python/ops/stochastic_tensor_impl.py</code></a>.</p>
<p>See the guide: <a href="../../../../../../api_guides/python/contrib.bayesflow.stochastic_tensor.md#Stochastic_Tensor_Classes">BayesFlow Stochastic Tensors (contrib) &gt; Stochastic Tensor Classes</a></p>
<p>StochasticTensor is a BaseStochasticTensor backed by a distribution.</p>
<h2 id="properties">Properties</h2>
<h3 id="distribution">
<code>distribution</code>
</h3>
<h3 id="dtype">
<code>dtype</code>
</h3>
<h3 id="graph">
<code>graph</code>
</h3>
<h3 id="name">
<code>name</code>
</h3>
<h3 id="value_type">
<code>value_type</code>
</h3>
<h2 id="methods">Methods</h2>
<h3 id="__init__">
<code><strong>init</strong></code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="fu">__init__</span>(
    dist,
    name<span class="op">=</span><span class="st">&#39;StochasticTensor&#39;</span>,
    dist_value_type<span class="op">=</span><span class="va">None</span>,
    loss_fn<span class="op">=</span>sge.score_function
)</code></pre></div>
<p>Construct a <code>StochasticTensor</code>.</p>
<p><code>StochasticTensor</code> is backed by the <code>dist</code> distribution and its <code>value</code> method will return the same value each time it is called. What <code>value</code> is returned is controlled by the <code>dist_value_type</code> (defaults to <code>SampleValue</code>).</p>
<p>Some distributions' sample functions are not differentiable (e.g. a sample from a discrete distribution like a Bernoulli) and so to differentiate wrt parameters upstream of the sample requires a gradient estimator like the score function estimator. This is accomplished by passing a differentiable <code>loss_fn</code> to the <code>StochasticTensor</code>, which defaults to a function whose derivative is the score function estimator. Calling <code>stochastic_graph.surrogate_loss(final_losses)</code> will call <code>loss()</code> on every <code>StochasticTensor</code> upstream of final losses.</p>
<p><code>loss()</code> will return None for <code>StochasticTensor</code>s backed by reparameterized distributions; it will also return None if the value type is <code>MeanValueType</code> or if <code>loss_fn=None</code>.</p>
<h4 id="args">Args:</h4>
<ul>
<li><b><code>dist</code></b>: an instance of <code>Distribution</code>.</li>
<li><b><code>name</code></b>: a name for this <code>StochasticTensor</code> and its ops.</li>
<li><b><code>dist_value_type</code></b>: a <code>_StochasticValueType</code>, which will determine what the <code>value</code> of this <code>StochasticTensor</code> will be. If not provided, the value type set with the <code>value_type</code> context manager will be used.</li>
<li><b><code>loss_fn</code></b>: callable that takes <code>(st, st.value(), influenced_loss)</code>, where <code>st</code> is this <code>StochasticTensor</code>, and returns a <code>Tensor</code> loss. By default, <code>loss_fn</code> is the <code>score_function</code>, or more precisely, the integral of the score function, such that when the gradient is taken, the score function results. See the <code>stochastic_gradient_estimators</code> module for additional loss functions and baselines.</li>
</ul>
<h4 id="raises">Raises:</h4>
<ul>
<li><b><code>TypeError</code></b>: if <code>dist</code> is not an instance of <code>Distribution</code>.</li>
<li><b><code>TypeError</code></b>: if <code>loss_fn</code> is not <code>callable</code>.</li>
</ul>
<h3 id="entropy">
<code>entropy</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">entropy(name<span class="op">=</span><span class="st">&#39;entropy&#39;</span>)</code></pre></div>
<h3 id="loss">
<code>loss</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">loss(
    final_loss,
    name<span class="op">=</span><span class="st">&#39;Loss&#39;</span>
)</code></pre></div>
<h3 id="mean">
<code>mean</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">mean(name<span class="op">=</span><span class="st">&#39;mean&#39;</span>)</code></pre></div>
<h3 id="value">
<code>value</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">value(name<span class="op">=</span><span class="st">&#39;value&#39;</span>)</code></pre></div>

<div itemscope="" itemtype="http://developers.google.com/ReferenceObject">
<p><meta itemprop="name" content="tf.contrib.keras.layers.Layer" /> <meta itemprop="property" content="constraints"/> <meta itemprop="property" content="graph"/> <meta itemprop="property" content="input"/> <meta itemprop="property" content="input_mask"/> <meta itemprop="property" content="input_shape"/> <meta itemprop="property" content="losses"/> <meta itemprop="property" content="non_trainable_variables"/> <meta itemprop="property" content="non_trainable_weights"/> <meta itemprop="property" content="output"/> <meta itemprop="property" content="output_mask"/> <meta itemprop="property" content="output_shape"/> <meta itemprop="property" content="scope_name"/> <meta itemprop="property" content="trainable_variables"/> <meta itemprop="property" content="trainable_weights"/> <meta itemprop="property" content="updates"/> <meta itemprop="property" content="variables"/> <meta itemprop="property" content="weights"/> <meta itemprop="property" content="__call__"/> <meta itemprop="property" content="__deepcopy__"/> <meta itemprop="property" content="__init__"/> <meta itemprop="property" content="add_loss"/> <meta itemprop="property" content="add_update"/> <meta itemprop="property" content="add_variable"/> <meta itemprop="property" content="add_weight"/> <meta itemprop="property" content="apply"/> <meta itemprop="property" content="build"/> <meta itemprop="property" content="call"/> <meta itemprop="property" content="compute_mask"/> <meta itemprop="property" content="count_params"/> <meta itemprop="property" content="from_config"/> <meta itemprop="property" content="get_config"/> <meta itemprop="property" content="get_input_at"/> <meta itemprop="property" content="get_input_mask_at"/> <meta itemprop="property" content="get_input_shape_at"/> <meta itemprop="property" content="get_losses_for"/> <meta itemprop="property" content="get_output_at"/> <meta itemprop="property" content="get_output_mask_at"/> <meta itemprop="property" content="get_output_shape_at"/> <meta itemprop="property" content="get_updates_for"/> <meta itemprop="property" content="get_weights"/> <meta itemprop="property" content="set_weights"/></p>
</div>
<a name="//apple_ref/cpp/Class/tf.contrib.keras.layers.Layer" class="dashAnchor"></a><h1 id="tf.contrib.keras.layers.layer">tf.contrib.keras.layers.Layer</h1>
<h3 id="class-tf.contrib.keras.layers.layer"><code>class tf.contrib.keras.layers.Layer</code></h3>
<p>Defined in <a href="https://www.tensorflow.org/code/tensorflow/contrib/keras/python/keras/engine/topology.py"><code>tensorflow/contrib/keras/python/keras/engine/topology.py</code></a>.</p>
<p>Abstract base layer class.</p>
<h1 id="properties">Properties</h1>
<pre><code>name: String, must be unique within a model.
input_spec: List of InputSpec class instances
    each entry describes one required input:
        - ndim
        - dtype
    A layer with `n` input tensors must have
    an `input_spec` of length `n`.
trainable: Boolean, whether the layer weights
    will be updated during training.
uses_learning_phase: Whether any operation
    of the layer uses `K.in_training_phase()`
    or `K.in_test_phase()`.
input_shape: Shape tuple. Provided for convenience,
    but note that there may be cases in which this
    attribute is ill-defined (e.g. a shared layer
    with multiple input shapes), in which case
    requesting `input_shape` will raise an Exception.
    Prefer using `layer.get_input_shape_for(input_shape)`,
    or `layer.get_input_shape_at(node_index)`.
output_shape: Shape tuple. See above.
inbound_nodes: List of nodes.
outbound_nodes: List of nodes.
input, output: Input/output tensor(s). Note that if the layer is used
    more than once (shared layer), this is ill-defined
    and will raise an exception. In such cases, use
    `layer.get_input_at(node_index)`.
input_mask, output_mask: Same as above, for masks.
trainable_weights: List of variables.
non_trainable_weights: List of variables.
weights: The concatenation of the lists trainable_weights and
    non_trainable_weights (in this order).
constraints: Dict mapping weights to constraints.</code></pre>
<h1 id="methods">Methods</h1>
<pre><code>call(x, mask=None): Where the layer&#39;s logic lives.
__call__(x, mask=None): Wrapper around the layer logic (`call`).
    If x is a Keras tensor:
        - Connect current layer with last layer from tensor:
            `self._add_inbound_node(last_layer)`
        - Add layer to tensor history
    If layer is not built:
        - Build from inputs shape
get_weights()
set_weights(weights)
get_config()
count_params()
_compute_output_shape(input_shape)
compute_mask(x, mask)
get_input_at(node_index)
get_output_at(node_index)
get_input_shape_at(node_index)
get_output_shape_at(node_index)
get_input_mask_at(node_index)
get_output_mask_at(node_index)</code></pre>
<h1 id="class-methods">Class Methods</h1>
<pre><code>from_config(config)</code></pre>
<h1 id="internal-methods">Internal methods:</h1>
<pre><code>build(input_shape)
_add_inbound_node(layer, index=0)</code></pre>
<h2 id="properties-1">Properties</h2>
<h3 id="constraints">
<code>constraints</code>
</h3>
<h3 id="graph">
<code>graph</code>
</h3>
<h3 id="input">
<code>input</code>
</h3>
<p>Retrieves the input tensor(s) of a layer.</p>
<p>Only applicable if the layer has exactly one inbound node, i.e. if it is connected to one incoming layer.</p>
<h4 id="returns">Returns:</h4>
<pre><code>Input tensor or list of input tensors.</code></pre>
<h4 id="raises">Raises:</h4>
<pre><code>AttributeError: if the layer is connected to
more than one incoming layers.</code></pre>
<h3 id="input_mask">
<code>input_mask</code>
</h3>
<p>Retrieves the input mask tensor(s) of a layer.</p>
<p>Only applicable if the layer has exactly one inbound node, i.e. if it is connected to one incoming layer.</p>
<h4 id="returns-1">Returns:</h4>
<pre><code>Input mask tensor (potentially None) or list of input
mask tensors.</code></pre>
<h4 id="raises-1">Raises:</h4>
<pre><code>AttributeError: if the layer is connected to
more than one incoming layers.</code></pre>
<h3 id="input_shape">
<code>input_shape</code>
</h3>
<p>Retrieves the input shape(s) of a layer.</p>
<p>Only applicable if the layer has exactly one inbound node, i.e. if it is connected to one incoming layer.</p>
<h4 id="returns-2">Returns:</h4>
<pre><code>Input shape, as `TensorShape`
(or list of `TensorShape`, one tuple per input tensor).</code></pre>
<h4 id="raises-2">Raises:</h4>
<pre><code>AttributeError: if the layer is connected to
more than one incoming layers.</code></pre>
<h3 id="losses">
<code>losses</code>
</h3>
<h3 id="non_trainable_variables">
<code>non_trainable_variables</code>
</h3>
<h3 id="non_trainable_weights">
<code>non_trainable_weights</code>
</h3>
<h3 id="output">
<code>output</code>
</h3>
<p>Retrieves the output tensor(s) of a layer.</p>
<p>Only applicable if the layer has exactly one inbound node, i.e. if it is connected to one incoming layer.</p>
<h4 id="returns-3">Returns:</h4>
<pre><code>Output tensor or list of output tensors.</code></pre>
<h4 id="raises-3">Raises:</h4>
<pre><code>AttributeError: if the layer is connected to
more than one incoming layers.</code></pre>
<h3 id="output_mask">
<code>output_mask</code>
</h3>
<p>Retrieves the output mask tensor(s) of a layer.</p>
<p>Only applicable if the layer has exactly one inbound node, i.e. if it is connected to one incoming layer.</p>
<h4 id="returns-4">Returns:</h4>
<pre><code>Output mask tensor (potentially None) or list of output
mask tensors.</code></pre>
<h4 id="raises-4">Raises:</h4>
<pre><code>AttributeError: if the layer is connected to
more than one incoming layers.</code></pre>
<h3 id="output_shape">
<code>output_shape</code>
</h3>
<p>Retrieves the output shape(s) of a layer.</p>
<p>Only applicable if the layer has one inbound node, or if all inbound nodes have the same output shape.</p>
<h4 id="returns-5">Returns:</h4>
<pre><code>Output shape, as `TensorShape`
(or list of `TensorShape`, one tuple per output tensor).</code></pre>
<h4 id="raises-5">Raises:</h4>
<pre><code>AttributeError: if the layer is connected to
more than one incoming layers.</code></pre>
<h3 id="scope_name">
<code>scope_name</code>
</h3>
<h3 id="trainable_variables">
<code>trainable_variables</code>
</h3>
<h3 id="trainable_weights">
<code>trainable_weights</code>
</h3>
<h3 id="updates">
<code>updates</code>
</h3>
<h3 id="variables">
<code>variables</code>
</h3>
<p>Returns the list of all layer variables/weights.</p>
<h4 id="returns-6">Returns:</h4>
<p>A list of variables.</p>
<h3 id="weights">
<code>weights</code>
</h3>
<p>Returns the list of all layer variables/weights.</p>
<h4 id="returns-7">Returns:</h4>
<p>A list of variables.</p>
<h2 id="methods-1">Methods</h2>
<h3 id="__init__">
<code><strong>init</strong></code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="fu">__init__</span>(<span class="op">**</span>kwargs)</code></pre></div>
<h3 id="__call__">
<code><strong>call</strong></code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="fu">__call__</span>(
    inputs,
    <span class="op">**</span>kwargs
)</code></pre></div>
<p>Wrapper around self.call(), for handling internal references.</p>
<p>If a Keras tensor is passed: - We call self._add_inbound_node(). - If necessary, we <code>build</code> the layer to match the shape of the input(s). - We update the _keras_history of the output tensor(s) with the current layer. This is done as part of _add_inbound_node().</p>
<h4 id="arguments">Arguments:</h4>
<pre><code>inputs: Can be a tensor or list/tuple of tensors.
**kwargs: Additional keyword arguments to be passed to `call()`.</code></pre>
<h4 id="returns-8">Returns:</h4>
<pre><code>Output of the layer&#39;s `call` method.</code></pre>
<h4 id="raises-6">Raises:</h4>
<pre><code>ValueError: in case the layer is missing shape information
    for its `build` call.</code></pre>
<h3 id="__deepcopy__">
<code><strong>deepcopy</strong></code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">__deepcopy__(memo)</code></pre></div>
<h3 id="add_loss">
<code>add_loss</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">add_loss(
    losses,
    inputs<span class="op">=</span><span class="va">None</span>
)</code></pre></div>
<p>Add loss tensor(s), potentially dependent on layer inputs.</p>
<p>Some losses (for instance, activity regularization losses) may be dependent on the inputs passed when calling a layer. Hence, when reusing a same layer on different inputs <code>a</code> and <code>b</code>, some entries in <code>layer.losses</code> may be dependent on <code>a</code> and some on <code>b</code>. This method automatically keeps track of dependencies.</p>
<p>The <code>get_losses_for</code> method allows to retrieve the losses relevant to a specific set of inputs.</p>
<h4 id="arguments-1">Arguments:</h4>
<ul>
<li><b><code>losses</code></b>: Loss tensor, or list/tuple of tensors.</li>
<li><b><code>inputs</code></b>: Optional input tensor(s) that the loss(es) depend on. Must match the <code>inputs</code> argument passed to the <code>__call__</code> method at the time the losses are created. If <code>None</code> is passed, the losses are assumed to be unconditional, and will apply across all dataflows of the layer (e.g. weight regularization losses).</li>
</ul>
<h3 id="add_update">
<code>add_update</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">add_update(
    updates,
    inputs<span class="op">=</span><span class="va">None</span>
)</code></pre></div>
<p>Add update op(s), potentially dependent on layer inputs.</p>
<p>Weight updates (for instance, the updates of the moving mean and variance in a BatchNormalization layer) may be dependent on the inputs passed when calling a layer. Hence, when reusing a same layer on different inputs <code>a</code> and <code>b</code>, some entries in <code>layer.updates</code> may be dependent on <code>a</code> and some on <code>b</code>. This method automatically keeps track of dependencies.</p>
<p>The <code>get_updates_for</code> method allows to retrieve the updates relevant to a specific set of inputs.</p>
<h4 id="arguments-2">Arguments:</h4>
<ul>
<li><b><code>updates</code></b>: Update op, or list/tuple of update ops.</li>
<li><b><code>inputs</code></b>: Optional input tensor(s) that the update(s) depend on. Must match the <code>inputs</code> argument passed to the <code>__call__</code> method at the time the updates are created. If <code>None</code> is passed, the updates are assumed to be unconditional, and will apply across all dataflows of the layer.</li>
</ul>
<h3 id="add_variable">
<code>add_variable</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">add_variable(
    name,
    shape,
    dtype<span class="op">=</span><span class="va">None</span>,
    initializer<span class="op">=</span><span class="va">None</span>,
    regularizer<span class="op">=</span><span class="va">None</span>,
    trainable<span class="op">=</span><span class="va">True</span>
)</code></pre></div>
<p>Adds a new variable to the layer, or gets an existing one; returns it.</p>
<h4 id="arguments-3">Arguments:</h4>
<ul>
<li><b><code>name</code></b>: variable name.</li>
<li><b><code>shape</code></b>: variable shape.</li>
<li><b><code>dtype</code></b>: The type of the variable. Defaults to <code>self.dtype</code>.</li>
<li><b><code>initializer</code></b>: initializer instance (callable).</li>
<li><b><code>regularizer</code></b>: regularizer instance (callable).</li>
<li><b><code>trainable</code></b>: whether the variable should be part of the layer's &quot;trainable_variables&quot; (e.g. variables, biases) or &quot;non_trainable_variables&quot; (e.g. BatchNorm mean, stddev).</li>
</ul>
<h4 id="returns-9">Returns:</h4>
<p>The created variable.</p>
<h3 id="add_weight">
<code>add_weight</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">add_weight(
    name,
    shape,
    dtype<span class="op">=</span><span class="va">None</span>,
    initializer<span class="op">=</span><span class="va">None</span>,
    regularizer<span class="op">=</span><span class="va">None</span>,
    trainable<span class="op">=</span><span class="va">True</span>,
    constraint<span class="op">=</span><span class="va">None</span>
)</code></pre></div>
<p>Adds a weight variable to the layer.</p>
<h4 id="arguments-4">Arguments:</h4>
<pre><code>name: String, the name for the weight variable.
shape: The shape tuple of the weight.
dtype: The dtype of the weight.
initializer: An Initializer instance (callable).
regularizer: An optional Regularizer instance.
trainable: A boolean, whether the weight should
    be trained via backprop or not (assuming
    that the layer itself is also trainable).
constraint: An optional Constraint instance.</code></pre>
<h4 id="returns-10">Returns:</h4>
<pre><code>The created weight variable.</code></pre>
<h3 id="apply">
<code>apply</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="bu">apply</span>(
    inputs,
    <span class="op">*</span>args,
    <span class="op">**</span>kwargs
)</code></pre></div>
<p>Apply the layer on a input.</p>
<p>This simply wraps <code>self.__call__</code>.</p>
<h4 id="arguments-5">Arguments:</h4>
<ul>
<li><b><code>inputs</code></b>: Input tensor(s). *args: additional positional arguments to be passed to <code>self.call</code>. **kwargs: additional keyword arguments to be passed to <code>self.call</code>.</li>
</ul>
<h4 id="returns-11">Returns:</h4>
<p>Output tensor(s).</p>
<h3 id="build">
<code>build</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">build(input_shape)</code></pre></div>
<p>Creates the layer weights.</p>
<p>Must be implemented on all layers that have weights.</p>
<h4 id="arguments-6">Arguments:</h4>
<pre><code>input_shape: Keras tensor (future input to layer)
    or list/tuple of Keras tensors to reference
    for weight shape computations.</code></pre>
<h3 id="call">
<code>call</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">call(
    inputs,
    <span class="op">**</span>kwargs
)</code></pre></div>
<p>This is where the layer's logic lives.</p>
<h4 id="arguments-7">Arguments:</h4>
<pre><code>inputs: Input tensor, or list/tuple of input tensors.
**kwargs: Additional keyword arguments.</code></pre>
<h4 id="returns-12">Returns:</h4>
<pre><code>A tensor or list/tuple of tensors.</code></pre>
<h3 id="compute_mask">
<code>compute_mask</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">compute_mask(
    inputs,
    mask<span class="op">=</span><span class="va">None</span>
)</code></pre></div>
<p>Computes an output mask tensor.</p>
<h4 id="arguments-8">Arguments:</h4>
<pre><code>inputs: Tensor or list of tensors.
mask: Tensor or list of tensors.</code></pre>
<h4 id="returns-13">Returns:</h4>
<pre><code>None or a tensor (or list of tensors,
    one per output tensor of the layer).</code></pre>
<h3 id="count_params">
<code>count_params</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">count_params()</code></pre></div>
<p>Count the total number of scalars composing the weights.</p>
<h4 id="returns-14">Returns:</h4>
<pre><code>An integer count.</code></pre>
<h4 id="raises-7">Raises:</h4>
<pre><code>RuntimeError: if the layer isn&#39;t yet built
    (in which case its weights aren&#39;t yet defined).</code></pre>
<h3 id="from_config">
<code>from_config</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">from_config(
    cls,
    config
)</code></pre></div>
<p>Creates a layer from its config.</p>
<p>This method is the reverse of <code>get_config</code>, capable of instantiating the same layer from the config dictionary. It does not handle layer connectivity (handled by Container), nor weights (handled by <code>set_weights</code>).</p>
<h4 id="arguments-9">Arguments:</h4>
<pre><code>config: A Python dictionary, typically the
    output of get_config.</code></pre>
<h4 id="returns-15">Returns:</h4>
<pre><code>A layer instance.</code></pre>
<h3 id="get_config">
<code>get_config</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">get_config()</code></pre></div>
<p>Returns the config of the layer.</p>
<p>A layer config is a Python dictionary (serializable) containing the configuration of a layer. The same layer can be reinstantiated later (without its trained weights) from this configuration.</p>
<p>The config of a layer does not include connectivity information, nor the layer class name. These are handled by <code>Container</code> (one layer of abstraction above).</p>
<h4 id="returns-16">Returns:</h4>
<pre><code>Python dictionary.</code></pre>
<h3 id="get_input_at">
<code>get_input_at</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">get_input_at(node_index)</code></pre></div>
<p>Retrieves the input tensor(s) of a layer at a given node.</p>
<h4 id="arguments-10">Arguments:</h4>
<pre><code>node_index: Integer, index of the node
    from which to retrieve the attribute.
    E.g. `node_index=0` will correspond to the
    first time the layer was called.</code></pre>
<h4 id="returns-17">Returns:</h4>
<pre><code>A tensor (or list of tensors if the layer has multiple inputs).</code></pre>
<h3 id="get_input_mask_at">
<code>get_input_mask_at</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">get_input_mask_at(node_index)</code></pre></div>
<p>Retrieves the input mask tensor(s) of a layer at a given node.</p>
<h4 id="arguments-11">Arguments:</h4>
<pre><code>node_index: Integer, index of the node
    from which to retrieve the attribute.
    E.g. `node_index=0` will correspond to the
    first time the layer was called.</code></pre>
<h4 id="returns-18">Returns:</h4>
<pre><code>A mask tensor
(or list of tensors if the layer has multiple inputs).</code></pre>
<h3 id="get_input_shape_at">
<code>get_input_shape_at</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">get_input_shape_at(node_index)</code></pre></div>
<p>Retrieves the input shape(s) of a layer at a given node.</p>
<h4 id="arguments-12">Arguments:</h4>
<pre><code>node_index: Integer, index of the node
    from which to retrieve the attribute.
    E.g. `node_index=0` will correspond to the
    first time the layer was called.</code></pre>
<h4 id="returns-19">Returns:</h4>
<pre><code>A shape tuple
(or list of shape tuples if the layer has multiple inputs).</code></pre>
<h3 id="get_losses_for">
<code>get_losses_for</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">get_losses_for(inputs)</code></pre></div>
<p>Retrieves losses relevant to a specific set of inputs.</p>
<h4 id="arguments-13">Arguments:</h4>
<ul>
<li><b><code>inputs</code></b>: Input tensor or list/tuple of input tensors. Must match the <code>inputs</code> argument passed to the <code>__call__</code> method at the time the losses were created. If you pass <code>inputs=None</code>, unconditional losses are returned, such as weight regularization losses.</li>
</ul>
<h4 id="returns-20">Returns:</h4>
<p>List of loss tensors of the layer that depend on <code>inputs</code>.</p>
<h3 id="get_output_at">
<code>get_output_at</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">get_output_at(node_index)</code></pre></div>
<p>Retrieves the output tensor(s) of a layer at a given node.</p>
<h4 id="arguments-14">Arguments:</h4>
<pre><code>node_index: Integer, index of the node
    from which to retrieve the attribute.
    E.g. `node_index=0` will correspond to the
    first time the layer was called.</code></pre>
<h4 id="returns-21">Returns:</h4>
<pre><code>A tensor (or list of tensors if the layer has multiple outputs).</code></pre>
<h3 id="get_output_mask_at">
<code>get_output_mask_at</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">get_output_mask_at(node_index)</code></pre></div>
<p>Retrieves the output mask tensor(s) of a layer at a given node.</p>
<h4 id="arguments-15">Arguments:</h4>
<pre><code>node_index: Integer, index of the node
    from which to retrieve the attribute.
    E.g. `node_index=0` will correspond to the
    first time the layer was called.</code></pre>
<h4 id="returns-22">Returns:</h4>
<pre><code>A mask tensor
(or list of tensors if the layer has multiple outputs).</code></pre>
<h3 id="get_output_shape_at">
<code>get_output_shape_at</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">get_output_shape_at(node_index)</code></pre></div>
<p>Retrieves the output shape(s) of a layer at a given node.</p>
<h4 id="arguments-16">Arguments:</h4>
<pre><code>node_index: Integer, index of the node
    from which to retrieve the attribute.
    E.g. `node_index=0` will correspond to the
    first time the layer was called.</code></pre>
<h4 id="returns-23">Returns:</h4>
<pre><code>A shape tuple
(or list of shape tuples if the layer has multiple outputs).</code></pre>
<h3 id="get_updates_for">
<code>get_updates_for</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">get_updates_for(inputs)</code></pre></div>
<p>Retrieves updates relevant to a specific set of inputs.</p>
<h4 id="arguments-17">Arguments:</h4>
<ul>
<li><b><code>inputs</code></b>: Input tensor or list/tuple of input tensors. Must match the <code>inputs</code> argument passed to the <code>__call__</code> method at the time the updates were created. If you pass <code>inputs=None</code>, unconditional updates are returned.</li>
</ul>
<h4 id="returns-24">Returns:</h4>
<p>List of update ops of the layer that depend on <code>inputs</code>.</p>
<h3 id="get_weights">
<code>get_weights</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">get_weights()</code></pre></div>
<p>Returns the current weights of the layer.</p>
<h4 id="returns-25">Returns:</h4>
<pre><code>Weights values as a list of numpy arrays.</code></pre>
<h3 id="set_weights">
<code>set_weights</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">set_weights(weights)</code></pre></div>
<p>Sets the weights of the layer, from Numpy arrays.</p>
<h4 id="arguments-18">Arguments:</h4>
<pre><code>weights: a list of Numpy arrays. The number
    of arrays and their shape must match
    number of the dimensions of the weights
    of the layer (i.e. it should match the
    output of `get_weights`).</code></pre>
<h4 id="raises-8">Raises:</h4>
<pre><code>ValueError: If the provided weights list does not match the
    layer&#39;s specifications.</code></pre>

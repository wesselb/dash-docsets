<div itemscope="" itemtype="http://developers.google.com/ReferenceObject">
<p><meta itemprop="name" content="tf.contrib.keras.preprocessing.text.Tokenizer" /> <meta itemprop="property" content="__init__"/> <meta itemprop="property" content="fit_on_sequences"/> <meta itemprop="property" content="fit_on_texts"/> <meta itemprop="property" content="sequences_to_matrix"/> <meta itemprop="property" content="texts_to_matrix"/> <meta itemprop="property" content="texts_to_sequences"/> <meta itemprop="property" content="texts_to_sequences_generator"/></p>
</div>
<a name="//apple_ref/cpp/Class/tf.contrib.keras.preprocessing.text.Tokenizer" class="dashAnchor"></a><h1 id="tf.contrib.keras.preprocessing.text.tokenizer">tf.contrib.keras.preprocessing.text.Tokenizer</h1>
<h3 id="class-tf.contrib.keras.preprocessing.text.tokenizer"><code>class tf.contrib.keras.preprocessing.text.Tokenizer</code></h3>
<p>Defined in <a href="https://www.tensorflow.org/code/tensorflow/contrib/keras/python/keras/preprocessing/text.py"><code>tensorflow/contrib/keras/python/keras/preprocessing/text.py</code></a>.</p>
<p>Text tokenization utility class.</p>
<p>This class allows to vectorize a text corpus, by turning each text into either a sequence of integers (each integer being the index of a token in a dictionary) or into a vector where the coefficient for each token could be binary, based on word count, based on tf-idf...</p>
<h4 id="arguments">Arguments:</h4>
<pre><code>num_words: the maximum number of words to keep, based
    on word frequency. Only the most common `num_words` words will
    be kept.
filters: a string where each element is a character that will be
    filtered from the texts. The default is all punctuation, plus
    tabs and line breaks, minus the `&#39;` character.
lower: boolean. Whether to convert the texts to lowercase.
split: character or string to use for token splitting.
char_level: if True, every character will be treated as a word.</code></pre>
<p>By default, all punctuation is removed, turning the texts into space-separated sequences of words (words maybe include the <code>'</code> character). These sequences are then split into lists of tokens. They will then be indexed or vectorized.</p>
<p><code>0</code> is a reserved index that won't be assigned to any word.</p>
<h2 id="methods">Methods</h2>
<h3 id="__init__">
<code><strong>init</strong></code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="fu">__init__</span>(
    num_words<span class="op">=</span><span class="va">None</span>,
    filters<span class="op">=</span><span class="st">&#39;!&quot;#$%&amp;()*+,-./:;&lt;=&gt;?@[</span><span class="ch">\\</span><span class="st">]^_`{|}~</span><span class="ch">\t\n</span><span class="st">&#39;</span>,
    lower<span class="op">=</span><span class="va">True</span>,
    split<span class="op">=</span><span class="st">&#39; &#39;</span>,
    char_level<span class="op">=</span><span class="va">False</span>,
    <span class="op">**</span>kwargs
)</code></pre></div>
<h3 id="fit_on_sequences">
<code>fit_on_sequences</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">fit_on_sequences(sequences)</code></pre></div>
<p>Updates internal vocabulary based on a list of sequences.</p>
<p>Required before using <code>sequences_to_matrix</code> (if <code>fit_on_texts</code> was never called).</p>
<h4 id="arguments-1">Arguments:</h4>
<pre><code>sequences: A list of sequence.
    A &quot;sequence&quot; is a list of integer word indices.</code></pre>
<h3 id="fit_on_texts">
<code>fit_on_texts</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">fit_on_texts(texts)</code></pre></div>
<p>Updates internal vocabulary based on a list of texts.</p>
<p>Required before using <code>texts_to_sequences</code> or <code>texts_to_matrix</code>.</p>
<h4 id="arguments-2">Arguments:</h4>
<pre><code>texts: can be a list of strings,
    or a generator of strings (for memory-efficiency)</code></pre>
<h3 id="sequences_to_matrix">
<code>sequences_to_matrix</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">sequences_to_matrix(
    sequences,
    mode<span class="op">=</span><span class="st">&#39;binary&#39;</span>
)</code></pre></div>
<p>Converts a list of sequences into a Numpy matrix.</p>
<h4 id="arguments-3">Arguments:</h4>
<pre><code>sequences: list of sequences
    (a sequence is a list of integer word indices).
mode: one of &quot;binary&quot;, &quot;count&quot;, &quot;tfidf&quot;, &quot;freq&quot;</code></pre>
<h4 id="returns">Returns:</h4>
<pre><code>A Numpy matrix.</code></pre>
<h4 id="raises">Raises:</h4>
<pre><code>ValueError: In case of invalid `mode` argument,
    or if the Tokenizer requires to be fit to sample data.</code></pre>
<h3 id="texts_to_matrix">
<code>texts_to_matrix</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">texts_to_matrix(
    texts,
    mode<span class="op">=</span><span class="st">&#39;binary&#39;</span>
)</code></pre></div>
<p>Convert a list of texts to a Numpy matrix.</p>
<h4 id="arguments-4">Arguments:</h4>
<pre><code>texts: list of strings.
mode: one of &quot;binary&quot;, &quot;count&quot;, &quot;tfidf&quot;, &quot;freq&quot;.</code></pre>
<h4 id="returns-1">Returns:</h4>
<pre><code>A Numpy matrix.</code></pre>
<h3 id="texts_to_sequences">
<code>texts_to_sequences</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">texts_to_sequences(texts)</code></pre></div>
<p>Transforms each text in texts in a sequence of integers.</p>
<p>Only top &quot;num_words&quot; most frequent words will be taken into account. Only words known by the tokenizer will be taken into account.</p>
<h4 id="arguments-5">Arguments:</h4>
<pre><code>texts: A list of texts (strings).</code></pre>
<h4 id="returns-2">Returns:</h4>
<pre><code>A list of sequences.</code></pre>
<h3 id="texts_to_sequences_generator">
<code>texts_to_sequences_generator</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">texts_to_sequences_generator(texts)</code></pre></div>
<p>Transforms each text in texts in a sequence of integers.</p>
<p>Only top &quot;num_words&quot; most frequent words will be taken into account. Only words known by the tokenizer will be taken into account.</p>
<h4 id="arguments-6">Arguments:</h4>
<pre><code>texts: A list of texts (strings).</code></pre>
<h4 id="yields">Yields:</h4>
<pre><code>Yields individual sequences.</code></pre>

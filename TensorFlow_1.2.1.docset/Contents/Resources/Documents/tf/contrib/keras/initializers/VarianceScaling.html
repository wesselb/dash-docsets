<div itemscope="" itemtype="http://developers.google.com/ReferenceObject">
<p><meta itemprop="name" content="tf.contrib.keras.initializers.VarianceScaling" /> <meta itemprop="property" content="__call__"/> <meta itemprop="property" content="__init__"/> <meta itemprop="property" content="from_config"/> <meta itemprop="property" content="get_config"/></p>
</div>
<a name="//apple_ref/cpp/Class/tf.contrib.keras.initializers.VarianceScaling" class="dashAnchor"></a><h1 id="tf.contrib.keras.initializers.variancescaling">tf.contrib.keras.initializers.VarianceScaling</h1>
<h3 id="class-tf.contrib.keras.initializers.variancescaling"><code>class tf.contrib.keras.initializers.VarianceScaling</code></h3>
<p>Defined in <a href="https://www.tensorflow.org/code/tensorflow/python/ops/init_ops.py"><code>tensorflow/python/ops/init_ops.py</code></a>.</p>
<p>Initializer capable of adapting its scale to the shape of weights tensors.</p>
<p>With <code>distribution=&quot;normal&quot;</code>, samples are drawn from a truncated normal distribution centered on zero, with <code>stddev = sqrt(scale / n)</code> where n is: - number of input units in the weight tensor, if mode = &quot;fan_in&quot; - number of output units, if mode = &quot;fan_out&quot; - average of the numbers of input and output units, if mode = &quot;fan_avg&quot;</p>
<p>With <code>distribution=&quot;uniform&quot;</code>, samples are drawn from a uniform distribution within [-limit, limit], with <code>limit = sqrt(3 * scale / n)</code>.</p>
<h4 id="arguments">Arguments:</h4>
<ul>
<li><b><code>scale</code></b>: Scaling factor (positive float).</li>
<li><b><code>mode</code></b>: One of &quot;fan_in&quot;, &quot;fan_out&quot;, &quot;fan_avg&quot;.</li>
<li><b><code>distribution</code></b>: Random distribution to use. One of &quot;normal&quot;, &quot;uniform&quot;.</li>
<li><b><code>seed</code></b>: A Python integer. Used to create random seeds. See <a href="../../../../tf/set_random_seed.html"><code>tf.set_random_seed</code></a> for behavior.</li>
<li><b><code>dtype</code></b>: The data type. Only floating point types are supported.</li>
</ul>
<h4 id="raises">Raises:</h4>
<ul>
<li><b><code>ValueError</code></b>: In case of an invalid value for the &quot;scale&quot;, mode&quot; or &quot;distribution&quot; arguments.</li>
</ul>
<h2 id="methods">Methods</h2>
<h3 id="__init__">
<code><strong>init</strong></code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="fu">__init__</span>(
    scale<span class="op">=</span><span class="fl">1.0</span>,
    mode<span class="op">=</span><span class="st">&#39;fan_in&#39;</span>,
    distribution<span class="op">=</span><span class="st">&#39;normal&#39;</span>,
    seed<span class="op">=</span><span class="va">None</span>,
    dtype<span class="op">=</span>tf.float32
)</code></pre></div>
<h3 id="__call__">
<code><strong>call</strong></code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="fu">__call__</span>(
    shape,
    dtype<span class="op">=</span><span class="va">None</span>,
    partition_info<span class="op">=</span><span class="va">None</span>
)</code></pre></div>
<h3 id="from_config">
<code>from_config</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">from_config(
    cls,
    config
)</code></pre></div>
<p>Instantiates an initializer from a configuration dictionary.</p>
<p>Example:</p>
<pre><code>initializer = RandomUniform(-1, 1)
config = initializer.get_config()
initializer = RandomUniform.from_config(config)</code></pre>
<h4 id="arguments-1">Arguments:</h4>
<ul>
<li><b><code>config</code></b>: A Python dictionary. It will typically be the output of <code>get_config</code>.</li>
</ul>
<h4 id="returns">Returns:</h4>
<p>An Initializer instance.</p>
<h3 id="get_config">
<code>get_config</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">get_config()</code></pre></div>

<div itemscope="" itemtype="http://developers.google.com/ReferenceObject">
<p><meta itemprop="name" content="tf.contrib.keras.callbacks.TensorBoard" /> <meta itemprop="property" content="__init__"/> <meta itemprop="property" content="on_batch_begin"/> <meta itemprop="property" content="on_batch_end"/> <meta itemprop="property" content="on_epoch_begin"/> <meta itemprop="property" content="on_epoch_end"/> <meta itemprop="property" content="on_train_begin"/> <meta itemprop="property" content="on_train_end"/> <meta itemprop="property" content="set_model"/> <meta itemprop="property" content="set_params"/></p>
</div>
<a name="//apple_ref/cpp/Class/tf.contrib.keras.callbacks.TensorBoard" class="dashAnchor"></a><h1 id="tf.contrib.keras.callbacks.tensorboard">tf.contrib.keras.callbacks.TensorBoard</h1>
<h3 id="class-tf.contrib.keras.callbacks.tensorboard"><code>class tf.contrib.keras.callbacks.TensorBoard</code></h3>
<p>Defined in <a href="https://www.tensorflow.org/code/tensorflow/contrib/keras/python/keras/callbacks.py"><code>tensorflow/contrib/keras/python/keras/callbacks.py</code></a>.</p>
<p>Tensorboard basic visualizations.</p>
<p>This callback writes a log for TensorBoard, which allows you to visualize dynamic graphs of your training and test metrics, as well as activation histograms for the different layers in your model.</p>
<h4 id="arguments">Arguments:</h4>
<pre><code>log_dir: the path of the directory where to save the log
    files to be parsed by Tensorboard.
histogram_freq: frequency (in epochs) at which to compute activation
    histograms for the layers of the model. If set to 0,
    histograms won&#39;t be computed.
write_graph: whether to visualize the graph in Tensorboard.
    The log file can become quite large when
    write_graph is set to True.
write_images: whether to write model weights to visualize as
    image in Tensorboard.
embeddings_freq: frequency (in epochs) at which selected embedding
    layers will be saved.
embeddings_layer_names: a list of names of layers to keep eye on. If
    None or empty list all the embedding layer will be watched.
embeddings_metadata: a dictionary which maps layer name to a file name
    in which metadata for this embedding layer is saved. See the
    [details](https://www.tensorflow.org/how_tos/embedding_viz/#metadata_optional)
    about metadata files format. In case if the same metadata file is
    used for all embedding layers, string can be passed.</code></pre>
<h2 id="methods">Methods</h2>
<h3 id="__init__">
<code><strong>init</strong></code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="fu">__init__</span>(
    log_dir<span class="op">=</span><span class="st">&#39;./logs&#39;</span>,
    histogram_freq<span class="op">=</span><span class="dv">0</span>,
    write_graph<span class="op">=</span><span class="va">True</span>,
    write_images<span class="op">=</span><span class="va">False</span>,
    embeddings_freq<span class="op">=</span><span class="dv">0</span>,
    embeddings_layer_names<span class="op">=</span><span class="va">None</span>,
    embeddings_metadata<span class="op">=</span><span class="va">None</span>
)</code></pre></div>
<h3 id="on_batch_begin">
<code>on_batch_begin</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">on_batch_begin(
    batch,
    logs<span class="op">=</span><span class="va">None</span>
)</code></pre></div>
<h3 id="on_batch_end">
<code>on_batch_end</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">on_batch_end(
    batch,
    logs<span class="op">=</span><span class="va">None</span>
)</code></pre></div>
<h3 id="on_epoch_begin">
<code>on_epoch_begin</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">on_epoch_begin(
    epoch,
    logs<span class="op">=</span><span class="va">None</span>
)</code></pre></div>
<h3 id="on_epoch_end">
<code>on_epoch_end</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">on_epoch_end(
    epoch,
    logs<span class="op">=</span><span class="va">None</span>
)</code></pre></div>
<h3 id="on_train_begin">
<code>on_train_begin</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">on_train_begin(logs<span class="op">=</span><span class="va">None</span>)</code></pre></div>
<h3 id="on_train_end">
<code>on_train_end</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">on_train_end(_)</code></pre></div>
<h3 id="set_model">
<code>set_model</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">set_model(model)</code></pre></div>
<h3 id="set_params">
<code>set_params</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">set_params(params)</code></pre></div>

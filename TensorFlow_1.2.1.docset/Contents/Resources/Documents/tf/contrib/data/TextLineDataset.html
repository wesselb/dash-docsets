<div itemscope="" itemtype="http://developers.google.com/ReferenceObject">
<p><meta itemprop="name" content="tf.contrib.data.TextLineDataset" /> <meta itemprop="property" content="output_shapes"/> <meta itemprop="property" content="output_types"/> <meta itemprop="property" content="__init__"/> <meta itemprop="property" content="batch"/> <meta itemprop="property" content="dense_to_sparse_batch"/> <meta itemprop="property" content="enumerate"/> <meta itemprop="property" content="filter"/> <meta itemprop="property" content="flat_map"/> <meta itemprop="property" content="from_sparse_tensor_slices"/> <meta itemprop="property" content="from_tensor_slices"/> <meta itemprop="property" content="from_tensors"/> <meta itemprop="property" content="group_by_window"/> <meta itemprop="property" content="make_dataset_resource"/> <meta itemprop="property" content="make_initializable_iterator"/> <meta itemprop="property" content="make_one_shot_iterator"/> <meta itemprop="property" content="map"/> <meta itemprop="property" content="padded_batch"/> <meta itemprop="property" content="range"/> <meta itemprop="property" content="read_batch_features"/> <meta itemprop="property" content="repeat"/> <meta itemprop="property" content="shuffle"/> <meta itemprop="property" content="skip"/> <meta itemprop="property" content="take"/> <meta itemprop="property" content="unbatch"/> <meta itemprop="property" content="zip"/></p>
</div>
<a name="//apple_ref/cpp/Class/tf.contrib.data.TextLineDataset" class="dashAnchor"></a><h1 id="tf.contrib.data.textlinedataset">tf.contrib.data.TextLineDataset</h1>
<h3 id="class-tf.contrib.data.textlinedataset"><code>class tf.contrib.data.TextLineDataset</code></h3>
<p>Defined in <a href="https://www.tensorflow.org/code/tensorflow/contrib/data/python/ops/dataset_ops.py"><code>tensorflow/contrib/data/python/ops/dataset_ops.py</code></a>.</p>
<p>A <code>Dataset</code> comprising lines from one or more text files.</p>
<h2 id="properties">Properties</h2>
<h3 id="output_shapes">
<code>output_shapes</code>
</h3>
<h3 id="output_types">
<code>output_types</code>
</h3>
<h2 id="methods">Methods</h2>
<h3 id="__init__">
<code><strong>init</strong></code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="fu">__init__</span>(filenames)</code></pre></div>
<p>Creates a <code>TextLineDataset</code>.</p>
<h4 id="args">Args:</h4>
<ul>
<li><b><code>filenames</code></b>: A <code>tf.string</code> tensor containing one or more filenames.</li>
</ul>
<h3 id="batch">
<code>batch</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">batch(batch_size)</code></pre></div>
<p>Combines consecutive elements of this dataset into batches.</p>
<h4 id="args-1">Args:</h4>
<ul>
<li><b><code>batch_size</code></b>: A <code>tf.int64</code> scalar <code>tf.Tensor</code>, representing the number of consecutive elements of this dataset to combine in a single batch.</li>
</ul>
<h4 id="returns">Returns:</h4>
<p>A <code>Dataset</code>.</p>
<h3 id="dense_to_sparse_batch">
<code>dense_to_sparse_batch</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">dense_to_sparse_batch(
    batch_size,
    row_shape
)</code></pre></div>
<p>Batches ragged elements of this dataset into <code>tf.SparseTensor</code>s.</p>
<p>Like <code>Dataset.padded_batch()</code>, this method combines multiple consecutive elements of this dataset, which might have different shapes, into a single element. The resulting element has three components (<code>indices</code>, <code>values</code>, and <code>dense_shape</code>), which comprise a <code>tf.SparseTensor</code> that represents the same data. The <code>row_shape</code> represents the dense shape of each row in the resulting <code>tf.SparseTensor</code>, to which the effective batch size is prepended. For example:</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="co"># </span><span class="al">NOTE</span><span class="co">: The following examples use `{ ... }` to represent the</span>
<span class="co"># contents of a dataset.</span>
a <span class="op">=</span> { [<span class="st">&#39;a&#39;</span>, <span class="st">&#39;b&#39;</span>, <span class="st">&#39;c&#39;</span>], [<span class="st">&#39;a&#39;</span>, <span class="st">&#39;b&#39;</span>], [<span class="st">&#39;a&#39;</span>, <span class="st">&#39;b&#39;</span>, <span class="st">&#39;c&#39;</span>, <span class="st">&#39;d&#39;</span>] }

a.dense_to_sparse_batch(batch_size<span class="op">=</span><span class="dv">2</span>, row_shape<span class="op">=</span>[<span class="dv">6</span>]) <span class="op">==</span> {
    ([[<span class="dv">0</span>, <span class="dv">0</span>], [<span class="dv">0</span>, <span class="dv">1</span>], [<span class="dv">0</span>, <span class="dv">2</span>], [<span class="dv">1</span>, <span class="dv">0</span>], [<span class="dv">1</span>, <span class="dv">1</span>]],  <span class="co"># indices</span>
     [<span class="st">&#39;a&#39;</span>, <span class="st">&#39;b&#39;</span>, <span class="st">&#39;c&#39;</span>, <span class="st">&#39;a&#39;</span>, <span class="st">&#39;b&#39;</span>],                 <span class="co"># values</span>
     [<span class="dv">2</span>, <span class="dv">6</span>]),                                   <span class="co"># dense_shape</span>
    ([[<span class="dv">2</span>, <span class="dv">0</span>], [<span class="dv">2</span>, <span class="dv">1</span>], [<span class="dv">2</span>, <span class="dv">2</span>], [<span class="dv">2</span>, <span class="dv">3</span>]],
     [<span class="st">&#39;a&#39;</span>, <span class="st">&#39;b&#39;</span>, <span class="st">&#39;c&#39;</span>, <span class="st">&#39;d&#39;</span>],
     [<span class="dv">1</span>, <span class="dv">6</span>])
}</code></pre></div>
<h4 id="args-2">Args:</h4>
<ul>
<li><b><code>batch_size</code></b>: A <code>tf.int64</code> scalar <code>tf.Tensor</code>, representing the number of consecutive elements of this dataset to combine in a single batch.</li>
<li><b><code>row_shape</code></b>: A <code>tf.TensorShape</code> or <code>tf.int64</code> vector tensor-like object representing the equivalent dense shape of a row in the resulting <code>tf.SparseTensor</code>. Each element of this dataset must have the same rank as <code>row_shape</code>, and must have size less than or equal to <code>row_shape</code> in each dimension.</li>
</ul>
<h4 id="returns-1">Returns:</h4>
<p>A <code>Dataset</code>.</p>
<h3 id="enumerate">
<code>enumerate</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="bu">enumerate</span>(start<span class="op">=</span><span class="dv">0</span>)</code></pre></div>
<p>Enumerate the elements of this dataset. Similar to python's <code>enumerate</code>.</p>
<p>For example:</p>
<p>``<code>python # NOTE: The following examples use</code>{ ... }` to represent the # contents of a dataset. a = { 1, 2, 3 } b = { (7, 8), (9, 10), (11, 12) }</p>
<h1 id="the-nested-structure-of-the-datasets-argument-determines-the">The nested structure of the <code>datasets</code> argument determines the</h1>
<h1 id="structure-of-elements-in-the-resulting-dataset.">structure of elements in the resulting dataset.</h1>
<p>a.enumerate(start=5) == { (5, 1), (6, 2), (7, 3) } b.enumerate() == { (0, (7, 8)), (1, (9, 10)), (2, (11, 12)) }</p>
<h4 id="args-3">Args:</h4>
<ul>
<li><b><code>start</code></b>: A <code>tf.int64</code> scalar <code>tf.Tensor</code>, representing the start value for enumeration.</li>
</ul>
<h4 id="returns-2">Returns:</h4>
<p>A <code>Dataset</code>.</p>
<h3 id="filter">
<code>filter</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="bu">filter</span>(predicate)</code></pre></div>
<p>Filters this dataset according to <code>predicate</code>.</p>
<h4 id="args-4">Args:</h4>
<ul>
<li><b><code>predicate</code></b>: A function mapping a nested structure of tensors (having shapes and types defined by <code>self.output_shapes</code> and <code>self.output_types</code>) to a scalar <code>tf.bool</code> tensor.</li>
</ul>
<h4 id="returns-3">Returns:</h4>
<p>A <code>Dataset</code>.</p>
<h3 id="flat_map">
<code>flat_map</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">flat_map(map_func)</code></pre></div>
<p>Maps <code>map_func</code> across this dataset and flattens the result.</p>
<h4 id="args-5">Args:</h4>
<ul>
<li><b><code>map_func</code></b>: A function mapping a nested structure of tensors (having shapes and types defined by <code>self.output_shapes</code> and <code>self.output_types</code>) to a <code>Dataset</code>.</li>
</ul>
<h4 id="returns-4">Returns:</h4>
<p>A <code>Dataset</code>.</p>
<h3 id="from_sparse_tensor_slices">
<code>from_sparse_tensor_slices</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">from_sparse_tensor_slices(sparse_tensor)</code></pre></div>
<p>Splits each rank-N <code>tf.SparseTensor</code> in this dataset row-wise.</p>
<h4 id="args-6">Args:</h4>
<ul>
<li><b><code>sparse_tensor</code></b>: A <code>tf.SparseTensor</code>.</li>
</ul>
<h4 id="returns-5">Returns:</h4>
<p>A <code>Dataset</code> of rank-(N-1) sparse tensors.</p>
<h3 id="from_tensor_slices">
<code>from_tensor_slices</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">from_tensor_slices(tensors)</code></pre></div>
<p>Creates a <code>Dataset</code> whose elements are slices of the given tensors.</p>
<h4 id="args-7">Args:</h4>
<ul>
<li><b><code>tensors</code></b>: A nested structure of tensors, each having the same size in the 0th dimension.</li>
</ul>
<h4 id="returns-6">Returns:</h4>
<p>A <code>Dataset</code>.</p>
<h3 id="from_tensors">
<code>from_tensors</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">from_tensors(tensors)</code></pre></div>
<p>Creates a <code>Dataset</code> with a single element, comprising the given tensors.</p>
<h4 id="args-8">Args:</h4>
<ul>
<li><b><code>tensors</code></b>: A nested structure of tensors.</li>
</ul>
<h4 id="returns-7">Returns:</h4>
<p>A <code>Dataset</code>.</p>
<h3 id="group_by_window">
<code>group_by_window</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">group_by_window(
    key_func,
    reduce_func,
    window_size
)</code></pre></div>
<p>Performs a windowed &quot;group-by&quot; operation on this dataset.</p>
<p>This method maps each consecutive element in this dataset to a key using <code>key_func</code> and groups the elements by key. It then applies <code>reduce_func</code> to at most <code>window_size</code> elements matching the same key. All execpt the final window for each key will contain <code>window_size</code> elements; the final window may be smaller.</p>
<h4 id="args-9">Args:</h4>
<ul>
<li><b><code>key_func</code></b>: A function mapping a nested structure of tensors (having shapes and types defined by <code>self.output_shapes</code> and <code>self.output_types</code>) to a scalar <code>tf.int64</code> tensor.</li>
<li><b><code>reduce_func</code></b>: A function mapping a key and a dataset of up to <code>batch_size</code> consecutive elements matching that key to another dataset.</li>
<li><b><code>window_size</code></b>: A <code>tf.int64</code> scalar <code>tf.Tensor</code>, representing the number of consecutive elements matching the same key to combine in a single batch, which will be passed to <code>reduce_func</code>.</li>
</ul>
<h4 id="returns-8">Returns:</h4>
<p>A <code>Dataset</code>.</p>
<h3 id="make_dataset_resource">
<code>make_dataset_resource</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">make_dataset_resource()</code></pre></div>
<h3 id="make_initializable_iterator">
<code>make_initializable_iterator</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">make_initializable_iterator(shared_name<span class="op">=</span><span class="va">None</span>)</code></pre></div>
<p>Creates an <code>Iterator</code> for enumerating the elements of this dataset.</p>
<p><strong>N.B.</strong> The returned iterator will be in an uninitialized state, and you must run the <code>iterator.initializer</code> operation before using it.</p>
<h4 id="args-10">Args:</h4>
<ul>
<li><b><code>shared_name</code></b>: (Optional.) If non-empty, this iterator will be shared under the given name across multiple sessions that share the same devices (e.g. when using a remote server).</li>
</ul>
<h4 id="returns-9">Returns:</h4>
<p>An <code>Iterator</code> over the elements of this dataset.</p>
<h3 id="make_one_shot_iterator">
<code>make_one_shot_iterator</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">make_one_shot_iterator()</code></pre></div>
<p>Creates an <code>Iterator</code> for enumerating the elements of this dataset.</p>
<p><strong>N.B.</strong> The returned iterator will be initialized automatically. A &quot;one-shot&quot; iterator does not currently support re-initialization.</p>
<h4 id="returns-10">Returns:</h4>
<p>An <code>Iterator</code> over the elements of this dataset.</p>
<h3 id="map">
<code>map</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="bu">map</span>(
    map_func,
    num_threads<span class="op">=</span><span class="va">None</span>,
    output_buffer_size<span class="op">=</span><span class="va">None</span>
)</code></pre></div>
<p>Maps <code>map_func</code> across this datset.</p>
<h4 id="args-11">Args:</h4>
<ul>
<li><b><code>map_func</code></b>: A function mapping a nested structure of tensors (having shapes and types defined by <code>self.output_shapes</code> and <code>self.output_types</code>) to another nested structure of tensors.</li>
<li><b><code>num_threads</code></b>: (Optional.) A <code>tf.int32</code> scalar <code>tf.Tensor</code>, representing the number of threads to use for processing elements in parallel. If not specified, elements will be processed sequentially without buffering.</li>
<li><b><code>output_buffer_size</code></b>: (Optional.) A <code>tf.int64</code> scalar <code>tf.Tensor</code>, representing the maximum number of processed elements that will be buffered when processing in parallel.</li>
</ul>
<h4 id="returns-11">Returns:</h4>
<p>A <code>Dataset</code>.</p>
<h3 id="padded_batch">
<code>padded_batch</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">padded_batch(
    batch_size,
    padded_shapes,
    padding_values<span class="op">=</span><span class="va">None</span>
)</code></pre></div>
<p>Combines consecutive elements of this dataset into padded batches.</p>
<p>Like <code>Dataset.dense_to_sparse_batch()</code>, this method combines multiple consecutive elements of this dataset, which might have different shapes, into a single element. The tensors in the resulting element have an additional outer dimension, and are padded to the respective shape in <code>padded_shapes</code>.</p>
<h4 id="args-12">Args:</h4>
<ul>
<li><b><code>batch_size</code></b>: A <code>tf.int64</code> scalar <code>tf.Tensor</code>, representing the number of consecutive elements of this dataset to combine in a single batch.</li>
<li><b><code>padded_shapes</code></b>: A nested structure of <code>tf.TensorShape</code> or <code>tf.int64</code> vector tensor-like objects representing the shape to which the respective component of each input element should be padded prior to batching. Any unknown dimensions (e.g. <code>tf.Dimension(None)</code> in a <code>tf.TensorShape</code> or <code>-1</code> in a tensor-like object) will be padded to the maximum size of that dimension in each batch.</li>
<li><b><code>padding_values</code></b>: (Optional.) A nested structure of scalar-shaped <code>tf.Tensor</code>, representing the padding values to use for the respective components. Defaults are <code>0</code> for numeric types and the empty string for string types.</li>
</ul>
<h4 id="returns-12">Returns:</h4>
<p>A <code>Dataset</code>.</p>
<h3 id="range">
<code>range</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="bu">range</span>(<span class="op">*</span>args)</code></pre></div>
<p>Creates a <code>Dataset</code> of a step-separated range of values.</p>
<p>For example:</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">Dataset.<span class="bu">range</span>(<span class="dv">5</span>) <span class="op">==</span> [<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>]
Dataset.<span class="bu">range</span>(<span class="dv">2</span>, <span class="dv">5</span>) <span class="op">==</span> [<span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>]
Dataset.<span class="bu">range</span>(<span class="dv">1</span>, <span class="dv">5</span>, <span class="dv">2</span>) <span class="op">==</span> [<span class="dv">1</span>, <span class="dv">3</span>]
Dataset.<span class="bu">range</span>(<span class="dv">1</span>, <span class="dv">5</span>, <span class="op">-</span><span class="dv">2</span>) <span class="op">==</span> []
Dataset.<span class="bu">range</span>(<span class="dv">5</span>, <span class="dv">1</span>) <span class="op">==</span> []
Dataset.<span class="bu">range</span>(<span class="dv">5</span>, <span class="dv">1</span>, <span class="op">-</span><span class="dv">2</span>) <span class="op">==</span> [<span class="dv">5</span>, <span class="dv">3</span>]</code></pre></div>
<h4 id="args-13">Args:</h4>
<p>*args: follow same semantics as python's xrange. len(args) == 1 -&gt; start = 0, stop = args[0], step = 1 len(args) == 2 -&gt; start = args[0], stop = args[1], step = 1 len(args) == 3 -&gt; start = args[0], stop = args[1, stop = args[2]</p>
<h4 id="returns-13">Returns:</h4>
<p>A <code>RangeDataset</code>.</p>
<h4 id="raises">Raises:</h4>
<ul>
<li><b><code>ValueError</code></b>: if len(args) == 0.</li>
</ul>
<h3 id="read_batch_features">
<code>read_batch_features</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">read_batch_features(
    file_pattern,
    batch_size,
    features,
    reader,
    reader_args<span class="op">=</span><span class="va">None</span>,
    randomize_input<span class="op">=</span><span class="va">True</span>,
    num_epochs<span class="op">=</span><span class="va">None</span>,
    capacity<span class="op">=</span><span class="dv">10000</span>
)</code></pre></div>
<p>Reads batches of Examples.</p>
<h4 id="args-14">Args:</h4>
<ul>
<li><b><code>file_pattern</code></b>: A string pattern or a placeholder with list of filenames.</li>
<li><b><code>batch_size</code></b>: A <code>tf.int64</code> scalar <code>tf.Tensor</code>, representing the number of consecutive elements of this dataset to combine in a single batch.</li>
<li><b><code>features</code></b>: A <code>dict</code> mapping feature keys to <code>FixedLenFeature</code> or <code>VarLenFeature</code> values. See <code>tf.parse_example</code>.</li>
<li><b><code>reader</code></b>: A function or class that can be called with a <code>filenames</code> tensor and (optional) <code>reader_args</code> and returns a <code>Dataset</code> of serialized Examples.</li>
<li><b><code>reader_args</code></b>: Additional arguments to pass to the reader class.</li>
<li><b><code>randomize_input</code></b>: Whether the input should be randomized.</li>
<li><b><code>num_epochs</code></b>: Integer specifying the number of times to read through the dataset. If None, cycles through the dataset forever.</li>
<li><b><code>capacity</code></b>: Capacity of the ShuffleDataset.</li>
</ul>
<h4 id="returns-14">Returns:</h4>
<p>A <code>Dataset</code>.</p>
<h3 id="repeat">
<code>repeat</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">repeat(count<span class="op">=</span><span class="va">None</span>)</code></pre></div>
<p>Repeats this dataset <code>count</code> times.</p>
<h4 id="args-15">Args:</h4>
<ul>
<li><b><code>count</code></b>: (Optional.) A <code>tf.int64</code> scalar <code>tf.Tensor</code>, representing the number of times the elements of this dataset should be repeated. The default behavior (if <code>count</code> is <code>None</code> or <code>-1</code>) is for the elements to be repeated indefinitely.</li>
</ul>
<h4 id="returns-15">Returns:</h4>
<p>A <code>Dataset</code>.</p>
<h3 id="shuffle">
<code>shuffle</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">shuffle(
    buffer_size,
    seed<span class="op">=</span><span class="va">None</span>
)</code></pre></div>
<p>Randomly shuffles the elements of this dataset.</p>
<h4 id="args-16">Args:</h4>
<ul>
<li><b><code>buffer_size</code></b>: A <code>tf.int64</code> scalar <code>tf.Tensor</code>, representing the number of elements from this dataset from which the new dataset will sample.</li>
<li><b><code>seed</code></b>: (Optional.) A <code>tf.int64</code> scalar <code>tf.Tensor</code>, representing the random seed that will be used to create the distribution. See <a href="../../../tf/set_random_seed.html"><code>tf.set_random_seed</code></a> for behavior.</li>
</ul>
<h4 id="returns-16">Returns:</h4>
<p>A <code>Dataset</code>.</p>
<h3 id="skip">
<code>skip</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">skip(count)</code></pre></div>
<p>Creates a <code>Dataset</code> that skips <code>count</code> elements from this dataset.</p>
<h4 id="args-17">Args:</h4>
<ul>
<li><b><code>count</code></b>: A <code>tf.int64</code> scalar <code>tf.Tensor</code>, representing the number of elements of this dataset that should be skipped to form the new dataset. If <code>count</code> is greater than the size of this dataset, the new dataset will contain no elements. If <code>count</code> is -1, skips the entire dataset.</li>
</ul>
<h4 id="returns-17">Returns:</h4>
<p>A <code>Dataset</code>.</p>
<h3 id="take">
<code>take</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">take(count)</code></pre></div>
<p>Creates a <code>Dataset</code> with at most <code>count</code> elements from this dataset.</p>
<h4 id="args-18">Args:</h4>
<ul>
<li><b><code>count</code></b>: A <code>tf.int64</code> scalar <code>tf.Tensor</code>, representing the number of elements of this dataset that should be taken to form the new dataset. If <code>count</code> is -1, or if <code>count</code> is greater than the size of this dataset, the new dataset will contain all elements of this dataset.</li>
</ul>
<h4 id="returns-18">Returns:</h4>
<p>A <code>Dataset</code>.</p>
<h3 id="unbatch">
<code>unbatch</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">unbatch()</code></pre></div>
<p>Splits elements of this dataset into sequences of consecutive elements.</p>
<p>For example, if elements of this dataset are shaped <code>[B, a0, a1, ...]</code>, where <code>B</code> may vary from element to element, then for each element in this dataset, the unbatched dataset will contain <code>B</code> consecutive elements of shape <code>[a0, a1, ...]</code>.</p>
<h4 id="returns-19">Returns:</h4>
<p>A <code>Dataset</code>.</p>
<h3 id="zip">
<code>zip</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="bu">zip</span>(datasets)</code></pre></div>
<p>Creates a <code>Dataset</code> by zipping together the given datasets.</p>
<p>This method has similar semantics to the built-in <code>zip()</code> function in Python, with the main difference being that the <code>datasets</code> argument can be an arbitrary nested structure of <code>Dataset</code> objects. For example:</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="co"># </span><span class="al">NOTE</span><span class="co">: The following examples use `{ ... }` to represent the</span>
<span class="co"># contents of a dataset.</span>
a <span class="op">=</span> { <span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span> }
b <span class="op">=</span> { <span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">6</span> }
c <span class="op">=</span> { (<span class="dv">7</span>, <span class="dv">8</span>), (<span class="dv">9</span>, <span class="dv">10</span>), (<span class="dv">11</span>, <span class="dv">12</span>) }
d <span class="op">=</span> { <span class="dv">13</span>, <span class="dv">14</span> }

<span class="co"># The nested structure of the `datasets` argument determines the</span>
<span class="co"># structure of elements in the resulting dataset.</span>
Dataset.<span class="bu">zip</span>((a, b)) <span class="op">==</span> { (<span class="dv">1</span>, <span class="dv">4</span>), (<span class="dv">2</span>, <span class="dv">5</span>), (<span class="dv">3</span>, <span class="dv">6</span>) }
Dataset.<span class="bu">zip</span>((b, a)) <span class="op">==</span> { (<span class="dv">4</span>, <span class="dv">1</span>), (<span class="dv">5</span>, <span class="dv">2</span>), (<span class="dv">6</span>, <span class="dv">3</span>) }

<span class="co"># The `datasets` argument may contain an arbitrary number of</span>
<span class="co"># datasets.</span>
Dataset.<span class="bu">zip</span>((a, b, c) <span class="op">==</span> { (<span class="dv">1</span>, <span class="dv">4</span>, (<span class="dv">7</span>, <span class="dv">8</span>)),
                           (<span class="dv">2</span>, <span class="dv">5</span>, (<span class="dv">9</span>, <span class="dv">10</span>)),
                           (<span class="dv">3</span>, <span class="dv">6</span>, (<span class="dv">11</span>, <span class="dv">12</span>)) }

<span class="co"># The number of elements in the resulting dataset is the same as</span>
<span class="co"># the size of the smallest dataset in `datasets`.</span>
Dataset.<span class="bu">zip</span>((a, d)) <span class="op">==</span> { (<span class="dv">1</span>, <span class="dv">13</span>), (<span class="dv">2</span>, <span class="dv">14</span>) }</code></pre></div>
<h4 id="args-19">Args:</h4>
<ul>
<li><b><code>datasets</code></b>: A nested structure of datasets.</li>
</ul>
<h4 id="returns-20">Returns:</h4>
<p>A <code>Dataset</code>.</p>

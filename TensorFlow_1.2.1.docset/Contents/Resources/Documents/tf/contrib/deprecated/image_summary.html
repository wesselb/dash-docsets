<div itemscope="" itemtype="http://developers.google.com/ReferenceObject">
<p><meta itemprop="name" content="tf.contrib.deprecated.image_summary" /></p>
</div>
<a name="//apple_ref/cpp/Function/tf.contrib.deprecated.image_summary" class="dashAnchor"></a><h1 id="tf.contrib.deprecated.image_summary">tf.contrib.deprecated.image_summary</h1>
<h3 id="tf.contrib.deprecated.image_summary-1"><code>tf.contrib.deprecated.image_summary</code></h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">image_summary(
    tag,
    tensor,
    max_images<span class="op">=</span><span class="dv">3</span>,
    collections<span class="op">=</span><span class="va">None</span>,
    name<span class="op">=</span><span class="va">None</span>
)</code></pre></div>
<p>Defined in <a href="https://www.tensorflow.org/code/tensorflow/python/ops/logging_ops.py"><code>tensorflow/python/ops/logging_ops.py</code></a>.</p>
<p>Outputs a <code>Summary</code> protocol buffer with images. (deprecated)</p>
<p>THIS FUNCTION IS DEPRECATED. It will be removed after 2016-11-30. Instructions for updating: Please switch to tf.summary.image. Note that tf.summary.image uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, the max_images argument was renamed to max_outputs.</p>
<p>For an explanation of why this op was deprecated, and information on how to migrate, look <a href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/deprecated/__init__.py">'here'</a></p>
<p>The summary has up to <code>max_images</code> summary values containing images. The images are built from <code>tensor</code> which must be 4-D with shape <code>[batch_size, height, width, channels]</code> and where <code>channels</code> can be:</p>
<ul>
<li>1: <code>tensor</code> is interpreted as Grayscale.</li>
<li>3: <code>tensor</code> is interpreted as RGB.</li>
<li>4: <code>tensor</code> is interpreted as RGBA.</li>
</ul>
<p>The images have the same number of channels as the input tensor. For float input, the values are normalized one image at a time to fit in the range <code>[0, 255]</code>. <code>uint8</code> values are unchanged. The op uses two different normalization algorithms:</p>
<ul>
<li><p>If the input values are all positive, they are rescaled so the largest one is 255.</p></li>
<li><p>If any input value is negative, the values are shifted so input value 0.0 is at 127. They are then rescaled so that either the smallest value is 0, or the largest one is 255.</p></li>
</ul>
<p>The <code>tag</code> argument is a scalar <code>Tensor</code> of type <code>string</code>. It is used to build the <code>tag</code> of the summary values:</p>
<ul>
<li>If <code>max_images</code> is 1, the summary value tag is '<em>tag</em>/image'.</li>
<li>If <code>max_images</code> is greater than 1, the summary value tags are generated sequentially as '<em>tag</em>/image/0', '<em>tag</em>/image/1', etc.</li>
</ul>
<h4 id="args">Args:</h4>
<ul>
<li><b><code>tag</code></b>: A scalar <code>Tensor</code> of type <code>string</code>. Used to build the <code>tag</code> of the summary values.</li>
<li><b><code>tensor</code></b>: A 4-D <code>uint8</code> or <code>float32</code> <code>Tensor</code> of shape <code>[batch_size, height, width, channels]</code> where <code>channels</code> is 1, 3, or 4.</li>
<li><b><code>max_images</code></b>: Max number of batch elements to generate images for.</li>
<li><b><code>collections</code></b>: Optional list of ops.GraphKeys. The collections to add the summary to. Defaults to [ops.GraphKeys.SUMMARIES]</li>
<li><b><code>name</code></b>: A name for the operation (optional).</li>
</ul>
<h4 id="returns">Returns:</h4>
<p>A scalar <code>Tensor</code> of type <code>string</code>. The serialized <code>Summary</code> protocol buffer.</p>

<div itemscope="" itemtype="http://developers.google.com/ReferenceObject">
<p><meta itemprop="name" content="tf.train" /></p>
</div>
<a name="//apple_ref/cpp/Function/tf.train" class="dashAnchor"></a><h1 id="module-tf.train">Module: tf.train</h1>
<h3 id="module-tf.train-1">Module <code>tf.train</code></h3>
<p>Defined in <a href="https://www.tensorflow.org/code/tensorflow/python/training/training.py"><code>tensorflow/python/training/training.py</code></a>.</p>
<p>Support for training models.</p>
<p>See the <a href="../../../api_guides/python/train.html">Training</a> guide.</p>
<h2 id="modules">Modules</h2>
<p><a href="../tf/train/queue_runner.html"><code>queue_runner</code></a> module: Create threads to run multiple enqueue ops.</p>
<h2 id="classes">Classes</h2>
<p><a href="../tf/train/AdadeltaOptimizer.html"><code>class AdadeltaOptimizer</code></a>: Optimizer that implements the Adadelta algorithm.</p>
<p><a href="../tf/train/AdagradDAOptimizer.html"><code>class AdagradDAOptimizer</code></a>: Adagrad Dual Averaging algorithm for sparse linear models.</p>
<p><a href="../tf/train/AdagradOptimizer.html"><code>class AdagradOptimizer</code></a>: Optimizer that implements the Adagrad algorithm.</p>
<p><a href="../tf/train/AdamOptimizer.html"><code>class AdamOptimizer</code></a>: Optimizer that implements the Adam algorithm.</p>
<p><a href="../tf/train/BytesList.html"><code>class BytesList</code></a></p>
<p><a href="../tf/train/CheckpointSaverHook.html"><code>class CheckpointSaverHook</code></a>: Saves checkpoints every N steps or seconds.</p>
<p><a href="../tf/train/CheckpointSaverListener.html"><code>class CheckpointSaverListener</code></a>: Interface for listeners that take action before or after checkpoint save.</p>
<p><a href="../tf/train/ChiefSessionCreator.html"><code>class ChiefSessionCreator</code></a>: Creates a tf.Session for a chief.</p>
<p><a href="../tf/train/ClusterDef.html"><code>class ClusterDef</code></a></p>
<p><a href="../tf/train/ClusterSpec.html"><code>class ClusterSpec</code></a>: Represents a cluster as a set of &quot;tasks&quot;, organized into &quot;jobs&quot;.</p>
<p><a href="../tf/train/Coordinator.html"><code>class Coordinator</code></a>: A coordinator for threads.</p>
<p><a href="../tf/train/Example.html"><code>class Example</code></a></p>
<p><a href="../tf/train/ExponentialMovingAverage.html"><code>class ExponentialMovingAverage</code></a>: Maintains moving averages of variables by employing an exponential decay.</p>
<p><a href="../tf/train/Feature.html"><code>class Feature</code></a></p>
<p><a href="../tf/train/FeatureList.html"><code>class FeatureList</code></a></p>
<p><a href="../tf/train/FeatureLists.html"><code>class FeatureLists</code></a></p>
<p><a href="../tf/train/Features.html"><code>class Features</code></a></p>
<p><a href="../tf/train/FeedFnHook.html"><code>class FeedFnHook</code></a>: Runs <code>feed_fn</code> and sets the <code>feed_dict</code> accordingly.</p>
<p><a href="../tf/train/FinalOpsHook.html"><code>class FinalOpsHook</code></a>: A hook which evaluates <code>Tensors</code> at the end of a session.</p>
<p><a href="../tf/train/FloatList.html"><code>class FloatList</code></a></p>
<p><a href="../tf/train/FtrlOptimizer.html"><code>class FtrlOptimizer</code></a>: Optimizer that implements the FTRL algorithm.</p>
<p><a href="../tf/train/GlobalStepWaiterHook.html"><code>class GlobalStepWaiterHook</code></a>: Delays execution until global step reaches <code>wait_until_step</code>.</p>
<p><a href="../tf/train/GradientDescentOptimizer.html"><code>class GradientDescentOptimizer</code></a>: Optimizer that implements the gradient descent algorithm.</p>
<p><a href="../tf/train/Int64List.html"><code>class Int64List</code></a></p>
<p><a href="../tf/train/JobDef.html"><code>class JobDef</code></a></p>
<p><a href="../tf/train/LoggingTensorHook.html"><code>class LoggingTensorHook</code></a>: Prints the given tensors once every N local steps or once every N seconds.</p>
<p><a href="../tf/train/LooperThread.html"><code>class LooperThread</code></a>: A thread that runs code repeatedly, optionally on a timer.</p>
<p><a href="../tf/train/MomentumOptimizer.html"><code>class MomentumOptimizer</code></a>: Optimizer that implements the Momentum algorithm.</p>
<p><a href="../tf/train/MonitoredSession.html"><code>class MonitoredSession</code></a>: Session-like object that handles initialization, recovery and hooks.</p>
<p><a href="../tf/train/NanLossDuringTrainingError.html"><code>class NanLossDuringTrainingError</code></a></p>
<p><a href="../tf/train/NanTensorHook.html"><code>class NanTensorHook</code></a>: Monitors the loss tensor and stops training if loss is NaN.</p>
<p><a href="../tf/train/Optimizer.html"><code>class Optimizer</code></a>: Base class for optimizers.</p>
<p><a href="../tf/train/ProximalAdagradOptimizer.html"><code>class ProximalAdagradOptimizer</code></a>: Optimizer that implements the Proximal Adagrad algorithm.</p>
<p><a href="../tf/train/ProximalGradientDescentOptimizer.html"><code>class ProximalGradientDescentOptimizer</code></a>: Optimizer that implements the proximal gradient descent algorithm.</p>
<p><a href="../tf/train/QueueRunner.html"><code>class QueueRunner</code></a>: Holds a list of enqueue operations for a queue, each to be run in a thread.</p>
<p><a href="../tf/train/RMSPropOptimizer.html"><code>class RMSPropOptimizer</code></a>: Optimizer that implements the RMSProp algorithm.</p>
<p><a href="../tf/train/Saver.html"><code>class Saver</code></a>: Saves and restores variables.</p>
<p><a href="../tf/train/SaverDef.html"><code>class SaverDef</code></a></p>
<p><a href="../tf/train/Scaffold.html"><code>class Scaffold</code></a>: Structure to create or gather pieces commonly needed to train a model.</p>
<p><a href="../tf/train/SecondOrStepTimer.html"><code>class SecondOrStepTimer</code></a>: Timer that triggers at most once every N seconds or once every N steps.</p>
<p><a href="../tf/train/SequenceExample.html"><code>class SequenceExample</code></a></p>
<p><a href="../tf/train/Server.html"><code>class Server</code></a>: An in-process TensorFlow server, for use in distributed training.</p>
<p><a href="../tf/train/ServerDef.html"><code>class ServerDef</code></a></p>
<p><a href="../tf/train/SessionCreator.html"><code>class SessionCreator</code></a>: A factory for tf.Session.</p>
<p><a href="../tf/train/SessionManager.html"><code>class SessionManager</code></a>: Training helper that restores from checkpoint and creates session.</p>
<p><a href="../tf/train/SessionRunArgs.html"><code>class SessionRunArgs</code></a>: Represents arguments to be added to a <code>Session.run()</code> call.</p>
<p><a href="../tf/train/SessionRunContext.html"><code>class SessionRunContext</code></a>: Provides information about the <code>session.run()</code> call being made.</p>
<p><a href="../tf/train/SessionRunHook.html"><code>class SessionRunHook</code></a>: Hook to extend calls to MonitoredSession.run().</p>
<p><a href="../tf/train/SessionRunValues.html"><code>class SessionRunValues</code></a>: Contains the results of <code>Session.run()</code>.</p>
<p><a href="../tf/train/SingularMonitoredSession.html"><code>class SingularMonitoredSession</code></a>: Session-like object that handles initialization, restoring, and hooks.</p>
<p><a href="../tf/train/StepCounterHook.html"><code>class StepCounterHook</code></a>: Hook that counts steps per second.</p>
<p><a href="../tf/train/StopAtStepHook.html"><code>class StopAtStepHook</code></a>: Hook that requests stop at a specified step.</p>
<p><a href="../tf/train/SummarySaverHook.html"><code>class SummarySaverHook</code></a>: Saves summaries every N steps.</p>
<p><a href="../tf/train/Supervisor.html"><code>class Supervisor</code></a>: A training helper that checkpoints models and computes summaries.</p>
<p><a href="../tf/train/SyncReplicasOptimizer.html"><code>class SyncReplicasOptimizer</code></a>: Class to synchronize, aggregate gradients and pass them to the optimizer.</p>
<p><a href="../tf/train/WorkerSessionCreator.html"><code>class WorkerSessionCreator</code></a>: Creates a tf.Session for a worker.</p>
<h2 id="functions">Functions</h2>
<p><a href="../tf/train/MonitoredTrainingSession.html"><code>MonitoredTrainingSession(...)</code></a>: Creates a <code>MonitoredSession</code> for training.</p>
<p><a href="../tf/train/NewCheckpointReader.html"><code>NewCheckpointReader(...)</code></a></p>
<p><a href="../tf/train/add_queue_runner.html"><code>add_queue_runner(...)</code></a>: Adds a <code>QueueRunner</code> to a collection in the graph.</p>
<p><a href="../tf/train/assert_global_step.html"><code>assert_global_step(...)</code></a>: Asserts <code>global_step_tensor</code> is a scalar int <code>Variable</code> or <code>Tensor</code>.</p>
<p><a href="../tf/train/basic_train_loop.html"><code>basic_train_loop(...)</code></a>: Basic loop to train a model.</p>
<p><a href="../tf/train/batch.html"><code>batch(...)</code></a>: Creates batches of tensors in <code>tensors</code>.</p>
<p><a href="../tf/train/batch_join.html"><code>batch_join(...)</code></a>: Runs a list of tensors to fill a queue to create batches of examples.</p>
<p><a href="../tf/train/checkpoint_exists.html"><code>checkpoint_exists(...)</code></a>: Checks whether a V1 or V2 checkpoint exists with the specified prefix.</p>
<p><a href="../tf/train/create_global_step.html"><code>create_global_step(...)</code></a>: Create global step tensor in graph.</p>
<p><a href="../tf/train/do_quantize_training_on_graphdef.html"><code>do_quantize_training_on_graphdef(...)</code></a></p>
<p><a href="../tf/train/exponential_decay.html"><code>exponential_decay(...)</code></a>: Applies exponential decay to the learning rate.</p>
<p><a href="../tf/train/export_meta_graph.html"><code>export_meta_graph(...)</code></a>: Returns <code>MetaGraphDef</code> proto. Optionally writes it to filename.</p>
<p><a href="../tf/train/generate_checkpoint_state_proto.html"><code>generate_checkpoint_state_proto(...)</code></a>: Generates a checkpoint state proto.</p>
<p><a href="../tf/train/get_checkpoint_mtimes.html"><code>get_checkpoint_mtimes(...)</code></a>: Returns the mtimes (modification timestamps) of the checkpoints.</p>
<p><a href="../tf/train/get_checkpoint_state.html"><code>get_checkpoint_state(...)</code></a>: Returns CheckpointState proto from the &quot;checkpoint&quot; file.</p>
<p><a href="../tf/train/get_global_step.html"><code>get_global_step(...)</code></a>: Get the global step tensor.</p>
<p><a href="../tf/train/get_or_create_global_step.html"><code>get_or_create_global_step(...)</code></a>: Returns and create (if necessary) the global step tensor.</p>
<p><a href="../tf/train/global_step.html"><code>global_step(...)</code></a>: Small helper to get the global step.</p>
<p><a href="../tf/train/import_meta_graph.html"><code>import_meta_graph(...)</code></a>: Recreates a Graph saved in a <code>MetaGraphDef</code> proto.</p>
<p><a href="../tf/train/input_producer.html"><code>input_producer(...)</code></a>: Output the rows of <code>input_tensor</code> to a queue for an input pipeline.</p>
<p><a href="../tf/train/inverse_time_decay.html"><code>inverse_time_decay(...)</code></a>: Applies inverse time decay to the initial learning rate.</p>
<p><a href="../tf/train/latest_checkpoint.html"><code>latest_checkpoint(...)</code></a>: Finds the filename of latest saved checkpoint file.</p>
<p><a href="../tf/train/limit_epochs.html"><code>limit_epochs(...)</code></a>: Returns tensor <code>num_epochs</code> times and then raises an <code>OutOfRange</code> error.</p>
<p><a href="../tf/train/match_filenames_once.html"><code>match_filenames_once(...)</code></a>: Save the list of files matching pattern, so it is only computed once.</p>
<p><a href="../tf/train/maybe_batch.html"><code>maybe_batch(...)</code></a>: Conditionally creates batches of tensors based on <code>keep_input</code>.</p>
<p><a href="../tf/train/maybe_batch_join.html"><code>maybe_batch_join(...)</code></a>: Runs a list of tensors to conditionally fill a queue to create batches.</p>
<p><a href="../tf/train/maybe_shuffle_batch.html"><code>maybe_shuffle_batch(...)</code></a>: Creates batches by randomly shuffling conditionally-enqueued tensors.</p>
<p><a href="../tf/train/maybe_shuffle_batch_join.html"><code>maybe_shuffle_batch_join(...)</code></a>: Create batches by randomly shuffling conditionally-enqueued tensors.</p>
<p><a href="../tf/train/natural_exp_decay.html"><code>natural_exp_decay(...)</code></a>: Applies natural exponential decay to the initial learning rate.</p>
<p><a href="../tf/train/piecewise_constant.html"><code>piecewise_constant(...)</code></a>: Piecewise constant from boundaries and interval values.</p>
<p><a href="../tf/train/polynomial_decay.html"><code>polynomial_decay(...)</code></a>: Applies a polynomial decay to the learning rate.</p>
<p><a href="../tf/train/range_input_producer.html"><code>range_input_producer(...)</code></a>: Produces the integers from 0 to limit-1 in a queue.</p>
<p><a href="../tf/train/replica_device_setter.html"><code>replica_device_setter(...)</code></a>: Return a <code>device function</code> to use when building a Graph for replicas.</p>
<p><a href="../tf/train/sdca_fprint.html"><code>sdca_fprint(...)</code></a>: Computes fingerprints of the input strings.</p>
<p><a href="../tf/train/sdca_optimizer.html"><code>sdca_optimizer(...)</code></a>: Distributed version of Stochastic Dual Coordinate Ascent (SDCA) optimizer for</p>
<p><a href="../tf/train/sdca_shrink_l1.html"><code>sdca_shrink_l1(...)</code></a>: Applies L1 regularization shrink step on the parameters.</p>
<p><a href="../tf/train/shuffle_batch.html"><code>shuffle_batch(...)</code></a>: Creates batches by randomly shuffling tensors.</p>
<p><a href="../tf/train/shuffle_batch_join.html"><code>shuffle_batch_join(...)</code></a>: Create batches by randomly shuffling tensors.</p>
<p><a href="../tf/train/slice_input_producer.html"><code>slice_input_producer(...)</code></a>: Produces a slice of each <code>Tensor</code> in <code>tensor_list</code>.</p>
<p><a href="../tf/train/start_queue_runners.html"><code>start_queue_runners(...)</code></a>: Starts all queue runners collected in the graph.</p>
<p><a href="../tf/train/string_input_producer.html"><code>string_input_producer(...)</code></a>: Output strings (e.g. filenames) to a queue for an input pipeline.</p>
<p><a href="../tf/train/summary_iterator.html"><code>summary_iterator(...)</code></a>: An iterator for reading <code>Event</code> protocol buffers from an event file.</p>
<p><a href="../tf/train/update_checkpoint_state.html"><code>update_checkpoint_state(...)</code></a>: Updates the content of the 'checkpoint' file.</p>
<p><a href="../tf/train/write_graph.html"><code>write_graph(...)</code></a>: Writes a graph proto to a file.</p>

<div itemscope="" itemtype="http://developers.google.com/ReferenceObject">
<p><meta itemprop="name" content="tf.ConditionalAccumulatorBase" /> <meta itemprop="property" content="accumulator_ref"/> <meta itemprop="property" content="dtype"/> <meta itemprop="property" content="name"/> <meta itemprop="property" content="__init__"/> <meta itemprop="property" content="num_accumulated"/> <meta itemprop="property" content="set_global_step"/></p>
</div>
<a name="//apple_ref/cpp/Class/tf.ConditionalAccumulatorBase" class="dashAnchor"></a><h1 id="tf.conditionalaccumulatorbase">tf.ConditionalAccumulatorBase</h1>
<h3 id="class-tf.conditionalaccumulatorbase"><code>class tf.ConditionalAccumulatorBase</code></h3>
<p>Defined in <a href="https://www.tensorflow.org/code/tensorflow/python/ops/data_flow_ops.py"><code>tensorflow/python/ops/data_flow_ops.py</code></a>.</p>
<p>See the guide: <a href="../../../api_guides/python/io_ops.md#Conditional_Accumulators">Inputs and Readers &gt; Conditional Accumulators</a></p>
<p>A conditional accumulator for aggregating gradients.</p>
<p>Up-to-date gradients (i.e., time step at which gradient was computed is equal to the accumulator's time step) are added to the accumulator.</p>
<p>Extraction of the average gradient is blocked until the required number of gradients has been accumulated.</p>
<h2 id="properties">Properties</h2>
<h3 id="accumulator_ref">
<code>accumulator_ref</code>
</h3>
<p>The underlying accumulator reference.</p>
<h3 id="dtype">
<code>dtype</code>
</h3>
<p>The datatype of the gradients accumulated by this accumulator.</p>
<h3 id="name">
<code>name</code>
</h3>
<p>The name of the underlying accumulator.</p>
<h2 id="methods">Methods</h2>
<h3 id="__init__">
<code><strong>init</strong></code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="fu">__init__</span>(
    dtype,
    shape,
    accumulator_ref
)</code></pre></div>
<p>Creates a new ConditionalAccumulator.</p>
<h4 id="args">Args:</h4>
<ul>
<li><b><code>dtype</code></b>: Datatype of the accumulated gradients.</li>
<li><b><code>shape</code></b>: Shape of the accumulated gradients.</li>
<li><b><code>accumulator_ref</code></b>: A handle to the conditional accumulator, created by sub- classes</li>
</ul>
<h3 id="num_accumulated">
<code>num_accumulated</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">num_accumulated(name<span class="op">=</span><span class="va">None</span>)</code></pre></div>
<p>Number of gradients that have currently been aggregated in accumulator.</p>
<h4 id="args-1">Args:</h4>
<ul>
<li><b><code>name</code></b>: Optional name for the operation.</li>
</ul>
<h4 id="returns">Returns:</h4>
<p>Number of accumulated gradients currently in accumulator.</p>
<h3 id="set_global_step">
<code>set_global_step</code>
</h3>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">set_global_step(
    new_global_step,
    name<span class="op">=</span><span class="va">None</span>
)</code></pre></div>
<p>Sets the global time step of the accumulator.</p>
<p>The operation logs a warning if we attempt to set to a time step that is lower than the accumulator's own time step.</p>
<h4 id="args-2">Args:</h4>
<ul>
<li><b><code>new_global_step</code></b>: Value of new time step. Can be a variable or a constant</li>
<li><b><code>name</code></b>: Optional name for the operation.</li>
</ul>
<h4 id="returns-1">Returns:</h4>
<p>Operation that sets the accumulator's time step.</p>
